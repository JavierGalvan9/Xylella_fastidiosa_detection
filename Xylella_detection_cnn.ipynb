{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd77124d",
   "metadata": {},
   "source": [
    "## Load librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ecb623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:43:57.693458Z",
     "start_time": "2022-08-15T16:43:36.740325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 18:09:01.707363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from collections import Counter\n",
    "\n",
    "parentDir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(os.path.join(parentDir, \"general_utils\"))\n",
    "import file_management\n",
    "from data_preprocessing import data_preprocessing\n",
    "\n",
    "seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9393971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_path = os.path.join('Classification datasets', 'Train and test sets')\n",
    "# X_train, X_test, y_train, y_test, std_scale, cluster_id_train, cluster_id_test = data_preprocessing(train_test_path, use_spectral_bands=True, use_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabe1e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>RE</th>\n",
       "      <th>N</th>\n",
       "      <th>N2</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>NPQI_4</th>\n",
       "      <th>NPQI_5</th>\n",
       "      <th>CLR</th>\n",
       "      <th>CLG</th>\n",
       "      <th>BNDVI</th>\n",
       "      <th>CTR1</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>Lats</th>\n",
       "      <th>Longs</th>\n",
       "      <th>PCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101.791316</td>\n",
       "      <td>105.028978</td>\n",
       "      <td>92.869693</td>\n",
       "      <td>80.781102</td>\n",
       "      <td>82.648763</td>\n",
       "      <td>87.892319</td>\n",
       "      <td>105.754415</td>\n",
       "      <td>68.802438</td>\n",
       "      <td>0.122639</td>\n",
       "      <td>-0.091424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027296</td>\n",
       "      <td>-0.031158</td>\n",
       "      <td>0.203227</td>\n",
       "      <td>0.138740</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.811943</td>\n",
       "      <td>0</td>\n",
       "      <td>39.618415</td>\n",
       "      <td>2.581133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>106.277035</td>\n",
       "      <td>106.998271</td>\n",
       "      <td>92.443685</td>\n",
       "      <td>82.544882</td>\n",
       "      <td>81.172892</td>\n",
       "      <td>90.712394</td>\n",
       "      <td>108.550410</td>\n",
       "      <td>71.596446</td>\n",
       "      <td>0.144302</td>\n",
       "      <td>-0.062686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>-0.006732</td>\n",
       "      <td>0.196644</td>\n",
       "      <td>0.174233</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>0.763786</td>\n",
       "      <td>0</td>\n",
       "      <td>39.618415</td>\n",
       "      <td>2.581139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>115.938584</td>\n",
       "      <td>114.219013</td>\n",
       "      <td>97.768783</td>\n",
       "      <td>93.480315</td>\n",
       "      <td>86.830397</td>\n",
       "      <td>99.329288</td>\n",
       "      <td>114.800282</td>\n",
       "      <td>77.533712</td>\n",
       "      <td>0.138718</td>\n",
       "      <td>-0.056562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>0.014878</td>\n",
       "      <td>0.155755</td>\n",
       "      <td>0.174202</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.748934</td>\n",
       "      <td>0</td>\n",
       "      <td>39.618415</td>\n",
       "      <td>2.581145</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60.384679</td>\n",
       "      <td>58.094153</td>\n",
       "      <td>51.333936</td>\n",
       "      <td>38.450394</td>\n",
       "      <td>42.554274</td>\n",
       "      <td>43.711153</td>\n",
       "      <td>63.485543</td>\n",
       "      <td>38.184771</td>\n",
       "      <td>0.197391</td>\n",
       "      <td>-0.054119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033620</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>0.452388</td>\n",
       "      <td>0.236717</td>\n",
       "      <td>0.044344</td>\n",
       "      <td>0.704720</td>\n",
       "      <td>1</td>\n",
       "      <td>39.618415</td>\n",
       "      <td>2.581203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>75.912168</td>\n",
       "      <td>70.238129</td>\n",
       "      <td>60.067095</td>\n",
       "      <td>43.741732</td>\n",
       "      <td>45.014058</td>\n",
       "      <td>53.268072</td>\n",
       "      <td>80.919397</td>\n",
       "      <td>49.011551</td>\n",
       "      <td>0.285114</td>\n",
       "      <td>0.042515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067594</td>\n",
       "      <td>0.077119</td>\n",
       "      <td>0.519098</td>\n",
       "      <td>0.347150</td>\n",
       "      <td>0.070663</td>\n",
       "      <td>0.592976</td>\n",
       "      <td>1</td>\n",
       "      <td>39.618415</td>\n",
       "      <td>2.581209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781331</th>\n",
       "      <td>104.206703</td>\n",
       "      <td>77.787087</td>\n",
       "      <td>63.475157</td>\n",
       "      <td>53.618898</td>\n",
       "      <td>38.372640</td>\n",
       "      <td>67.525115</td>\n",
       "      <td>88.320561</td>\n",
       "      <td>57.626408</td>\n",
       "      <td>0.394243</td>\n",
       "      <td>0.200562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253001</td>\n",
       "      <td>0.288749</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>0.391419</td>\n",
       "      <td>0.063414</td>\n",
       "      <td>0.368236</td>\n",
       "      <td>2530</td>\n",
       "      <td>39.614754</td>\n",
       "      <td>2.586622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781332</th>\n",
       "      <td>97.650652</td>\n",
       "      <td>74.504931</td>\n",
       "      <td>61.771126</td>\n",
       "      <td>50.267717</td>\n",
       "      <td>36.158834</td>\n",
       "      <td>68.151798</td>\n",
       "      <td>95.228315</td>\n",
       "      <td>58.906995</td>\n",
       "      <td>0.449583</td>\n",
       "      <td>0.239289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234261</td>\n",
       "      <td>0.267340</td>\n",
       "      <td>0.397297</td>\n",
       "      <td>0.541632</td>\n",
       "      <td>0.122094</td>\n",
       "      <td>0.370288</td>\n",
       "      <td>2530</td>\n",
       "      <td>39.614754</td>\n",
       "      <td>2.586628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781333</th>\n",
       "      <td>92.474823</td>\n",
       "      <td>72.207422</td>\n",
       "      <td>60.919111</td>\n",
       "      <td>48.327559</td>\n",
       "      <td>35.174920</td>\n",
       "      <td>68.621811</td>\n",
       "      <td>99.833483</td>\n",
       "      <td>59.954747</td>\n",
       "      <td>0.478923</td>\n",
       "      <td>0.260485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214396</td>\n",
       "      <td>0.244654</td>\n",
       "      <td>0.454836</td>\n",
       "      <td>0.638788</td>\n",
       "      <td>0.160578</td>\n",
       "      <td>0.380373</td>\n",
       "      <td>2530</td>\n",
       "      <td>39.614754</td>\n",
       "      <td>2.586634</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781334</th>\n",
       "      <td>89.714380</td>\n",
       "      <td>70.894560</td>\n",
       "      <td>60.493103</td>\n",
       "      <td>46.740157</td>\n",
       "      <td>33.945028</td>\n",
       "      <td>68.465140</td>\n",
       "      <td>101.807127</td>\n",
       "      <td>60.071164</td>\n",
       "      <td>0.499897</td>\n",
       "      <td>0.277890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204108</td>\n",
       "      <td>0.232906</td>\n",
       "      <td>0.486992</td>\n",
       "      <td>0.682954</td>\n",
       "      <td>0.178994</td>\n",
       "      <td>0.378368</td>\n",
       "      <td>2530</td>\n",
       "      <td>39.614754</td>\n",
       "      <td>2.586640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781335</th>\n",
       "      <td>91.094601</td>\n",
       "      <td>72.207422</td>\n",
       "      <td>61.558122</td>\n",
       "      <td>47.269291</td>\n",
       "      <td>34.682963</td>\n",
       "      <td>70.501860</td>\n",
       "      <td>105.754415</td>\n",
       "      <td>61.933836</td>\n",
       "      <td>0.506072</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201476</td>\n",
       "      <td>0.229908</td>\n",
       "      <td>0.500023</td>\n",
       "      <td>0.717960</td>\n",
       "      <td>0.188507</td>\n",
       "      <td>0.380736</td>\n",
       "      <td>2530</td>\n",
       "      <td>39.614754</td>\n",
       "      <td>2.586645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181782 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C           B          G          Y          R         RE  \\\n",
       "17      101.791316  105.028978  92.869693  80.781102  82.648763  87.892319   \n",
       "18      106.277035  106.998271  92.443685  82.544882  81.172892  90.712394   \n",
       "19      115.938584  114.219013  97.768783  93.480315  86.830397  99.329288   \n",
       "29       60.384679   58.094153  51.333936  38.450394  42.554274  43.711153   \n",
       "30       75.912168   70.238129  60.067095  43.741732  45.014058  53.268072   \n",
       "...            ...         ...        ...        ...        ...        ...   \n",
       "781331  104.206703   77.787087  63.475157  53.618898  38.372640  67.525115   \n",
       "781332   97.650652   74.504931  61.771126  50.267717  36.158834  68.151798   \n",
       "781333   92.474823   72.207422  60.919111  48.327559  35.174920  68.621811   \n",
       "781334   89.714380   70.894560  60.493103  46.740157  33.945028  68.465140   \n",
       "781335   91.094601   72.207422  61.558122  47.269291  34.682963  70.501860   \n",
       "\n",
       "                 N         N2    NDVI_1    NDVI_2  ...    NPQI_4    NPQI_5  \\\n",
       "17      105.754415  68.802438  0.122639 -0.091424  ... -0.027296 -0.031158   \n",
       "18      108.550410  71.596446  0.144302 -0.062686  ... -0.005897 -0.006732   \n",
       "19      114.800282  77.533712  0.138718 -0.056562  ...  0.013032  0.014878   \n",
       "29       63.485543  38.184771  0.197391 -0.054119  ...  0.033620  0.038342   \n",
       "30       80.919397  49.011551  0.285114  0.042515  ...  0.067594  0.077119   \n",
       "...            ...        ...       ...       ...  ...       ...       ...   \n",
       "781331   88.320561  57.626408  0.394243  0.200562  ...  0.253001  0.288749   \n",
       "781332   95.228315  58.906995  0.449583  0.239289  ...  0.234261  0.267340   \n",
       "781333   99.833483  59.954747  0.478923  0.260485  ...  0.214396  0.244654   \n",
       "781334  101.807127  60.071164  0.499897  0.277890  ...  0.204108  0.232906   \n",
       "781335  105.754415  61.933836  0.506072  0.282051  ...  0.201476  0.229908   \n",
       "\n",
       "             CLR       CLG     BNDVI      CTR1  cluster_id       Lats  \\\n",
       "17      0.203227  0.138740  0.003442  0.811943           0  39.618415   \n",
       "18      0.196644  0.174233  0.007201  0.763786           0  39.618415   \n",
       "19      0.155755  0.174202  0.002538  0.748934           0  39.618415   \n",
       "29      0.452388  0.236717  0.044344  0.704720           1  39.618415   \n",
       "30      0.519098  0.347150  0.070663  0.592976           1  39.618415   \n",
       "...          ...       ...       ...       ...         ...        ...   \n",
       "781331  0.307966  0.391419  0.063414  0.368236        2530  39.614754   \n",
       "781332  0.397297  0.541632  0.122094  0.370288        2530  39.614754   \n",
       "781333  0.454836  0.638788  0.160578  0.380373        2530  39.614754   \n",
       "781334  0.486992  0.682954  0.178994  0.378368        2530  39.614754   \n",
       "781335  0.500023  0.717960  0.188507  0.380736        2530  39.614754   \n",
       "\n",
       "           Longs  PCR  \n",
       "17      2.581133  NaN  \n",
       "18      2.581139  NaN  \n",
       "19      2.581145  NaN  \n",
       "29      2.581203  NaN  \n",
       "30      2.581209  NaN  \n",
       "...          ...  ...  \n",
       "781331  2.586622  NaN  \n",
       "781332  2.586628  NaN  \n",
       "781333  2.586634  NaN  \n",
       "781334  2.586640  NaN  \n",
       "781335  2.586645  NaN  \n",
       "\n",
       "[181782 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = file_management.load_pickle('Processed Data/QPCR_labelled_df2.lzma')\n",
    "# replace nan values in the PCR column with 0\n",
    "# df['PCR'] = df['PCR'].fillna(0)\n",
    "# remove all rows with cluster_id == 65535\n",
    "df = df.loc[df['cluster_id'] != 65535]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1901d2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>RE</th>\n",
       "      <th>N</th>\n",
       "      <th>N2</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>NPQI_4</th>\n",
       "      <th>NPQI_5</th>\n",
       "      <th>CLR</th>\n",
       "      <th>CLG</th>\n",
       "      <th>BNDVI</th>\n",
       "      <th>CTR1</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>Lats</th>\n",
       "      <th>Longs</th>\n",
       "      <th>PCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61299</th>\n",
       "      <td>122.494635</td>\n",
       "      <td>108.311133</td>\n",
       "      <td>93.082697</td>\n",
       "      <td>97.007874</td>\n",
       "      <td>78.713108</td>\n",
       "      <td>94.315822</td>\n",
       "      <td>105.754415</td>\n",
       "      <td>69.384523</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>-0.062989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107193</td>\n",
       "      <td>0.122374</td>\n",
       "      <td>0.121280</td>\n",
       "      <td>0.136134</td>\n",
       "      <td>-0.011944</td>\n",
       "      <td>0.642584</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618129</td>\n",
       "      <td>2.583230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61300</th>\n",
       "      <td>122.839690</td>\n",
       "      <td>106.341840</td>\n",
       "      <td>89.674635</td>\n",
       "      <td>95.596850</td>\n",
       "      <td>75.515388</td>\n",
       "      <td>94.159151</td>\n",
       "      <td>105.918885</td>\n",
       "      <td>71.363612</td>\n",
       "      <td>0.167573</td>\n",
       "      <td>-0.028267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125564</td>\n",
       "      <td>0.143346</td>\n",
       "      <td>0.124892</td>\n",
       "      <td>0.181147</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>0.614747</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618129</td>\n",
       "      <td>2.583236</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61301</th>\n",
       "      <td>125.255077</td>\n",
       "      <td>107.982918</td>\n",
       "      <td>89.035623</td>\n",
       "      <td>97.007874</td>\n",
       "      <td>76.253323</td>\n",
       "      <td>96.039201</td>\n",
       "      <td>107.892529</td>\n",
       "      <td>74.623288</td>\n",
       "      <td>0.171816</td>\n",
       "      <td>-0.010804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129179</td>\n",
       "      <td>0.147475</td>\n",
       "      <td>0.123422</td>\n",
       "      <td>0.211791</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>0.608784</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618129</td>\n",
       "      <td>2.583242</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>136.641902</td>\n",
       "      <td>119.142247</td>\n",
       "      <td>99.472814</td>\n",
       "      <td>108.472441</td>\n",
       "      <td>87.322354</td>\n",
       "      <td>106.692816</td>\n",
       "      <td>119.405451</td>\n",
       "      <td>83.470979</td>\n",
       "      <td>0.155195</td>\n",
       "      <td>-0.022550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119377</td>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.119152</td>\n",
       "      <td>0.200383</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.639060</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618129</td>\n",
       "      <td>2.583247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62264</th>\n",
       "      <td>79.362721</td>\n",
       "      <td>73.192069</td>\n",
       "      <td>64.327173</td>\n",
       "      <td>60.850394</td>\n",
       "      <td>53.623305</td>\n",
       "      <td>58.751550</td>\n",
       "      <td>68.584123</td>\n",
       "      <td>43.190702</td>\n",
       "      <td>0.122422</td>\n",
       "      <td>-0.107759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070439</td>\n",
       "      <td>0.080371</td>\n",
       "      <td>0.167359</td>\n",
       "      <td>0.066177</td>\n",
       "      <td>-0.032502</td>\n",
       "      <td>0.675674</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618124</td>\n",
       "      <td>2.583218</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777186</th>\n",
       "      <td>103.861648</td>\n",
       "      <td>94.197864</td>\n",
       "      <td>80.089460</td>\n",
       "      <td>62.085039</td>\n",
       "      <td>59.034831</td>\n",
       "      <td>87.735649</td>\n",
       "      <td>120.721214</td>\n",
       "      <td>78.930716</td>\n",
       "      <td>0.343167</td>\n",
       "      <td>0.144209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085064</td>\n",
       "      <td>0.097094</td>\n",
       "      <td>0.375965</td>\n",
       "      <td>0.507330</td>\n",
       "      <td>0.123411</td>\n",
       "      <td>0.568399</td>\n",
       "      <td>2550</td>\n",
       "      <td>39.614773</td>\n",
       "      <td>2.585013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777187</th>\n",
       "      <td>101.101205</td>\n",
       "      <td>93.541433</td>\n",
       "      <td>80.302464</td>\n",
       "      <td>66.318110</td>\n",
       "      <td>64.446357</td>\n",
       "      <td>84.288891</td>\n",
       "      <td>110.688525</td>\n",
       "      <td>72.411365</td>\n",
       "      <td>0.264037</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067708</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.313204</td>\n",
       "      <td>0.378395</td>\n",
       "      <td>0.083960</td>\n",
       "      <td>0.637444</td>\n",
       "      <td>2550</td>\n",
       "      <td>39.614773</td>\n",
       "      <td>2.585019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777188</th>\n",
       "      <td>102.136371</td>\n",
       "      <td>96.495373</td>\n",
       "      <td>84.136534</td>\n",
       "      <td>74.255118</td>\n",
       "      <td>72.563646</td>\n",
       "      <td>84.132220</td>\n",
       "      <td>104.932063</td>\n",
       "      <td>68.220353</td>\n",
       "      <td>0.182362</td>\n",
       "      <td>-0.030851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049512</td>\n",
       "      <td>0.056514</td>\n",
       "      <td>0.247228</td>\n",
       "      <td>0.247164</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.710458</td>\n",
       "      <td>2550</td>\n",
       "      <td>39.614773</td>\n",
       "      <td>2.585025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778153</th>\n",
       "      <td>97.650652</td>\n",
       "      <td>91.572140</td>\n",
       "      <td>78.598433</td>\n",
       "      <td>60.674016</td>\n",
       "      <td>64.446357</td>\n",
       "      <td>79.432096</td>\n",
       "      <td>100.820305</td>\n",
       "      <td>69.733774</td>\n",
       "      <td>0.220092</td>\n",
       "      <td>0.039405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055994</td>\n",
       "      <td>0.063909</td>\n",
       "      <td>0.269264</td>\n",
       "      <td>0.282727</td>\n",
       "      <td>0.048069</td>\n",
       "      <td>0.659969</td>\n",
       "      <td>2550</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778154</th>\n",
       "      <td>99.375929</td>\n",
       "      <td>95.838942</td>\n",
       "      <td>82.858511</td>\n",
       "      <td>66.847244</td>\n",
       "      <td>71.825711</td>\n",
       "      <td>79.745438</td>\n",
       "      <td>98.517721</td>\n",
       "      <td>67.638269</td>\n",
       "      <td>0.156695</td>\n",
       "      <td>-0.030025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>0.235403</td>\n",
       "      <td>0.188987</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>0.722768</td>\n",
       "      <td>2550</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38176 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C           B          G           Y          R          RE  \\\n",
       "61299   122.494635  108.311133  93.082697   97.007874  78.713108   94.315822   \n",
       "61300   122.839690  106.341840  89.674635   95.596850  75.515388   94.159151   \n",
       "61301   125.255077  107.982918  89.035623   97.007874  76.253323   96.039201   \n",
       "61302   136.641902  119.142247  99.472814  108.472441  87.322354  106.692816   \n",
       "62264    79.362721   73.192069  64.327173   60.850394  53.623305   58.751550   \n",
       "...            ...         ...        ...         ...        ...         ...   \n",
       "777186  103.861648   94.197864  80.089460   62.085039  59.034831   87.735649   \n",
       "777187  101.101205   93.541433  80.302464   66.318110  64.446357   84.288891   \n",
       "777188  102.136371   96.495373  84.136534   74.255118  72.563646   84.132220   \n",
       "778153   97.650652   91.572140  78.598433   60.674016  64.446357   79.432096   \n",
       "778154   99.375929   95.838942  82.858511   66.847244  71.825711   79.745438   \n",
       "\n",
       "                 N         N2    NDVI_1    NDVI_2  ...    NPQI_4    NPQI_5  \\\n",
       "61299   105.754415  69.384523  0.146591 -0.062989  ...  0.107193  0.122374   \n",
       "61300   105.918885  71.363612  0.167573 -0.028267  ...  0.125564  0.143346   \n",
       "61301   107.892529  74.623288  0.171816 -0.010804  ...  0.129179  0.147475   \n",
       "61302   119.405451  83.470979  0.155195 -0.022550  ...  0.119377  0.136299   \n",
       "62264    68.584123  43.190702  0.122422 -0.107759  ...  0.070439  0.080371   \n",
       "...            ...        ...       ...       ...  ...       ...       ...   \n",
       "777186  120.721214  78.930716  0.343167  0.144209  ...  0.085064  0.097094   \n",
       "777187  110.688525  72.411365  0.264037  0.058199  ...  0.067708  0.077281   \n",
       "777188  104.932063  68.220353  0.182362 -0.030851  ...  0.049512  0.056514   \n",
       "778153  100.820305  69.733774  0.220092  0.039405  ...  0.055994  0.063909   \n",
       "778154   98.517721  67.638269  0.156695 -0.030025  ...  0.031586  0.036052   \n",
       "\n",
       "             CLR       CLG     BNDVI      CTR1  cluster_id       Lats  \\\n",
       "61299   0.121280  0.136134 -0.011944  0.642584         261  39.618129   \n",
       "61300   0.124892  0.181147 -0.001993  0.614747         261  39.618129   \n",
       "61301   0.123422  0.211791 -0.000419  0.608784         261  39.618129   \n",
       "61302   0.119152  0.200383  0.001103  0.639060         261  39.618129   \n",
       "62264   0.167359  0.066177 -0.032502  0.675674         261  39.618124   \n",
       "...          ...       ...       ...       ...         ...        ...   \n",
       "777186  0.375965  0.507330  0.123411  0.568399        2550  39.614773   \n",
       "777187  0.313204  0.378395  0.083960  0.637444        2550  39.614773   \n",
       "777188  0.247228  0.247164  0.041885  0.710458        2550  39.614773   \n",
       "778153  0.269264  0.282727  0.048069  0.659969        2550  39.614768   \n",
       "778154  0.235403  0.188987  0.013783  0.722768        2550  39.614768   \n",
       "\n",
       "           Longs  PCR  \n",
       "61299   2.583230  1.0  \n",
       "61300   2.583236  1.0  \n",
       "61301   2.583242  1.0  \n",
       "61302   2.583247  1.0  \n",
       "62264   2.583218  1.0  \n",
       "...          ...  ...  \n",
       "777186  2.585013  0.0  \n",
       "777187  2.585019  0.0  \n",
       "777188  2.585025  0.0  \n",
       "778153  2.585013  0.0  \n",
       "778154  2.585019  0.0  \n",
       "\n",
       "[38176 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find unique values in the PCR column\n",
    "df.dropna(subset=['PCR'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2d36dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the maximum size of a cluster_id\n",
    "max_cluster_id = df['cluster_id'].value_counts().max()\n",
    "max_cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "055fbbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>RE</th>\n",
       "      <th>N</th>\n",
       "      <th>N2</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>NPQI_4</th>\n",
       "      <th>NPQI_5</th>\n",
       "      <th>CLR</th>\n",
       "      <th>CLG</th>\n",
       "      <th>BNDVI</th>\n",
       "      <th>CTR1</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>Lats</th>\n",
       "      <th>Longs</th>\n",
       "      <th>PCR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">261</th>\n",
       "      <th>0</th>\n",
       "      <td>116.628694</td>\n",
       "      <td>111.593289</td>\n",
       "      <td>101.389849</td>\n",
       "      <td>90.658268</td>\n",
       "      <td>79.943000</td>\n",
       "      <td>97.449238</td>\n",
       "      <td>126.313205</td>\n",
       "      <td>76.369542</td>\n",
       "      <td>0.224818</td>\n",
       "      <td>-0.022861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.296195</td>\n",
       "      <td>0.245817</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.685449</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.474823</td>\n",
       "      <td>85.007829</td>\n",
       "      <td>72.847328</td>\n",
       "      <td>54.324409</td>\n",
       "      <td>56.575046</td>\n",
       "      <td>72.068568</td>\n",
       "      <td>94.899374</td>\n",
       "      <td>63.912925</td>\n",
       "      <td>0.253009</td>\n",
       "      <td>0.060901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073316</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>0.316793</td>\n",
       "      <td>0.302716</td>\n",
       "      <td>0.054981</td>\n",
       "      <td>0.611789</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618102</td>\n",
       "      <td>2.583224</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.404491</td>\n",
       "      <td>85.992476</td>\n",
       "      <td>75.403375</td>\n",
       "      <td>57.322835</td>\n",
       "      <td>59.280809</td>\n",
       "      <td>69.718506</td>\n",
       "      <td>92.432319</td>\n",
       "      <td>60.071164</td>\n",
       "      <td>0.218514</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043585</td>\n",
       "      <td>0.049742</td>\n",
       "      <td>0.325793</td>\n",
       "      <td>0.225838</td>\n",
       "      <td>0.036093</td>\n",
       "      <td>0.655729</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618093</td>\n",
       "      <td>2.583236</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124.910022</td>\n",
       "      <td>128.660498</td>\n",
       "      <td>119.069171</td>\n",
       "      <td>96.125984</td>\n",
       "      <td>96.669535</td>\n",
       "      <td>102.776045</td>\n",
       "      <td>134.372250</td>\n",
       "      <td>82.423226</td>\n",
       "      <td>0.163186</td>\n",
       "      <td>-0.079547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025807</td>\n",
       "      <td>-0.029465</td>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.128523</td>\n",
       "      <td>0.021715</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618093</td>\n",
       "      <td>2.583253</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124.910022</td>\n",
       "      <td>128.660498</td>\n",
       "      <td>119.069171</td>\n",
       "      <td>96.125984</td>\n",
       "      <td>96.669535</td>\n",
       "      <td>102.776045</td>\n",
       "      <td>134.372250</td>\n",
       "      <td>82.423226</td>\n",
       "      <td>0.163186</td>\n",
       "      <td>-0.079547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025807</td>\n",
       "      <td>-0.029465</td>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.128523</td>\n",
       "      <td>0.021715</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>261</td>\n",
       "      <td>39.618093</td>\n",
       "      <td>2.583253</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2550</th>\n",
       "      <th>370</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266625 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         C           B           G          Y          R  \\\n",
       "cluster_id                                                                 \n",
       "261        0    116.628694  111.593289  101.389849  90.658268  79.943000   \n",
       "           1     92.474823   85.007829   72.847328  54.324409  56.575046   \n",
       "           2     90.404491   85.992476   75.403375  57.322835  59.280809   \n",
       "           3    124.910022  128.660498  119.069171  96.125984  96.669535   \n",
       "           4    124.910022  128.660498  119.069171  96.125984  96.669535   \n",
       "...                    ...         ...         ...        ...        ...   \n",
       "2550       370    0.000000    0.000000    0.000000   0.000000   0.000000   \n",
       "           371    0.000000    0.000000    0.000000   0.000000   0.000000   \n",
       "           372    0.000000    0.000000    0.000000   0.000000   0.000000   \n",
       "           373    0.000000    0.000000    0.000000   0.000000   0.000000   \n",
       "           374    0.000000    0.000000    0.000000   0.000000   0.000000   \n",
       "\n",
       "                        RE           N         N2    NDVI_1    NDVI_2  ...  \\\n",
       "cluster_id                                                             ...   \n",
       "261        0     97.449238  126.313205  76.369542  0.224818 -0.022861  ...   \n",
       "           1     72.068568   94.899374  63.912925  0.253009  0.060901  ...   \n",
       "           2     69.718506   92.432319  60.071164  0.218514  0.006622  ...   \n",
       "           3    102.776045  134.372250  82.423226  0.163186 -0.079547  ...   \n",
       "           4    102.776045  134.372250  82.423226  0.163186 -0.079547  ...   \n",
       "...                    ...         ...        ...       ...       ...  ...   \n",
       "2550       370    0.000000    0.000000   0.000000  0.000000  0.000000  ...   \n",
       "           371    0.000000    0.000000   0.000000  0.000000  0.000000  ...   \n",
       "           372    0.000000    0.000000   0.000000  0.000000  0.000000  ...   \n",
       "           373    0.000000    0.000000   0.000000  0.000000  0.000000  ...   \n",
       "           374    0.000000    0.000000   0.000000  0.000000  0.000000  ...   \n",
       "\n",
       "                  NPQI_4    NPQI_5       CLR       CLG     BNDVI      CTR1  \\\n",
       "cluster_id                                                                   \n",
       "261        0    0.038485  0.043935  0.296195  0.245817  0.061873  0.685449   \n",
       "           1    0.073316  0.083672  0.316793  0.302716  0.054981  0.611789   \n",
       "           2    0.043585  0.049742  0.325793  0.225838  0.036093  0.655729   \n",
       "           3   -0.025807 -0.029465  0.307428  0.128523  0.021715  0.773913   \n",
       "           4   -0.025807 -0.029465  0.307428  0.128523  0.021715  0.773913   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "2550       370  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "           371  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "           372  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "           373  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "           374  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                cluster_id       Lats     Longs  PCR  \n",
       "cluster_id                                            \n",
       "261        0           261  39.618106  2.583259  1.0  \n",
       "           1           261  39.618102  2.583224  1.0  \n",
       "           2           261  39.618093  2.583236  1.0  \n",
       "           3           261  39.618093  2.583253  1.0  \n",
       "           4           261  39.618093  2.583253  1.0  \n",
       "...                    ...        ...       ...  ...  \n",
       "2550       370           0   0.000000  0.000000  0.0  \n",
       "           371           0   0.000000  0.000000  0.0  \n",
       "           372           0   0.000000  0.000000  0.0  \n",
       "           373           0   0.000000  0.000000  0.0  \n",
       "           374           0   0.000000  0.000000  0.0  \n",
       "\n",
       "[266625 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad with zeros columns to make all cluster_id the same size\n",
    "df = df.groupby('cluster_id').apply(lambda x: x.reindex(range(max_cluster_id), fill_value=0))\n",
    "# df = df.groupby('cluster_id').apply(lambda x: x.sample(max_cluster_id, replace=True)).reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03122cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{63.490176790123456,\n",
       " 64.87039802469135,\n",
       " 65.5605086419753,\n",
       " 65.90556395061728,\n",
       " 66.59567456790123,\n",
       " 67.28578518518518,\n",
       " 67.63084049382715,\n",
       " 67.97589580246913,\n",
       " 68.32095111111111,\n",
       " 68.66600641975307,\n",
       " 69.01106172839505,\n",
       " 69.35611703703704,\n",
       " 69.70117234567901,\n",
       " 70.04622765432099,\n",
       " 70.39128296296295,\n",
       " 70.73633827160494,\n",
       " 71.08139358024691,\n",
       " 71.42644888888888,\n",
       " 71.77150419753086,\n",
       " 72.11655950617283,\n",
       " 72.46161481481481,\n",
       " 72.80667012345678,\n",
       " 73.15172543209876,\n",
       " 73.49678074074073,\n",
       " 73.8418360493827,\n",
       " 74.18689135802468,\n",
       " 74.53194666666667,\n",
       " 74.87700197530864,\n",
       " 75.2220572839506,\n",
       " 75.56711259259258,\n",
       " 75.91216790123457,\n",
       " 76.25722320987654,\n",
       " 76.6022785185185,\n",
       " 76.94733382716049,\n",
       " 77.29238913580247,\n",
       " 77.63744444444444,\n",
       " 77.98249975308642,\n",
       " 78.32755506172839,\n",
       " 78.67261037037036,\n",
       " 79.01766567901234,\n",
       " 79.36272098765431,\n",
       " 79.70777629629629,\n",
       " 80.05283160493826,\n",
       " 80.39788691358024,\n",
       " 80.74294222222221,\n",
       " 81.0879975308642,\n",
       " 81.43305283950616,\n",
       " 81.77810814814814,\n",
       " 82.12316345679012,\n",
       " 82.4682187654321,\n",
       " 82.81327407407407,\n",
       " 83.15832938271603,\n",
       " 83.50338469135802,\n",
       " 83.84844,\n",
       " 84.19349530864197,\n",
       " 84.53855061728395,\n",
       " 84.88360592592592,\n",
       " 85.2286612345679,\n",
       " 85.57371654320987,\n",
       " 85.91877185185184,\n",
       " 86.26382716049382,\n",
       " 86.60888246913579,\n",
       " 86.95393777777777,\n",
       " 87.29899308641976,\n",
       " 87.64404839506172,\n",
       " 87.98910370370369,\n",
       " 88.33415901234567,\n",
       " 88.67921432098765,\n",
       " 89.02426962962963,\n",
       " 89.36932493827159,\n",
       " 89.71438024691358,\n",
       " 90.05943555555555,\n",
       " 90.40449086419753,\n",
       " 90.74954617283949,\n",
       " 91.09460148148148,\n",
       " 91.43965679012345,\n",
       " 91.78471209876543,\n",
       " 92.1297674074074,\n",
       " 92.47482271604937,\n",
       " 92.81987802469135,\n",
       " 93.16493333333332,\n",
       " 93.5099886419753,\n",
       " 93.85504395061727,\n",
       " 94.20009925925925,\n",
       " 94.54515456790122,\n",
       " 94.89020987654321,\n",
       " 95.23526518518518,\n",
       " 95.58032049382714,\n",
       " 95.92537580246912,\n",
       " 96.27043111111111,\n",
       " 96.61548641975308,\n",
       " 96.96054172839506,\n",
       " 97.30559703703703,\n",
       " 97.650652345679,\n",
       " 97.99570765432098,\n",
       " 98.34076296296296,\n",
       " 98.68581827160493,\n",
       " 99.03087358024692,\n",
       " 99.37592888888886,\n",
       " 99.72098419753085,\n",
       " 100.06603950617283,\n",
       " 100.4110948148148,\n",
       " 100.75615012345678,\n",
       " 101.10120543209877,\n",
       " 101.44626074074074,\n",
       " 101.79131604938271,\n",
       " 102.13637135802469,\n",
       " 102.48142666666666,\n",
       " 102.82648197530862,\n",
       " 103.1715372839506,\n",
       " 103.51659259259259,\n",
       " 103.86164790123456,\n",
       " 104.20670320987654,\n",
       " 104.55175851851851,\n",
       " 104.89681382716049,\n",
       " 105.24186913580247,\n",
       " 105.58692444444445,\n",
       " 105.93197975308641,\n",
       " 106.27703506172838,\n",
       " 106.62209037037036,\n",
       " 106.96714567901233,\n",
       " 107.31220098765431,\n",
       " 107.6572562962963,\n",
       " 108.00231160493827,\n",
       " 108.34736691358025,\n",
       " 108.69242222222222,\n",
       " 109.03747753086418,\n",
       " 109.38253283950615,\n",
       " 109.72758814814813,\n",
       " 110.07264345679012,\n",
       " 110.41769876543209,\n",
       " 110.76275407407407,\n",
       " 111.10780938271604,\n",
       " 111.45286469135803,\n",
       " 111.79792,\n",
       " 112.14297530864195,\n",
       " 112.48803061728394,\n",
       " 112.83308592592591,\n",
       " 113.17814123456789,\n",
       " 113.52319654320986,\n",
       " 113.86825185185185,\n",
       " 114.21330716049383,\n",
       " 114.5583624691358,\n",
       " 114.90341777777778,\n",
       " 115.24847308641974,\n",
       " 115.59352839506171,\n",
       " 115.93858370370369,\n",
       " 116.28363901234567,\n",
       " 116.62869432098765,\n",
       " 116.97374962962962,\n",
       " 117.3188049382716,\n",
       " 117.66386024691357,\n",
       " 118.00891555555556,\n",
       " 118.3539708641975,\n",
       " 118.6990261728395,\n",
       " 119.04408148148147,\n",
       " 119.38913679012344,\n",
       " 119.73419209876542,\n",
       " 120.0792474074074,\n",
       " 120.42430271604938,\n",
       " 120.76935802469136,\n",
       " 121.11441333333333,\n",
       " 121.4594686419753,\n",
       " 121.80452395061727,\n",
       " 122.14957925925924,\n",
       " 122.49463456790122,\n",
       " 122.8396898765432,\n",
       " 123.18474518518518,\n",
       " 123.52980049382715,\n",
       " 123.87485580246913,\n",
       " 124.21991111111112,\n",
       " 124.56496641975309,\n",
       " 124.91002172839504,\n",
       " 125.25507703703703,\n",
       " 125.600132345679,\n",
       " 125.94518765432097,\n",
       " 126.29024296296295,\n",
       " 126.63529827160494,\n",
       " 126.98035358024691,\n",
       " 127.32540888888889,\n",
       " 127.67046419753086,\n",
       " 128.0155195061728,\n",
       " 128.3605748148148,\n",
       " 128.70563012345679,\n",
       " 129.05068543209876,\n",
       " 129.39574074074073,\n",
       " 129.7407960493827,\n",
       " 130.08585135802468,\n",
       " 130.43090666666666,\n",
       " 130.77596197530863,\n",
       " 131.1210172839506,\n",
       " 131.46607259259258,\n",
       " 131.81112790123456,\n",
       " 132.15618320987653,\n",
       " 132.5012385185185,\n",
       " 132.84629382716048,\n",
       " 133.19134913580245,\n",
       " 133.53640444444443,\n",
       " 133.88145975308643,\n",
       " 134.22651506172838,\n",
       " 134.57157037037035,\n",
       " 134.91662567901233,\n",
       " 135.2616809876543,\n",
       " 135.60673629629628,\n",
       " 135.95179160493825,\n",
       " 136.29684691358025,\n",
       " 136.64190222222223,\n",
       " 136.9869575308642,\n",
       " 137.33201283950615,\n",
       " 137.67706814814812,\n",
       " 138.0221234567901,\n",
       " 138.36717876543207,\n",
       " 138.71223407407408,\n",
       " 139.05728938271605,\n",
       " 139.40234469135802,\n",
       " 139.7474,\n",
       " 140.09245530864197,\n",
       " 140.43751061728392,\n",
       " 140.7825659259259,\n",
       " 141.1276212345679,\n",
       " 141.47267654320987,\n",
       " 141.81773185185185,\n",
       " 142.16278716049382,\n",
       " 142.5078424691358,\n",
       " 142.85289777777777,\n",
       " 143.19795308641974,\n",
       " 143.54300839506172,\n",
       " 143.8880637037037,\n",
       " 144.23311901234567,\n",
       " 144.57817432098764,\n",
       " 144.92322962962962,\n",
       " 145.2682849382716,\n",
       " 145.61334024691357,\n",
       " 145.95839555555554,\n",
       " 146.30345086419752,\n",
       " 146.64850617283952,\n",
       " 146.99356148148146,\n",
       " 147.33861679012344,\n",
       " 147.6836720987654,\n",
       " 148.0287274074074,\n",
       " 148.37378271604936,\n",
       " 148.71883802469134,\n",
       " 149.06389333333334,\n",
       " 149.40894864197531,\n",
       " 149.7540039506173,\n",
       " 150.09905925925923,\n",
       " 150.4441145679012,\n",
       " 150.78916987654318,\n",
       " 151.13422518518516,\n",
       " 151.47928049382716,\n",
       " 151.82433580246914,\n",
       " 152.1693911111111,\n",
       " 152.51444641975309,\n",
       " 152.85950172839506,\n",
       " 153.204557037037,\n",
       " 153.54961234567898,\n",
       " 153.89466765432098,\n",
       " 154.23972296296296,\n",
       " 154.58477827160493,\n",
       " 154.9298335802469,\n",
       " 155.27488888888888,\n",
       " 155.61994419753086,\n",
       " 155.96499950617283,\n",
       " 156.3100548148148,\n",
       " 156.65511012345678,\n",
       " 157.00016543209875,\n",
       " 157.34522074074073,\n",
       " 157.6902760493827,\n",
       " 158.03533135802468,\n",
       " 158.38038666666665,\n",
       " 158.72544197530863,\n",
       " 159.0704972839506,\n",
       " 159.41555259259258,\n",
       " 159.76060790123455,\n",
       " 160.10566320987652,\n",
       " 160.4507185185185,\n",
       " 160.79577382716047,\n",
       " 161.14082913580245,\n",
       " 161.48588444444442,\n",
       " 161.83093975308643,\n",
       " 162.1759950617284,\n",
       " 162.52105037037035,\n",
       " 162.86610567901232,\n",
       " 163.2111609876543,\n",
       " 163.55621629629627,\n",
       " 163.90127160493824,\n",
       " 164.24632691358025,\n",
       " 164.59138222222222,\n",
       " 164.9364375308642,\n",
       " 165.28149283950617,\n",
       " 165.62654814814815,\n",
       " 165.9716034567901,\n",
       " 166.31665876543207,\n",
       " 166.66171407407407,\n",
       " 167.00676938271604,\n",
       " 167.35182469135802,\n",
       " 167.69688,\n",
       " 168.04193530864197,\n",
       " 168.38699061728394,\n",
       " 168.73204592592592,\n",
       " 169.0771012345679,\n",
       " 169.42215654320987,\n",
       " 169.76721185185184,\n",
       " 170.11226716049381,\n",
       " 170.4573224691358,\n",
       " 170.80237777777776,\n",
       " 171.14743308641974,\n",
       " 171.4924883950617,\n",
       " 171.8375437037037,\n",
       " 172.18259901234566,\n",
       " 172.52765432098764,\n",
       " 172.8727096296296,\n",
       " 173.21776493827159,\n",
       " 173.56282024691356,\n",
       " 173.90787555555553,\n",
       " 174.2529308641975,\n",
       " 174.5979861728395,\n",
       " 174.9430414814815,\n",
       " 175.28809679012343,\n",
       " 175.6331520987654,\n",
       " 175.97820740740738,\n",
       " 176.32326271604936,\n",
       " 176.66831802469133,\n",
       " 177.01337333333333,\n",
       " 177.3584286419753,\n",
       " 177.70348395061728,\n",
       " 178.04853925925926,\n",
       " 178.3935945679012,\n",
       " 178.73864987654318,\n",
       " 179.08370518518515,\n",
       " 179.42876049382716,\n",
       " 179.77381580246913,\n",
       " 180.1188711111111,\n",
       " 180.46392641975308,\n",
       " 180.80898172839505,\n",
       " 181.15403703703703,\n",
       " 181.49909234567897,\n",
       " 181.84414765432098,\n",
       " 182.18920296296295,\n",
       " 182.53425827160493,\n",
       " 182.8793135802469,\n",
       " 183.22436888888888,\n",
       " 183.56942419753085,\n",
       " 183.91447950617282,\n",
       " 184.2595348148148,\n",
       " 184.60459012345677,\n",
       " 184.94964543209875,\n",
       " 185.29470074074072,\n",
       " 185.6397560493827,\n",
       " 185.98481135802467,\n",
       " 186.32986666666665,\n",
       " 186.67492197530862,\n",
       " 187.71008790123454,\n",
       " 188.05514320987652,\n",
       " 188.74525382716047,\n",
       " 189.43536444444442,\n",
       " 189.78041975308642,\n",
       " 190.1254750617284,\n",
       " 191.85075160493824,\n",
       " 192.54086222222222,\n",
       " 192.8859175308642,\n",
       " 193.57602814814814,\n",
       " 194.2661387654321,\n",
       " 195.64636,\n",
       " 197.71669185185186,\n",
       " 198.06174716049384,\n",
       " 199.09691308641973,\n",
       " 200.47713432098763,\n",
       " 203.9276874074074,\n",
       " 205.30790864197527,\n",
       " 210.48373827160495,\n",
       " 222.90572938271606,\n",
       " 226.0112271604938}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 50 first rows of the dataframe\n",
    "set(df['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f4681a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([375])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of samples in each cluster_id\n",
    "df['cluster_id'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9230fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees with PCR value 0:  167250\n",
      "Number of trees with PCR value 1:  99375\n"
     ]
    }
   ],
   "source": [
    "# print the number of rows with PCR value 0 and 1\n",
    "print('Number of trees with PCR value 0: ', len(df.loc[df['PCR']==0]))\n",
    "print('Number of trees with PCR value 1: ', len(df.loc[df['PCR']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8506e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>RE</th>\n",
       "      <th>N</th>\n",
       "      <th>N2</th>\n",
       "      <th>PCR</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>...</th>\n",
       "      <th>SAVI_6</th>\n",
       "      <th>NPQI_1</th>\n",
       "      <th>NPQI_2</th>\n",
       "      <th>NPQI_3</th>\n",
       "      <th>NPQI_4</th>\n",
       "      <th>NPQI_5</th>\n",
       "      <th>CLR</th>\n",
       "      <th>CLG</th>\n",
       "      <th>BNDVI</th>\n",
       "      <th>CTR1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61299</th>\n",
       "      <td>122.494635</td>\n",
       "      <td>108.311133</td>\n",
       "      <td>93.082697</td>\n",
       "      <td>97.007874</td>\n",
       "      <td>78.713108</td>\n",
       "      <td>94.315822</td>\n",
       "      <td>105.754415</td>\n",
       "      <td>69.384523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125134</td>\n",
       "      <td>0.061452</td>\n",
       "      <td>0.076732</td>\n",
       "      <td>0.091979</td>\n",
       "      <td>0.107193</td>\n",
       "      <td>0.122374</td>\n",
       "      <td>0.121280</td>\n",
       "      <td>0.136134</td>\n",
       "      <td>-0.011944</td>\n",
       "      <td>0.642584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61300</th>\n",
       "      <td>122.839690</td>\n",
       "      <td>106.341840</td>\n",
       "      <td>89.674635</td>\n",
       "      <td>95.596850</td>\n",
       "      <td>75.515388</td>\n",
       "      <td>94.159151</td>\n",
       "      <td>105.918885</td>\n",
       "      <td>71.363612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056151</td>\n",
       "      <td>0.071986</td>\n",
       "      <td>0.089884</td>\n",
       "      <td>0.107744</td>\n",
       "      <td>0.125564</td>\n",
       "      <td>0.143346</td>\n",
       "      <td>0.124892</td>\n",
       "      <td>0.181147</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>0.614747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61301</th>\n",
       "      <td>125.255077</td>\n",
       "      <td>107.982918</td>\n",
       "      <td>89.035623</td>\n",
       "      <td>97.007874</td>\n",
       "      <td>76.253323</td>\n",
       "      <td>96.039201</td>\n",
       "      <td>107.892529</td>\n",
       "      <td>74.623288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021465</td>\n",
       "      <td>0.074054</td>\n",
       "      <td>0.092468</td>\n",
       "      <td>0.110843</td>\n",
       "      <td>0.129179</td>\n",
       "      <td>0.147475</td>\n",
       "      <td>0.123422</td>\n",
       "      <td>0.211791</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>0.608784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61302</th>\n",
       "      <td>136.641902</td>\n",
       "      <td>119.142247</td>\n",
       "      <td>99.472814</td>\n",
       "      <td>108.472441</td>\n",
       "      <td>87.322354</td>\n",
       "      <td>106.692816</td>\n",
       "      <td>119.405451</td>\n",
       "      <td>83.470979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044837</td>\n",
       "      <td>0.068416</td>\n",
       "      <td>0.085436</td>\n",
       "      <td>0.102423</td>\n",
       "      <td>0.119377</td>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.119152</td>\n",
       "      <td>0.200383</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.639060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62264</th>\n",
       "      <td>79.362721</td>\n",
       "      <td>73.192069</td>\n",
       "      <td>64.327173</td>\n",
       "      <td>60.850394</td>\n",
       "      <td>53.623305</td>\n",
       "      <td>58.751550</td>\n",
       "      <td>68.584123</td>\n",
       "      <td>43.190702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213315</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>0.050478</td>\n",
       "      <td>0.060475</td>\n",
       "      <td>0.070439</td>\n",
       "      <td>0.080371</td>\n",
       "      <td>0.167359</td>\n",
       "      <td>0.066177</td>\n",
       "      <td>-0.032502</td>\n",
       "      <td>0.675674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777186</th>\n",
       "      <td>103.861648</td>\n",
       "      <td>94.197864</td>\n",
       "      <td>80.089460</td>\n",
       "      <td>62.085039</td>\n",
       "      <td>59.034831</td>\n",
       "      <td>87.735649</td>\n",
       "      <td>120.721214</td>\n",
       "      <td>78.930716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286343</td>\n",
       "      <td>0.048792</td>\n",
       "      <td>0.060914</td>\n",
       "      <td>0.073004</td>\n",
       "      <td>0.085064</td>\n",
       "      <td>0.097094</td>\n",
       "      <td>0.375965</td>\n",
       "      <td>0.507330</td>\n",
       "      <td>0.123411</td>\n",
       "      <td>0.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777187</th>\n",
       "      <td>101.101205</td>\n",
       "      <td>93.541433</td>\n",
       "      <td>80.302464</td>\n",
       "      <td>66.318110</td>\n",
       "      <td>64.446357</td>\n",
       "      <td>84.288891</td>\n",
       "      <td>110.688525</td>\n",
       "      <td>72.411365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115554</td>\n",
       "      <td>0.038839</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>0.058110</td>\n",
       "      <td>0.067708</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.313204</td>\n",
       "      <td>0.378395</td>\n",
       "      <td>0.083960</td>\n",
       "      <td>0.637444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777188</th>\n",
       "      <td>102.136371</td>\n",
       "      <td>96.495373</td>\n",
       "      <td>84.136534</td>\n",
       "      <td>74.255118</td>\n",
       "      <td>72.563646</td>\n",
       "      <td>84.132220</td>\n",
       "      <td>104.932063</td>\n",
       "      <td>68.220353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061266</td>\n",
       "      <td>0.028399</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.042492</td>\n",
       "      <td>0.049512</td>\n",
       "      <td>0.056514</td>\n",
       "      <td>0.247228</td>\n",
       "      <td>0.247164</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.710458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778153</th>\n",
       "      <td>97.650652</td>\n",
       "      <td>91.572140</td>\n",
       "      <td>78.598433</td>\n",
       "      <td>60.674016</td>\n",
       "      <td>64.446357</td>\n",
       "      <td>79.432096</td>\n",
       "      <td>100.820305</td>\n",
       "      <td>69.733774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078228</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.040101</td>\n",
       "      <td>0.048058</td>\n",
       "      <td>0.055994</td>\n",
       "      <td>0.063909</td>\n",
       "      <td>0.269264</td>\n",
       "      <td>0.282727</td>\n",
       "      <td>0.048069</td>\n",
       "      <td>0.659969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778154</th>\n",
       "      <td>99.375929</td>\n",
       "      <td>95.838942</td>\n",
       "      <td>82.858511</td>\n",
       "      <td>66.847244</td>\n",
       "      <td>71.825711</td>\n",
       "      <td>79.745438</td>\n",
       "      <td>98.517721</td>\n",
       "      <td>67.638269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059623</td>\n",
       "      <td>0.018118</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>0.235403</td>\n",
       "      <td>0.188987</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>0.722768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38176 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C           B          G           Y          R          RE  \\\n",
       "61299   122.494635  108.311133  93.082697   97.007874  78.713108   94.315822   \n",
       "61300   122.839690  106.341840  89.674635   95.596850  75.515388   94.159151   \n",
       "61301   125.255077  107.982918  89.035623   97.007874  76.253323   96.039201   \n",
       "61302   136.641902  119.142247  99.472814  108.472441  87.322354  106.692816   \n",
       "62264    79.362721   73.192069  64.327173   60.850394  53.623305   58.751550   \n",
       "...            ...         ...        ...         ...        ...         ...   \n",
       "777186  103.861648   94.197864  80.089460   62.085039  59.034831   87.735649   \n",
       "777187  101.101205   93.541433  80.302464   66.318110  64.446357   84.288891   \n",
       "777188  102.136371   96.495373  84.136534   74.255118  72.563646   84.132220   \n",
       "778153   97.650652   91.572140  78.598433   60.674016  64.446357   79.432096   \n",
       "778154   99.375929   95.838942  82.858511   66.847244  71.825711   79.745438   \n",
       "\n",
       "                 N         N2  PCR    NDVI_1  ...    SAVI_6    NPQI_1  \\\n",
       "61299   105.754415  69.384523  1.0  0.146591  ... -0.125134  0.061452   \n",
       "61300   105.918885  71.363612  1.0  0.167573  ... -0.056151  0.071986   \n",
       "61301   107.892529  74.623288  1.0  0.171816  ... -0.021465  0.074054   \n",
       "61302   119.405451  83.470979  1.0  0.155195  ... -0.044837  0.068416   \n",
       "62264    68.584123  43.190702  1.0  0.122422  ... -0.213315  0.040449   \n",
       "...            ...        ...  ...       ...  ...       ...       ...   \n",
       "777186  120.721214  78.930716  0.0  0.343167  ...  0.286343  0.048792   \n",
       "777187  110.688525  72.411365  0.0  0.264037  ...  0.115554  0.038839   \n",
       "777188  104.932063  68.220353  0.0  0.182362  ... -0.061266  0.028399   \n",
       "778153  100.820305  69.733774  0.0  0.220092  ...  0.078228  0.032124   \n",
       "778154   98.517721  67.638269  0.0  0.156695  ... -0.059623  0.018118   \n",
       "\n",
       "          NPQI_2    NPQI_3    NPQI_4    NPQI_5       CLR       CLG     BNDVI  \\\n",
       "61299   0.076732  0.091979  0.107193  0.122374  0.121280  0.136134 -0.011944   \n",
       "61300   0.089884  0.107744  0.125564  0.143346  0.124892  0.181147 -0.001993   \n",
       "61301   0.092468  0.110843  0.129179  0.147475  0.123422  0.211791 -0.000419   \n",
       "61302   0.085436  0.102423  0.119377  0.136299  0.119152  0.200383  0.001103   \n",
       "62264   0.050478  0.060475  0.070439  0.080371  0.167359  0.066177 -0.032502   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "777186  0.060914  0.073004  0.085064  0.097094  0.375965  0.507330  0.123411   \n",
       "777187  0.048487  0.058110  0.067708  0.077281  0.313204  0.378395  0.083960   \n",
       "777188  0.035454  0.042492  0.049512  0.056514  0.247228  0.247164  0.041885   \n",
       "778153  0.040101  0.048058  0.055994  0.063909  0.269264  0.282727  0.048069   \n",
       "778154  0.022619  0.027108  0.031586  0.036052  0.235403  0.188987  0.013783   \n",
       "\n",
       "            CTR1  \n",
       "61299   0.642584  \n",
       "61300   0.614747  \n",
       "61301   0.608784  \n",
       "61302   0.639060  \n",
       "62264   0.675674  \n",
       "...          ...  \n",
       "777186  0.568399  \n",
       "777187  0.637444  \n",
       "777188  0.710458  \n",
       "778153  0.659969  \n",
       "778154  0.722768  \n",
       "\n",
       "[38176 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral_bands = ['C', 'B', 'G', 'Y', 'R', 'RE', 'N', 'N2', 'PCR']\n",
    "df = df.loc[:, spectral_bands + list(df.columns[8:-4])]\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efec0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For each column make an histogram differencing the two classes of PCR pause after every iteration\n",
    "# for col in df.columns:\n",
    "#     plt.hist(df.loc[df['PCR'] == 0, col], bins=20, alpha=0.5, label='No PCR', density=True)\n",
    "#     plt.hist(df.loc[df['PCR'] == 1, col], bins=20, alpha=0.5, label='PCR', density=True)\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.title(col)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86ee8e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>RE</th>\n",
       "      <th>N</th>\n",
       "      <th>N2</th>\n",
       "      <th>PCR</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>...</th>\n",
       "      <th>SAVI_6</th>\n",
       "      <th>NPQI_1</th>\n",
       "      <th>NPQI_2</th>\n",
       "      <th>NPQI_3</th>\n",
       "      <th>NPQI_4</th>\n",
       "      <th>NPQI_5</th>\n",
       "      <th>CLR</th>\n",
       "      <th>CLG</th>\n",
       "      <th>BNDVI</th>\n",
       "      <th>CTR1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69085</th>\n",
       "      <td>103.861648</td>\n",
       "      <td>98.464667</td>\n",
       "      <td>83.497522</td>\n",
       "      <td>69.492913</td>\n",
       "      <td>62.970486</td>\n",
       "      <td>82.408841</td>\n",
       "      <td>103.287360</td>\n",
       "      <td>64.727844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.242496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027310</td>\n",
       "      <td>0.026675</td>\n",
       "      <td>0.033302</td>\n",
       "      <td>0.039913</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.253353</td>\n",
       "      <td>0.237011</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>0.606292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77736</th>\n",
       "      <td>89.714380</td>\n",
       "      <td>78.115302</td>\n",
       "      <td>69.013258</td>\n",
       "      <td>58.028346</td>\n",
       "      <td>51.409498</td>\n",
       "      <td>65.018382</td>\n",
       "      <td>83.221981</td>\n",
       "      <td>52.154809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.236293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.069112</td>\n",
       "      <td>0.086262</td>\n",
       "      <td>0.103360</td>\n",
       "      <td>0.120408</td>\n",
       "      <td>0.137406</td>\n",
       "      <td>0.279976</td>\n",
       "      <td>0.205884</td>\n",
       "      <td>0.031652</td>\n",
       "      <td>0.573035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85434</th>\n",
       "      <td>132.846294</td>\n",
       "      <td>130.629791</td>\n",
       "      <td>117.578144</td>\n",
       "      <td>89.600000</td>\n",
       "      <td>93.471815</td>\n",
       "      <td>111.549610</td>\n",
       "      <td>145.062821</td>\n",
       "      <td>93.017171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004850</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.300433</td>\n",
       "      <td>0.233757</td>\n",
       "      <td>0.052352</td>\n",
       "      <td>0.703609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87470</th>\n",
       "      <td>81.778108</td>\n",
       "      <td>86.977122</td>\n",
       "      <td>85.201553</td>\n",
       "      <td>54.500787</td>\n",
       "      <td>71.087775</td>\n",
       "      <td>69.248494</td>\n",
       "      <td>104.109712</td>\n",
       "      <td>62.399504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129206</td>\n",
       "      <td>-0.030808</td>\n",
       "      <td>-0.038453</td>\n",
       "      <td>-0.046076</td>\n",
       "      <td>-0.053675</td>\n",
       "      <td>-0.061253</td>\n",
       "      <td>0.503422</td>\n",
       "      <td>0.221923</td>\n",
       "      <td>0.089659</td>\n",
       "      <td>0.869276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91325</th>\n",
       "      <td>86.608882</td>\n",
       "      <td>75.817793</td>\n",
       "      <td>64.327173</td>\n",
       "      <td>65.965354</td>\n",
       "      <td>51.409498</td>\n",
       "      <td>73.008593</td>\n",
       "      <td>86.675858</td>\n",
       "      <td>56.695072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.255395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096890</td>\n",
       "      <td>0.066437</td>\n",
       "      <td>0.082918</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>0.115730</td>\n",
       "      <td>0.132060</td>\n",
       "      <td>0.187201</td>\n",
       "      <td>0.347422</td>\n",
       "      <td>0.066821</td>\n",
       "      <td>0.593582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724430</th>\n",
       "      <td>85.573717</td>\n",
       "      <td>79.756380</td>\n",
       "      <td>70.078278</td>\n",
       "      <td>52.913386</td>\n",
       "      <td>58.542874</td>\n",
       "      <td>67.211774</td>\n",
       "      <td>89.965264</td>\n",
       "      <td>56.112987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042019</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>0.043916</td>\n",
       "      <td>0.052620</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.069949</td>\n",
       "      <td>0.338534</td>\n",
       "      <td>0.283782</td>\n",
       "      <td>0.060151</td>\n",
       "      <td>0.684122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727846</th>\n",
       "      <td>106.967146</td>\n",
       "      <td>90.587493</td>\n",
       "      <td>80.089460</td>\n",
       "      <td>80.781102</td>\n",
       "      <td>60.264723</td>\n",
       "      <td>88.519003</td>\n",
       "      <td>106.905707</td>\n",
       "      <td>71.014361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162530</td>\n",
       "      <td>0.082912</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.124054</td>\n",
       "      <td>0.144547</td>\n",
       "      <td>0.164989</td>\n",
       "      <td>0.207715</td>\n",
       "      <td>0.334829</td>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.563395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727864</th>\n",
       "      <td>76.947334</td>\n",
       "      <td>66.299542</td>\n",
       "      <td>56.446029</td>\n",
       "      <td>59.615748</td>\n",
       "      <td>46.243951</td>\n",
       "      <td>62.198308</td>\n",
       "      <td>71.544589</td>\n",
       "      <td>44.587705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036071</td>\n",
       "      <td>0.074332</td>\n",
       "      <td>0.092753</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0.147633</td>\n",
       "      <td>0.150266</td>\n",
       "      <td>0.267487</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>0.600982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730786</th>\n",
       "      <td>87.644048</td>\n",
       "      <td>85.007829</td>\n",
       "      <td>77.746417</td>\n",
       "      <td>61.555906</td>\n",
       "      <td>69.857883</td>\n",
       "      <td>73.791947</td>\n",
       "      <td>102.629479</td>\n",
       "      <td>63.563674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093649</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.022837</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>0.390795</td>\n",
       "      <td>0.320054</td>\n",
       "      <td>0.093913</td>\n",
       "      <td>0.797064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740413</th>\n",
       "      <td>112.833086</td>\n",
       "      <td>109.295780</td>\n",
       "      <td>98.620798</td>\n",
       "      <td>79.722835</td>\n",
       "      <td>80.680935</td>\n",
       "      <td>104.029412</td>\n",
       "      <td>143.747059</td>\n",
       "      <td>91.154500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.281008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121197</td>\n",
       "      <td>0.015925</td>\n",
       "      <td>0.019883</td>\n",
       "      <td>0.023833</td>\n",
       "      <td>0.027774</td>\n",
       "      <td>0.031706</td>\n",
       "      <td>0.381792</td>\n",
       "      <td>0.457573</td>\n",
       "      <td>0.136148</td>\n",
       "      <td>0.715047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1148 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C           B           G          Y          R          RE  \\\n",
       "69085   103.861648   98.464667   83.497522  69.492913  62.970486   82.408841   \n",
       "77736    89.714380   78.115302   69.013258  58.028346  51.409498   65.018382   \n",
       "85434   132.846294  130.629791  117.578144  89.600000  93.471815  111.549610   \n",
       "87470    81.778108   86.977122   85.201553  54.500787  71.087775   69.248494   \n",
       "91325    86.608882   75.817793   64.327173  65.965354  51.409498   73.008593   \n",
       "...            ...         ...         ...        ...        ...         ...   \n",
       "724430   85.573717   79.756380   70.078278  52.913386  58.542874   67.211774   \n",
       "727846  106.967146   90.587493   80.089460  80.781102  60.264723   88.519003   \n",
       "727864   76.947334   66.299542   56.446029  59.615748  46.243951   62.198308   \n",
       "730786   87.644048   85.007829   77.746417  61.555906  69.857883   73.791947   \n",
       "740413  112.833086  109.295780   98.620798  79.722835  80.680935  104.029412   \n",
       "\n",
       "                 N         N2  PCR    NDVI_1  ...    SAVI_6    NPQI_1  \\\n",
       "69085   103.287360  64.727844  1.0  0.242496  ...  0.027310  0.026675   \n",
       "77736    83.221981  52.154809  1.0  0.236293  ...  0.014256  0.069112   \n",
       "85434   145.062821  93.017171  0.0  0.216283  ... -0.004850  0.008413   \n",
       "87470   104.109712  62.399504  0.0  0.188484  ... -0.129206 -0.030808   \n",
       "91325    86.675858  56.695072  1.0  0.255395  ...  0.096890  0.066437   \n",
       "...            ...        ...  ...       ...  ...       ...       ...   \n",
       "724430   89.965264  56.112987  0.0  0.211587  ... -0.042019  0.035186   \n",
       "727846  106.905707  71.014361  0.0  0.279003  ...  0.162530  0.082912   \n",
       "727864   71.544589  44.587705  1.0  0.214797  ... -0.036071  0.074332   \n",
       "730786  102.629479  63.563674  0.0  0.189994  ... -0.093649  0.015269   \n",
       "740413  143.747059  91.154500  1.0  0.281008  ...  0.121197  0.015925   \n",
       "\n",
       "          NPQI_2    NPQI_3    NPQI_4    NPQI_5       CLR       CLG     BNDVI  \\\n",
       "69085   0.033302  0.039913  0.046508  0.053087  0.253353  0.237011  0.023904   \n",
       "77736   0.086262  0.103360  0.120408  0.137406  0.279976  0.205884  0.031652   \n",
       "85434   0.010506  0.012595  0.014680  0.016761  0.300433  0.233757  0.052352   \n",
       "87470  -0.038453 -0.046076 -0.053675 -0.061253  0.503422  0.221923  0.089659   \n",
       "91325   0.082918  0.099349  0.115730  0.132060  0.187201  0.347422  0.066821   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "724430  0.043916  0.052620  0.061298  0.069949  0.338534  0.283782  0.060151   \n",
       "727846  0.103509  0.124054  0.144547  0.164989  0.207715  0.334829  0.082627   \n",
       "727864  0.092753  0.111110  0.129403  0.147633  0.150266  0.267487  0.038051   \n",
       "730786  0.019059  0.022837  0.026605  0.030362  0.390795  0.320054  0.093913   \n",
       "740413  0.019883  0.023833  0.027774  0.031706  0.381792  0.457573  0.136148   \n",
       "\n",
       "            CTR1  \n",
       "69085   0.606292  \n",
       "77736   0.573035  \n",
       "85434   0.703609  \n",
       "87470   0.869276  \n",
       "91325   0.593582  \n",
       "...          ...  \n",
       "724430  0.684122  \n",
       "727846  0.563395  \n",
       "727864  0.600982  \n",
       "730786  0.797064  \n",
       "740413  0.715047  \n",
       "\n",
       "[1148 rows x 36 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9429f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a PCA of all the features except the PCR label and the ratio_red_NDVI2\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "mask = np.logical_and(df.columns != 'PCR', df.columns != 'ratio_red_NDVI2')\n",
    "pca.fit(df.loc[:, mask])\n",
    "\n",
    "# make 2 subplots with histograms 2d with pca transformation with matplotlib\n",
    "# first subplot is the histogram of PCR value 0\n",
    "# second subplot is the histogram of PCR value 1\n",
    "# third subplot is the scatter plot of the PCA\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "\n",
    "# plot the scatter plot of the PCA with labels and legend\n",
    "a1 = ax1.scatter(pca.transform(df.loc[df['PCR'] == 0, mask])[:, 0], pca.transform(df.loc[df['PCR'] == 0, mask])[:, 1], alpha=0.5, label='Negative')\n",
    "a2 = ax1.scatter(pca.transform(df.loc[df['PCR'] == 1, mask])[:, 0], pca.transform(df.loc[df['PCR'] == 1, mask])[:, 1], alpha=0.5, label='Positive')\n",
    "# include legend with the different classes\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_title('PCA 2D')\n",
    "ax1.set_xlabel('PCA 1')\n",
    "ax1.set_ylabel('PCA 2')\n",
    "# plot the histograms of the different classes\n",
    "a2 = ax2.hist2d(pca.transform(df.loc[df['PCR'] == 0, mask])[:, 0], pca.transform(df.loc[df['PCR'] == 0, mask])[:, 1], bins=20, alpha=1, label='No PCR', density=True)\n",
    "ax2.set_title('Negative QPCR')\n",
    "ax2.set_xlabel('PCA 1')\n",
    "# cbar = plt.colorbar(a1[3], ax=ax1)\n",
    "# \n",
    "\n",
    "a3 = ax3.hist2d(pca.transform(df.loc[df['PCR'] == 1, mask])[:, 0], pca.transform(df.loc[df['PCR'] == 1, mask])[:, 1], bins=20, alpha=1, label='PCR', density=True)\n",
    "ax3.set_title('Positive QPCR')\n",
    "ax3.set_xlabel('PCA 1')\n",
    "# cbar = plt.colorbar(a2[3], ax=ax2)\n",
    "# Include shared colorbar between ax1 and ax2. Use scientific notation\n",
    "fig.colorbar(a3[3], ax=[ax2, ax3], format='%.0e')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6811746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from scipy.stats import kstwobign, pearsonr\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "__all__ = ['ks2d2s', 'estat', 'estat2d']\n",
    "\n",
    "\n",
    "def ks2d2s(x1, y1, x2, y2, nboot=None, extra=False):\n",
    "    '''Two-dimensional Kolmogorov-Smirnov test on two samples. \n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, y1 : ndarray, shape (n1, )\n",
    "        Data of sample 1.\n",
    "    x2, y2 : ndarray, shape (n2, )\n",
    "        Data of sample 2. Size of two samples can be different.\n",
    "    nboot : None or int\n",
    "        Number of bootstrap resample to estimate the p-value. A large number is expected.\n",
    "        If None, an approximate analytic estimate will be used.\n",
    "    extra: bool, optional\n",
    "        If True, KS statistic is also returned. Default is False.\n",
    "    Returns\n",
    "    -------\n",
    "    p : float\n",
    "        Two-tailed p-value.\n",
    "    D : float, optional\n",
    "        KS statistic, returned if keyword `extra` is True.\n",
    "    Notes\n",
    "    -----\n",
    "    This is the two-sided K-S test. Small p-values means that the two samples are significantly different. \n",
    "    Note that the p-value is only an approximation as the analytic distribution is unkonwn. The approximation\n",
    "    is accurate enough when N > ~20 and p-value < ~0.20 or so. When p-value > 0.20, the value may not be accurate,\n",
    "    but it certainly implies that the two samples are not significantly different. (cf. Press 2007)\n",
    "    References\n",
    "    ----------\n",
    "    Peacock, J.A. 1983, Two-Dimensional Goodness-of-Fit Testing in Astronomy, MNRAS, 202, 615-627\n",
    "    Fasano, G. and Franceschini, A. 1987, A Multidimensional Version of the Kolmogorov-Smirnov Test, MNRAS, 225, 155-170\n",
    "    Press, W.H. et al. 2007, Numerical Recipes, section 14.8\n",
    "    '''\n",
    "    assert (len(x1) == len(y1)) and (len(x2) == len(y2))\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    D = avgmaxdist(x1, y1, x2, y2)\n",
    "\n",
    "    if nboot is None:\n",
    "        sqen = np.sqrt(n1 * n2 / (n1 + n2))\n",
    "        r1 = pearsonr(x1, y1)[0]\n",
    "        r2 = pearsonr(x2, y2)[0]\n",
    "        r = np.sqrt(1 - 0.5 * (r1**2 + r2**2))\n",
    "        d = D * sqen / (1 + r * (0.25 - 0.75 / sqen))\n",
    "        p = kstwobign.sf(d)\n",
    "    else:\n",
    "        n = n1 + n2\n",
    "        x = np.concatenate([x1, x2])\n",
    "        y = np.concatenate([y1, y2])\n",
    "        d = np.empty(nboot, 'f')\n",
    "        for i in range(nboot):\n",
    "            idx = random.choice(n, n, replace=True)\n",
    "            ix1, ix2 = idx[:n1], idx[n1:]\n",
    "            #ix1 = random.choice(n, n1, replace=True)\n",
    "            #ix2 = random.choice(n, n2, replace=True)\n",
    "            d[i] = avgmaxdist(x[ix1], y[ix1], x[ix2], y[ix2])\n",
    "        p = np.sum(d > D).astype('f') / nboot\n",
    "    if extra:\n",
    "        return p, D\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "\n",
    "def avgmaxdist(x1, y1, x2, y2):\n",
    "    D1 = maxdist(x1, y1, x2, y2)\n",
    "    D2 = maxdist(x2, y2, x1, y1)\n",
    "    return (D1 + D2) / 2\n",
    "\n",
    "\n",
    "def maxdist(x1, y1, x2, y2):\n",
    "    n1 = len(x1)\n",
    "    D1 = np.empty((n1, 4))\n",
    "    for i in range(n1):\n",
    "        a1, b1, c1, d1 = quadct(x1[i], y1[i], x1, y1)\n",
    "        a2, b2, c2, d2 = quadct(x1[i], y1[i], x2, y2)\n",
    "        D1[i] = [a1 - a2, b1 - b2, c1 - c2, d1 - d2]\n",
    "\n",
    "    # re-assign the point to maximize difference,\n",
    "    # the discrepancy is significant for N < ~50\n",
    "    D1[:, 0] -= 1 / n1\n",
    "\n",
    "    dmin, dmax = -D1.min(), D1.max() + 1 / n1\n",
    "    return max(dmin, dmax)\n",
    "\n",
    "\n",
    "def quadct(x, y, xx, yy):\n",
    "    n = len(xx)\n",
    "    ix1, ix2 = xx <= x, yy <= y\n",
    "    a = np.sum(ix1 & ix2) / n\n",
    "    b = np.sum(ix1 & ~ix2) / n\n",
    "    c = np.sum(~ix1 & ix2) / n\n",
    "    d = 1 - a - b - c\n",
    "    return a, b, c, d\n",
    "\n",
    "\n",
    "def estat2d(x1, y1, x2, y2, **kwds):\n",
    "    return estat(np.c_[x1, y1], np.c_[x2, y2], **kwds)\n",
    "\n",
    "\n",
    "def estat(x, y, nboot=1000, replace=False, method='log', fitting=False):\n",
    "    '''\n",
    "    Energy distance statistics test.\n",
    "    Reference\n",
    "    ---------\n",
    "    Aslan, B, Zech, G (2005) Statistical energy as a tool for binning-free\n",
    "      multivariate goodness-of-fit tests, two-sample comparison and unfolding.\n",
    "      Nuc Instr and Meth in Phys Res A 537: 626-636\n",
    "    Szekely, G, Rizzo, M (2014) Energy statistics: A class of statistics\n",
    "      based on distances. J Stat Planning & Infer 143: 1249-1272\n",
    "    Brian Lau, multdist, https://github.com/brian-lau/multdist\n",
    "    '''\n",
    "    n, N = len(x), len(x) + len(y)\n",
    "    stack = np.vstack([x, y])\n",
    "    stack = (stack - stack.mean(0)) / stack.std(0)\n",
    "    if replace:\n",
    "        rand = lambda x: random.randint(x, size=x)\n",
    "    else:\n",
    "        rand = random.permutation\n",
    "\n",
    "    en = energy(stack[:n], stack[n:], method)\n",
    "    en_boot = np.zeros(nboot, 'f')\n",
    "    for i in range(nboot):\n",
    "        idx = rand(N)\n",
    "        en_boot[i] = energy(stack[idx[:n]], stack[idx[n:]], method)\n",
    "\n",
    "    if fitting:\n",
    "        param = genextreme.fit(en_boot)\n",
    "        p = genextreme.sf(en, *param)\n",
    "        return p, en, param\n",
    "    else:\n",
    "        p = (en_boot >= en).sum() / nboot\n",
    "        return p, en, en_boot\n",
    "\n",
    "\n",
    "def energy(x, y, method='log'):\n",
    "    dx, dy, dxy = pdist(x), pdist(y), cdist(x, y)\n",
    "    n, m = len(x), len(y)\n",
    "    if method == 'log':\n",
    "        dx, dy, dxy = np.log(dx), np.log(dy), np.log(dxy)\n",
    "    elif method == 'gaussian':\n",
    "        raise NotImplementedError\n",
    "    elif method == 'linear':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError\n",
    "    z = dxy.sum() / (n * m) - dx.sum() / n**2 - dy.sum() / m**2\n",
    "    # z = ((n*m)/(n+m)) * z # ref. SR\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a3baad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=1.13e-20, D=0.362\n"
     ]
    }
   ],
   "source": [
    "# 2D KS\n",
    "# Reshape the output of the pca.transform method\n",
    "x1 = pca.transform(df.loc[df['PCR'] == 0, mask])[:,0]\n",
    "y1 = pca.transform(df.loc[df['PCR'] == 0, mask])[:,1]\n",
    "x2 = pca.transform(df.loc[df['PCR'] == 1, mask])[:,0]\n",
    "y2 = pca.transform(df.loc[df['PCR'] == 1, mask])[:,1]\n",
    "\n",
    "P, D = ks2d2s(x1, y1, x2, y2, extra=True)\n",
    "print(f\"{P=:.3g}, {D=:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2adf04d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D-KS test statistic:  0.27561015831134567\n",
      "p-value:  2.3836003396692107e-09\n",
      "The two distributions are statistically different.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Reshape the output of the pca.transform method\n",
    "x1 = pca.transform(df.loc[df['PCR'] == 0, mask])[:160, 1]\n",
    "x2 = pca.transform(df.loc[df['PCR'] == 1, mask])[:, 1]\n",
    "\n",
    "# Calculate the 2D-KS test statistic and p-value\n",
    "D, p_value = ks_2samp(x1, x2)\n",
    "\n",
    "# Print the test statistic and p-value\n",
    "print(\"2D-KS test statistic: \", D)\n",
    "print(\"p-value: \", p_value)\n",
    "\n",
    "# Determine if the two distributions are statistically different\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The two distributions are statistically different.\")\n",
    "else:\n",
    "    print(\"The two distributions are not statistically different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32899cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5519905709795705\n",
      "Confusion matrix:  [[2182 2427]\n",
      " [ 994 2033]]\n",
      "f1_score 0.5430746627487645\n",
      "precision_score 0.45582959641255605\n",
      "recall_score 0.671622068054179\n",
      "auc_score 0.5725218172772522\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHFCAYAAAAe+pb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJaUlEQVR4nOzdeVhU5f//8ecMOwgYKCiogIK7iIrgvqe5VJaVhvtSorlnuVSmZh9Ly8x9R0UtTSutTDN3E1MRd00UFFRQQNnXmTm/P/w6vwgs0IFheT+ui+tyDmd5z5xh5uV97vs+KkVRFIQQQgghyiG1sQsQQgghhDAWCUJCCCGEKLckCAkhhBCi3JIgJIQQQohyS4KQEEIIIcotCUJCCCGEKLckCAkhhBCi3JIgJIQQQohyS4KQEEIIIcotCUIij/Xr16NSqfQ/pqamVK1alX79+hEeHm7s8gBwd3dnyJAhxi6jTFm2bBnr16/Ps/zmzZuoVKp8f1cSPK7viy++MHYphZaens7MmTM5dOhQkez/0KFDqFSqQu+/tL4XSiKVSsXMmTONXYb4F6bGLkCUXEFBQdStW5fMzEz++OMPPv30Uw4ePMjVq1d57rnnjFrbDz/8gJ2dnVFrKGuWLVtGpUqV8gTMqlWrEhISQq1atYxTWBmWnp7OrFmzAOjQoYPB99+0aVNCQkKoX79+obaT94IoTyQIiSdq2LAhvr6+wKMPaa1Wy8cff8yPP/7I0KFDjVpbkyZNiv2YWq0WjUaDhYVFsR+7sBRFITMzEysrq2fel4WFBS1atDBAVaVbRkYGlpaWqFQqY5fyn3JyclCpVNjZ2Rn03Ml7QZRFcmlMFNjjUHTv3r1cy0+fPs1LL72Eg4MDlpaWNGnShG3btuXZ/s6dO7z99ttUr14dc3NzXFxceO2113LtLzk5mcmTJ+Ph4YG5uTmurq5MmDCBtLS0XPv6+6WxuLg4zM3N+eijj/Ic8+rVq6hUKhYtWqRfFhsby8iRI6lWrRrm5uZ4eHgwa9YsNBqNfp3HlwDmzZvHnDlz8PDwwMLCgoMHDz7x9cnMzGTatGm5an/nnXdITEzMU3uvXr344Ycf8Pb2xtLSkpo1a+aqsbCvh0qlYsyYMaxYsYJ69ephYWHBhg0bAJg1axb+/v44ODhgZ2dH06ZNWbt2LX+/37K7uzuXLl3i8OHD+kui7u7uuV6Lv18OmTlzJiqVikuXLvHmm29ib2+Ps7Mzw4YNIykpKVdtiYmJDB8+HAcHBypUqEDPnj2JiIgo8CWDxMRE3n33XWrWrImFhQVOTk706NGDq1ev5ll3wYIFeHh4UKFCBVq2bMmJEydy/f706dP069cPd3d3rKyscHd358033+TWrVu51nt8efi3335j2LBhVK5cGWtra7Kysrh+/TpDhw7Fy8sLa2trXF1defHFF7lw4UKhar958yaVK1fWn6PHr/vfW2HCw8MJCAjAyckJCwsL6tWrx9KlS3Md4/Hlr+DgYN59911cXV2xsLDg+vXr+V4ai4iIoF+/fri4uGBhYYGzszOdO3fm7NmzQOHfC/Do7+zNN9/E2dkZCwsLatSowaBBg8jKyvq3U0t2djZz5syhbt26WFhYULlyZYYOHUpcXJx+nc8++wy1Ws1PP/2Ua9shQ4ZgbW2tf90zMzN599138fHxwd7eHgcHB1q2bMnOnTvzHPfx30tQUBB16tTBysoKX19fTpw4gaIozJ8/X/8+6tSpE9evX8+1fYcOHWjYsCFHjx6lRYsWWFlZ4erqykcffYRWq/3X5wwF+wwSxUdahESBRUZGAlC7dm39soMHD/LCCy/g7+/PihUrsLe359tvv6Vv376kp6frP9Tv3LlD8+bNycnJYfr06Xh7e5OQkMDevXt5+PAhzs7OpKen0759e27fvq1f59KlS8yYMYMLFy7w+++/5/u/8cqVK9OrVy82bNjArFmzUKv/f74PCgrC3Nyc/v37A48+gPz8/FCr1cyYMYNatWoREhLCnDlzuHnzJkFBQbn2vWjRImrXrs0XX3yBnZ0dXl5e+b42iqLQu3dv9u/fz7Rp02jbti3nz5/n448/JiQkhJCQkFwtSWfPnmXChAnMnDmTKlWqsHnzZsaPH092djaTJ08GKPTr8eOPP3L06FFmzJhBlSpVcHJyAh59eY0cOZIaNWoAcOLECcaOHcudO3eYMWMG8OhS42uvvYa9vT3Lli0DKFDLV58+fejbty/Dhw/nwoULTJs2DYB169YBoNPpePHFFzl9+jQzZ87UX6p54YUX/nPfACkpKbRp04abN28yZcoU/P39SU1N5ciRI8TExFC3bl39ukuXLqVu3bosXLgQgI8++ogePXoQGRmJvb29/rWoU6cO/fr1w8HBgZiYGJYvX07z5s25fPkylSpVynX8YcOG0bNnT4KDg0lLS8PMzIy7d+/i6OjIZ599RuXKlXnw4AEbNmzA39+fsLAw6tSpU6DaW7VqxZ49e3jhhRcYPnw4I0aMANCHo8uXL9OqVStq1KjBl19+SZUqVdi7dy/jxo0jPj6ejz/+OFet06ZNo2XLlqxYsQK1Wo2TkxOxsbF5XtMePXqg1WqZN28eNWrUID4+nuPHj+sDe2HfC+fOnaNNmzZUqlSJ2bNn4+XlRUxMDLt27SI7O/uJ2+p0Ol5++WWOHj3K+++/T6tWrbh16xYff/wxHTp04PTp01hZWTFlyhSOHj3K4MGDCQsLw83NjaCgIDZs2MCaNWto1KgRAFlZWTx48IDJkyfj6upKdnY2v//+O6+++ipBQUEMGjQo1/F//vlnwsLC+Oyzz1CpVEyZMoWePXsyePBgIiIiWLJkCUlJSUyaNIk+ffpw9uzZXH9vsbGx9OvXj6lTpzJ79mx++eUX5syZw8OHD1myZMkTX6/CfgaJYqAI8Q9BQUEKoJw4cULJyclRUlJSlD179ihVqlRR2rVrp+Tk5OjXrVu3rtKkSZNcyxRFUXr16qVUrVpV0Wq1iqIoyrBhwxQzMzPl8uXLTzzu3LlzFbVarZw6dSrX8u3btyuAsnv3bv0yNzc3ZfDgwfrHu3btUgDlt99+0y/TaDSKi4uL0qdPH/2ykSNHKhUqVFBu3bqV6xhffPGFAiiXLl1SFEVRIiMjFUCpVauWkp2d/V8vmbJnzx4FUObNm5dr+datWxVAWbVqVa7aVSqVcvbs2VzrPv/884qdnZ2SlpZW6NcDUOzt7ZUHDx78a51arVbJyclRZs+erTg6Oio6nU7/uwYNGijt27fPs83j1yIoKEi/7OOPP873+Y4ePVqxtLTU7/eXX35RAGX58uW51ps7d64CKB9//PG/1jt79mwFUPbt2/fEdR7X16hRI0Wj0eiXnzx5UgGUb7755onbajQaJTU1VbGxsVG+/vpr/fLHfwODBg361/oe7yM7O1vx8vJSJk6cWKja4+Linvg6dOvWTalWrZqSlJSUa/mYMWMUS0tL/bk+ePCgAijt2rXLs4/Hvzt48KCiKIoSHx+vAMrChQv/9TkV5r3QqVMnpWLFisr9+/f/dZ//9M033yiAsmPHjlzLT506pQDKsmXL9Mvi4+OVatWqKX5+fsqZM2cUa2trZcCAAf+6f41Go+Tk5CjDhw9XmjRpkut3gFKlShUlNTVVv+zHH39UAMXHxyfX38XChQsVQDl//rx+Wfv27RVA2blzZ679vvXWW4parc71+fLP81vQzyBRfOTSmHiiFi1aYGZmhq2tLS+88ALPPfccO3fuxNT0UUPi9evXuXr1qr61RaPR6H969OhBTEwMf/31FwC//vorHTt2pF69ek883s8//0zDhg3x8fHJta9u3br958iX7t27U6VKlVz/m9q7dy93795l2LBhuY7RsWNHXFxcch2je/fuABw+fDjXfl966SXMzMz+87U6cOAAQJ7Opa+//jo2Njbs378/1/IGDRrQuHHjXMsCAgJITk7mzJkzT/V6dOrUKd9O7AcOHKBLly7Y29tjYmKCmZkZM2bMICEhgfv37//nc/s3L730Uq7H3t7eZGZm6vf7+PV84403cq335ptvFmj/v/76K7Vr16ZLly7/uW7Pnj0xMTHJVQuQ67JXamoqU6ZMwdPTE1NTU0xNTalQoQJpaWlcuXIlzz779OmTZ5lGo+F///sf9evXx9zcHFNTU8zNzQkPD8+1j8LU/k+ZmZns37+fV155BWtr6zx/W5mZmXku++VX6z85ODhQq1Yt5s+fz4IFCwgLC0On0xW6vsfS09M5fPgwb7zxhr4lq6B+/vlnKlasyIsvvpjr+fn4+FClSpVc729HR0e2bt3KmTNn9K1kK1asyLPP7777jtatW1OhQgVMTU0xMzNj7dq1+Z7bjh07YmNjo3/8+LOpe/fuuVp+Hi//5+VTW1vbPO//gIAAdDodR44c+dfnXZjPIFH0JAiJJ9q4cSOnTp3iwIEDjBw5kitXruT6Anvct2fy5MmYmZnl+hk9ejQA8fHxwKN+PNWqVfvX4927d4/z58/n2ZetrS2Kouj3lR9TU1MGDhzIDz/8oG/iX79+PVWrVqVbt265jvHTTz/lOUaDBg1y1ftY1apVC/RaJSQkYGpqmufLQKVSUaVKFRISEnItr1KlSp59PF72eN3Cvh751Xry5Em6du0KwOrVq/njjz84deoUH3zwAfCoA/CzcHR0zPX48WWQx/t9/Lo4ODjkWs/Z2blA+y/I+6agtcCjL6olS5YwYsQI9u7dy8mTJzl16hSVK1fO97XI7zWdNGkSH330Eb179+ann37izz//5NSpUzRu3DjXPgpT+z8lJCSg0WhYvHhxnvPfo0cP4OneqyqViv3799OtWzfmzZtH06ZNqVy5MuPGjSMlJaXQdT58+BCtVvtUz/PevXskJiZibm6e5znGxsbmeX7+/v40aNCAzMxMRo0alSvEAHz//fe88cYbuLq6smnTJkJCQjh16hTDhg0jMzMzz/H/+Z40Nzf/1+X/3Ed+7+F//g0/6XkX5jNIFD3pIySeqF69evoO0h07dkSr1bJmzRq2b9/Oa6+9pu9PMW3aNF599dV89/G4v0TlypW5ffv2vx6vUqVKWFlZ6fuX5Pf7fzN06FDmz5+v76O0a9cuJkyYkKuVoFKlSnh7e/Ppp5/muw8XF5dcjws6QsjR0RGNRkNcXFyuMKQoCrGxsTRv3jzX+vn13Xi87PEXemFfj/xq/fbbbzEzM+Pnn3/G0tJSv/zHH38s0PN6Vo9flwcPHuT6gsnv+eenIO+bgkpKSuLnn3/m448/ZurUqfrlj/uW5Ce/13TTpk0MGjSI//3vf7mWx8fHU7FiRYPU/txzz2FiYsLAgQN555138l3Hw8PjP2vNj5ubG2vXrgXg2rVrbNu2jZkzZ5KdnZ1vK8u/cXBwwMTE5KmeZ6VKlXB0dGTPnj35/t7W1jbX448//pgLFy7QrFkzZsyYQa9evahZs6b+95s2bcLDw4OtW7fmei3+q8P20/rnoBHI+zecn8J+BomiJ0FIFNi8efPYsWMHM2bM4NVXX6VOnTp4eXlx7ty5PF8K/9S9e3eCg4P566+/9OHon3r16sX//vc/HB0d83zIF0S9evXw9/cnKCgIrVZLVlZWnmH+vXr1Yvfu3dSqVcugcyF17tyZefPmsWnTJiZOnKhfvmPHDtLS0ujcuXOu9S9dusS5c+dyXR7bsmULtra2NG3aVF/rs7wegH5CzL+HwYyMDIKDg/Osa2Fh8cwtRP/Uvn175s2bx9atWxk1apR++bffflug7bt3786MGTM4cOAAnTp1eqZaVCoViqLk6by7Zs2aAo30+ft+/rmPX375hTt37uDp6Vmo2vNrtQKwtramY8eOhIWF4e3trW+VMLTatWvz4YcfsmPHDv0l2cd1FeS9YGVlRfv27fnuu+/49NNP//M/K3/Xq1cvvv32W7RaLf7+/v+67r59+5g7dy4ffvghEyZMwMfHh759+/LHH3/oXxuVSoW5uXmeDs35jRozhJSUFHbt2pXr8tiWLVtQq9W0a9fuidsV1WeQeHoShESBPffcc0ybNo3333+fLVu2MGDAAFauXEn37t3p1q0bQ4YMwdXVlQcPHnDlyhXOnDnDd999B8Ds2bP59ddfadeuHdOnT6dRo0YkJiayZ88eJk2aRN26dZkwYQI7duygXbt2TJw4EW9vb3Q6HVFRUfz222+8++67//mBOWzYMEaOHMndu3dp1apVntA1e/Zs9u3bR6tWrRg3bhx16tQhMzOTmzdvsnv3blasWPFUzfzPP/883bp1Y8qUKSQnJ9O6dWv9qLEmTZowcODAXOu7uLjw0ksvMXPmTKpWrcqmTZvYt28fn3/+OdbW1gAGeT169uzJggULCAgI4O233yYhIYEvvvgi35E8jRo14ttvv2Xr1q3UrFkTS0tL/Yicp/XCCy/QunVr3n33XZKTk2nWrBkhISFs3LgRINcIv/xMmDCBrVu38vLLLzN16lT8/PzIyMjg8OHD9OrVi44dOxa4Fjs7O9q1a8f8+fOpVKkS7u7uHD58mLVr1+ZqyfkvvXr1Yv369dStWxdvb29CQ0OZP39+nvdNQWq3tbXFzc2NnTt30rlzZxwcHPS1ff3117Rp04a2bdsyatQo3N3dSUlJ4fr16/z000/6fmmFcf78ecaMGcPrr7+Ol5cX5ubmHDhwgPPnz+dqJSvMe2HBggW0adMGf39/pk6diqenJ/fu3WPXrl2sXLkyT8vOY/369WPz5s306NGD8ePH4+fnh5mZGbdv3+bgwYO8/PLLvPLKK8TExDBgwADat2/Pxx9/jFqtZuvWrbRr1473339fP0qwV69efP/994wePZrXXnuN6OhoPvnkE6pWrVokM+I7OjoyatQooqKiqF27Nrt372b16tWMGjVKP0IzP0X1GSSegXH7aouS6PGImX+OVlIURcnIyFBq1KiheHl56UfonDt3TnnjjTcUJycnxczMTKlSpYrSqVMnZcWKFbm2jY6OVoYNG6ZUqVJFMTMzU1xcXJQ33nhDuXfvnn6d1NRU5cMPP1Tq1KmjmJubK/b29kqjRo2UiRMnKrGxsfr1/jlq7LGkpCTFyspKAZTVq1fn+/zi4uKUcePGKR4eHoqZmZni4OCgNGvWTPnggw/0o0gej46ZP39+gV+3jIwMZcqUKYqbm5tiZmamVK1aVRk1apTy8OHDXOu5ubkpPXv2VLZv3640aNBAMTc3V9zd3ZUFCxbk2WdBXw9Aeeedd/Kta926dUqdOnUUCwsLpWbNmsrcuXOVtWvXKoASGRmpX+/mzZtK165dFVtbWwVQ3Nzccr0W+Y0ai4uLy3Wsx++dv+/3wYMHytChQ5WKFSsq1tbWyvPPP6+cOHFCAXKN1HqShw8fKuPHj1dq1KihmJmZKU5OTkrPnj2Vq1ev5qovv3PFP0bs3L59W+nTp4/y3HPPKba2tsoLL7ygXLx4Mc/76d/+Bh4+fKgMHz5ccXJyUqytrZU2bdooR48eVdq3b59npNV/1a4oivL7778rTZo0USwsLBQgVx2RkZHKsGHDFFdXV8XMzEypXLmy0qpVK2XOnDn6dR6PDPvuu+/y1PrPUWP37t1ThgwZotStW1exsbFRKlSooHh7eytfffVVrhF3hXkvKIqiXL58WXn99dcVR0dHxdzcXKlRo4YyZMgQJTMzM09Nf5eTk6N88cUXSuPGjRVLS0ulQoUKSt26dZWRI0cq4eHhikajUdq3b684OzsrMTExubadP3++Aig//PCDftlnn32muLu7KxYWFkq9evWU1atX69+rf5ff38uT3kf5vb7t27dXGjRooBw6dEjx9fVVLCwslKpVqyrTp0/PM4L2n+9BRSnYZ5AoPipF+dusakKIIufu7k7Dhg35+eefjV2K0WzZsoX+/fvzxx9/0KpVK2OXI0ShdOjQgfj4eC5evGjsUoQByKUxIUSR+uabb7hz5w6NGjVCrVZz4sQJ5s+fT7t27SQECSGMToKQEKJI2dra8u233zJnzhzS0tKoWrUqQ4YMYc6cOcYuTQghkEtjQgghhCi3ZEJFIYQQQpRbEoSEEEIIUW5JEBJCCCFEuVXuOkvrdDru3r2Lra1tgaekF0IIIYRxKYpCSkoKLi4u/zkZa2GUuyB09+5dqlevbuwyhBBCCPEUoqOjDTr7drkLQo+ne4+OjsbOzs7I1QghhBCiIJKTk6levfoTb9vytMpdEHp8OczOzk6CkBBCCFHKGLpbi3SWFkIIIUS5JUFICCGEEOWWBCEhhBBClFsShIQQQghRbkkQEkIIIUS5JUFICCGEEOWWBCEhhBBClFsShIQQQghRbkkQEkIIIUS5JUFICCGEEOWWUYPQkSNHePHFF3FxcUGlUvHjjz/+5zaHDx+mWbNmWFpaUrNmTVasWFH0hQohhBCiTDJqEEpLS6Nx48YsWbKkQOtHRkbSo0cP2rZtS1hYGNOnT2fcuHHs2LGjiCsVQgghRFlk1Juudu/ene7duxd4/RUrVlCjRg0WLlwIQL169Th9+jRffPEFffr0KaIqhRBCCFFWlao+QiEhIXTt2jXXsm7dunH69GlycnKMVJUQQgghilpCcnqR7LdUBaHY2FicnZ1zLXN2dkaj0RAfH5/vNllZWSQnJ+f6EUIIIUTpkJiezYLf/sK7fa8i2b9RL409DZVKleuxoij5Ln9s7ty5zJo1q8jrEkIIIYThPEjLZs3RCDYcv0lathZr/9dJjQg1+HFKVYtQlSpViI2NzbXs/v37mJqa4ujomO8206ZNIykpSf8THR1dHKUKIYQQ4inEpWQxd/cV/KZuZv6ydaRla6lbxZalY18pkuOVqhahli1b8tNPP+Va9ttvv+Hr64uZmVm+21hYWGBhYVEc5QkhhBDiKd1PzmTlkQg2nbhJQtjvPPh9BWhzmD24KyNfaUtqakqRHNeoQSg1NZXr16/rH0dGRnL27FkcHByoUaMG06ZN486dO2zcuBGAwMBAlixZwqRJk3jrrbcICQlh7dq1fPPNN8Z6CkIIIYR4BjFJGaw8HMGWk1FkpCbzYM8S0v86BkDbtm3p4euFWp1/9xdDMGoQOn36NB07dtQ/njRpEgCDBw9m/fr1xMTEEBUVpf+9h4cHu3fvZuLEiSxduhQXFxcWLVokQ+eFEEKIUuZOYgbLD11n26nbZGt1ZEadJ/nXhWQkPuryMmvWLKZMmYKJiUmR1qFSHvc2LieSk5Oxt7cnKSkJOzs7Y5cjhBBClCvRD9JZdug620Nvk6N9FEGsL+zg6q/rURQFLy8vNm/eTPPmzXNtV1Tf36Wqj5AQQgghSqeb8WksPXid78PuoNU9CkAtazoyrrMXx76/zPu7Fd566y0WLFhAhQoViq0uCUJCCCGEKDI34lJZevA6O8/e1QegNp6ODPRxoJtvbQD8332X5s2b06FDh2KvT4KQEEIIIQwu/F4KSw5e56dzd/m//EOHOpUZ0Pg5Fs18l/FfXOPMmTNYW1ujVquNEoJAgpAQQgghDOhqbDKLD1xn94UYHvdC7lLPibGdvIi5dIKBPV8mNjYWc3Nzjh8/TpcuXYxarwQhIYQQQjyzS3eTWLz/Onsu/f+Jj7s1cGZsJy88HS2YMmUKixYtAqB+/fps2bKFxo0bG6tcPQlCQgghhHhq528nsmj/dX6/cg8AlQp6NKrK2E6e1K1ix4ULF2j+QgAXL14EYMyYMcybNw8rKytjlq0nQUgIIYQQhXYm6iGL94dz8K84ANQqeLGxC2M6euLlbKtfb/r06Vy8eBEnJyeCgoLo0aOHsUrOlwQhIYQQQhTY6ZsP+Hp/OEfD44FHAah3E1fe6ehJrcp5h72vWLGCKVOmsGDBApycnIq73P8kEyoKIYQQ4j+diEhg0f5wjt9IAMBEreLV/wtA7pVs9Ovt3LmTkJAQPvvsM4MeXyZUFEIIIUSxUhSF4zcS+Hp/OCcjHwBgZqLitWbVGN3Bk+oO1vp109LSmDRpEqtWrQKgU6dOdO3a1Sh1F4YEISGEEELkoigKR8LjWbQ/nNBbDwEwN1HzRvNqBLavRbXnrHOtHxoaSkBAANeuXUOlUjF58mTat29vjNILTYKQEEIIIYBHAejgX/f5ev91zkUnAmBuqibArwYj29ekqn3ukV5arZb58+fz0UcfodFocHV1ZePGjXTq1MkI1T8dCUJCCCFEOacoCvsu32PRgXAu3kkGwNJMTX9/N0a2q4mTnWW+2/Xt25cdO3YA0KdPH1atWoWDg0Ox1W0IEoSEEEKIckqnU9h7KZZFB65zJeZRALIyM2FQSzdGtK1JZVuLf91+wIAB7N27l0WLFjFkyBBUKlVxlG1QEoSEEEKIckarU9h9IYbFB8K5di8VABtzEwa3cmd4Gw8cK+QfgJKTk7l69Sp+fn4A9O7dm4iICCpXrlxstRuaBCEhhBCinNBodfx8/lEAuhGXBoCthSlDW7szrI0HFa3Nn7htSEgI/fv3JykpiQsXLuDi4gJQqkMQSBASQgghyjyNVsePZ++y9OB1IuMfBSA7S1OGt6nJkNbu2FuZPXlbjYY5c+YwZ84ctFot7u7u3Lt3Tx+ESjsJQkIIIUQZla3R8UPYbZYevEHUg3QAKlqb8Vbbmgxq6Yat5ZMDEEBERAQDBgwgJCQEeNQnaMmSJdjb2xd57cVFgpAQQghRxmRptGwPvc2ygze4k5gBgKONOW+1q8mAFm5UsPjvr/8NGzYwZswYUlNTsbe3Z/ny5bz55ptFXXqxkyAkhBBClBGZOVq2nY5m+aEbxCRlAlCpggWB7WsS4F8Da/OCf+2fOHGC1NRU2rZtS3BwMG5ubkVVtlFJEBJCCCFKucwcLVv+jGLF4RvcT8kCwNnOgsD2tXjTrwaWZiYF2o9Go8HU9FE0+PLLL2nYsCGBgYGYmBRs+9JIgpAQQghRSqVna9h8IoqVRyKIT30UgKraWzK6Qy1e961e4ACUnZ3NjBkzCA0NZe/evajVaqytrXnnnXeKsvwSQYKQEEIIUcqkZmkIDrnF6qMRPEjLBsC1ohXvdPSkTzNXLEwL3oJz9epV+vfvz5kzZwD47bffeOGFF4qk7pJIgpAQQghRSiRn5rDx+E3WHIskMT0HgBoO1ozp6MkrTV0xM1EXeF+KorBy5UomTZpERkYGDg4OrFmzplyFIJAgJIQQQpR4SRk5BP0RybpjkSRnagDwqGTDmI6evOzjgmkhAhBAXFwcw4cP56effgKgS5cubNiwoczMDVQYEoSEEEKIEioxPZt1xyIJ+uMmKVmPAlCtyjaM6+xFL28XTNRPd2+vfv36ceDAAczNzZk7dy4TJkxArS5cmCorJAgJIYQQJUxCahZrjkWy8fhN0rK1ANRxtmVsZ0+6N6z61AHosS+//JJhw4YRFBRE48aNDVFyqSVBSAghhCgh4lKyWH00guCQW2TkPApA9araMb6zJ13rV0H9lAHowoULhIWFMWjQIAB8fHwIDQ0tlXeLNzQJQkIIIYSR3UvOZOXhCLacvEVmjg6ARq72jOvsRZd6Tk8dWHQ6HYsXL2bKlCnodDoaNmxI06ZNASQE/R8JQkIIIYSRxCRlsOLQDb45FU225lEAaly9IhM6e9GhTuVnCisxMTEMGTKE3377DYCePXtSrVo1g9RdlkgQEkIIIYrZ7YfpLD90g+9O3yZb+ygANXN7jvGdvWjrVemZW2t27tzJ8OHDSUhIwNLSkgULFhAYGCitQPmQICSEEEIUk6iEdJYdus720NtodAoAfh4OTOjsRctajgYJKuPHj2fRokXAo75AW7ZsoV69es+837JKgpAQQghRxCLj01h68Do/hN1B+38BqLWnI2M7edGipqNBj+Xu7g7A5MmTmTNnDhYWFgbdf1mjUhRFMXYRxSk5ORl7e3uSkpKws7MzdjlCCCHKsBtxqSw9cJ0fz97h//IP7WpXZlwnT3zdHQxyDK1WS2xsLK6ursCjDtKhoaE0b97cIPsvKYrq+1tahIQQQggDu3YvhSUHrvPT+bs8bm7oVNeJsZ08aVLjOYMdJzo6moEDBxITE8OZM2ewsbFBrVaXuRBUlCQICSGEEAZyJSaZJQeus/tijD4APV/fmXGdvGhUzd6gx9q6dSuBgYEkJiZiY2NDWFgYbdq0MegxygMJQkIIIcQzungnicUHwtl76Z5+WfeGVRjTyZMGLoYNQMnJyYwdO5aNGzcC4Ofnx+bNm/H09DToccoLCUJCCCHEUzoXncjiA+H8fuU+ACoV9GxUlTGdPKlbxfD9UENCQujfvz+RkZGo1Wo++OADPvroI8zMzAx+rPJCgpAQQghRSKG3HrL4QDiH/ooDQK2Clxq7MKaTJ55OtkV23Dlz5hAZGYm7uzvBwcFyKcwAJAgJIYQQBXTq5gMW7Q/naHg8ACZqFS/7uDCmoyc1K1co8uOvWbOGTz75hLlz52Jvb9hLbuWVDJ8XQggh/oWiKJyIeBSAQiISADBVq3i1qSujO3jiXsmmyI4bHBxMWFgYX331VZEcozSR4fNCCCFEMVIUhT+uJ7Bofzgnbz4AwMxExWvNqjO6Qy2qO1gX2bEfPnxIYGAg27ZtA6BXr1507ty5yI5XnkkQEkIIIf5GURQOX4tj0f5wzkQlAmBuoqZv8+oEdqiFa0WrIj3+oUOHGDhwILdv38bU1JRZs2bRoUOHIj1meSZBSAghhOBRADpw9T6L9odz7nYSABamat70q0Fg+1pUsbcs0uNnZ2czY8YM5s2bh6IoeHl5sXnzZpkcsYhJEBJCCFGu6XQK+67cY9H+cC7dTQbA0kzNAH833m5XEye7og1Aj/Xu3Ztff/0VgBEjRvDVV19RoULRd8Au7yQICSGEKJd0OoU9l2JZtD+cq7EpAFibmzCwpRtvta1JpQrFe7PSUaNGcfLkSVavXs0rr7xSrMcuzyQICSGEKFe0OoVfLsSweH844fdTAahgYcrgVm4Mb1MTBxvzYqkjLi6Oq1ev0rZtWwBefPFFIiIiZERzMZMgJIQQolzQaHX8dP4uiw9cJyIuDQBbS1OGtvZgWGt3KloXTwAC2Lt3L0OGDCErK4vz589TrVo1AAlBRiBBSAghRJmWo9XxY9gdlh68zs2EdADsrcwY3saDwa3csbcqvttTZGZmMnXqVL7++msA6tevT0pKSrEdX+QlQUgIIUSZlK3R8f2Z2yw9dJ3oBxkAPGdtxoi2NRnU0g1by+K9P9eFCxcICAjg4sWLAIwZM4Z58+ZhZVW0w/HFv5MgJIQQokzJ0mj57vRtlh+6wZ3ERwHI0cact9vVZEALN2wsiv+r7+uvv2bKlClkZWXh5OREUFAQPXr0KPY6RF4ShIQQQpQJmTlatp6KZvmhG8QmZwJQ2daCke1q0t/fDStzE6PVdu3aNbKysujZsyfr1q3DycnJaLWI3CQICSGEKNUysrVsORnFysM3uJ+SBYCznQWj2tein18NLM2ME4CysrKwsHg0BH/+/Pn4+/szcOBAVCqVUeoR+ZMgJIQQolRKz9aw6cQtVh2JID41GwAXe0tGdfTk9WbVjBaA0tLSePfdd/nrr7/4/fffMTExwdramkGDBhmlHvHvJAgJIYQoVVKzNGwMucmao5E8SHsUgKo9Z8U7HT3p07Qa5qZqo9UWGhpK//79+euvvwA4cuQIHTt2NFo94r9JEBJCCFEqJGfmsOGPm6z9I5LE9BwA3ByteaejJ680ccXMxHgBSKvV8sUXX/Dhhx+i0WhwdXVlw4YNEoJKAQlCQgghSrSk9BzW/RFJ0B+RJGdqAKhZyYYxnTx5qbELpkYMQADR0dEMHDiQw4cPA9CnTx9WrlyJo6OjUesSBSNBSAghRIn0MC2bdX9Esv6Pm6RkPQpAnk4VGNvJk17eLpioS0an44CAAI4dO4aNjQ2LFi1i6NCh0iG6FJEgJIQQokRJSM1izbFINh6/SVq2FoA6zraM6+xF94ZVUJeQAPTYkiVLGDt2LOvWrcPT09PY5YhCkiAkhBCiRLifksnqIxFsOhFFRs6jAFS/qh3jOnvRtb5ziQlAISEhXLx4kbfeeguAxo0bc/jwYWkFKqWMe2EVWLZsGR4eHlhaWtKsWTOOHj36r+tv3ryZxo0bY21tTdWqVRk6dCgJCQnFVK0QQghDu5ecyayfLtH284OsPhpJRo4W72r2rBnkyy/j2vBCCWkF0mg0zJw5k7Zt2zJ69GhCQ0P1v5MQVHoZtUVo69atTJgwgWXLltG6dWtWrlxJ9+7duXz5MjVq1Miz/rFjxxg0aBBfffUVL774Infu3CEwMJARI0bwww8/GOEZCCGEeFp3EzNYcfgG356KJlujA8CnekXGd/GiQ+3KJSpcREREMGDAAEJCQgDo37+/XAYrI1SKoijGOri/vz9NmzZl+fLl+mX16tWjd+/ezJ07N8/6X3zxBcuXL+fGjRv6ZYsXL2bevHlER0cX6JjJycnY29uTlJSEnZ3dsz8JIYQQhRL9IJ3lh2/w3elocrSPvoJ83Z5jfBcv2nhWKlEBSFEUgoODeeedd0hNTcXOzo7ly5cTEBBg7NLKnaL6/jZai1B2djahoaFMnTo11/KuXbty/PjxfLdp1aoVH3zwAbt376Z79+7cv3+f7du307NnzyceJysri6ysLP3j5ORkwzwBIYQQhRKVkM7Sg9fZceY2Gt2jANSipgPjOnvRsqZjiQpAjw0dOpQNGzYA0KZNG4KDg3F3dzduUcKgjNZHKD4+Hq1Wi7Ozc67lzs7OxMbG5rtNq1at2Lx5M3379sXc3JwqVapQsWJFFi9e/MTjzJ07F3t7e/1P9erVDfo8hBBC/LvI+DTe3XaOjl8eYuvpaDQ6hTaeldj6dgu+fbslrWqVrFagv2vSpAmmpqZ8+umnHDp0SEJQGWT0ztL/fPMrivLEP4jLly8zbtw4ZsyYQWhoKHv27CEyMpLAwMAn7n/atGkkJSXpfwp6CU0IIcSzuX4/lYlbz9L5y0PsOHMbrU6hfe3K7BjVkk0j/PGvWfImHMzOzubmzZv6x2PHjuXcuXNMnz4dExPj3b1eFB2jXRqrVKkSJiYmeVp/7t+/n6eV6LG5c+fSunVr3nvvPQC8vb2xsbGhbdu2zJkzh6pVq+bZxsLCQn/3XyGEEEXv2r0UFh+4zs/n7/K4F2rnuk6M7eyFT/WKRq3t3/z1118EBASQnJxMWFgYFSpUQK1WU79+fWOXJoqQ0YKQubk5zZo1Y9++fbzyyiv65fv27ePll1/Od5v09HRMTXOX/DihG7HPtxBCCODy3WSWHAxn94X//x/crvWdGdvJi0bV7I1Y2b9TFIVVq1YxceJEMjIycHBw4MqVKzRv3tzYpYliYNTh85MmTWLgwIH4+vrSsmVLVq1aRVRUlP5S17Rp07hz5w4bN24E4MUXX+Stt95i+fLldOvWjZiYGCZMmICfnx8uLi7GfCpCCFFuXbyTxKL94fx2+Z5+WY9GVRjT0Yv6LiV7dG5cXBwjRoxg165dAHTp0oX169fj6upq5MpEcTFqEOrbty8JCQnMnj2bmJgYGjZsyO7du3FzcwMgJiaGqKgo/fpDhgwhJSWFJUuW8O6771KxYkU6derE559/bqynIIQQ5dbZ6EQW7w9n/9X7AKhU0MvbhTEdPalTxdbI1f23vXv3MmTIEGJjYzE3N2fu3LlMmDABtdro3WdFMTLqPELGIPMICSHEswm99ZBF+8M5fC0OALUKXvZx5Z2OtfB0KvkBCB5dDuvVqxe7d++mXr16bNmyBR8fH2OXJf5FmZtHSAghROlyMvIBi/aHc+x6PAAmahW9fVwZ08kTj0o2Rq6ucFQqFWvXruWrr75i5syZWFlZGbskYSTSIiSEEOKJFEUhJCKBRfvDORHxAABTtYo+TasxumMt3BxLRwDS6XQsXryYv/76i2XLlhm7HPEUpEVICCFEsVEUhWPX41m0P5xTNx8CYGai4nXf6oxqX4vqDtZGrrDgYmJiGDp0KHv37gUe9U9t3769kasSJYUEISGEEHqKonDoWhyL9ocTFpUIgLmpmn7NqxPYvhYuFUvXJaSdO3cyYsQI4uPjsbS0ZMGCBbRr187YZYkSRIKQEEIIFEVh/5X7LDoQzvnbSQBYmKrp7+/GyPY1cbazNHKFhZOWlsa7777LypUrAfDx8WHLli3Uq1fPyJWJkkaCkBBClGM6ncJvl++xaH84l2Me3ZTaysyEgS3dGNHWAyfb0hWA4FGo69GjB0eOHAHgvffe45NPPpG7DIh8SRASQohySKdT+PViLIsPhHM1NgUAG3MTBrVyZ0QbDxwrlN7QoFKpmDJlCjdu3GDDhg107tzZ2CWJEkyCkBBClCNancLP5++y5MB1wu+nAmBrYcqQ1u4Ma+3BczbmRq7w6URHR3Pt2jV96OnRowfh4eEyLF78JwlCQghRDmi0OnadexSAIuLTALC1NGVYaw+GtfbA3trMyBU+va1bt+pvzXTu3Dlq1KgBICFIFIgEISGEKMNytDp+CLvD0oPXuZWQDoC9lRkj2ngwuLU7dpalNwAlJyczduxY/f0o/fz80Gq1Rq5KlDYShIQQogzK1ujYceY2Sw9e5/bDDAAcbMwZ0daDQS3dqWBRuj/+Q0JC6N+/P5GRkajVaj744AM++ugjzMxKb7ATxlG6/xKEEELkkqXRsu30bZYfvM7dpEwAKlUw5+12Nenv74ZNKQ9AiqLwySefMHv2bLRaLe7u7gQHB9OmTRtjlyZKqdL9FyGEEAKAzBwt356MYsXhCGKTHwWgyrYWBLavRYBfDazMTYxcoWGoVCoSEhLQarUMGDCAJUuWYG9vb+yyRCkmQUgIIUqxjGwtm/+8xcojEcSlZAFQxc6SUR1q0bd5dSzNSn8AUhSFtLQ0KlSoAMBnn31Gp06dePnll41cmSgLJAgJIUQplJalYdOJW6w+GkF8ajYArhWtGNWhFq/7VsPCtPQHIICHDx8ycuRIYmNjOXjwICYmJlhZWUkIEgYjQUgIIUqRlMwcNobcYs3RCB6m5wBQ3cGKdzp48mrTapibqo1coeEcPHiQQYMGcfv2bUxNTfnzzz9p1aqVscsSZYwEISGEKAWSMnLYcPwma49FkpTxKAC5O1rzTkdPejdxxcyk7ASg7OxsPvroI+bPn4+iKHh5ebF582aaN29u7NJEGSRBSAghSrCk9BzW/hFJ0B+RpGRqAKhZ2YaxnTx50dsF0zIUgACuXr1K//79OXPmDABvvfUWCxYs0PcPEsLQJAgJIUQJ9DAtm7XHIll//CapWY8CkJdTBcZ29qJno6qYqFVGrtDwFEVhyJAhnDlzBgcHB9asWcMrr7xi7LJEGSdBSAghSpD41CzWHI1kY8hN0rMfzZJct4ot4zp78UKDKqjLYAB6TKVSsWbNGqZNm8bKlStxcXExdkmiHFApiqIYu4jilJycjL29PUlJSdjZ2Rm7HCGEAOB+Siarj0Sw6UQUGTmPAlADFzvGdfbi+XrOZTYA7d27l2vXrjF27FhjlyJKuKL6/pYWISGEMKLYpExWHL7BNyejyNLoAGhczZ5xnb3oVNcJlapsBqDMzEymTJnCokWLMDExoWXLlvj6+hq7LFEOSRASQggjuJOYwYpDN9h6Kpps7aMA1KRGRcZ39qJ97cplNgABXLhwgYCAAC5evAjAqFGjaNCggZGrEuWVBCEhhChG0Q/SWXboBttDo8nRPuqZ0Nz9OcZ3rk1rT8cyHYB0Oh2LFy9mypQpZGVl4eTkRFBQED169DB2aaIckyAkhBDF4FZCGksPXuf7M3fQ6B4FoJY1HRnX2YsWNR3KdACCRyPCXn31VXbu3AlAr169WLt2LU5OTkauTJR3EoSEEKIIRcSlsuTgdXaevYv2/wJQW69KjO3khZ+Hg5GrKz4qlYouXbqwd+9eFixYQGBgYJkPf6J0kFFjQghRBK7fT2HJgevsOneX/8s/dKhTmbGdvGjm9pxxiysmaWlp3Llzh9q1awOPWoVu3ryJh4eHkSsTpZGMGhNCiFLgr9gUFh8I55cLMTz+b2aXek6M7eRF4+oVjVpbcQoNDSUgIACNRsPZs2extbVFpVJJCBIljgQhIYQwgEt3k1hy4Dq/XozVL+vWwJmxnbxo6GpvxMqKl1arZf78+Xz00UdoNBpcXV2JjIzE29vb2KUJka+nCkIajYZDhw5x48YNAgICsLW15e7du9jZ2cn9YIQQ5cqF20ksOhDOvsv3AFCpoEfDqozp5Em9quXr8ntUVBSDBg3i8OHDAPTp04dVq1bh4FB++kKJ0qfQQejWrVu88MILREVFkZWVxfPPP4+trS3z5s0jMzOTFStWFEWdQghRooRFPWTxgescuHofeBSAXvR2YUwnT2o72xq5uuK3detWRo4cSVJSEjY2NixevJghQ4ZIh2hR4hU6CI0fPx5fX1/OnTuHo6Ojfvkrr7zCiBEjDFqcEEKUNKG3HvD1/uscuRYHgFoFvX1cGd3RE0+n8tkirigKmzZtIikpCT8/PzZv3oynp6exyxKiQAodhI4dO8Yff/yBubl5ruVubm7cuXPHYIUJIURJ8mdEAosOhPPH9QQATNQqXm3iyjsdPXGvZGPk6oxDURRUKhUqlYq1a9eyZs0a3nvvPczMzIxdmhAFVuggpNPp0Gq1eZbfvn0bW9vy1xwshCi7FEUh5EYCX+8P58/IBwCYqlW87luNUe09qeFobeQKjUOj0TBnzhyioqJYt24dAE5OTkyfPt3IlQlReIUOQs8//zwLFy5k1apVwKNJslJTU/n4449lmnQhRJmgKApHw+NZtD+c07ceAmBuouaN5tUIbF+Las+VzwAEEBERwYABAwgJCQFgxIgRtGrVyshVCfH0Ch2EvvrqKzp27Ej9+vXJzMwkICCA8PBwKlWqxDfffFMUNQohRLFQFIVDf8Xx9f5wzkYnAmBuqibArwYj29ekqr2VcQs0IkVR2LhxI2PGjCE1NRU7OzuWL18uIUiUeoUOQi4uLpw9e5Zvv/2W0NBQdDodw4cPp3///lhZld8PCSFE6aUoCr9fuc+i/eFcuJMEgKWZmv7+boxsVxMnO0sjV2hcDx8+ZOTIkXz33XcAtG3bluDgYNzc3IxcmRDPrtC32Dhy5AitWrXC1DR3htJoNBw/fpx27doZtEBDk1tsCCH+7mpsMpO2nuNyTDIAVmYmDGrpxoi2Nalsa2Hk6oxPURT8/f05deoUpqamzJo1iylTpmBiYmLs0kQ5U1Tf34UOQiYmJsTExOS5Y3BCQgJOTk75dqQuSSQICSEeOxGRwFsbT5OSqcHG3ITBrdwZ3sYDxwoSgP5uz549jB8/nk2bNtG8eXNjlyPKqRJzr7HHwyX/KSEhARub8jmEVAhR+uy5GMO4b8+SrdHh5+7AioHNcLAx/+8Ny4GrV68SGRlJ9+7dAXjhhRe4ePGiDIsXZVKBg9Crr74KPBolNmTIECws/v//mLRaLefPn5dOc0KIUmHzn7f46MeL6BToWt+ZRW82wdJMLvUoisKqVauYOHEiZmZmnDt3Dnd3dwAJQaLMKnAQsrd/dNNARVGwtbXN1THa3NycFi1a8NZbbxm+QiGEMBBFUVi0/zpf/X4NgDf9avDJyw0wNVEbuTLji4uLY8SIEezatQuA1q1b55k4V4iyqMBBKCgoCAB3d3cmT54sl8GEEKWKVqcwY+dFNv8ZBcC4zl5M7OIl98LiUR+goUOHEhsbi7m5OXPnzmXChAmo1RIQRdlX6M7SpZ10lhai/MnM0TLh27PsuRSLSgWzX27IwBYy9FtRFCZNmsTChQsBqF+/Plu2bKFx48bGLUyIfJSYztIA27dvZ9u2bURFRZGdnZ3rd2fOnDFIYUIIYQhJGTm8vfE0f0Y+wNxEzcJ+PvRoVNXYZZUIf28NGzNmDPPmzZP54ES5U+h2z0WLFjF06FCcnJwICwvDz88PR0dHIiIi9CMMhBCiJLifnEnflSH8GfkAWwtTNgzzK/chSKfTkZiYqH88d+5c9u/fz+LFiyUEiXKp0EFo2bJlrFq1iiVLlmBubs7777/Pvn37GDduHElJSUVRoxBCFFpEXCqvLj/O1dgUKtta8O3IFrSs5WjssowqJiaGHj160KtXLzQaDQCWlpZ06tTJyJUJYTyFDkJRUVH6YfJWVlakpKQAMHDgQLnXmBCiRDgXnchrK0K4/TADd0drvh/VigYu9sYuy6h27tyJt7c3e/fuJTQ0lLCwMGOXJESJUOggVKVKFRISEgBwc3PjxIkTAERGRlLO+l0LIUqgw9fieHP1CR6kZeNdzZ7to1pR3aH83i0+LS2NwMBAevfuTXx8PD4+PoSGhsoM0UL8n0IHoU6dOvHTTz8BMHz4cCZOnMjzzz9P3759eeWVVwxeoBBCFNSPYXcYvv4U6dla2npVYstbLahUjm+XERoaStOmTVm5ciUAkydP5sSJE9SvX9/IlQlRchR6+LxOp0On0+lvurpt2zaOHTuGp6cngYGBJX4CLhk+L0TZtOZoBHN+uQLAyz4uzH+tMeam5XcenL/fLNXV1ZUNGzbQuXNnY5clxFMrMTdd/Td37tzB1dXVULsrEhKEhChbFEXhs1+vsvJIBADDWnvwYc96qNUyUeLly5f59NNPWbx4MQ4ODsYuR4hnUlTf3wb571JsbCxjx47F09PTELsTQogCydHqePe7c/oQNLV7XT7qVX5D0NatW/nyyy/1j+vXr8/mzZslBAnxLwochBITE+nfvz+VK1fGxcWFRYsWodPpmDFjBjVr1uTEiROsW7euKGsVQgi99GwNb208zfdn7mCiVvHF640JbF+rXN4yIzk5mcGDB9OvXz+mTJkiE9sKUQgFnll6+vTpHDlyhMGDB7Nnzx4mTpzInj17yMzM5Ndff6V9+/ZFWacQQug9SMtm2PpTnI1OxNJMzbL+TelU19nYZRlFSEgI/fv3JzIyErVazfTp02nUqJGxyxKi1ChwEPrll18ICgqiS5cujB49Gk9PT2rXrq2/R40QQhSH2w/TGbTuJBFxaVS0NmPdkOY0rfGcscsqdhqNhjlz5jBnzhy0Wi3u7u4EBwfTpk0bY5cmRKlS4CB09+5d/ZDLmjVrYmlpyYgRI4qsMCGE+Ke/YlMYtO5P7iVn4WJvycbhfng62Rq7rGKnKAovvPAC+/fvB2DAgAEsWbIEe/vyPWmkEE+jwH2EdDodZmZm+scmJibY2NgUSVFCCPFPJyMf8PqK49xLzqK2cwV2jG5VLkMQPLpZap8+fbCzs2Pz5s0EBwdLCBLiKRV4+LxaraZ79+5YWDyanOynn36iU6dOecLQ999/b/gqDUiGzwtR+vx2KZax34SRpdHh6/Ycawc3x97a7L83LEMePnzInTt3aNiwIfCoVejevXtUqVLFyJUJUTyMPnx+8ODBODk5YW9vj729PQMGDMDFxUX/+PFPYS1btgwPDw8sLS1p1qwZR48e/df1s7Ky+OCDD3Bzc8PCwoJatWrJaDUhyrBvTkYRuCmULI2OLvWc2TTCv9yFoEOHDuHt7c2LL75IcnIy8KhVSEKQEM+uwH2EgoKCDH7wrVu3MmHCBJYtW0br1q1ZuXIl3bt35/Lly9SoUSPfbd544w3u3bvH2rVr8fT05P79+/q7KAshyg5FUVh84DoL9l0DoF/z6szp3RBTk/IzW3R2djYzZsxg3rx5KIqCp6cnMTEx0pothAEZdGbpwvL396dp06YsX75cv6xevXr07t2buXPn5ll/z5499OvXj4iIiKeeIEwujQlR8ml1CjN3XSL4xC0AxnbyZNLztcvVHEF//fUXAQEB+jmBRowYwVdffUWFChWMXJkQxmH0S2OGlp2dTWhoKF27ds21vGvXrhw/fjzfbXbt2oWvry/z5s3D1dWV2rVrM3nyZDIyMoqjZCFEMcjSaBn7zRmCT9xCpYJZLzXg3a51yk0IUhSFlStX0qRJE86cOYODgwM7duxg9erVEoKEKAIFvjRmaPHx8Wi1Wpydc0+C5uzsTGxsbL7bREREcOzYMSwtLfnhhx+Ij49n9OjRPHjw4In9hLKyssjKytI/fnx9XQhR8iRn5jByYyghEQmYm6hZ0LcxvbxdjF1Wsdu9ezcZGRl06dKF9evXl/h7OApRmhn9Yvs//5enKMoT/+en0+lQqVRs3rwZPz8/evTowYIFC1i/fv0TW4Xmzp2bqzN39erVDf4chBDP7n5KJv1WniAkIoEKFqasH9q8XIUgnU4HPPpMXLNmDYsXL2bv3r0SgoQoYkYLQpUqVcLExCRP68/9+/fztBI9VrVqVVxdXXONTqtXrx6KonD79u18t5k2bRpJSUn6n+joaMM9CSGEQUTGp9Fn+XEuxyRTqYIF377dglaelYxdVrHIzMxkwoQJDB48WL+scuXKjBkzBrXa6P9XFaLMe6q/suDgYFq3bo2Liwu3bj3qzLhw4UJ27txZ4H2Ym5vTrFkz9u3bl2v5vn37aNWqVb7btG7dmrt375Kamqpfdu3aNdRqNdWqVct3GwsLC+zs7HL9CCFKjvO3E3lt+XGiH2Tg5mjN96Na0dC1fEwOeOHCBZo3b87XX3/Npk2bOH36tLFLEqLcKXQQWr58OZMmTaJHjx4kJiai1WoBqFixYqHvOzZp0iTWrFnDunXruHLlChMnTiQqKorAwEDgUWvOoEGD9OsHBATg6OjI0KFDuXz5MkeOHOG9995j2LBhWFlZFfapCCGM7Gh4HP1WnSAhLZuGrnZsD2xFDUdrY5dV5HQ6HV9//TXNmzfn4sWLODk58csvv+Dr62vs0oQodwodhBYvXszq1av54IMPMDEx0S/39fXlwoULhdpX3759WbhwIbNnz8bHx4cjR46we/du3NzcAIiJiSEqKkq/foUKFdi3bx+JiYn4+vrSv39/XnzxRRYtWlTYpyGEMLKdZ+8wbP0p0rO1tPZ05Nu3W1LZ1sLYZRW5mJgYevTowYQJE8jKyqJnz55cuHCBHj16GLs0IcqlQs8jZGVlxdWrV3Fzc8PW1pZz585Rs2ZNwsPD8fb2LvFD2WUeISGMb92xSGb/fBmAXt5V+fKNxliYmvzHVqWfoij4+Phw/vx5LC0tWbBgAYGBgeVmagAhnkWJmUfIw8ODs2fP5ln+66+/6u9OL4QQ+VEUhc/3XNWHoCGt3FnUr0m5CEHwaETYF198QZMmTQgNDWXUqFESgoQwskLPI/Tee+/xzjvvkJmZiaIonDx5km+++Ya5c+eyZs2aoqhRCFEG5Gh1TPv+AttDH43wfP+FOoxqX6vMB4HQ0FBu377Nyy+/DMDzzz9P586dZUSYECVEoYPQ0KFD0Wg0vP/++6SnpxMQEICrqytff/01/fr1K4oahRClXEa2lne2nOHA1fuYqFXMfbURb/iW7Tm9tFotX3zxBR9++CFWVlacO3cODw8PAAlBQpQgTzWz9FtvvcVbb71FfHw8Op0OJycnQ9clhCgjHqZlM2zDKcKiErE0U7M0oCmd6+U/V1hZER0dzcCBAzl8+DDw6NZB0idRiJKp0P8tmTVrFjdu3AAeTYooIUgI8SR3EzN4fWUIYVGJ2FuZsXmEf5kPQVu3bsXb25vDhw9jY2PD2rVr+e6773B0dDR2aUKIfBQ6CO3YsYPatWvTokULlixZQlxcXFHUJYQo5a7dS+HVZce5fj+VqvaWbA9sSTM3B2OXVWQURWHo0KH069ePxMRE/Pz8OHv2LMOGDSvz/aCEKM0KHYTOnz/P+fPn6dSpEwsWLMDV1ZUePXqwZcsW0tPTi6JGIUQpc/rmA15bfpzY5Ey8nCqwY1QrvJxtjV1WkVKpVFSqVAm1Ws2HH37IsWPH8PT0NHZZQoj/UOh5hP7pjz/+YMuWLXz33XdkZmaW+Lu7yzxCQhStfZfvMWbLGbI0Opq5Pcfawb5UtDY3dllFQqPR8PDhQypXrgxAVlYWZ8+exd/f38iVCVH2lJh5hP7JxsYGKysrzM3NycnJMURNQohSauupKEYGnyZLo6NzXSc2DfcvsyEoIiKCdu3a8fLLL6PRaIBH9zaUECRE6fJUQSgyMpJPP/2U+vXr4+vry5kzZ5g5c2aeO8kLIcoHRVFYevA6U3ZcQKfAG77VWDmwGVbmZW+iREVR2LhxIz4+PoSEhHDp0iUuX75s7LKEEE+p0MPnW7ZsycmTJ2nUqBFDhw7VzyMkhCifdDqF2T9fZv3xmwCM7lCL97rVKZMdhB8+fEhgYCDbtm0DoE2bNgQHB+Pu7m7cwoQQT63QQahjx46sWbOGBg0aFEU9QohSJEujZdK2c/xyPgaVCmb0qs/Q1h7GLqtIHDp0iIEDB3L79m1MTU2ZNWsWU6ZMyXXzaSFE6fPMnaVLG+ksLYRhpGTmMDI4lOM3EjAzUbHgDR9ebOxi7LKKhE6nw9/fn9OnT+Pl5cXmzZtp3ry5scsSolwpqu/vArUITZo0iU8++QQbGxsmTZr0r+suWLDAIIUJIUqu+ymZDA06xaW7ydiYm7ByoC9tvCoZu6wio1ar2bhxI4sXL2bevHlUqFDB2CUJIQykQEEoLCxMPyIsLCysSAsSQpRsN+PTGLTuJFEP0qlUwZz1Q/1o6Gpv7LIMSlEUVq9eTXx8PNOnTwegXr16LFu2zMiVCSEMTS6NCSEK7OKdJIYEnSQ+NZsaDtZsHOaHeyUbY5dlUHFxcbz11lvs3LkTtVpNaGgoPj4+xi5LiHKvxMwjNGzYMFJSUvIsT0tLY9iwYQYpSghR8vxxPZ6+K0OIT82mflU7to9qWeZC0N69e/H29mbnzp2Ym5vzxRdf4O3tbeyyhBBFqNAtQiYmJsTExOS52Wp8fDxVqlTRTyxWUkmLkBCF99O5u0zadpYcrUKrWo6sHNgMW0szY5dlMJmZmUybNo2FCxcCUL9+fbZs2ULjxo2NW5gQQs+onaUfF6AoCoqikJKSgqWlpf53Wq2W3bt3y53ohSiD1v8RyayfL6Mo0NO7KgveaIyFadkZMq7T6ejYsSMnTpwAYMyYMcybNw8rKysjVyaEKA4FDkIVK1ZEpVKhUqmoXbt2nt+rVCpmzZpl0OKEEMajKArz9/7FskM3ABjc0o2PX2yAWl22JkpUq9UMGTKEiIgIgoKC6NGjh7FLEkIUowJfGjt8+DCKotCpUyd27NiBg4OD/nfm5ua4ubnh4lLy5xCRS2NC/DeNVsf0Hy6w7fRtAN7rVofRHWqVmdmiY2JiiI2NpUmTJsCj0Pfw4cNcn2tCiJLF6JfG2rdvDzy6z1iNGjXKzAeiECK3jGwtY785w+9X7qNWwf9eaUQ/vxrGLstgdu7cyfDhw7GxseHcuXP61m4JQUKUTwUKQufPn6dhw4ao1WqSkpK4cOHCE9eVERZClF6J6dkM33Ca0FsPsTBVsySgKc/XdzZ2WQaRlpbGu+++y8qVKwGoXr06iYmJVKxY0biFCSGMqkBByMfHh9jYWJycnPDx8UGlUpHfFTWVSoVWqzV4kUKIonc3MYPB604Sfj8VO0tT1g1pjq972WglCQ0NJSAggGvXrqFSqZg8eTKffPIJFhYWxi5NCGFkBQpCkZGRVK5cWf9vIUTZEn4vhUHrThKTlEkVO0s2DvejtrOtsct6Zjqdjvnz5/Phhx+i0WhwdXVl48aNdOrUydilCSFKiAIFITc3t3z/LYQo/UJvPWDY+tMkZeRQq7ING4f741qxbAwdV6lU/Pnnn2g0Gvr06cOqVaukL5AQIpdCzyy9YcMGfvnlF/3j999/n4oVK9KqVStu3bpl0OKEEEVr/5V79F/zJ0kZOTSpUZHtga3KRAh6fG9ElUrF6tWr2bhxI999952EICFEHoUOQv/73//0E42FhISwZMkS5s2bR6VKlZg4caLBCxRCFI1tp6N5OziUzBwdneo6sXmEP8/ZmBu7rGeSnJzM4MGDGThwoL4fo6OjIwMHDpSRrkKIfBV4+Pxj0dHReHp6AvDjjz/y2muv8fbbb9O6dWs6dOhg6PqEEAamKArLD99g3p6/AOjTtBqf9WmEmUmh/19Uohw/fpwBAwYQGRmJWq1m2rRpcosMIcR/KvQnX4UKFUhISADgt99+o0uXLgBYWlqSkZFh2OqEEAal0ynM+umyPgSN6lCLL173LtUhSKPRMHPmTNq2bUtkZCTu7u4cPnxYQpAQokAK3SL0/PPPM2LECJo0acK1a9fo2bMnAJcuXcLd3d3Q9QkhDCRLo2Xyd+f56dxdAD7qVZ/hbTyMXNWzuXHjBgMGDNDfJ2zAgAEsWbIEe3t7I1cmhCgtCv3fwKVLl9KyZUvi4uLYsWMHjo6OwKN5Ot58802DFyiEeHapWRqGrz/NT+fuYmai4ut+PqU+BOl0Onr16sWJEyewt7dny5YtBAcHSwgSQhRKge81VlbIvcZEeROfmsWQoJNcvJOMtbkJKwY0o13tysYuyyAOHDjA7Nmz2bBhg0ztIUQZV1Tf308VhBITE1m7di1XrlxBpVJRr149hg8fXir+JyZBSJQnUQnpDFr3JzcT0nG0MSdoaHO8q1U0dllP7eDBg8THx/P666/rlymKIiPChCgHiur7u9CXxk6fPk2tWrX46quvePDgAfHx8Xz11VfUqlWLM2fOGKwwIcSzuXgniVeXH+dmQjrVHazYPqpVqQ1B2dnZTJ06lc6dOzNs2DBu3Lih/52EICHEsyh0Z+mJEyfy0ksvsXr1akxNH22u0WgYMWIEEyZM4MiRIwYvUghROMevx/N2cCipWRrqVbVjw7DmONlaGrusp3L16lX69++v/49Wv379cHYuGzeCFUIYX6EvjVlZWREWFkbdunVzLb98+TK+vr6kp6cbtEBDk0tjoqz7+fxdJm09R7ZWR4uaDqwa5IudpZmxyyo0RVFYuXIlkyZNIiMjAwcHB9asWcMrr7xi7NKEEEZQVN/fhW4RsrOzIyoqKk8Qio6Oxta29N+kUYjSbGPITT7edQlFgR6NqrDgDR8szUyMXVah6XQ6+vTpw48//ghAly5d2LBhAy4uLsYtTAhR5hS6j1Dfvn0ZPnw4W7duJTo6mtu3b/Ptt98yYsQIGT4vhJEoisKXv/3FjJ2PQtDAFm4sfrNpqQxBAGq1mjp16mBubs6CBQvYu3evhCAhRJEo9KWx7Oxs3nvvPVasWIFGowHAzMyMUaNG8dlnn2FhYVEkhRqKXBoTZY1Gq+PDHy/y7aloACY9X5uxnTxLXSfizMxMHjx4oA882dnZhIeH06BBAyNXJoQoCUrU8HmA9PR0bty4gaIoeHp6Ym1tbbCiipIEIVGWZOZoGbMljN+v3EOtgk9facSbfjWMXVahXbhwgYCAAKytrTl27BhmZqWvT5MQomgZffh8eno677zzDq6urjg5OTFixAiqVq2Kt7d3qQlBQpQlSek5DFz7J79fuYeFqZrlA5qVuhCk0+n4+uuvad68ORcvXuTmzZtcv37d2GUJIcqRAgehjz/+mPXr19OzZ0/69evHvn37GDVqVFHWJoR4gpikDF5feZxTNx9ia2lK8HB/ujWoYuyyCiUmJobu3bszYcIEsrKy6NmzJxcuXKBevXrGLk0IUY4UeNTY999/z9q1a+nXrx/w6OaGrVu3RqvVYmJSOjtkClEaXb+fwqC1J7mblImznQUbhvlRt0rpusy7c+dOhg8fTkJCApaWlixYsIDAwMBS169JCFH6FTgIRUdH07ZtW/1jPz8/TE1NuXv3LtWrVy+S4oQQuZ2Jesiw9adITM+hZmUbNg7zo9pzpevStFarZc6cOSQkJODj48OWLVukFUgIYTQFvjSm1WoxNzfPtczU1FQ/ckwIUbQOXr1PwOoTJKbn4FO9ItsDW5W6EARgYmLC5s2bmTJlCidOnJAQJIQwqgKPGlOr1XTv3j3X8PiffvqJTp06YWNjo1/2/fffG75KA5JRY6I02h56myk7zqPVKXSoU5ll/ZtibV7o+VCNQqvVMn/+fDIzM5k5c6axyxFClFJGn1l68ODBeZYNGDDAYIUIIfJSFIWVRyL47NerALza1JXP+3hjZlLouVCNIjo6moEDB3L48GFUKhWvvfYaDRs2NHZZQgihV+AgFBQUVJR1CCH+QadT+HT3FdYeiwRgZLuaTO1et9R0KN66dSuBgYEkJiZiY2PD4sWLZXJEIUSJUzra1oUoZ7I1Ot7bfo6dZ+8C8GHPeoxoW9PIVRVMcnIyY8eOZePGjcCjgRWbN2/G09PTyJUJIUReEoSEKGFSszSM2hTK0fB4TNUqvni9Mb2buBq7rALRarW0adOGCxcuoFar+eCDD/joo49kpmghRIlVOjoaCFFOxKdmEbD6BEfD47E2N2HtkOalJgTBoxFh48ePx93dncOHDzN79mwJQUKIEu2p7zVWWsmoMVFSRT9IZ+DaP7mZkI6DjTlBQ5rTuHpFY5f1nyIiIoiPj8fPzw941ME7PT0912hSIYR4Vka/15gQouhcupvEq8uPczMhHdeKVmwPbFniQ5CiKGzcuJHGjRvTp08fHj58CIBKpZIQJIQoNZ4qCAUHB9O6dWtcXFy4desWAAsXLmTnzp0GLU6I8iDkRgL9Vp4gLiWLulVs+X50K2pWrmDssv7Vw4cP6devH4MHDyY1NRV3d3fS09ONXZYQQhRaoYPQ8uXLmTRpEj169CAxMRGtVgtAxYoVWbhwoaHrE6JM+/VCDIPXnSQlS4OfhwNbR7bE2c7S2GX9q0OHDuHt7c22bdswNTXl008/5dChQ7i6lp6+TEII8Vihg9DixYtZvXo1H3zwQa6brfr6+nLhwgWDFidEWRZ84hajt5whW6vjhQZV2DjMD3urktuxWKvVMnXqVDp16sTt27fx8vLi+PHjTJ8+XW68LIQotQodhCIjI2nSpEme5RYWFqSlpRmkKCHKMkVRWLDvGh/9eBFFgf7+NVjavymWZiU7TKjVam7cuIGiKIwYMYIzZ87QvHlzY5clhBDPpNDzCHl4eHD27Fnc3NxyLf/111+pX7++wQoToizSaHV8tPMS35yMAmBil9qM6+xZYmeLVhSFzMxMrKysUKlUrFy5koEDB/LSSy8ZuzQhhDCIQgeh9957j3feeYfMzEwUReHkyZN88803zJ07lzVr1hRFjUKUCZk5WsZ9E8Zvl++hVsEnvRvS39/tvzc0kri4OEaMGIG5uTnbtm1DpVLh4OAgIUgIUaYU+tLY0KFD+fjjj3n//fdJT08nICCAFStW8PXXX9OvX79CF7Bs2TI8PDywtLSkWbNmHD16tEDb/fHHH5iamuLj41PoYwpR3JIychi09iS/Xb6HuamaZf2blugQtGfPHry9vdm1axe7du3iypUrxi5JCCGKxDNNqBgfH49Op8PJyemptt+6dSsDBw5k2bJltG7dmpUrV7JmzRouX75MjRo1nrhdUlISTZs2xdPTk3v37nH27NkCH1MmVBTF7V5yJoPXneRqbAq2FqasHuxLi5qOxi4rX5mZmUyZMoVFixYBUL9+fbZs2ULjxo2NXJkQorwrqu9vo84s7e/vT9OmTVm+fLl+Wb169ejduzdz58594nb9+vXDy8sLExMTfvzxRwlCosS6EZfKoLUnuZOYgZOtBRuG+VGvasl83124cIGAgAAuXrwIwJgxY5g3bx5WVlZGrkwIIYru+/upOkv/W8fOiIiIAu0nOzub0NBQpk6dmmt5165dOX78+BO3CwoK4saNG2zatIk5c+b853GysrLIysrSP05OTi5QfUI8q7Cohwxbf4qH6TnUrGTDhmF+VHewNnZZ+dJqtbz66qtcv34dJycngoKC6NGjh7HLEkKIIlfoIDRhwoRcj3NycggLC2PPnj289957Bd5PfHw8Wq0WZ2fnXMudnZ2JjY3Nd5vw8HCmTp3K0aNHMTUtWOlz585l1qxZBa5LCEM4+Nd9Rm86Q0aOlsbVK7JusC+OFSyMXdYTmZiYsHr1ahYsWMCaNWue+nK3EEKUNoUOQuPHj893+dKlSzl9+nShC/hn65KiKPm2OGm1WgICApg1axa1a9cu8P6nTZvGpEmT9I+Tk5OpXr16oesUoqC+P3Ob97efR6NTaFe7Msv7N8XGotB/akVu165dpKamEhAQAECHDh3o0KGDcYsSQohiZrCbrnbv3p0dO3YUeP1KlSphYmKSp/Xn/v37eVqJAFJSUjh9+jRjxozB1NQUU1NTZs+ezblz5zA1NeXAgQP5HsfCwgI7O7tcP0IUlVVHbjBp2zk0OoVXmriyZpBviQtBaWlpBAYG8vLLL/P2229z48YNY5ckhBBGY7BP6O3bt+Pg4FDg9c3NzWnWrBn79u3jlVde0S/ft28fL7/8cp717ezs8tzCY9myZRw4cIDt27fj4eHx9MUL8Yx0OoW5v15h9dFIAN5q68G07vVQq0vWRImhoaEEBARw7do1AEaNGkW1atWMXJUQQhhPoYNQkyZNcl26UhSF2NhY4uLiWLZsWaH2NWnSJAYOHIivry8tW7Zk1apVREVFERgYCDy6rHXnzh02btyIWq2mYcOGubZ3cnLC0tIyz3IhilOOVsf728/zQ9gdAKb3qMvb7WoZuarctFot8+fP56OPPkKj0eDq6sqGDRvo3LmzsUsTQgijKnQQ6t27d67HarWaypUr06FDB+rWrVuoffXt25eEhARmz55NTEwMDRs2ZPfu3frbd8TExBAVFVXYEoUoNmlZGkZtPsORa3GYqlXMe82bV5uWrBYWjUZDt27d9JeP+/Tpw6pVqwrVgiuEEGVVoeYR0mg0bN68mW7dulGlSpWirKvIyDxCwlASUrMYtv4U524nYWVmwrIBTelYp2SOtpo+fTqLFi1i8eLFDBkypMTe20wIIZ6kxEyoaG1tzZUrV/LcdLW0kCAkDCH6QTqD150kIj6N56zNWDekOU1qPGfssvSSk5NJTEzUz9Cek5NDdHQ0NWvWNHJlQgjxdIrq+7vQo8b8/f0JCwszWAFClDZXYpLps/w4EfFpuFa0YvuoViUqBIWEhODj40OfPn3IyckBwMzMTEKQEELko9B9hEaPHs27777L7du3adasGTY2Nrl+7+3tbbDihChpTkQk8NbG06RkaqjjbMuGYX5Usbc0dlnAo0vXc+bMYc6cOWi1WnQ6HVFRUdSqVbI6bgshRElS4Etjw4YNY+HChVSsWDHvTlQq/USIWq3W0DUalFwaE09rz8UYxn17lmyNDj93B1YP9sXeyszYZQGPbm0zYMAAQkJCAOjfvz9Lly7F3t7eyJUJIYRhGL2PkImJCTExMWRkZPzreiW975AEIfE0Np24xYydF9Ep0LW+M4vebIKlmYmxy0JRFDZu3MiYMWNITU3Fzs6O5cuX62eLFkKIssLoN119nJdKetARwpAUReHr/eEs/D0cgDf9ajCnd0NMSshEiVqtlmXLlpGamkrbtm0JDg6Wv1EhhCiEQvURkiG3ojzR6hRm7LzI5j8fzWU1rrMXE7t4lYi/g8eXok1NTdm0aRM7duzgvffew8TE+K1UQghRmhT40pharcbe3v4/vwQePHhgkMKKilwaEwWRmaNlwrdn2XMpFpUKZr/ckIEtjN/Skp2dzYwZMzAxMeHTTz81djlCCFFsjH5pDGDWrFnS+VKUeUkZOby98TR/Rj7A3ETNwn4+9GhU1dhl8ddffxEQEMCZM2dQqVQMGjSIOnXqGLssIYQo1QoVhPr164eTU8mcOVcIQ7iXnMngdSe5GpuCrYUpqwb50rKWo1FrUhSFVatWMXHiRDIyMnBwcGD16tUSgoQQwgAKHIRKQr8IIYpSRFwqA9ee5E5iBpVtLdgw1I/6Lsa9fBoXF8eIESPYtWsXAF26dGH9+vW4uroatS4hhCgrCj1qTIiy6Fx0IkPXn+JBWjbujtYED/enuoO1UWvSaDS0bt2a8PBwzM3NmTt3LhMmTECtLvSE8EIIIZ6gwJ+oOp1OLouJMunwtTjeXH2CB2nZeFezZ/uoVkYPQQCmpqZMnz6devXq8eeffzJp0iQJQUIIYWCFvulqaSejxsTf/Rh2h8nfnUOjU2jrVYnlA5pRwaLQd54xmAsXLpCSkkKrVq2ARy2x2dnZWFhYGK0mIYQoCUrMTVeFKCvWHI1gwtazaHQKL/u4sHZwc6OFIJ1Ox9dff03z5s1544039NNQqFQqCUFCCFGEjPdfXyGMRKdT+HzPVVYeiQBgeBsPPuhRD7WRZouOiYlh6NCh7N27F4DGjRuX+Hv2CSFEWSFBSJQrOVodU7af5/uwOwBM7V6Xke1qGm1U5M6dOxkxYgTx8fFYWlry5ZdfMmrUKBmlKYQQxUSCkCg30rM1jN58hkN/xWGiVvF5H29ea1bNKLVoNBrGjBnDypUrAfDx8WHz5s3Ur1/fKPUIIUR5JX2ERLnwIC2bgNV/cuivOCzN1Kwe1MxoIQjAxMSEhw8fAjB58mROnDghIUgIIYxARo2JMu/2w3QGrTtJRFwaFa3NWDekOU1rPFfsdWi1WjIyMqhQoQIADx8+5OzZs3Ts2LHYaxFCiNJGRo0J8RSuxibTZ/lxIuLScLG3ZHtgS6OEoOjoaLp06cKgQYP0k5M+99xzEoKEEMLIpI+QKLNORj5g+IZTpGRqqO1cgQ3D/Khqb1XsdWzbto2RI0eSmJiIjY0N169fx8vLq9jrEEIIkZe0CIkyae+lWAas/ZOUTA2+bs/x3chWxR6CkpOTGTJkCH379iUxMRE/Pz/CwsIkBAkhRAkiQUiUOd+cjGLUplCyNTq61HNm0wh/7K3NirWGkJAQfHx82LBhA2q1mg8//JBjx45JCBJCiBJGLo2JMkNRFBYfuM6CfdcA6Ne8OnN6N8TUpHjzvkajYcCAAURGRuLm5samTZto06ZNsdYghBCiYKRFSJQJWp3CjJ2X9CFobCdP5r7aqNhDEDy6WWpQUBADBgzg3LlzEoKEEKIEk+HzotTLzNEyadtZdl+IRaWCWS81YFBL92I7vqIoBAcHoygKgwcPLrbjCiFEeVJU399yaUyUasmZOby98TQnIh5gbqLmq74+9PSuWmzHf/jwIYGBgWzbtg1ra2vatm1LzZo1i+34Qgghno0EIVFq3U/OZHDQKa7EJFPBwpRVA5vRyrNSsR3/0KFDDBw4kNu3b2NqasqHH36Im5tbsR1fCCHEs5MgJEqlyPg0Bq37k+gHGVSqYMH6oc1p6GpfLMfOzs5mxowZzJs3D0VR8PLyYvPmzTRv3rxYji+EEMJwJAiJUuf87USGBp0iIS0bN0drgof5U8PRuliOnZOTQ5s2bTh16hQAI0aM4KuvvtLfNkMIIUTpIkFIlCpHw+MYGRxKeraWhq52BA3xo7KtRbEd38zMjG7dunHjxg1Wr17Nq6++WmzHFkIIYXgyakyUGjvP3mHyd+fI0Sq08azEioHNqGBR9Fk+Li6OlJQUfSfonJwc4uPjqVq1+DplCyFEeSc3XRXl2tpjkYz/9iw5WoUXG7uwbkjzYglBe/bswdvbm9dff53s7GzgUauQhCAhhCgbJAiJEk1RFD779Sqf/HwZgCGt3Pm6rw/mpkX71s3MzGTChAl0796d2NhYMjMziY2NLdJjCiGEKH7SR0iUWDlaHdO+v8D20NsAvP9CHUa1r4VKpSrS4164cIGAgAAuXrwIwNixY/n888+xsir+O9cLIYQoWhKERImUka3lnS1nOHD1PiZqFXNfbcQbvtWL9Jg6nY7FixczZcoUsrKycHJyIigoiB49ehTpcYUQQhiPBCFR4jxMy2bYhlOERSViaaZmaUBTOtdzLvLj6nQ6vv32W7KysujVqxdr167FycmpyI8rhBDCeCQIiRLlTmIGg9b+yY24NOytzFg3xJdmbg5FekxFUVCpVJiamrJp0yb27dvHyJEji/wSnBBCCOOTICRKjGv3Uhi09iSxyZlUtbdk4zA/vJxti+x4aWlpTJo0CXt7e+bNmwdArVq1qFWrVpEdUwghRMkiQUiUCKdvPmDY+lMkZ2rwcqrAhmF+uFQsus7Jp0+fpn///ly7dg21Ws3IkSMlAAkhRDkkw+eF0e27fI/+a/4kOVNDM7fn+C6wZZGFIK1Wy2effUbLli25du0arq6u7Nu3T0KQEEKUU9IiJIxq66kopn1/AZ0Cnes6sSSgKVbmJkVyrKioKAYNGsThw4cB6NOnD6tWrcLBoWj7IAkhhCi5JAgJo1AUhaUHr/PFb9cAeMO3Gv97pRGmJkXTSJmdnU3btm2JiorCxsaGxYsXM2TIEOkQLYQQ5ZxcGhPFTqtTmLnrkj4EvdOxFp/38S6yEARgbm7OnDlz8PPz4+zZswwdOlRCkBBCCLnpqiheWRotk7ad45fzMahUMKNXfYa29iiSYx0/fpycnBzat28PPGqF0mq1mJpKQ6gQQpQ2ctNVUeqlZOYwNOgUv5yPwcxExaJ+TYokBGk0GmbOnEnbtm158803SUhIANDPFSSEEEI8Jt8KoljcT8lkaNApLt1NxsbchJUDfWnjVcngx4mIiKB///6cOHECgM6dO0v4EUII8UTyDSGK3M34NAatO0nUg3QqVTBn/VA/GrraG/QYiqKwceNGxowZQ2pqKvb29ixfvpw333zToMcRQghRtkgQEkXq4p0khgSdJD41mxoO1gQP98PN0cagx8jOzmbgwIFs27YNgLZt2xIcHIybm5tBjyOEEKLskT5CosgcC4+n78oQ4lOzaeBix45RrQweguDRiDBTU1NMTU359NNPOXjwoIQgIYQQBSKjxkSR+OncXSZtO0uOVqFVLUdWDmyGraWZwfafnZ1NRkYG9vaPLrElJSURHh6Or6+vwY4hhBCi5JBRY6LUWP9HJOO+DSNHq9DTuypBQ5sbNARdvXqVli1bMnjwYB7neHt7ewlBQgghCk2CkDAYRVGYt+cqM3+6jKLA4JZuLO7XBAtTw9wyQ1EUVq5cSdOmTTlz5gxHjx7l5s2bBtm3EEKI8kk6SwuD0Gh1TP/hAttO3wbgvW51GN2hlsFmb46Li2PEiBHs2rULgC5durBhwwZcXFwMsn8hhBDlkwQh8cwysrWM2XKG/Vfvo1bB3Fcb0bd5DYPtf8+ePQwdOpTY2FjMzc357LPPGD9+PGq1NGgKIYR4NhKExDNJTM9m+IbThN56iIWpmiUBTXm+vrPB9p+dnc3o0aOJjY2lfv36bNmyhcaNGxts/0IIIco3CULiqd1NzGDwupOE30/FztKUdUOa4+vuYNBjmJubExwczNatW/n888+xsrIy6P6FEEKUbzJ8XjyV8HspDFp3kpikTKrYWbJxuB+1nW2feb86nY7FixdjY2PDiBEjDFCpEEKIsqDMDp9ftmwZHh4eWFpa0qxZM44ePfrEdb///nuef/55KleujJ2dHS1btmTv3r3FWK0ACL31gNdWhBCTlImnUwV2jG5lkBAUExND9+7dmTBhAuPGjZMRYUIIIYqcUYPQ1q1bmTBhAh988AFhYWG0bduW7t27ExUVle/6R44c4fnnn2f37t2EhobSsWNHXnzxRcLCwoq58vLr98v36L/mT5IycmhSoyLfjWyJa8Vnv1y1c+dOGjVqxG+//YalpSVffvmlzA4thBCiyBn10pi/vz9NmzZl+fLl+mX16tWjd+/ezJ07t0D7aNCgAX379mXGjBkFWl8ujT29baejmfb9BbQ6hU51nVga0BQr82ebIygtLY13332XlStXAuDj48OWLVuoV6+eIUoWQghRRhTV97fROktnZ2cTGhrK1KlTcy3v2rUrx48fL9A+dDodKSkpODg8uYNuVlYWWVlZ+sfJyclPV3A5pigKyw7dYP7evwDo07Qan/VphJnJszUoZmVl4efnx+XLlwF47733+OSTT7CwsHjmmoUQQoiCMNqlsfj4eLRaLc7OuYdaOzs7ExsbW6B9fPnll6SlpfHGG288cZ25c+dib2+v/6levfoz1V3e6HQKs366rA9BozrU4ovXvZ85BAFYWFjw+uuv4+rqyu+//868efMkBAkhhChWRu8s/c+ZhxVFKdBsxN988w0zZ85k69atODk5PXG9adOmkZSUpP+Jjo5+5prLiyyNlvFbz7L++E0APupVnykv1H2m2aKjo6O5du2a/vGHH37I+fPn6dy587OWK4QQQhSa0S6NVapUCRMTkzytP/fv38/TSvRPW7duZfjw4Xz33Xd06dLlX9e1sLCQVoankJqlITA4lGPX4zEzUfHF64152cf1mfa5detWAgMDcXNz488//8TCwgJTU9N/vbQphBBCFCWjtQiZm5vTrFkz9u3bl2v5vn37aNWq1RO3++abbxgyZAhbtmyhZ8+eRV1muRSXkkW/VSEcux6PtbkJ64Y0f6YQlJyczODBg+nXrx+JiYlYWlry8OFDA1YshBBCPB2jziw9adIkBg4ciK+vLy1btmTVqlVERUURGBgIPLqsdefOHTZu3Ag8CkGDBg3i66+/pkWLFvrWJCsrK+zt7Y32PMqSWwlpDFp3klsJ6TjamBM0tDne1So+9f6OHz/OgAEDiIyMRK1W88EHH/DRRx9hZmZmuKKFEEKIp2TUINS3b18SEhKYPXs2MTExNGzYkN27d+vnj4mJick1p9DKlSvRaDS88847vPPOO/rlgwcPZv369cVdfplz8U4SQ4JOEZ+aRXUHKzYO88ejks1T7Uuj0TBnzhw++eQTdDod7u7uBAcH06ZNGwNXLYQQQjw9ucWGAOD49XjeDg4lNUtDvap2bBjWHCdby6fen0ajoX379voWoSVLlkirnRBCiKdW5uYREiXHz+fvMmnrObK1OlrUdGDVIF/sLAt/6UpRFHQ6HSYmJpiamrJp0yZOnDjBm2++WQRVCyGEEM9OglA5t+H4TWb+dAlFgR6NqvBVXx8sTAs/W/TDhw8JDAzE1dWVBQsWAODh4YGHh4ehSxZCCCEMRoJQOaUoCl/+do0lB68DMLCFGzNfaoCJuvBzBB06dIiBAwdy+/ZtzMzMmDBhAjVq1DB0yUIIIYTBGX1CRVH8NFodU3dc0IegSc/XZvbLhQ9B2dnZTJ06lU6dOnH79m28vLz4448/JAQJIYQoNaRFqJzJzNEyZksYv1+5h1oFn77SiDf9Ch9crl69Sv/+/Tlz5gwAI0aM4KuvvqJChQqGLlkIIYQoMhKEypGk9BxGbDzFqZsPsTBVs+jNJnRrUKXQ+8nKyqJTp07ExMTg4ODAmjVreOWVV4qgYiGEEKJoyaWxciImKYPXVx7n1M2H2FmaEjzc/6lCEDy6bckXX3xBly5duHDhgoQgIYQQpZbMI1QOXL+fwqC1J7mblImznQUbh/lTp4ptofaxZ88ezMzMct0ctaA3yBVCCCGeVVF9f0uLUBkXeushr60I4W5SJjUr27BjVKtChaDMzEzGjx9P9+7dGTBgAHFxcfrfSQgSQghR2kkfoTLswNV7jN58hswcHT7VK7JuSHMcbMwLvP2FCxcICAjg4sWLALz22mvSGVoIIUSZIkGojNoeepspO86j1Sl0qFOZZf2bYm1esNOt0+lYvHgxU6ZMISsrCycnJ4KCgujRo0cRVy2EEEIULwlCZYyiKKw8EsFnv14F4NWmrnzexxszk4JdBc3MzKR3797s3bsXgJ49e7Ju3TqcnJyKrGYhhBDCWCQIlSE6ncKcX66w7o9IAEa2r8nUF+oWqi+PpaUlTk5OWFpasmDBAgIDA6UvkBBCiDJLRo2VEdkaHZO/O8euc3cB+LBnPUa0rVmgbdPS0sjKysLBwQF49BrduXOHevXqFVm9QgghRGHIqDHxRKlZGoZvOMWuc3cxVatY2NenwCEoNDSUpk2bMnjwYB5nYjs7OwlBQgghygUJQqVcfGoWAatPcDQ8HmtzE9YOaU7vJq7/uZ1Wq+Xzzz+nRYsWXLt2jbCwMO7cuVMMFQshhBAlh/QRKsWiH6QzcO2f3ExIx8HGnKAhzWlcveJ/bxcdzcCBAzl8+DAAffr0YeXKlTg6OhZxxUIIIUTJIi1CpdSlu0m8uvw4NxPSqfacFdsDWxYoBG3duhVvb28OHz6MjY0Na9eu5bvvvpMQJIQQolySFqFSKORGAm9vPE1Kloa6VWzZOMwPJzvL/9wuMzOT6dOnk5iYiJ+fH5s3b8bT07MYKhZCCCFKJglCpczuCzFM+PYs2Vod/h4OrB7si52lWYG2tbS0ZPPmzfzyyy/MmDEDM7OCbSeEEEKUVRKESpHgE7eYsfMiigIvNKjCwn4+WJqZPHF9jUbDnDlzcHZ2ZtSoUQC0aNGCFi1aFFfJQgghRIkmQagUUBSFr34PZ9H+cAD6+9dg9ssNMVE/eaLDiIgIBgwYQEhICJaWlrz44otUq1atuEoWQgghSgUJQiWcRqvjo52X+OZkFAATu9RmXGfPJ872rCgKwcHBvPPOO6SmpmJnZ8fy5cslBAkhhBD5kCBUgmXmaBn3TRi/Xb6HWgWf9G5If3+3J67/8OFDAgMD2bZtGwBt27YlODgYN7cnbyOEEEKUZxKESqikjBze2nCakzcfYG6qZlE/H15oWPWJ62dkZNCsWTMiIyMxNTVl1qxZTJkyBROTJ/chEkIIIco7CUIlUGxSJoPXneSveynYWpiyerAvLWr++zw/VlZWDB06lODgYDZv3kzz5s2LqVohhBCi9JKbrpYw1++nMnjdSe4kZuBka8GGYX7Uq5p/nX/99Rc6nU5/XzCNRkNmZiYVKlQozpKFEEKIIic3XS0HwqIe8vqK49xJzKBmJRt2jGqVbwhSFIWVK1fSpEkT+vbtS2ZmJgCmpqYSgoQQQohCkEtjJcTBv+4zetMZMnK0NK5ekXWDfXGsYJFnvbi4OEaMGMGuXbsAcHJyIjU1FUvL/55ZWgghhBC5SYtQCbAj9DZvbThNRo6WdrUrs2WEf74haO/evXh7e7Nr1y7Mzc358ssv+e2336hUqZIRqhZCCCFKP2kRMrJVR27wv91XAXiliSvzXvPGzCR3Ps3OzmbKlCksXLgQgPr167NlyxYaN25c3OUKIYQQZYq0CBmJTqfw6S+X9SHorbYefPl64zwhCMDExITQ0FAAxowZw+nTpyUECSGEEAYgLUJGkKPV8f728/wQdgeA6T3q8na7WrnW0el0aLVazMzMMDExITg4mEuXLtGjRw9jlCyEEEKUSRKEillaloZRm89w5FocpmoV817z5tWmuW9/ERMTw9ChQ6lbt67+cpibm5vMEC2EEEIYmFwaK0YJqVkErD7BkWtxWJmZsGawb54QtHPnTry9vdm7dy+rV6/m7t27RqpWCCGEKPskCBWT6AfpvLYihHO3k3jO2owtb/nToY6T/vdpaWkEBgbSu3dv4uPj8fHx4fTp07i4uBixaiGEEKJsk0tjxeBKTDKD153kfkoWrhWt2Djcj1qV///Eh6GhoQQEBHDt2jUAJk+ezJw5c7CwyDuEXgghhBCGI0GoiJ2ISOCtDadJydJQx9mWDcP8qGL//yc/TE9Pp3v37sTFxeHq6sqGDRvo3LmzESsWQgghyg8JQkVoz8UYxn17lmyNDj93B1YP9sXeyizXOtbW1ixatIjt27ezcuVKHB3//eaqQgghhDAcuelqEdl04hYzdl5Ep0DX+s4serMJlmYmAGzbtg17e3u6deumX19RFFQqVZHVI4QQQpRmRfX9LS1CBqYoCl/vD2fh7+EAvOlXgzm9G2KiVpGcnMy4cePYsGEDTk5OXLx4kcqVKwNICBJCCCGMQIKQAWl1Ch/tvMiWP6MAGNfZi4ldvFCpVISEhNC/f38iIyNRq9WMHDmSihUrGrdgIYQQopyTIGQgmTlaJnx7lj2XYlGpYPbLDRnYwg2NRsOcOXOYM2cOWq0WNzc3Nm3aRJs2bYxdshBCCFHuSRAygKSMHN7aeJqTkQ8wN1GzsJ8PPRpVJT09nS5duhASEgJA//79Wbp0Kfb29kauWAghhBAgEyo+s3vJmfRdGcLJyAfYWpiyYZgfPRpVBR6NCKtduzZ2dnZs3ryZTZs2SQgSQgghShAZNfYMIuJSGbj2JHcSM6hsa8GGoX5UtdKi0Wj0naBTUlJISEjA3d3dANULIYQQ5VNRjRqTFqGndDY6kddWhHAnMQOPSjZ8P6oV96+dwdvbmyFDhvA4X9ra2koIEkIIIUooCUJP4fC1OAJWn+BBWjbe1ezZMqwZS+fNplOnTty+fZvw8HDu3btn7DKFEEII8R+ks3Qh/Rh2h8nfnUOjU2jrVYmJfhXo9XwHzpw5A8CIESP46quvqFChwn/sSQghhBDGJkGoENYcjWDOL1cAeKlxVeo8/JM2/u+SkZGBg4MDq1ev5tVXXzVylUIIIYQoKAlCBaDTKXy+5yorj0QAMLyNBxM7uOHj8wYZGRl06dKF9evX4+rqauRKhRBCCFEYEoT+Q45Wx5Tt5/k+7A4A07rX5e12NVGpVGzevJljx44xceJE1GrpbiWEEEKUNhKE/kV6tobRm89w6K84VLoc6kX/RNa5xqjajwPA398ff39/I1cphBBCiKclQegJHqRlM3T9Kc5FJ6J6eAvVwcX8Gn6Vgz9a8sYbb1ClShVjlyiEEEKIZyRBKB+3H6YzaN1JbtxPQXP+F+IOBJGTnY2TkxNBQUESgoQQQogyQoLQP1yNTWbwupPcuRtD6m9fkxQeCkCvXr1Yu3YtTk5ORq5QCCGEEIYiQehvTkY+YPiGUyQlpxIXPJHs5AQsLS1ZsGABgYGBqFQqY5cohBBCCAOSIPR/9l6KZew3YWRrdPjXrkr9SRPY9eMOtmzZQr169YxdnhBCCCGKgNx0FdjyZxTvrfgBRW1Kj3b+LAlogpkaNBoNFhYWRq5YCCGEEGX2pqvLli3Dw8MDS0tLmjVrxtGjR/91/cOHD9OsWTMsLS2pWbMmK1aseOpjK4rCV3uv8s6UGdzd+C45+77iqz71sDQzwcTEREKQEEIIUcYZNQht3bqVCRMm8MEHHxAWFkbbtm3p3r07UVFR+a4fGRlJjx49aNu2LWFhYUyfPp1x48axY8eOQh9bq1MYv3Y/0956ncTDG0Cnpb2fDzqt5lmflhBCCCFKCaNeGvP396dp06YsX75cv6xevXr07t2buXPn5ll/ypQp7Nq1iytXruiXBQYGcu7cOUJCQgp0zMdNax3fnsHhDV+iy0rDwsqa5UuXMGTIEOkQLYQQQpRAZe7SWHZ2NqGhoXTt2jXX8q5du3L8+PF8twkJCcmzfrdu3Th9+jQ5OTmFOv7BVbPRZaVRu2ETLp4/x9ChQyUECSGEEOWM0UaNxcfHo9VqcXZ2zrXc2dmZ2NjYfLeJjY3Nd32NRkN8fDxVq1bNs01WVhZZWVn6x0lJSfp/B7w1hkVzZ2JmZkZycvKzPB0hhBBCFKHH39OGvpBl9OHz/2yFURTlX1tm8ls/v+WPzZ07l1mzZuX7uy2rl7Bl9ZLClCuEEEIII0pISMDe3t5g+zNaEKpUqRImJiZ5Wn/u37+fp9XnsSpVquS7vqmpKY6OjvluM23aNCZNmqR/nJiYiJubG1FRUQZ9IcXTSU5Opnr16kRHRxv0mq8oPDkXJYeci5JDzkXJkZSURI0aNXBwcDDofo0WhMzNzWnWrBn79u3jlVde0S/ft28fL7/8cr7btGzZkp9++inXst9++w1fX1/MzMzy3cbCwiLfYfD29vbypi5B7Ozs5HyUEHIuSg45FyWHnIuSQ602bPdmow6fnzRpEmvWrGHdunVcuXKFiRMnEhUVRWBgIPCoNWfQoEH69QMDA7l16xaTJk3iypUrrFu3jrVr1zJ58mRjPQUhhBBClGJG7SPUt29fEhISmD17NjExMTRs2JDdu3fj5uYGQExMTK45hTw8PNi9ezcTJ05k6dKluLi4sGjRIvr06WOspyCEEEKIUszonaVHjx7N6NGj8/3d+vXr8yxr3749Z86ceerjWVhY8PHHH8us0SWEnI+SQ85FySHnouSQc1FyFNW5KHf3GhNCCCGEeMzo9xoTQgghhDAWCUJCCCGEKLckCAkhhBCi3JIgJIQQQohyq0wGoWXLluHh4YGlpSXNmjXj6NGj/7r+4cOHadasGZaWltSsWZMVK1YUU6VlX2HOxffff8/zzz9P5cqVsbOzo2XLluzdu7cYqy37Cvu38dgff/yBqakpPj4+RVtgOVLYc5GVlcUHH3yAm5sbFhYW1KpVi3Xr1hVTtWVbYc/F5s2bady4MdbW1lStWpWhQ4eSkJBQTNWWXUeOHOHFF1/ExcUFlUrFjz/++J/bGOT7Wyljvv32W8XMzExZvXq1cvnyZWX8+PGKjY2NcuvWrXzXj4iIUKytrZXx48crly9fVlavXq2YmZkp27dvL+bKy57Cnovx48crn3/+uXLy5Enl2rVryrRp0xQzMzPlzJkzxVx52VTY8/FYYmKiUrNmTaVr165K48aNi6fYMu5pzsVLL72k+Pv7K/v27VMiIyOVP//8U/njjz+KseqyqbDn4ujRo4parVa+/vprJSIiQjl69KjSoEEDpXfv3sVcedmze/du5YMPPlB27NihAMoPP/zwr+sb6vu7zAUhPz8/JTAwMNeyunXrKlOnTs13/ffff1+pW7durmUjR45UWrRoUWQ1lheFPRf5qV+/vjJr1ixDl1YuPe356Nu3r/Lhhx8qH3/8sQQhAynsufj1118Ve3t7JSEhoTjKK1cKey7mz5+v1KxZM9eyRYsWKdWqVSuyGsujggQhQ31/l6lLY9nZ2YSGhtK1a9dcy7t27crx48fz3SYkJCTP+t26deP06dPk5OQUWa1l3dOci3/S6XSkpKQY/AZ75dHTno+goCBu3LjBxx9/XNQllhtPcy527dqFr68v8+bNw9XVldq1azN58mQyMjKKo+Qy62nORatWrbh9+za7d+9GURTu3bvH9u3b6dmzZ3GULP7GUN/fRp9Z2pDi4+PRarV57l7v7Oyc5671j8XGxua7vkajIT4+nqpVqxZZvWXZ05yLf/ryyy9JS0vjjTfeKIoSy5WnOR/h4eFMnTqVo0ePYmpapj4qjOppzkVERATHjh3D0tKSH374gfj4eEaPHs2DBw+kn9AzeJpz0apVKzZv3kzfvn3JzMxEo9Hw0ksvsXjx4uIoWfyNob6/y1SL0GMqlSrXY0VR8iz7r/XzWy4Kr7Dn4rFvvvmGmTNnsnXrVpycnIqqvHKnoOdDq9USEBDArFmzqF27dnGVV64U5m9Dp9OhUqnYvHkzfn5+9OjRgwULFrB+/XppFTKAwpyLy5cvM27cOGbMmEFoaCh79uwhMjJSf7NwUbwM8f1dpv6bV6lSJUxMTPIk+fv37+dJjY9VqVIl3/VNTU1xdHQsslrLuqc5F49t3bqV4cOH891339GlS5eiLLPcKOz5SElJ4fTp04SFhTFmzBjg0ZexoiiYmpry22+/0alTp2Kpvax5mr+NqlWr4urqir29vX5ZvXr1UBSF27dv4+XlVaQ1l1VPcy7mzp1L69atee+99wDw9vbGxsaGtm3bMmfOHLmKUIwM9f1dplqEzM3NadasGfv27cu1fN++fbRq1SrfbVq2bJln/d9++w1fX1/MzMyKrNay7mnOBTxqCRoyZAhbtmyRa+4GVNjzYWdnx4ULFzh79qz+JzAwkDp16nD27Fn8/f2Lq/Qy52n+Nlq3bs3du3dJTU3VL7t27RpqtZpq1aoVab1l2dOci/T0dNTq3F+dJiYmwP9vjRDFw2Df34XqWl0KPB4KuXbtWuXy5cvKhAkTFBsbG+XmzZuKoijK1KlTlYEDB+rXfzz8buLEicrly5eVtWvXyvB5AynsudiyZYtiamqqLF26VImJidH/JCYmGusplCmFPR//JKPGDKew5yIlJUWpVq2a8tprrymXLl1SDh8+rHh5eSkjRoww1lMoMwp7LoKCghRTU1Nl2bJlyo0bN5Rjx44pvr6+ip+fn7GeQpmRkpKihIWFKWFhYQqgLFiwQAkLC9NPZVBU399lLggpiqIsXbpUcXNzU8zNzZWmTZsqhw8f1v9u8ODBSvv27XOtf+jQIaVJkyaKubm54u7urixfvryYKy67CnMu2rdvrwB5fgYPHlz8hZdRhf3b+DsJQoZV2HNx5coVpUuXLoqVlZVSrVo1ZdKkSUp6enoxV102FfZcLFq0SKlfv75iZWWlVK1aVenfv79y+/btYq667Dl48OC/fgcU1fe3SlGkLU8IIYQQ5VOZ6iMkhBBCCFEYEoSEEEIIUW5JEBJCCCFEuSVBSAghhBDllgQhIYQQQpRbEoSEEEIIUW5JEBJCCCFEuSVBSAiRy/r166lYsaKxy3hq7u7uLFy48F/XmTlzJj4+PsVSjxCiZJMgJEQZNGTIEFQqVZ6f69evG7s01q9fn6umqlWr8sYbbxAZGWmQ/Z86dYq3335b/1ilUvHjjz/mWmfy5Mns37/fIMd7kn8+T2dnZ1588UUuXbpU6P2U5mAqREknQUiIMuqFF14gJiYm14+Hh4exywIe3dQ1JiaGu3fvsmXLFs6ePctLL72EVqt95n1XrlwZa2vrf12nQoUKhbo79dP6+/P85ZdfSEtLo2fPnmRnZxf5sYUQBSNBSIgyysLCgipVquT6MTExYcGCBTRq1AgbGxuqV/9/7d1rSJPvGwfw76ZbrqkdfJGah+Fk6YuK7KAZFZah7EfGwlE5UiRLU1vYwepNE8IgxEMFaS9iphgq5UKokDyWGjSV0lWIkowoJSI1UlOn1+/Fnx6c2rnfP2jXB3xxH5571+0NevE813h8kZqaavdW89mePn2KiIgIuLm5wd3dHWvXrkVbW5sw3traii1btkAmk8HX1xd6vR4jIyNfjU0kEsHT0xNeXl6IiIiAwWCAxWIR7lgVFhZCqVRCKpVixYoVKC0ttbs+KysLfn5+WLBgAby9vaHX64WxmY/GFAoFAECj0UAkEgntmY/Gampq4OLigqGhIbvP0Ov12Lp162/b57p165CRkQGr1Yru7m5hztfOo7GxEYmJiRgeHhbuLGVlZQEAJiYmkJmZieXLl0MulyM0NBSNjY1fjYcxNhcnQow5GLFYjEuXLsFiseD69euor69HZmbmF+frdDr4+PjAbDajvb0dp0+fhkQiAQB0dXUhKioKu3fvRmdnJyoqKtDc3Iz09PQfikkmkwEAJicnYTKZcPToURw/fhwWiwXJyclITExEQ0MDAODmzZvIz8/H1atX0dPTg9u3b2PlypXzrms2mwEARqMR/f39QnumyMhILF68GLdu3RL6pqamUFlZCZ1O99v2OTQ0hBs3bgCA8PsDvn4e4eHhKCgoEO4s9ff348SJEwCAxMREtLS0oLy8HJ2dndBqtYiOjkZPT893x8QYA/7Kt88z5ugSEhLIycmJ5HK58BMbGzvv3MrKSvLw8BDaRqORFi1aJLTd3NyouLh43mv3799Phw4dsut7+PAhicViGhsbm/ea2eu/evWKwsLCyMfHh8bHxyk8PJwOHjxod41WqyW1Wk1ERLm5uaRSqWhiYmLe9f39/Sk/P19oAyCTyWQ3x2Aw0OrVq4W2Xq+nbdu2Ce2amhqSSqX0/v37X9onAJLL5bRw4ULhTdoxMTHzzv/sW+dBRNTb20sikYhev35t1799+3Y6c+bMV9dnjNlz/rNpGGPsvxIREYHCwkKhLZfLAQANDQ04f/48nj9/jg8fPsBms+HTp08YGRkR5sx07NgxJCUlobS0FJGRkdBqtVAqlQCA9vZ29Pb2oqysTJhPRJienkZfXx+Cg4PnjW14eBiurq4gIoyOjiIkJARVVVWQSqV48eKFXbEzAGzatAkXL14EAGi1WhQUFCAgIADR0dFQq9XYuXMnnJ1//s+ZTqfDxo0b8ebNG3h7e6OsrAxqtRpLliz5pX26ubmho6MDNpsNTU1NyMnJQVFRkd2cHz0PAOjo6AARQaVS2fWPj4//X2qfGPubcCLE2F9KLpcjMDDQrs9qtUKtViMlJQXnzp3D0qVL0dzcjAMHDmBycnLedbKyshAXF4c7d+7g3r17MBgMKC8vh0ajwfT0NJKTk+1qdD7z8/P7YmyfEwSxWIxly5bN+YcvEons2kQk9Pn6+qK7uxv3799HbW0tUlNTkZOTg6amJrtHTj9iw4YNUCqVKC8vx+HDh2EymWA0GoXxn92nWCwWziAoKAgDAwPYs2cPHjx4AODnzuNzPE5OTmhvb4eTk5PdmKur6w/tnTFHx4kQYw6kra0NNpsNubm5EIv/VyJYWVn5zetUKhVUKhUyMjKwb98+GI1GaDQahISE4NmzZ3MSrm+ZmSDMFhwcjObmZsTHxwt9ra2tdnddZDIZYmJiEBMTg7S0NAQFBaGrqwshISFz1pNIJN/1bbS4uDiUlZXBx8cHYrEY//zzjzD2s/ucLSMjA3l5eTCZTNBoNN91HlKpdE78a9aswdTUFN6+fYvNmzf/UkyMOToulmbMgSiVSthsNly+fBkvX75EaWnpnEc1M42NjSE9PR2NjY2wWq1oaWmB2WwWkpJTp07h0aNHSEtLw5MnT9DT04Pq6mocOXLkp2M8efIkiouLUVRUhJ6eHuTl5aGqqkooEi4uLsa1a9dgsViEPchkMvj7+8+7nkKhQF1dHQYGBjA4OPjFz9XpdOjo6EB2djZiY2Ph4uIijP2ufbq7uyMpKQkGgwFE9F3noVAo8PHjR9TV1eHdu3cYHR2FSqWCTqdDfHw8qqqq0NfXB7PZjAsXLuDu3bs/FBNjDu9PFigxxv4bCQkJtGvXrnnH8vLyyMvLi2QyGUVFRVFJSQkBoMHBQSKyL84dHx+nvXv3kq+vL0mlUvL29qb09HS7AuHHjx/Tjh07yNXVleRyOa1atYqys7O/GNt8xb+zXblyhQICAkgikZBKpaKSkhJhzGQyUWhoKLm7u5NcLqewsDCqra0VxmcXS1dXV1NgYCA5OzuTv78/Ec0tlv5s/fr1BIDq6+vnjP2ufVqtVnJ2dqaKigoi+vZ5EBGlpKSQh4cHASCDwUBERBMTE3T27FlSKBQkkUjI09OTNBoNdXZ2fjEmxthcIiKiP5uKMcYYY4z9GfxojDHGGGMOixMhxhhjjDksToQYY4wx5rA4EWKMMcaYw+JEiDHGGGMOixMhxhhjjDksToQYY4wx5rA4EWKMMcaYw+JEiDHGGGMOixMhxhhjjDksToQYY4wx5rA4EWKMMcaYw/oXgdelF5tx/dgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a SVC model with the PCA transformed data\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# split the data in train and test set\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=34)\n",
    "mask = np.logical_and(df.columns != 'PCR', df.columns != 'ratio_red_NDVI2')\n",
    "pca.fit(df.loc[:, mask])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca.transform(df.loc[:, mask]), df['PCR'], test_size=0.2, random_state=0)\n",
    "\n",
    "# train the model\n",
    "svc = SVC(kernel='rbf', class_weight='balanced', random_state=0)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# print the metrics\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print('Confusion matrix: ', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print the f1 score\n",
    "print('f1_score', f1_score(y_test, y_pred))\n",
    "\n",
    "# print the precision score\n",
    "print('precision_score', precision_score(y_test, y_pred))\n",
    "\n",
    "# print the recall score\n",
    "print('recall_score', recall_score(y_test, y_pred))\n",
    "\n",
    "# print the roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "\n",
    "# print the auc score\n",
    "print('auc_score', auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "387dfbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3Rc5Zn48e/0rt57sapl2XLv3QbTMSWEvkBCQhJCCJuEkA2QTWAhgbAHkrDZ0Db8SEhCD6HZgI2xwXLHttwlWVYvo+n93t8fQsKyitVHst7POT6gmTv3PjO6mvvctzyvQpZlGUEQBEEQhElEGe4ABEEQBEEQxppIgARBEARBmHREAiQIgiAIwqQjEiBBEARBECYdkQAJgiAIgjDpiARIEARBEIRJRyRAgiAIgiBMOiIBEgRBEARh0hEJkCAIgiAIk45IgAbh+eefR6FQdP3T6/UkJSWxYsUKHn74YZqamkb1+FVVVSgUCp5//vlBve7mm28mKytrVGLqT2e8v/nNb8b82COh8/ddVVUV7lCG5OWXX2bq1KkYDAYUCgV79uwJd0hUVFRwww03kJOTg16vJy4ujpkzZ/Ld734Xu91OIBAgMTGR+fPn97kPSZLIyMigtLQUgI8//rjrb7Kvv42VK1eiUChG7O/ggQceQKFQjMi+hkqhUPDAAw90e2zjxo3Mnj0bk8mEQqHg9ddfnxDncW/fUQ899BCvv/56j20738+OHTvGJrgh6jxHOv9pNBoyMjL4xje+QUNDQ4/ts7KyelxfpkyZwt13301LS0u/+z7931NPPdVvXFlZWVx00UUj+l7HSm/n/HCoR2xPk8hzzz1HYWEhgUCApqYmtmzZwiOPPMJvfvMbXn75ZVavXj0qx01OTmbbtm3k5uYO6nX/8R//wfe///1RiUkYn5qbm7nhhhs4//zz+f3vf49OpyM/Pz+sMe3evZtFixZRVFTEz3/+c7KysmhpaWHv3r389a9/5Z577iErK4sbbriBxx57jIMHD1JcXNxjPxs2bKCmpoYf/vCH3R63WCw888wz3Hzzzd0er6ys5OOPPyYiImI0396Y27ZtG2lpaV0/y7LM1VdfTX5+Pm+++SYmk4mCggKCwSDbtm0jOTk5jNH2r7fvqIceeogrr7ySyy67LDxBjZB3332XyMhInE4n77//Po899hhbt25lz549aDSabtsuWrSo64bR4/GwY8cOHnjgATZv3txrwte579NlZ2eP3ps5x4gEaAhKSkqYPXt2189XXHEFP/jBD1i8eDHr16/n6NGjJCYmjvhxdTpdv3fGfRlswiSMDrfbjdFoHJNjHTlyhEAgwPXXX8+yZcvG5Jhn88QTT6BUKvn444+xWCxdj1955ZX853/+J53LEt5666089thjPPvss722Hj777LNotVquv/76bo9/7Wtf409/+hNHjx4lLy+v2/apqalMmzaNgwcPjtK7G3tnfhfU1dXR1tbG5ZdfzqpVq7o9Fx8fP2LHHY3z+Fz+jpo1axZxcXEArF69mpaWFp577jm2bNnCihUrum0bFRXV7fe6YsUKHA4H//mf/8mRI0d63MScvu/xYiy/54ZLdIGNkIyMDB577DEcDgf/8z//0+25HTt2cMkllxATE4Ner6esrIy//e1vPfZRW1vLN7/5TdLT09FqtaSkpHDllVfS2NgI9N4F1tzc3PUanU5HfHw8ixYtYsOGDV3b9Na87PV6uffee8nOzkar1ZKamsp3vvMd2tvbu23X2Vz67rvvMnPmTAwGA4WFhTz77LMD/mwkSeJXv/oVGRkZ6PV6Zs+ezcaNG3tst2XLFlatWoXFYsFoNLJw4ULefvvtbtv01fXQWzP/YGL/7LPPWLRoEXq9npSUFO69914CgUCP7V5++WXWrl1LcnIyBoOBoqIifvKTn+Byubptd/PNN2M2m/niiy9Yu3YtFouFVatW8Z//+Z+o1Wpqamp67PuWW24hNjYWr9fb52cJ8Oabb7JgwQKMRiMWi4U1a9awbdu2bsdevHgx0JEUKBQKli9f3uf+mpubueOOOyguLsZsNpOQkMDKlSv55JNPum13epfm448/TnZ2NmazmQULFvDZZ5/1GzNAa2srERERmM3mXp/v/L0WFRWxYMEC/vznPxMMBrtt097ezhtvvMGll15KbGxst+fWrFlDenp6t9+vJEm88MIL3HTTTSiVA/+6e/fdd1m1ahWRkZEYjUaKiop4+OGH+33NQM+NEydOcM0115CSkoJOpyMxMZFVq1Z166L88MMPWb58ObGxsRgMBjIyMrjiiitwu93dPq/O7oAHHnigqzXoxz/+cbfuvr66wDZs2MCqVauIiIjAaDSyaNGiHn+XnX9vu3bt4sorryQ6OrrPZMVut6NWq/n1r3/d9VhLSwtKpZLIyMhuv8s777yT+Pj4rqT3zO8ohUKBy+XihRde6OraOfMcdjgcfPvb3yYuLo7Y2FjWr19PXV1dr7GdbseOHVxzzTVkZWVhMBjIysri61//OtXV1d226/zcPvrooyEdpy+dN8+d3+tn09nCc2Zr0Uj6/e9/j1qt5v777+96bLjnx2C+fxsaGrj99ttJS0tDq9WSnZ3Ngw8+2OPvf6SJBGgEXXDBBahUKjZv3tz12EcffcSiRYtob2/n6aef5o033mDGjBl87Wtf65bI1NbWMmfOHF577TXuvvtu3nnnHZ544gkiIyOxWq19HvOGG27g9ddf5+c//znvv/8+f/rTn1i9ejWtra19vkaWZS677DJ+85vfcMMNN/D2229z991388ILL7By5Up8Pl+37ffu3csPf/hDfvCDH/DGG29QWlrKrbfe2u199uepp57i3Xff5YknnuDFF19EqVSybt26bhftTZs2sXLlSmw2G8888wx/+ctfsFgsXHzxxbz88ssDOk5vBhL7wYMHWbVqFe3t7Tz//PM8/fTT7N69m1/+8pc99nf06FEuuOACnnnmGd59913uuusu/va3v3HxxRf32Nbv93PJJZewcuVK3njjDR588EFuv/121Gp1jyS5ra2Nv/71r9x6663o9fo+389LL73EpZdeSkREBH/5y1945plnsFqtLF++nC1btgAd3Qm/+93vgI5uhG3btvH73/++z322tbUBcP/99/P222/z3HPPkZOTw/Lly/n44497bP+73/2ODz74gCeeeIL/9//+Hy6XiwsuuACbzdbnMQAWLFhAfX091113HZs2bcLj8fS57a233kpTU1OPBPill17C6/Vy66239niNUqnk5ptv5v/+7/8IhUIAvP/++5w6dYp/+7d/6ze20z3zzDNccMEFSJLE008/zVtvvcWdd97JqVOn+n3dQM+NCy64gJ07d/Loo4/ywQcf8Ic//IGysrKum4+qqiouvPBCtFotzz77LO+++y7/9V//hclkwu/393rs2267jVdffRWA733ve2zbto3XXnutz1hffPFF1q5dS0REBC+88AJ/+9vfiImJ4bzzzuv15mT9+vVMmTKFv//97zz99NO97jMiIoI5c+Z0u/nauHEjOp0Oh8PB9u3bux7fsGFD17is3mzbtg2DwcAFF1zAtm3bej2Hb7vtNjQaDS+99BKPPvooH3/8cY9Wwd5UVVVRUFDAE088wXvvvccjjzxCfX09c+bM6THWZjjH6UtlZSVAr13SsiwTDAYJBoM4nU4++ugjnnjiCRYtWtRr11YoFOraPhgMdp33AyXLMvfccw933XUXf/rTn3jwwQeBkTs/BvL929DQwNy5c3nvvff4+c9/zjvvvMOtt97Kww8/zDe+8Y1BvZ9Bk4UBe+6552RALi8v73ObxMREuaioqOvnwsJCuaysTA4EAt22u+iii+Tk5GQ5FArJsizLt9xyi6zRaOSDBw/2ue/KykoZkJ977rmux8xms3zXXXf1G/dNN90kZ2Zmdv387rvvyoD86KOPdtvu5ZdflgH5j3/8Y9djmZmZsl6vl6urq7se83g8ckxMjHz77bf3e9zOeFNSUmSPx9P1uN1ul2NiYuTVq1d3PTZ//nw5ISFBdjgcXY8Fg0G5pKRETktLkyVJkmVZlu+//365t9O283dTWVk56Ni/9rWvyQaDQW5oaOh27MLCwh77PJ0kSXIgEJA3bdokA/LevXu7nrvppptkQH722Wd7vO6mm26SExISZJ/P1/XYI488IiuVyj6PJcuyHAqF5JSUFHnatGld540sy7LD4ZATEhLkhQsXdj320UcfyYD897//vc/99SUYDMqBQEBetWqVfPnll3c93vn7nDZtmhwMBrse3759uwzIf/nLX/rdr9frlS+77DIZkAFZpVLJZWVl8n333Sc3NTV129bhcMhms1m+5JJLuj0+a9YsOT09vdv7P/29njhxQlYoFPI///lPWZZl+aqrrpKXL18uy7IsX3jhhd3+DnrjcDjkiIgIefHixV3nXG/6Og879XVutLS0yID8xBNP9Pnaf/zjHzIg79mzp99YAfn+++/v+rnz9/PrX/+623Zn/m24XC45JiZGvvjii7ttFwqF5OnTp8tz587t8T5//vOf9xtLp5/97GeywWCQvV6vLMuyfNttt8nnn3++XFpaKj/44IOyLMtybW1tj++ZM7+jZFmWTSaTfNNNN/U4Ruf7ueOOO7o9/uijj8qAXF9fP6BYOwWDQdnpdMomk0n+7//+7xE7Tudn19DQIAcCAdlqtcp/+9vfZJPJJH/961/vsX1mZmbX38bp/+bOndvjWJ37PvNfamrqWd9vZmamfOGFF8put1u+4oor5MjISHnDhg1dz4/U+THQ79/bb79dNpvN3baTZVn+zW9+IwPygQMHuh4785wfLtECNMLkL5t0AY4dO8ahQ4e47rrrALpl6hdccAH19fUcPnwYgHfeeYcVK1ZQVFQ0qOPNnTuX559/nl/+8pd89tlnvXbbnOnDDz8E6DFY9KqrrsJkMvXI8GfMmEFGRkbXz3q9nvz8/B5Nxn1Zv359t1aNzpadzZs3EwqFcLlcfP7551x55ZXdukdUKhU33HADp06d6vqcBmsgsX/00UesWrWq27gtlUrF1772tR77O3HiBNdeey1JSUmoVCo0Gk3XGJuKiooe219xxRU9Hvv+979PU1MTf//734GObpo//OEPXHjhhf3OUjp8+DB1dXXccMMN3bpzzGYzV1xxBZ999lm3LpLBePrpp5k5cyZ6vR61Wo1Go2Hjxo29vqcLL7wQlUrV9XPnbKyznQ86nY7XXnuNgwcP8tvf/pZrrrmG5uZmfvWrX1FUVNTtd2w2m7n66qv517/+1dVVsH//fnbu3MnNN9/cZ3dWdnY2y5cv59lnn6W1tZU33niDW265ZcCfw9atW7Hb7dxxxx2DnuU1kHMjJiaG3Nxcfv3rX/P444+ze/duJEnqtp8ZM2ag1Wr55je/yQsvvMCJEycGFcfZbN26lba2Nm666aZu30mSJHH++edTXl7eo9uut/O4N6tWrcLj8bB161ago6VnzZo1rF69mg8++KDrMWDYk0UuueSSbj8P9Dx0Op38+Mc/ZsqUKajVatRqNWazGZfL1ev5PtTjdEpKSkKj0RAdHc3VV1/NrFmzeOGFF3rddvHixZSXl1NeXs6nn37KM888Q3NzMytXruy1dWrDhg1d25eXl/Ovf/1rQDG1traycuVKtm/f3jX0oNNInh8D+f795z//yYoVK0hJSel2vHXr1gEdvQOjRSRAI8jlctHa2kpKSgrwVR/vPffcg0aj6fbvjjvuAOg6qZubm7vN6Biol19+mZtuuok//elPLFiwgJiYGG688cZep1l2am1tRa1W9xgYqVAoSEpK6tF9duZYC+i4mPXXhXG6pKSkXh/z+/04nU6sViuyLPc6S6Xzs+yvS68/A4m9tbW1zxhP53Q6WbJkCZ9//jm//OUv+fjjjykvL+/qejjz8zAajb3OPCorK2PJkiVd3VT//Oc/qaqq4rvf/W6/76XzM+jrc5Ikqd/u0r48/vjjfPvb32bevHm88sorfPbZZ5SXl3P++ef3+js+8zPV6XRAz/ffl6KiIu666y5efPFFTp48yeOPP05rayv/8R//0W27W2+9lWAwyJ///GegYzCzQqE4a3fWrbfeyltvvcXjjz+OwWDgyiuvHFBc0PF3CAz6b3Gg54ZCoWDjxo2cd955PProo8ycOZP4+HjuvPNOHA4H0DEgeMOGDSQkJPCd73yH3NxccnNz+e///u9BxdSXzu+lK6+8ssf30iOPPIIsy13dop0GOoNs4cKFGI1GNmzYwLFjx6iqqupKgD7//HOcTicbNmwgJydn2LOVhnoeXnvttTz11FPcdtttvPfee2zfvp3y8nLi4+NH5XzvTFLee+89rrjiCjZv3sz3vve9XreNjIxk9uzZzJ49m4ULF3LLLbfw0ksvUVFRwWOPPdZj++nTp3dtP3v27K7k7GyOHDnC559/zrp16ygpKen23EieHwP5/m1sbOStt97qcaypU6cC9Jr4jRQxC2wEvf3224RCoa7Bep2j8++9917Wr1/f62sKCgqAjlkaZxtj0Ju4uDieeOIJnnjiCU6ePMmbb77JT37yE5qamnj33Xd7fU1sbCzBYJDm5uZuSZAsyzQ0NDBnzpxBx9Gf3pKxhoYGtFotZrMZtVqNUqmkvr6+x3adgw07P8vOliSfz9f1RQTD+yOJjY3tM8bTffjhh9TV1fHxxx93m1l15sDxTv21INx5551cddVV7Nq1i6eeeor8/HzWrFlz1jiBPj8npVJJdHR0v/vozYsvvsjy5cv5wx/+0O3xzgvyaFIoFPzgBz/gF7/4Bfv37+/23MKFCykqKuK5557j+9//Pi+++CIrV64864Vz/fr1fOc73+G//uu/+MY3voHBYBhwPJ1/D4P9WxzMuZGZmckzzzwDdFyI/va3v/HAAw/g9/u7xk8sWbKEJUuWEAqF2LFjB08++SR33XUXiYmJXHPNNYOK7Uydf0tPPvlkn7NKz5zFOtDWMK1Wy+LFi9mwYQNpaWkkJSUxbdo0cnJygI6aTRs3bgxbHRqbzcY///lP7r//fn7yk590Pe7z+Xpc1EfK9OnTuz7zNWvWcN555/HHP/6RW2+9dUDftZ1Jzd69e0cspgULFnDVVVd1jaX7wx/+0NWqOprnR2/i4uIoLS3lV7/6Va/Pd94EjwbRAjRCTp48yT333ENkZCS333470JHc5OXlsXfv3m5Z+un/OqcDr1u3jo8++mjIXT3QMRPtu9/9LmvWrGHXrl19btfZ3Pniiy92e/yVV17B5XL1mEI7XK+++mq3mU0Oh4O33nqLJUuWoFKpMJlMzJs3j1dffbXbnYEkSbz44oukpaV1DRjs7CLat29ft2O89dZbQ45vxYoVbNy4sdusjFAo1GPwdecf+emJF9BjQPNAXH755WRkZPDDH/6QDRs2DKjLpaCggNTUVF566aVuXa0ul4tXXnmla2bYYCkUih7vad++fd0GqY+E3hI36Eje7HZ7r190t9xyCwcPHuRnP/sZzc3NA+rOMhgM/PznP+fiiy/m29/+9qBiXLhwIZGRkTz99NPdPuOzGeq5kZ+fz89+9jOmTZvW69+sSqVi3rx5Xa2F/f1dD9SiRYuIiori4MGDfX4vabXaIe9/9erV7Ny5k1deeaWrm8tkMjF//nyefPJJ6urqBtT9NZhW5oFSKBTIstzj9/SnP/1p0AOIh3r83/3ud6hUKn72s58N6DWdswMTEhJGNJabbrqJv/71rzz33HPceOONXe9/tM+PM1100UXs37+f3NzcXo81mgmQaAEagv3793f1UzY1NfHJJ5/w3HPPoVKpeO2117q1qvzP//wP69at47zzzuPmm28mNTWVtrY2Kioq2LVrV9c4kF/84he88847LF26lJ/+9KdMmzaN9vZ23n33Xe6++24KCwt7xGGz2VixYgXXXnsthYWFWCwWysvLeffdd/tscYKv7kJ+/OMfY7fbWbRoEfv27eP++++nrKyMG264YUQ/L5VKxZo1a7j77ruRJIlHHnkEu93eNeMA4OGHH2bNmjWsWLGCe+65B61Wy+9//3v279/PX/7yl64LzAUXXEBMTAy33norv/jFL1Cr1Tz//PO9TisfqJ/97Ge8+eabrFy5kp///OcYjUZ+97vf9ejnXrhwIdHR0XzrW9/i/vvvR6PR8P/+3/8b0p2ZSqXiO9/5Dj/+8Y8xmUw9xmP1RqlU8uijj3Lddddx0UUXcfvtt+Pz+fj1r39Ne3s7//Vf/zXoOKDjC+g///M/uf/++1m2bBmHDx/mF7/4BdnZ2SM6DfWb3/wm7e3tXHHFFZSUlKBSqTh06BC//e1vUSqV/PjHP+7xmhtvvJGf/vSn/PrXvyYqKqrf8/p0d999N3ffffegYzSbzTz22GPcdtttrF69mm984xskJiZy7Ngx9u7d22eV3YGeG/v27eO73/0uV111FXl5eWi1Wj788EP27dvX1SLx9NNP8+GHH3LhhReSkZGB1+vtmjo8EkVWzWYzTz75JDfddBNtbW1ceeWVJCQk0NzczN69e2lubu7RGjgYq1atIhQKsXHjxm5jXVavXs3999+PQqFg5cqVZ93PtGnT+Pjjj3nrrbdITk7GYrF0tZgPVUREBEuXLuXXv/41cXFxZGVlsWnTJp555hmioqKGte+BysvL45vf/Ca///3v2bJlS1fJCuhoMewsKREIBKioqOChhx5Cp9Pxne98Z8RjufLKKzEajVx55ZV4PB7+8pe/jPr5caZf/OIXfPDBByxcuJA777yTgoICvF4vVVVV/Otf/+Lpp58e0vCQARmx4dSTQOesgM5/Wq1WTkhIkJctWyY/9NBDPWaydNq7d6989dVXywkJCbJGo5GTkpLklStXyk8//XS37WpqauRbbrlFTkpKkjUajZySkiJfffXVcmNjoyzLPWeBeb1e+Vvf+pZcWloqR0REyAaDQS4oKJDvv/9+2eVyde23txkWHo9H/vGPfyxnZmbKGo1GTk5Olr/97W/LVqu123adMwbOtGzZMnnZsmX9fl6d8T7yyCPygw8+KKelpclarVYuKyuT33vvvR7bf/LJJ/LKlStlk8kkGwwGef78+fJbb73VY7vt27fLCxculE0mk5yamirff//98p/+9KdeZ4ENNPZPP/1Unj9/vqzT6eSkpCT53//93+U//vGPPfa5detWecGCBbLRaJTj4+Pl2267Td61a1eP2Xk33XSTbDKZ+v18qqqqZED+1re+1e92Z3r99dflefPmyXq9XjaZTPKqVavkTz/9tNs2g5kF5vP55HvuuUdOTU2V9Xq9PHPmTPn111/vcd70NctIlgc2O+O9996Tb7nlFrm4uFiOjIyU1Wq1nJycLK9fv17etm1bn6+7/PLLe52NM9j3OpBZYJ3+9a9/ycuWLZNNJpNsNBrl4uJi+ZFHHul6vrdZYAM5NxobG+Wbb75ZLiwslE0mk2w2m+XS0lL5t7/9bdfMum3btsmXX365nJmZKet0Ojk2NlZetmyZ/Oabb3Y73pmf+UBngXXatGmTfOGFF8oxMTGyRqORU1NT5QsvvLDb59j5Ppubmwf0uclyxwy4uLg4GZBra2u7Hv/0009lQJ45c2aP1/T2HbVnzx550aJFstFolIGuv9m+ZuN2ngcfffRRv/GdOnVKvuKKK+To6GjZYrHI559/vrx//345MzOz26yz4R6nv8+usbFRNpvN8ooVK7oeO3MWmEqlkjMyMuQrr7xS3r1794D3fTa9fS9+9NFHstlsls8//3zZ7XbLsjz882Mw37/Nzc3ynXfeKWdnZ8sajUaOiYmRZ82aJd93332y0+ns2m4g3zODofhyp4IgjLEnn3ySO++8k/3793cN+BMEQRDGhkiABGGM7d69m8rKSm6//XYWLVrU64KPgiAIwugSCZAgjLGsrCwaGhpYsmQJf/7zn3udgi8IgiCMLpEACYIgCIIw6Yhp8IIgCIIgTDoiARIEQRAEYdIRCZAgCIIgCJOOKIR4BkmSqKurw2KxDKu8tyAIgiAIY0eWZRwOBykpKX0umHw6kQCdoa6ujvT09HCHIQiCIAjCENTU1AyoerRIgM7QuTbXZ//3V8xDWFdJEITx7dCWHRzcvB2lUsn0tUvInimKUApD4z15gqSp6RjyCjnsM/H5kWYyI3Vnf6EwKtwuJ9dfuLDrOn42IgE6Q2e3l9loxGIyhTkaQRBGWtHcGeALoFaryS8rQW8SNzrC0KgNBiJMJgwWC2atGYPJg8msD3dYk95Ah6+IBEgQhEnFHB3JnEuGv6ioIAgTm5gFJgiCIAjCpCMSIEEQBEEQJh2RAAmCIAiCMOmIBEgQBEEQhElHJECCIAiCIEw6IgESBEEQBGHSEQmQIAiCIAiTjkiABEEQBGEoPA5kWcLpC9FgdYU7GmGQRCFEQRAEQRgET9Ux8DhInlNMS2Iux61qTjQ6yY4SVaAnEpEACYIgCMIAeaqOIbttRJd1JD9bmlR4vCL5mYhEAiQIgiAIA+Cp2I0sS0SXFbMvfjr1TT483oBIfiYokQAJgiAIwll4qo6RMrcEQ0ExFT4zJw41diQ+elW4QxOGaNwMgt68eTMXX3wxKSkpKBQKXn/99W7Py7LMAw88QEpKCgaDgeXLl3PgwIFu2/h8Pr73ve8RFxeHyWTikksu4dSpU2P4LgRBEARBmAjGTQLkcrmYPn06Tz31VK/PP/roozz++OM89dRTlJeXk5SUxJo1a3A4HF3b3HXXXbz22mv89a9/ZcuWLTidTi666CJCodBYvQ1BEARBECaAcdMFtm7dOtatW9frc7Is88QTT3Dfffexfv16AF544QUSExN56aWXuP3227HZbDzzzDP8+c9/ZvXq1QC8+OKLpKens2HDBs4777wxey+CMFHIkkRLTT0anZaopPhwhyMIgjBmxk0LUH8qKytpaGhg7dq1XY/pdDqWLVvG1q1bAdi5cyeBQKDbNikpKZSUlHRt0xufz4fdbu/2TxAmixO7D7D15bf59K9v01QpuosFQZg8JkQC1NDQAEBiYmK3xxMTE7uea2hoQKvVEh0d3ec2vXn44YeJjIzs+peenj7C0QvC+OVsbcfrdOO22XFZbeEORxAEYcxMiASok0Kh6PazLMs9HjvT2ba59957sdlsXf9qampGJFZBCJe2uka2vPQmO97cgM/t6XfbzOlFpBblkjm9kKS8rLEJUBAEYRwYN2OA+pOUlAR0tPIkJyd3Pd7U1NTVKpSUlITf78dqtXZrBWpqamLhwoV97lun06HT6UYpckEYe5W7DlB3+ARKlYr4rHQySwv63DYqMY7FX794DKMTBEEYHyZEC1B2djZJSUl88MEHXY/5/X42bdrUldzMmjULjUbTbZv6+nr279/fbwIkCOcaS2wUWqMBY1QE5piIcIcjCIIwLo2bFiCn08mxY8e6fq6srGTPnj3ExMSQkZHBXXfdxUMPPUReXh55eXk89NBDGI1Grr32WgAiIyO59dZb+eEPf0hsbCwxMTHcc889TJs2rWtWmCBMBlPmziA6JRGtXkdkYly4wxEEQRiXxk0CtGPHDlasWNH189133w3ATTfdxPPPP8+PfvQjPB4Pd9xxB1arlXnz5vH+++9jsVi6XvPb3/4WtVrN1VdfjcfjYdWqVTz//POoVKJSpzAxhCSJ9/af5HiznWX5KZSmDz6BUaqUxGemjkJ0giAI5w6FLMtyuIMYT+x2O5GRkez/x5tYTKZwhyNMMlUtDp7cuBebx09OfAQ/WTcLpbL/gf6CIIw+T8VukucUI2UXUS5Wfx+XXE4H65eXYrPZiIg4e/f/uGkBEgQBIg1aok16fMEQyZEmkfwIQph5qo6Bx0HUjEJaEnM5LpKfc4ZIgARhHIk26fjm0mIa7R5yEyLDHY4gTGqeqmPIbhvRZcU05S9kd1UbHq9Ifs4VIgEShHEmIcJIQoQx3GEIwqTmqdiNLEskfe0qyq1q6qvaSNKrxOrv5xCRAAmTUntDM0c/24MxykLBwlmotZpwhyQIwjjhqTpGytwSDAXFVPjMnGhsFK0+5yCRAAmT0uGtu6jeewiVVk10cgIpBTnhDkkQBEEYQyIBEiYlY6QFlUaN3mREZzKEO5wJz+t0U723Ao1eR+b0QlRq8dUiCML4Jr6lhEmpaMkcolMS0JtNxKYln/0FQr+Obd/Dwc3laLRaNDot6SX54Q5JEAShXyIBEiYltVZDWtGUcIdxzlAolCiVShRKBQrlhFhhRxCESU4kQIIgDNuUedPRmQyodVpSCrLDHY4gCMJZiQRIEIRh0xkNTJk7PdxhCIIgDJhIgARBEMKg/kglJ3YdIC49mfwFZaLrUBDGmPiLE4QBsDe3Ub3vEK52e7hDEc4BsiRx4OPPOXXwKIe37qK9sSXcIQnCpCMSIEE4C5/bw/bX3ufzV9+n/I0NhILBcIckTHQKBeaYSNQaDYYIMzqTqPwtCGNNdIEJwlkE/QF8bi9SKITP5UYKSajEX44wDAqFgrILlpMxrQBLXDTGCPNZX+NxuAAZg+Xs2wqCcHbia1wQzsIYaWHaqgU0VtaQVpiLRqcNd0jCOUBnNAy4AnnLyTp2vvUhkiwx84LlJOZkjHJ0k1fn6u+yLHHS6qHBpwh3SMIoEQmQIJyFQqEgY1oBGdMKwh2KcJpQIEjD8Wq0Bj1xGSkoFOfuhar1VAPtDc3IskxrTYNIgEZJZ/ITNaOQlsRctjSpxOrv5zCRAAmCMCEd3rabQ5+UozXombt+LQlZaeEOadQkZKcRl5mKLIVIzE0PdzjnJE/VMWS3jeiyYpryF7K7qg2PNyCSn3OYSIAEIcx8bg/OtnYiE+LEqvSD4LE7CfoDyLKMz+kOdzijKjo5gWU3Xg4gzpERdnqXl/biS9nnM1Jf1UaSXgV6Vdd2siyz71AVLe12puVnkhAbFb6ghREhEiBBCCO/18dn/3gHa30zKQU5zLl09TndlTOS8uZNRwqF0JsMJOVlhTucUScSn9GTMrcEQ0ExFT4zJ0429trqU9vYyoate3A4PDS12Pj6xUvDEKkwkkQCJAinkUISpw4eJeD1kTY1D51xdFeK99id2Jra8LnctJ1qIBQIigvdAEXExzDn0tXhDiNsHK1WWmsaiE1PwhIbHe5wznkatRqNSo1SpUSnEZfOc4H4LQrCaeqPVrLrXx8T8PrwOFyUrFwwqsezxEaTNaOIxmPV5MyeJpIfYUACPj/lr2+gpaaeuPRkllx/qZidOMoS46K4aNUcrDYnUzJTwh2OMAJEAiQIp5ElGTkkIcsyUig06sdTqpSUrl6EvGpht64vv8fL3g+24LbaKV4+j/jM1FGPZbxwWm1U7jyAzmwgd/Y0VGrxNXWmUDCIz+1BCnX8NxQMjlgCJMsygOiK7UVOehKIMejnDPHNIginSc7PonTtYvweH1kzisbsuGdebJoqT1G9p4JQKITebJpUCdDRbbs5+vle1DoNxkgLaUVTwh3SuKM3GSlds4j6I1Uk52WhH6FK0q1OL3/ZfhSPP8hVs3PJiosYkf0KwngkEiBBOI1KrSZ39rRwh4E5JhJzTBRel5uopLhwhzOm1DotSrUStUaDWiO6BPuSWphLamHuiO7zQF0be2takCSZHVVNIgESzmkiARKEcSgqKZ5F11yEz+0hJjUp3OGMqYJFszDHRKEz6knMFQX/xlJKlImkCCP+UIj0GEu4wxGEUSUSIEEYpyxx0ViYfLN7tHod2WXF4Q5jUpqSEMn3Vk3DH5JIjTKFOxxBGFUiARIEQRC6JESIlemFyUEZ7gAEQRg6R6uVpsoaQoFguEMRBEGYUEQLkCBMUI4WK1v/9jZum4Pc2aWUrlkU7pAEQRAmDJEACcIE5Wq342q3E/T5sTW2hDscQZhwTl8H7KTVQ4NP1D6aTEQCJAgTVFxGCjkzS7A3t5G/sCzc4QjChNKZ/ETNKKQlMZctTSo8XqdY/X0SEQmQIExQaq2GGeeLBRkFYbA8FbuRZYnosmL2xU+nvsmHxxsQyc8kM2EGQQeDQX72s5+RnZ2NwWAgJyeHX/ziF0iS1LWNLMs88MADpKSkYDAYWL58OQcOHAhj1IIgCMJ44ak6hqdiN8lzitFefCn74qdzotFJkl4lkp9JaMIkQI888ghPP/00Tz31FBUVFTz66KP8+te/5sknn+za5tFHH+Xxxx/nqaeeory8nKSkJNasWYPD4Qhj5MJkEPD6sDW2jMn6YYIgDF3K3BKMhSW4jPGcaBRdXpPZhOkC27ZtG5deeikXXnghAFlZWfzlL39hx44dQEfrzxNPPMF9993H+vXrAXjhhRdITEzkpZde4vbbbw9b7MK5ze/x8tk/3qW9oZmMaQWiW0oQBGECmDAtQIsXL2bjxo0cOXIEgL1797JlyxYuuOACACorK2loaGDt2rVdr9HpdCxbtoytW7f2uV+fz4fdbu/2TxAGw2m1Ya1vwuNw0njiJFJIOvuLBEEQhLCaMC1AP/7xj7HZbBQWFqJSqQiFQvzqV7/i61//OgANDQ0AJCYmdntdYmIi1dXVfe734Ycf5sEHHxy9wIVzXmR8LKmFubScrCN3dilK1YS5rxAEQZi0JkwC9PLLL/Piiy/y0ksvMXXqVPbs2cNdd91FSkoKN910U9d2CkX3Og6yLPd47HT33nsvd999d9fPdrud9PT0kX8DwjlLpVEz6+KVSMEQKs2E+ZMSBEEYF2wONy1WGykJsRj02jE77oT5tv73f/93fvKTn3DNNdcAMG3aNKqrq3n44Ye56aabSErqWDG7oaGB5OTkrtc1NTX1aBU6nU6nQ6fTjW7wwjlPoVCI5EcQBGGQ3F4fr763lYZmK3lZKaw/byFK5dgUpJwwbfVutxulsnu4KpWqaxp8dnY2SUlJfPDBB13P+/1+Nm3axMKFC8c0VkEQBEEQzs7l9tJud+LzB2husxMaw5m0E+aW9eKLL+ZXv/oVGRkZTJ06ld27d/P4449zyy23AB134HfddRcPPfQQeXl55OXl8dBDD2E0Grn22mvDHL0gCIIQdl8ue+H0hWiwusIdjQDERkUwZ3o+lScbKZuag2YMW9InTAL05JNP8h//8R/ccccdNDU1kZKSwu23387Pf/7zrm1+9KMf4fF4uOOOO7BarcybN4/3338fi8USxsgFQRCEcOpc9iJ5TjEtibkct6pFDaBxQqlUsHhWMYtnFY/5sRWyLMtjftRxzG63ExkZyf5/vInFZAp3OIIgCMIweKqOIbttRJcV40rL+3LNL7HsxbnI5XSwfnkpNpuNiIiIs24/YVqAhNHhc3s48NFn+NweipfOJTIxLtwhCYIgjIjONb+SvnYV5VY19U0+kvQq0KvCHZowDogEaJKrP1rFiZ37kYIh9CYjZRcsD3dIZxX0BwgGAuhNxnCHIgjCOOWpOkbK3BIMBcVU+MycaGwUrT5CNyIBmuSMERYMEWYCXh+mmKhwh3NWbruT8tffx93uoGjZXLKmF4U7JEEQBGECEgnQJJeQncaCqy4g4PMRn5kW7nDOylrXSHN1HaFAgFMHjooEaIJw2520nKwjOikeS1z0sPcnyzL25jY0Oi3GSDHJQRCEwRMJkEBMat+FIseb6OQE4tKTcdscpBZNCXc4wgBIoRA73thA44mTRKcksuTaS9CZDMPaZ9WeCg58tA2NXsfcy9cSnZwwQtEKgjBZiARImFCMkRYWX3sJAZ8Pg8Uc7nCEAZBCEh6Hk1AwhM/pJuDzDzsBaqttwGm1o1KrsDW1igRokGxNrXgdLuIyUkQFc2HSEme+MOGotRrUWk24wxAGSK3VMG3VImoOHCEhOx1T9Nmnp55N+tR82uub0RoNJGSLtfsGw9bYwta//QuPw0XevOlMWyUq5QuTk0iABEEYdSkF2aQUZI/Y/hKy01hxy1UolIp+FzsWenLbHLjtDkL+II4Wa7jDEYSwEQnQOaTV6eXd/dWolEoumJZJhGHsVtUVhLGmVE2YpQzHlfisNKbMLsXR1k7e/BnhDmdUdS57IQi9EQnQOeTzEw18fLgWpUJJYoSBFYXjf1aXIAhjS63VMP28JeEOY1R1FkCUstd2FEC0tYkaQEIPIgE6h0QYdBi1GtRKJZEGXbjDEYQJJRQMUnvoBEqlkpSCHNHCNAF1rvkVNaMQV1oe5WLNL6EfIgE6hyzITSTKqEWlVFKQGBXucIRJRApJE348TtWeCva+/wlKpZKyC5aTWVoY7pCEQTh9za+m/IXsrmrD4xXJj9A3kQCdQ1RKJSWpseEOQ5hkGk+c5IsNWzFGWph54Qr05om5REnA5yfoD6BQKgl4/eEORxiEzpafKTdeQ4XPzO6qNrHml3BWIgESBGFYqvceovVUPdb6JtKm5pFRkh/ukIYka3oRQZ8PhVJFxrSJ+R4ms5S5JV3/7/EGRPIjnJVIgARBGJaYtCQaT5xEZzQQGR8T7nCGTG82UrJS1MQRhMlCJEDCpCaFJAI+H1qDfkKPXwmn3NnTiMtIQavXiXW5BEGYMEQCJExaQX+AHW9uwFrXRO7saeQvnBnukCYkhUJBVGJcuMMQwkQKSdhb2jBYTOiMw1viZCg6x/+4/UGarR4afOJGRhgYMc9TmLRsTa00HD+JvaWNyj0HkSUp3CEJwoRzYNNnbP6/19j68tt4HK4xPXbnzK+oGYU05S9kS5NKTHsXBky0AAmTliUumti0ZGyNzaQU5qBQivsBQRisphOnvlzsNoij1YrBYhr1Y3a2+siyhPbiS9nnM1IvZn4JgyQSIGHS0up1LLhqHV6nG1OUGLsiCGcjyzLN1bUEvD6ScjNRadTkzplG0O8nOjmB6OSEUY+hM/lJnlNMS2Iux31G0eojDIlIgIRJTa3VYI6JDHcYgjAhNFXWsP31Dwh4fRQvnUvh4tlkTS8ifWoeSpVqzCYSpMwtwVBQjMtn5sTJRpH8CEMiEiBBEARhQLxODz6Xh1AwiMfu7HpcpRaXEmHiEWetIAiCMCAp+VkULCjD6/aQO6c03OEIwrCIBEgQhB6aKk/hbGsnOT8Lg8Uc7nCEcUKj1zFt9aJwhyEII0JMexEEoZv2xhbK39jAzrc+ZO/7W8IdzoQkSxL25jb8Xl+4Qwm7oD+ALMvhDkMQehAtQIIwiQV8fva+9wm2plaKlswhpSCboD9AKBBAkiSCvq8WBXW0Wmk8XkNUcjxx6clhjHr8q/hkB8d3fIElNor5V66bsAvEDtex8n0c+3wvMWlJzLxgOWqtJtwhCUIXkQAJwiTWWlPPyS8OE/D7OVa+l5SCbGJTE5m2eiGOFisZpYVAR7Xfnf/8iKYTJ4lIiGXp9ZeJZS/60XCsGrfNQdDnx97cNikTIFmWObHjC2xNLXhdbnJnTyM2LSncYQlCF5EACcIkZo6JwhIXjbvdTmxqx8VJoVSSXTb1jC1lQv4AUkgiFAghhUJjH+wEkj2zGL/HS1RSHNHJ8eEOJywUCgVJuZl4XR4iE2JHpNzE6QUQT4plL4RhUsiic7Ybu91OZGQk+//xJhbT6Fc0Fc4dsixTd/gEtqZWUgtyiJwg62O5bQ48DifRyQkoVX1X0W09VU/toRPEpiaRWpQ77OPWVhyn4Xg1yXnZpBRkD3t/403QH0ClVk3qCuNSSOqoDh1hRqvXDWtfnclP1IxCXGl5bGlS4fEGRA0goYvL6WD98lJsNhsRERFn3V60AAnCCLE3t7Hnnc0429pprqpl6Q2XTYgV5o2RlgF1Z8WmJRObNjJjf7xON/s2bMHW1EpzVS2x6UlhWUhzNInxLqBUKYlMiB32fjwVu5FlieiyYvbFT6e+ySeSH2HYRAIkCCNEoVCgUCpQKBQoJ/Fd/0Co1Cq0BgNKlQqtUS8K6Qm96nXNL5tPrPkljAjxrSMIIyQiPoaZF67A3txGcl7WhGj9CReNXsecS1fTeqqBuIxk0Voi9Klz2YsKseyFMMIm1G1qbW0t119/PbGxsRiNRmbMmMHOnTu7npdlmQceeICUlBQMBgPLly/nwIEDYYxYCAWDONvakUJSuEMZE0lTMslfUIYlLjrcoYx7EfExZJcVY4kVn9VoC/j8tNU1EvQHwh2KIIwbEyYBslqtLFq0CI1GwzvvvMPBgwd57LHHiIqK6trm0Ucf5fHHH+epp56ivLycpKQk1qxZg8PhCF/gk1goEGT7ax/w0fOvsOe9zaIY2mn8Xh+hYDDcYQiTQCgQZPur7/HJn19nx5sbJs3NiCCczYTpAnvkkUdIT0/nueee63osKyur6/9lWeaJJ57gvvvuY/369QC88MILJCYm8tJLL3H77bePdciTntvmoOVkLW6bg4Zj1QS8PrQG0Xx9quIY+zduwxBhZs5lazBGnH2pCSkU4vDWXThb28mdU0pMauIYRCqcCzxOF9b6ZrwuN221jQS8PnSmoQ849zhchAIBTNGRY9bN6/SJsgvCyJswLUBvvvkms2fP5qqrriIhIYGysjL+93//t+v5yspKGhoaWLt2bddjOp2OZcuWsXXr1nCEPOmZoiNIzs/GEhtN+tQ8NMOcBnuuOHXgKLamFpoqa2itqR/Qa5qrazm0ZSeVuw9Q8cn2UY5QOJeYIi1kzigkMjGe7JklaI1Dvwlpb2jmkxdfZ9P/vUbNgaMjGGVPnordyG4bbn+Qcqua3VVto3o8YfKZMC1AJ06c4A9/+AN33303P/3pT9m+fTt33nknOp2OG2+8kYaGBgASE7vfGScmJlJdXd3nfn0+Hz7fV+v12O320XkDE0AoGOTUweNIoRDpU/OGPTBVqVIx68IV+D0+tEa9GBT8paQpWbSeasBgMRGdnND1uCzLtLl8WPQatOruM1x0RgM6k4FQMIgxQlRgFgZOoVQybeVCpi6bj1I1vHtea30T7Y0tSKEQLSfryCjJH6Eov9I58yt5TjEtibns8xk50ejsGPwsZn4JI2jCJECSJDF79mweeughAMrKyjhw4AB/+MMfuPHGG7u2O/MiK8tyvxfehx9+mAcffHB0gp5gag4cZffbH3esAeX3kzdvxrD3qVAqh9XcPlp8Lg/Hd3yBUq0id1bJmLZOZU4vJD4rFY1e16043Lv7T7LpcB2p0SZuWVyESfdVAhqVFM+89efhtjlIzM0Y8ZjqDp+g7nAlSVMySSueMuL7nygkSaayxY5WrSI95uxdkxPJcJMfgPisNBJzMvB7PKSNQDHMM3mqjiG7bUSXdSQ/HcUOnWLmlzAqJkwClJycTHFxcbfHioqKeOWVVwBISuoo49/Q0EBy8lfF2pqamnq0Cp3u3nvv5e677+762W63k56ePpKhTxhSMEQoFEIKSUjBc7PPXQpJ2FvaOLn/MIc+2dFRh0avI2dWyZjFoFAoMEX1rFK6q7qZFqcHTyBIvc3NlITuSwfEpiWNylpKfo+XfR98SntjM81Vp4hNT8ZgmZxV0LedaODVnSfQqZXcuLCQwmQxQ+105uhIllx3KbIkodKM7OWjs+UnZW4J1dnz2V3VJoodCqNqwiRAixYt4vDhw90eO3LkCJmZmQBkZ2eTlJTEBx98QFlZGQB+v59NmzbxyCOP9LlfnU6HTifGpgCkl+QT8PqQJImsGcVnf8EEdGhLOce27yPg7VjlXKVWj/gX+VDNy07E7Q+SFm0mNWrsEhClSoXOZECpUqM1GsbN5xEODe1ubB4fKqWSZodHJEC9UKqUMAKtSb3prPmDj2ElP4FgCIfTTWSECZUoSir0YcJ80/3gBz9g4cKFPPTQQ1x99dVs376dP/7xj/zxj38EOu6q77rrLh566CHy8vLIy8vjoYcewmg0cu2114Y5+olBo9NSsGhWuMMYVU2Vp/A4XKi0avLmTSc2LXncdPmsKk5jXm4iBo0a9ShdYHqj1mqYc+lqWk7WE5OaOOw1myayebmJ1NvcGLQqpqUNfwkHYewFgiHe3PA5J+uaKcxN4/ylM8X4Q6FXEyYBmjNnDq+99hr33nsvv/jFL8jOzuaJJ57guuuu69rmRz/6ER6PhzvuuAOr1cq8efN4//33sVjEoFGhQ87safg9XiIT4yhZsWDIY3+kkMTJ/Yfxe7xklBSgNxuHHZtCocCi1w57P0NhjonCHBMVlmOPJ2nRZr67alq4wxCGwWZ3UV3bhN3p5nh1PT5/AL0uPH9XwvgmVoM/g1gN/twnhUIolMph3RXWHa5k++vvE/B4yV8wk+nnLRnBCAVhcjlz5tfx02d+9cLX3k7th5tRqFSkrVqGxvzVgPVQSOKdTTupPNVISX4my+eViBagSUKsBi+MK36Pl/qj1RgjzcRnpoY7HKBjzMuIkEEGUeFaCBu3zYGzzUZMauKEXU9tKDO/WnbsoWHzVlAq0cfGkLx4QddzKpWSC5bPxuv3Y9BpRfIj9EkkQMKo2v/hNk7sOoDBYmbh1RcQnZJw9hdNAElTMplx/lJ8bg8Z0wrCHY5wjnBabbhtDmJTk846GN3jcLHtb//C3txGekkesy9ZPUZRjhxPxW5kWSLpa1dRblVT3zSwld7VZjNqoxGFSonG3LOlXqlUYJzEY9mEgREJkDCqvE43UjBEwOvF7/WO6bGlkDQitU96o1QpyZpRNCr7Fs59/mCI4812ooxakiM7LuBOq41tf3sbp9VOzsypTF/bf7eqx+7EabXh9/qw1jchSxKKCTLj6cwur3Krut8urzMlzClDYzGjVKmIzB/5ekTC5CASIGFUFS2dg85kxBITOWZdYLIsc3DT55w6eIz0kgKKlswel83g1vomrHVNJGSniQHIk8y/vqjmo4paokw6bl82lZQoE+52O85WG36fj/b65rPuIyopjpxZJbRU1zFl3vQJk/x06pzy7vKZOXGycVBT3hUqFTFTC0cxOmEyEAmQcFaudjvV+w5hMJvInF40qFaV6OQEZl00tt1ebpuDyt0HcVltBP1BssuKx11hP6/TTfkbG2ivbyYhO42lN1w2cmOThHGvvt2N2x8kJMu0Or2kRJmISU0ie+ZU2huayV9QdtZ9KFUqpq1aOAbRCsK5SSRAwlkd+qSc4zu+QGvQY4gwkzQlM9wh9UtvNhKTkkjIHyAmNRHdMBZ/HC2hYJCgz48khTqKT4YkkQBNIquK0ghKEgkRBvITo4COekwzzl8a3sAEYRIRCZBwVkq1GoVSiVKlQqEcf11JZ1Kp1cy5bA2OVisRcTHjMrEwRUVQumYxLSfrSCnIGfAMnlAgyOFtu3G328mbN53IxLgRjav1VAMtJ+uIz0olJqXvJWSE4clPiiI/KSrcYYSVLEs4fefmkjvCxCASIOGsipbMwRIbhd5sIiF74OukBf0BmipPYYjovur5WNDotKN2Afc4XBz9fA8qlYq8+TPQGobWwpRWPGXQVagbT9Rw6JNygn4/oWCQeevPG9Kxe+P3eNn5zw+x1jYSk5bE8pvWj+kiscLk0DnzS8pe2zHzy9Ym1vsSwkIkQMJZ6c1GpsydPujXVWzezpHP92CwmFlw1boxT4JGS9WegxzasgOlUoneYiJ39thVDtYa9eiMBmRZxmAZ2dXKZUlGliRkWe74N6J7FyaT1lMNNB4/SUxqYleXeefMr6gZhbjS8gY986uTFAzSsnsfIa+XuJkz0JiGX4VdmJxEAiSMGqfVTtAfxOtw4bG7iE4Od0QjQ6vXodZqUCpVaMa4xH5cejJz16/F63SP+FgsnclA2QXLaanu6AKbzGuCCUMXCgTZ884mmqtriUyMZdmN61FYG7uKHbrS8gZU7LAv1gOHqHztn0g+H0GXm/TzJ179I2F8EAmQAHRMHS+vauKU1cnsrAQyYoa/flrnTBZzdAQJ2Wl9buf3eKmtOI7GoCO1IGfcT+fNKitGa9CjVKlIzs8e8+PHpSdT8Uk5h7fuIruseERboBKy0kjI6vt31Revy00oEMQUdfby88I5TkHXUjMKpRLfqSr0yiBTbryGCp+Z3VVtAyp22CdZBknqqMQuSSMbuzCpiARIAOCU1cUrO47T4vRS1eLgB2umD7t2TmxaEguuWnfW7Y5s28WhLbvQ6LWo1GqS87KGddzRplKrSS/JD9vxnVYbx3fsx22zE/D6yCjJD+tYnfaGZra//gFBf4DS1YsGPa5JOLeo1GpmXrSCphM1RKckoJc9pEz7qrXS4w0MOPkJ+Xy07t2PUqMhtnQqCpWK6JIisi67kJDXS/zss5cLEIS+iARIAECjUqJWKVEpFeg1YztrKugPIoWChIJKQoHgmB57ItKbjETERxP0+4lKih+VNaDaG1uo3HUAc0wkubNL+6391FbbSHtDM1IoRHPVKZEACUQlxhH15QxFT9WxIe+nYdt2av71AUp1x6UqrqwUpVpN4vw5IxKnMLmJBEgAICnSyE0LC6m3uShJjR3Tysn5C8rQ6LRojXqS87PG7LgTlUavY/4V67C3tBGVGDcqXYYHP/6cUweOojUZiEyI7Xf2X0J2R7eZ3+sjpTBnxGMRJi/JF0AKBDr+/8v/ThSyJGE/UYVCqcSSnTkuq9FPdiIBErqEqzaJMdLC1BXzx/y4E5nOZCDeNHpLi+iMepTqjkHeGl3/3WvmmCiWXH8psiRP2BXJhdHROfPL7Q/SbPXQ4BtcEpC4sKOlR6nTEDu9ZDRCHDUtu/ZS9cbbKJQqcq68hJhpU8MdknAGkQAJwjjgcbiorTiOwWIipTAn7HeLJSsXEpuegjHKQnTK2csXqNTiq0TozlN1rGvmV1P+QnZXtQ165pfWYiH9vJWjGOXo8Vnb8dudHQPB223hDkfohfjWEkaN3+ujvaGZyPhYdCZDuMMZ1w5u2s6JnV+gMxnRGHRDmok1knQmA1kzipBlGZ/Lg9aoD3tSJkwMna0+siyhvfhS9vmM1A935tcEFFdWiqepBYVaKVp/ximRAAmjQgpJ7HhjA43HTxKbnszCr10oukf6IQWDSCEJKRRCDo2Pqb2yJLH3/S3UHT5Bcl4WM85fOu5LFExUoWCQk/sOE/QHyCgtQGecmDcMnclP8pxiWhJzOe4zDqnY4blAHxdL3nVXhTsMoR8iARJGRcDnw9bYgt/rxd7ShtflxqyNHNFj+NwebI0tRCbETfgWpqKlczFGRWCMNPdbM2kseV1uag8dx9nWjiRJ5C+cKer8jJLaQyfY8+5mgoEAfq+PqcvnhTukIUuZW4KhoBiXz8yJk42TMvkRJgaRAAmjQmc0kDe/jKq9FaQW5oz4hTMUDLL9tQ9orj5FfEYqC792ISrNxD2dzTGR4+6ipzMaSchORwpJJGSnj/jSG5ON2x9kY0UNwZDMyqJUIg2i0rYghNPEvWIIIyroD1C56wDBQICcmSUj0qIyZW4pU+aWjkB0PQW8fhwtbQS8fuwtbfg8XowacYEeSUqVklkXrcBtc2CMtPRbC6g/9uY2mqtriU1LIiopfoSjnDh2VDXxr33VhCQZnVrFBaVfFQdMLcwh5A90dYEJgjA47XYXtfVNg3qNSIAEAGoOHGHfhk8JBTsKERYtGdlCY8eabLQ4PZSkxmLWDX8skM5kIG9BGaf2HyW1OBeDxTTg13ocLg5t2YEsSRQumYMxQiROfVGqVJhjorp+Dnh91B+rxmAxEZ959mn4QX+AHW9upOVkHdEpCSy94bIJO75luPQaFTq1ipAkY9R2/+pVqdVkzzw3BsrKsoTTFwp3GJOWPxDkWFUdRqOezJT4STF5we508493PqWhUSRAwgAF/QFCwSA6owGlSo1SpUSWVShVIztTo6bNyXNbKmh1eVk8JZnrFwz/DlehUJA3dzp5Q1il/tSBoxz7fA8yYIyKoHDRrGHHM1kc3LydY5/vRW8xMf/KdcSmJfW7vSxJBHw+JClE0B9ACk3eC+OszHjUSiUhSWZ6euyAXmNvbqP+SCWRiXEjvvjtSDp95ldL4nKOW9XU29rE+J8w+HRnBdt2H8Kk13HZ2vlkpp69jMVEZ3e6sdqdeH3+Qb1OJECTlNNqo/z1D/C5PExbtZD0qVMAGSkYIm1q3ogey+0P4PYHCIUk7N7BnaCjQWc2ojUakCUJvckY7nAmFK/DTSgYxOf24Hd7zrq9Rq9jxvlLqT9aRULW5B5HpFIqmZk58C5AWZbZ/c4mGo5VYYmNZsn1l2KJjR7FCIemM/mJmlE47JXeheFzur0E/EFcgNvrC3c4YyI5PoZZJVOorK6hfBCvEwnQJNVa00DLyTpCwRB1h0+QWpRLZmnhqBxrSkIkF5Vm0Wj3sDg/eVSOMRjpxVPQfrl4aH9LPAg9FSyehVqnwRhpISFnYJ9dYk4GiTkZoxzZOUiWkWUZWe5YAB053AH11Huxw4BIfkZIIBBEqVKiGkT5ifkz8lEAEWYDUzLC/307FlQqJSsXlOKals3ffjPw14kEaJKKSU0gNi0Jr8sz6k3rKqWSVcXjJ9FQKJXjujthPItKjGPWRROzMu9Eo1AqKTt/KXVHqohMiMUSN35af0Sxw9F38OhJNm0/QEykmYtWzsFkHFhSGR8TyUUrxWKxAyESoEnKEhvNkusuJRgIjEq3hKvdTsXmchRKJcXL5gzrGKFgkAMffkZrbQP5C8pILcwdwUgFYfyKTIwj8stV1ccL0eU1NvYdrqKxxUpbu4NTDa0U5Ize2n+jyVVbT/PO3RgSEkiYO3NcFVMVCdAkptHr0OhHpxZJzf4jnNj5BQqFgoi4aPLmzxjyvqx1TZzYtR+f24ssSZMyAaraW8HJL46QWphDzqySSTGzQxh/PBW7kWWJ6LJi9sVPp77JJ7q8RklOehINzVYsZiOJcVHhDmfITr7zAW1fHEAbEYExKR5L1vhpfRcJkDAq9BYTOqMBhVKJ3jy8gcbGSAvmmEhkWSY6+dyf0XAmn9tDxebt2JutOFraSJqSKSoyC2Oq1y4vm2/cdXlJwSDWg4dRabVEFkyZ0DcKc0rzyMlIwmjQYRylG9WxoNbrO2YZ67Qotdpwh9ONSICEUZE5rQCD2YRCqSB+mAt7GiMtLLj6QlxWOzGpiSMU4fjgc3lQKBVoDX3fQau1GszRUbjbHZiiIvrdtjcBnx+3zYElNnrIxQyFiUeWZdpqG5Elidj05GEnA51LXFSM4yUuGj79nJp3PkCp1ZJ79eXElBSFO6QhUygUxEVP/BudzIvPJ2JKDvq4GEwp42tQtkiAhFGhUCpJzP1q5o8sy7TW1COFQsRnpg66H9gUFTEhWj1kSaJqTwVOq53M0gIi4mP63Lap8hS73/kYpVLJrEtWEZPSe3KnUquZc9ka2mobiUqOR6Mb+F2U3+vjs3+8Q3tDC5mlBUxfu2TQ70mYmOqPVLLz7Y+QQxLTz1tK5iSoMB1wOAl5fUjBIEG3O9zhCIA2MoLE+bPDHUavRAIkjIn6I1Xs/OeHhIJBpq9ZTEZpAW21jRgjLYNObELBIM1VtejNxnG3tELzyTr2bfgUr9ONs83Kgqsu6HPbpqpTWOuaUCgVtJys6zMBAtCbjaQUZA86HmdbO9baRrwuNw3Hqpm2apFoBRqGoD+AUqUc8WKho8FlteOxO5ElCVe7LdzhjInEBXMI+X2o9XpiphWHOxxhiGRZxt9uQ20yohrFbjORAAljwmN34HW6kCQJt83BwY8/5/iOLzBFR7Dgqgsxxwx8pfjDW3dz+NMd6IwG0oqngEJBZmkhkQmxBEMSJ5rtRBi0JEWOfZFDlVqNSt1RVVut0yLLMsfK99F0/CSZM4pIK5rStW1CdhrRKYmo1EriM0ZnhkdkfCwphbm01NSRM7NkwiU/sizTePwkAZ+f5Lws1NrhL6PS57Ekqd+WycbjJ9n7wRa0Bj2zL141qHN2KIIhCW8wNKClY6SQRM2BowS8XtKn5qMzGUgtyqWtrhEpFCJ9hIqbjvclLvSxMeSsvyTcYQjDVPfxFhq2bMOQmEDedVejGaWCtRM2AXr44Yf56U9/yve//32eeOIJoOPL8sEHH+SPf/wjVquVefPm8bvf/Y6pU8+NNXbGMykUonLXAbwuN1kzijFFReBqt9Nyso6oxDhSCnNpb2gmGAiSUVrArrc/xufxIkkyrnbboC4mzjYrAa8Pj8OFrakVpUqJo6WNRddczLv7T/LmZxVogwG+tWIaJcWDbzUZjpjURGZfsgpXu52Ughycre0c3rITV7sNp9VGUm5m10U8ISuNFf92BQqFYtRm46k0amZfsopQIDiqycNoaThaRfkbGwj6/UxdPp+CUVq2pHL3AY5+tof4zFRK1y5Gpe751Vh76DhttQ0oVSqaq0+NagLk9AV44dND1NtcrC1OZ2lB/wly/dFKdv/rYwI+Hx67k2mrF2GMtDBv/XnDjqVz5pfbH2Tfl0tcCMJoat37Bd6WVoJuD+76BiKn5IzKcSZkAlReXs4f//hHSku7rzT+6KOP8vjjj/P888+Tn5/PL3/5S9asWcPhw4exWCxhinZyaDhWzb4NnxLw+vG5vcw4byk7//khjcdPEpkYx9LrL2PqygVodFpUajX582cgBUNEJsURmza4gXFT5kwn4AugkGVaTzXgdbrR6DoSiMraFhrqmsHv5/OPPqe4IHNMWz0UCkW3Ios+lRJDhBmvy40pOqJH18lgBzQPNaaJmPwA+DxeAl4foWAQr2tkx3Q429qpO1KJJTaao5/twVrfhMfhInN6Ua+D7eMzU2k4Vo1GryW6n+7KkVDT5uRQvRVPIMhnlY1nTYDkrqrRHf9GQufMr+Q5xbQk5rLPZ+RE45f1fsbRzC/h3BM/cwZBlxtjUiKmlP7XGxyOCZcAOZ1OrrvuOv73f/+XX/7yl12Py7LME088wX333cf69esBeOGFF0hMTOSll17i9ttvD1fIY6attpH9H25DbzZSunZxv+tc2ZvbaD3VQFxG8oisL6RUqVCp1QRVQdRqNbIk4XO6kUIh/B4vx8v3Uf3FYSyx0cy5bDXJ+dkk5w+tdSYmNZFFX7sQ6OiWcLXbSc7PAmBJXhKHdx9EGwqQbtIS7lmwOqOBeVech62xhdj05AnXBRVuqQU5uBbb8Ht95M4pPfsLBmHPe5upO1SJKTqS6OQ4PHYnkQmxfY5JSy/JJyYtCZVGPepryKVFm8hNiKTR7qYs/ezj3FLys5m+djF+r29ElrQ5vdhhS2KuKHYojKmkJQuIm1mKSq9H2Utr7EiZcAnQd77zHS688EJWr17dLQGqrKykoaGBtWvXdj2m0+lYtmwZW7du7TMB8vl8+HxfLRhnt9tHL/hRVrn7IPVHq1CqVSTkpJM1vfcpoH6vj/LXP6CttoHYjBSWXn/ZsFsIEnPSmXnRCnwuD6lFubScrCM2PRlzXDTJeVlU7T6Io8WKx+Gkvb55xJaiOH2mGcCMvDTuv34VtsYWEnMzzjrbzOfyUHekEmOEmYSc9CFPFZYliYbjJ5GCIZLyMrt1oZijIzFHj+54kXOVRq9j6or5o7JvKSghSRKyJFGwaDaFi+dgiopAZzL0+Zqxmolo0Wv59vISnL4AMaazd48qVSpyZpWMyLHDWewwGAyxp+IEPn+Q6YVZmPv5XQjnLoVCgcY8+gsnT6gE6K9//Su7du2ivLzneq8NDQ0AJCZ2b5pOTEykurq6z30+/PDDPPjggyMbaJhEJsSiNxvR6nUolUr2f7gNU1QEWTOKuiUCoUAQv9dL6MvWGSkUAoaXACmUSuIzU7E1tmKtb2Lnmx/icbrInVVC1vQiAj4/rnY75pjIUZ+5FZ+ZSnzmwAYVH9jUMRjbYDax4Op1g+6O61R7+AQ73/qQUDBE6epFTJk7sq0VwsibvnYxcRkpRMTHEJOaOO6K5uk0KnSasetqGg9dXocra9nw6V78gQA+f4CVC8TfkTB6JkwCVFNTw/e//33ef/999Pq+70TO/BKTZbnfL7Z7772Xu+++u+tnu91Oevr4WbhzINpqGzm+8wssMVFMu+w8IiNMHNu6k6q9FeiMBoxRlm6rcRssJkpXL6bxxEmS87L6HYciyzK1FcexN7eRWpjT57pEoUCQ7a++T/PJOowRZgJe75fdXx2ta1PmlJJakIPWoB9X41H87o44A34/QV9gWPvpHKty8sBhmqtPkVFSQGrR5Fu2Y6Lob50tr8vN8e37UKqU5M6djnYUK/HKkoS1vhmdyRC2Wlenr+oezi4vlVKJUqlAqej4ryCMpgmTAO3cuZOmpiZmzfpqFkgoFGLz5s089dRTHD58GOhoCUpO/uouvqmpqUer0Ol0Oh063cQtMw5wcNPn1B46gS0kU5NTQHxmKmUKJUqlsmta9plSi3IHdHG2NbWy593NOK02mqtrWXrDZb0mlD6PF3tLW0cSYNSTv2gWQZ+f7LKOGXgKhQJj5PgbiF68bC6GCBPGqIhhVaxOLcrFabXhbnfQcLya5spT2JvbSMhJH1ThQmF8qN5TwYFNn6NUKtEa9CM+/uh0R7bt5vDWXejNRuZfua7f4pmjYTyt75WXncIFy2fj9fmZmjd+1owSzk0TJgFatWoVX3zxRbfH/u3f/o3CwkJ+/OMfk5OTQ1JSEh988AFlZWUA+P1+Nm3axCOPPBKOkAcl6A9wbPte/B4vuXNKB3UnaIgwo1KrafP6aPYGsTbaWDy3mJnpSRgsZnQmI6cOHiM2PRmDxdTnfpxtNpxt7cSmJ3ddtJVKJQplRzLVX/E3g8VE3rzp1Bw4Rsa0fLLLpnJk2y4OfbqDvLkziE7pvoaXq93OoS07UKnVFC2Z023chSzLNFXWEPQFeoynGWkR8TEjUh1ZZzRQunoRPreHLS+9RcDrxxhhQaU+92bLeBxODn78OZIsU7x07oSo0D1Yaq0GtUaDQqlENcotlq21jXgcTvxeH44W65gmQJ6qY92XuDjUGNZZXiqlkpJ8kfgIY2PCJEAWi4WSku6D/EwmE7GxsV2P33XXXTz00EPk5eWRl5fHQw89hNFo5Nprrw1HyINSd6SSAx9/TjAQRJZkpp838IvytFULic9Kw9Tmxt7sISHCyJS0eCLyUrsuyNa6RhJzM1l0zUW9zkRy2xxs+/vbOFrayZiWz+xLViPLMs62dmJSE0ktzGHK3NI+uxMVCgX5C2aSv2AmAPVHqzi0ZSdBv59QMMSCK9d1275qz0GOlX+BUqnAEhdN7uxpXc81HK2i/M2NBP1+SlYsIH9B2YA/i3DTGQ3MW7+W9oYWYtOTJkTF4LOpP1KJramVlIIcIuJjOHXgGCd27keWZczRURQt6bvMvSzLuG0O9CYjKs2E+boha0Yxap0OpVIx6t2YubNK8DqcmKIjictMGdVjjRd+mx13fSOm9NRRK3InCGczcb6RBuBHP/oRHo+HO+64o6sQ4vvvvz8hagBptJovW13kQRfF0xr0ZJTkky7LzHP7MGk1XYMnOwoGOgkFg7htdqRQqNcEyONw4m53EPD7sTW1Icsy9uY2dv9rE462dpLzsjANYiaTzmRAbzbicciYInp+/nqzCa1eh0qt6jGl2OvydAzODoZGvPYLgKPFSnN1LTFpSUQlxuH3eGk8fhJTdOSILLZqjonCHBM1/EDHAXtzG7v+9THO1nYaT9Sw9IbL0FtM6ExGZFnGENF3iyJAxeZyTuzaT1RSHHMvP2/AY2mkkISzrR1DhDksXYgqjXpIa2dJkszRpnYUCgV5CZEDGlidmJsxrBmIE03Q6+XIiy/jPHmKqPwpFNx8LYpz4EZBmHgmdAL08ccfd/tZoVDwwAMP8MADD4QlnuFIysti9iWrCfh8pBQMreqlQqEgxtS9394UHUnR0jk0Hq8hc1pB1wBkpy9ArdVJarQZs64j+TJGWVBptRQtmYNCoej4QlZ07FcxyAGJMSmJzLvifDwOZ7cB2J2yy4oxRpg7puxndx90nlqUi7PVit/rJ2fmyEzt7RT0Byh/cwMt1XVEpySw9IbL2P/hZ1Tu2o8pKoKFX7uwz4GxI8Hv9XG8fB+yJJEze9qo15MZMaddnNOKp6AzGpBliYR+xk3JssypimO4rDaCPj/25jbi0s8+y06WZfZ9sIWT+48QnZzA/CvOG7VK2SNte1Ujfy8/hlKh4Ovz8pmZObAZj5Ml+QEIOl34WtsIeX14mpoJ+f2oDX1Pd5dlGSRpwEmSLMtUnmrE6fKSl5WCQf9VAi0Fg9iOHEOhVhOZlzupPnehpwmdAJ1LFArFkBa7PJMsy9TsP4Kj1Ur61Hwi4mPInTWN3FlfdTH5gyGe21LB0cZ28pOiuX3ZVPZ/+BlttU0YIy3ozR0XZXNMFAULZ+H3eEmfmjfoL4vYtL4reCpVqj4LIWr1OqatXjSoY/Ul4PVxfMcXSCGJ3NnTUKqUBLw+JClE0O9HCoXw2B2EgiF8bg8+t3dEjtuXmv1HOPDRZ8iShFKtpnAISzucbc2qkRQRH8PMC5Zja24jJT+76xxIyD77gHGFQkHmtAKCPj9RyfFEDnBsixQK0XC8Go/dgSxJOK02opMTzv7CccDq8mH3+lGgwOr2nf0FYdQ588vtD9Js9bC7yT8mx9XFxpC8bBHWg4eJn13Wb/IT8vqofO0tXLV1pK5aTlzZ2Qejn6pv4c0Nn+Ny+5hTmsfaJV91oTeX76L6rXdQqNTkXHUZsaVimaTJTCRA55i22kb2vPcJHntHwcFFX7+4xzYuX5D6dhduf+d/A6BQdNzkf/lPlmX2vreZmoPHiEtPHvQ4HK/TTVttI9Ep8Rgso1/Qqi8n9x9h/4efIUkSKrWKgkWzmHHeUuqPVhGflYrBYqZo6Vx0RgMR8THEZQytDtBAqTRq1BoNkiSh1gxucK0sSez/+DPqDp0ge0Yx+Qtndj3ncbhoO9VAVHL8iA9KHk7V7vyFM8mcUdRRm2qAd/AqtZqcsqkc37mf+MyUMZ8VNRxzshJosLlRKRXMzBjdelfD0TnzK+lrV1FuVVPf5CNJrxqTwc8KhYKUZYtJWbb4rNs6T9XSuu8AQbeHhi2fDSgB8voDeH0BgqEQHm/3pM5vdxB0e1GolAQcziG/B+HcIBKgc4xSpUSpUqJQKlD2MQMpyqhlZWEaO6qbmJOVSIReS+nqRcSmJWGOjiQ6OYGgP0DD8ZN47A5aTsq42u1EJsQOKIZQMMj2196nueoUsRkpLP76xWGr/aPSqFFpVCglBaovE47E3IxuFaRj05L6ba0aSRkl+ShVKmRJ6rYy/EC42u1U7anA3W7n+I4vyCorRmvQI4VC7HhjA42VNcSkJLL4uktGtW7NYCgUiiF18+UvnEn2rBLUWs2E6qaIsxj4t8W9V2AfD84sdlhuVX9V7HAc0sfFYkxOxNvcSsSUgSXh2WmJLJtbgt3pZmZJ9wHs8XNmEnA4UahVxE4XrT+TnUiAzjFRSfHMumglzrZ2gv4Am154leSCbPLmzei6kCgUClZPTWf11K/G3phjIik4rUVBo9OSOb2I6r0Hic9KwxIb1fWcFJJoqqxBpVETl5HS4wIV9AU6xn0Egrisdvweb58JkNvmwNVuJyYlcVRmCWWU5KNUKpGGkHAMl9/jxdFqJTIhruv9K1UqMkryB7Uft91J1e6DqDRqIuJjCQWCRKcmdg0ODgWCuNrthAIBPHYnfo933CRAwyHqJ42s8VLscDB0UZEU3nI9/nY7xuSBTVBQq1UsmNn7emj6mGhyrrx0JEMUJjCRAJ1jFAoFyXlZ+D1eNv7pb9ib23C0tZNSkDPo9aiKlswmb24pap22W5JzYud+dry1saM6dFEuK/7tCoynzfTSmQwULZ3Lyf1HSC3MwRBh7phpdaIGU3QEMV+upO22Odj68ts42trJml5E2bplA45NliQqPtlB/dEqssuK+1wHSalSkTGt79k8sixTc+AobacaSC3KHfASGmcT9Af4/NX3aa2pI2lKJnMvP2/IC6Ee/Ww3hz/diVqnpWzdckpWzCcyIbZrHJBGr2Pq8nmc/OIwSXlZ52RdHmF4wtnlNVwas7nHulBBj4f6zVuRAkGSlyxAGynO+cGQJJmT9c2olErSkmInVCvrSBIJUJj4XB5CweCoVUdWazVY4qJw2x2YY6LQGQe/qKBCoeh19o3b7qC1ph6ntaNwosFsYuWtV3XbJmtGEVkzvuoK+GLDp1TuPtgx0+qai4hMiMXVbsfZ1o7f7cVa1zSo2JxtNo7v+AK3zY7f6yW9JH9QLQahYJDqvYdwtFqp3ncIt81Ja009K265ckRq93idbmyNzfjcHqx1TQR8viH9DqBjTIxSpUKpUqEz6nvtrksvySd9kC1LAM3VtThb20mckokxInxjtUZCy8k6XO12knIz+13QdDI5fVV3V1reuO/yGqjWvfs59cFHyKEQSq2G9LUrwx3ShLLvcCUbtuxBpVJx4YrZ5GePzI3fRCMSoDBob2im/I0PCPgCTF+zeFQKrSlVKuZcsgZrfRORiXFD7k5wtrWDQtGt9Si7rJgDH32G1+lCo9V+uZhq/zwOF6GQ9OVMKw/QMVU+a0YxbXWNFCyYeZY9dKc3G7HERXfMMEqMRz3I7rNTB4+z571P8Ls9yLKMSq1Go9eN2J2QKcpCdtlUag8dJ2tG0ZCTH4D8BWUYIy1o9DqS87JGJD7oqPFT/sYGXFYbacVTWHDVBSO277HW3tDM9tfex21zkDWjmNmXrAp3SGF3epeXKy1vQnR5DZRKr0Ol1yEHgqj7WctQ6J3N7sLp9qJUKrE5Rr7W2kQhEqAwaKttxFrXjCSFaKo6NWqVZnUmA0lThl5Wvv5IJbvf2YRCoWDWxSu76vVYYqO54r472PXOxwR8AVILczl18BiJOel91mspWjoHrVFPZHwscenJOK02jmzbjUarYfG1gx+0q9HrmH/l+dib24hOih/0tPAvSxyh1mrILC0gNj2loxjdCE0vVyiVTF0xn+Ll84adVGkN+j67+IYj6A8Q9AeQgiH8ntGd/j/a/F4ffq8PKRTCNwrFMyeazpafKTdeQ4XPzO6qthHp8vL6Amg16rAvVBo7bSpKtRopECSmZPwOOh+vSgqyaG13olGrKMwZ+hqIE51IgMIgPiuV+KxUAl7fiNT+6Y0sy7TW1BPw+UnMST9rt04gJNHs8BBn1qNVqwgFgpw8cBRrQwtqjRprfXO3goVao4H5V6zDWtfEtr//C4/dSe6cUmacv7TX/cemJROb9tUU88pdBzn6+V5UahXm2KiuRVMHQ28yDrmQYGpRLqFgkKA/QGZpIdpRuoscz33r0SkJTFu1AFtjKxlDqHo8nsSlp1C8bB7OVuuQzqVzUcrcr5Jmjzcw7ORn265D7DpwnPTkeNYtn4UmjOvcKVQqYkqKw3b8iS42ysL68xaEO4ywEwlQGFhio1l6w2WEgiECXh8Br2/EK902najp6Gbz+pm6cj758/uu4xOSJF7cdpiDdW0UJEVz86JCvtjwKdV7K/B7PCRm5/XZkuRze3BaO8byNJ6oQZblAV30dSY9Wp0WlUY9rO6hoVKp1eJCCbgSkvBFxmGKH73q12NBqVKSP39GuMM4Z4VCEnsqTtDcZsPj9TGndArJCROnPpMg9GZQCVB9fT0bN24kJiaG1atXo9V+Na7E5XLx2GOP8fOf/3zEgzwXqdRqqvZWcOiTHRgjLcxbf96IDoj2OFx4XW5CgRAeW/8Fv5y+AEcb27G6fRxrstHu9tFaU4csSUQmxJKcn03Q33uV2PisVDQ6LUGfD6e1HVtjC1FJ/ReAk2WZzNIiTJERqDRqEnMzCHh92JpaiYiPGbXWGKG7A3VtPP/pITz+IC2lmVxYmhXukIRxSqlUMCUzBY/XT3JCNNGjNHlDEMbSgBOg8vJy1q5diyRJBAIB0tLSeO2115g6teMu2ul08uCDD4oEaBDqD1fibGvH43BhrW8a0QQopSCbKQ3T8Xu9ZM/sv6UjQq9lTnYiu6qbmZ4eS4xJT/6CmRzZtguf20vFJ+VU7TnIvCvO77GWk0qtJj4zBb/Hg9agR5bkfo8VCgbZ/c4mmqtryZ1VQv6CmUghifI3N9J44iRxacksuPqCsBVOnEw8/hBefwh/SMLlC4Q7HGGEdI7/GcklLhQKBSsXllJWnEOExYh2FGp2TWSy3PG9N567vIWeBnwW//SnP2X9+vX87//+Ly6Xi5/85CcsW7aMDz74gLKywS2TIHRILynA0dreURsndWQrEWsN+j7H45xJoVBwWVk255dkoNeoUCgUZEwrIL0knx1vbqRy1wG8Tjdep6vX15euWUxsejKW2Giikvtv/bE3t1FbcRyv08WJXQfInVNK0BegvaEZv9uDrbkVr8uNWTu4mkXC4JWmxXJBaQYuX5AVhcObBivLMqFAUCSuYXb6zK+m/IXsrmrD4w2MyMwvlVJJXIyot3Mmv83OiVffJGB3knnx+UTkZIU7JGGABpwA7dy5k9/97ncolUosFgu/+93vyMzMZNWqVbz33ntkZPRc8VvoX2ZpAUlTMlBrNajUY3dHJcsyJ3bt59SBo6QWTSF39jQUCgUGbc8YQtnZtLd5KEmKJCm393FAEfExA16vyRwdSUxqItb6ZhJzMlCqVGiNKqbMLaV67yFSi6aIQn5jRKdRccEIdHtJIYl9H2yh/mgVmaUFFC2dK+6Ew6BHscMRmvkl9M929DjWLyqQQkFadu4RCdAEMqirrtfbfarsj370I5RKJWvXruXZZ58d0cAmi9EaAOxze/C7vZhjo3pcjLxON4e37MTR2o7Lau+o1tzLgqXVrQ5eP9KEVWVGGxHPwn7u7g/VW2l2eChNjyXS0PeA7o7p6+tw2xxYTostf35ZvwO1R4LP7aHucCUGi4nE3AxxkR4hbpudmoNHcbfbqdp7iNw5pWEZ2D5ZnavFDicKQ2I8hoQ4gh4vpvTJWVBwohpwAlRSUsLWrVspLe2+Gu8999yDLMt8/etfH/HghKFxtdv57B/v4rK2kzY1n9LVi7p1TWj1OswxUXgcLswxUfg8PuxNbcSmJ3fbzh+S8IdChCQZX6DvYocn2xy8sPUQbS4f85sSz7oYpEanHfDCqiOpYnM5x7bvRWcyMv/K80ds2YvJzmAxE5uWhBySiM9IOSfWIZsoeu/yEsnPWDKnp1H4jZsIeX0YU8ZmUWVhZAw4AbrxxhvZtGkT3/rWt3o89+///u/Isswf/vCHEQ1OOLvjTTYONbQzJSGCgqRoAGyNrbTVNtBcU8++6iaOtTq54uvrUH1Zt0OlUTP38rW0NzSjNeopf+19HK1WMksLmXXRVyXlp8RHcsWsXJodHubl9L0QoS8QwhcMEZIkvIHgoN9DKBCkcvdBgn4/WTOK0ZuHVtvnbAJfFsoL+vwEfUMfGCrLMn63F61BN2KFE8eLUDCIUqXqah0LBYN47C6MkZY+1zJTadTMvWwtLquto8XxHPtMxqPOVh9ZltBefCn7fMZx2eUlh0IE3G40ZvM53eKqjxUlASaiASdAt912G7fddlufz//oRz/iRz/60YgEJQyMxx/kpc+PUtliIyPGwt1rp2PRa4lNSyIuPZndjXYOGOPYf6KN9ON1LCj4qpCh3mwkaUomLTX1uNrtBHx+bI0t3favVCpYNCWZoD/Qsbq8QdvVQiTLMh67E41eR258JJeX5dBk9zA/d2ArNp/uVMVx9n2whWAgQNAfpGTl/OF9MH0oXDwbrVGPIcJCYu7QxqzJssz+D7dRc+AoCdlpzLxg+YisHTYe1Ow/wsHN5UQmxjLrwhUoVSq2v/4BLTV1pBVNYcb5S/u8iKm1GiITJ3YtoYnizC6v4z7juOzyCvn9HH/5NZzVJ0mYO4s0sV6XMM6IuYwTmEIBKiUoUKB0ufj0+VdwNDSRO7uURddcxCGNhYMnWlBFmHH10YMVk5JA7uxpNBw/idag53j5PrJnTu26qEuhEOVvbKCpsoaE7HTmrV+LUqXixM79HNqyA1NUBHPXn8eS/JQhvw+lSolCqUSpVKJS92w9CPoDVO87hCxJZJYWdisaKcsy9Ueq8LndpBbm9ltDyBIXzfS1S4YcJ3S0ItUcOIqjpY1QIIBr4UwssdF9bl93uJLaimMk5GSQMS1/XN8FH9/5Be0NzbisNrJnFGOIMNNcXYvH7qDhWBVB3/wRL9g53siyTN2hE9iaW0ktyBl3Sd1E6vLyNrVgO3IUv91B8669pKxcinIMJ3uEmyxJ+O12tBYLinPkJulcM3nOxnOQXqPm2nkFHGm0oq2q4ujmCpztdtx2JwnZaVx9+XJMeytRqZTMyU7odR9KlYppqxbi9/g4Vr6P5upaDBGWriU6fG4PbbUNeJ0uWk/VU7P/CIZIC7WHjuNss+F1uGivbx7WSuKphTlIIYmg39/riuY1+4+w593NyJKEJEndBks3nahhx5sb8Hu9OFrbKV29aMhxDIRGryNpSiahQJD4zBSMEX3Xbgr4/Hyx8VOs9c00VdUSl5Ec9hlukiRztKkdtVJJTnxEt4QsITsDe7MVc3QklrhodCYDyXlZNFedIn1qPuohLqg7XkmhEPs//IymqlNMmVtK1vQi7M1t7Hl3M862dpqrall6w2XjImkd6y4vWZY5WdeMzx8gJz0J9RCWvdDHx2LJycZVc4rY0qmTKgmQJYnKV9/CevAwUYV55FxxyaR6/4PV1u7g/U92E5Ik1iwuIyF2bMqgiARogsuKs5AVZ6FOHeRUpAWfx4vBYkJr0BNr1nPjooEtFKjWqlGqlKjU6q6xQgB6s4ms6UXUHDiKzmhg1zubUKnVpORnExEfjTk6ipjU7t1eAa8Pe0sbEfGxA1qFXqlSkTnEtaiCgQDBQBApGCLgHX7Bt7NRKBTMOG8p+fNnYIgw91u+QKlSojMZUalV6EyGcVEjZ9uJBl7ZcRy1Ssn18/MpTf+qhaNo8SxSCrIxmE3oTB2zuEpXLyTgC2CKjhgXicBIsjW1Urn7AF6nCykYJKOkAIVCgULZsVKucpyMZQpHl9eJmgbe3LAdnz/AivnTmDdj8H+fKp2O/Bu+ht/uQBcVec6dP/0JOJxYKw7jbW2l/ZDc8RlER4U7rHHrSGUdhytrkWSZjJR4kQAJXxlIldGUghzWfe9GmipriElJJCEnvc9tOzlarRzctB21Rk3e/DIssdHojIZur1UoFExdMZ/CJbM5tGUnTVWnUKqURCXFM231wh41jELBINtfe5/m6loSstOZf+X5wx4jk16SjyRJXV1gp0uakknJyvn4nG6yz7Jius/twdHaTlRi3LCSEaVKiTkm6uzbKZXMuXQ1LSfriE5OGBdTw9ucXuxePyqlkjaXr9tzCqWSqNO6fBqPn2TPe5tRa7XMvmRVWGbujSZjhIWIuBgkSSImNRGFUkFEfAwzL1yBvbmN5PyssF+0w9Xl5XR5cXu8BEMSdqd7yPtRqtXoY/ruIj5XaSxmoosLsR48RHRhPtp+WooFiIuJIDrCjCRLY1psc8QSoNbWVv785z9z1113jdQuz2khSeJoow2tWkl2XN93161OL38rP4onEOKKWblkxvb9hxSblkRs2sCnYVbvPUTV3gqUSiVRyR1jgQI+P8hyxwCj06jUajJLC3G321Gq1aQW5fZ6Qfe5PLQ3tuBze7DWN+Nze9EYDWw93oDT62d+bhIxpsF9eau1GnJnT+v1OZVaPaD6QQGfn89feY+22gaS87OZe9maUZutJMsyFZu3U3PgKOlT8ylaOifsF9JOc3MSabS70apVlGX2P76l4Xg11vomlEoVLSfrBpwAyZLEsfJ9WOuayCorJiErbSRCH3E6k4EFV1+As62dqKT4rt9R0pTMPhf/HSvhnuWVn53K3OkFeH1+yqbmjvrxzjUKpZLsyy8iddUytBEWMTPyLKZkJnPNxUuRZXnMWn9gmAmQLMu8//77PPPMM7zxxhtERESIBGiAth5r4NVdJ9CqldywoICS1N4vLvtr29h9soWQJJMZY+k3ARosU1QEOqMBlVqNwWLmWPk+jn6+h5iURGZdtLJHK4k5JpI5l63pd5+GCDPZM0s4deAI6SUF6M1G9p1q5ZWdx3H7g9g9Aa6Zlzdi72GgvA4XtqbWL8c0NRL0B0ZtQK/H4aJy98GOmXP+ANkzi3sUmgz6A4SCwTFvFUqMMHLb0v7XhuuUkJ1O3ZFKNFotsWesASeFQhz9bA9Oq43c2dO6LYBrbWimYnM5HocTZ5uNFbdcOeQE8Mxp+SNNbzaOWtmFoTqzy2tLk2rMBzob9FrWLJ4xZsc7FymUSnRRYkmfgRrLxKfTkBKgqqoqnn32WZ5//nlqa2u57rrrePvtt1mxYsVIx3fOanF6cPoCqAKKHl0Rp0uOMpIQYcAflEiNMY1oDFkzijBFR6BUqYhJS2LjH/+KvakVn9NNe2NLj4VPByIUCFKwcCau9Az2tzjQNNtRKRWoFB3/1Kq+L2Sudjs+t4fopPgRv2Myx0SSVVZE/eEqcmaVjOpsJp1RT3RyAgGfn+iUnl1f9ua2joHbHh/Tz1tCcl7WqMUyFE12N7tPthBvMbH85itQqdU9ihs2V9VycHM5Aa8Pn9vLwqsv6HpOa9CjMxrwe7wYI4de/6Xu8AkOfPQZpuhIZl60Ar1pfCUqo6FzOYvRWMtLEITuBpwA+Xw+Xn31Vf70pz+xdetW1q1bx+OPP87Xv/51fvKTn1BcXDyacZ5z5ucm0eL0olermZHed1dEfmIU311Zij8UIj166DOtziTLMn6Pj/istK+a/vOz8LrcRMTHYomNGvQ+ayuOs/+jbfiMZj7Rx9LqCXCs2cYP18zguvn5OH0BZmb2vliqvbmNz/7xDl6nm8JFs8hfOHM4b68HhVLJtJULKVmxYNS7o1RqNXMuW4OjxYolLrrHGKjWmnpaauqRgiHqj1aNuwTo1V0n2FnVTIxJx7dXTCMrrmeyqDXo0Rr0hIJBDGe0oJijI5l3xXnYW6wkZA+9+6tqTwVtdY3YmtvIPFlIatG52xUT7i4vQZiMBpwApaamUlxczPXXX88//vEPoqM7BraJJTCGJjnSxDcG2BWRFDmyd76yJLH73c00HK0itTCX0rWLUSgUlCyfT/rUfAIeL7IkD3q/1V8cor2hGa+qHTnThEqpxqBRo1YpmZXV+zT8TvaWNuwtVkLBIK21jUN9a2c1nOTH5/YgS/KAukw0Om2P2XGdYtKSiE1Nwu/1kTTEgowjye/xcvKLw6g0ajKmDWy2T3RKAnMvX4PH7ux1vExUUny3bjF7c1vHAP3UpD4/lzPFZ6bSeqoBg8VIZOLYDMCurThOw7EqkvKySC3snnA12NwcrGsjLcZMfmLUiB1zJLu8Qj4fIb8frUUMuhWEsxlwAhQKhTqmiCoUqEQ9g7CSZZmjn++hubqO7BlFpBTkDOr1bruTukMncLXbOFVxjPyFMzFYTCiUSmoPHuP4ji8wRUey4Kp1GCO7f5E2V9fSdqqBhJx0opO7JzWJORm01TYSZzYxe3ExrZKCouRolMqzJx3xmamkFU/B3W4nZ+bAEsPRJMsy1romQsEgcenJWOub2fHWRkL+AAk56RgizGRNL+rx+QxEZEIsS264DCkYGhfjT46X72P/R5+h1nTM6Fs/M4fsuAjiLQYyY/tudRzoWmqhQJAdb22kuboWU3wM9QUl+JQaLi3LJj2m7/1PmTedhJx0dEbDmHxOXpebfRs+xdbUQlN1LXHpKV3lACRJ5qXPj3CwzkpypJG71kwn1jz8bqnTu7z2xU+nvsk35C4vn7Wdoy/9Hb/NTvp5q4ifNWPY8QnCuWzACVB9fT2vvPIKzzzzDN///vdZt24d119//biZ3TKZ2JtaOfzpTtw2B26rjaQpmYOaam6wmEjISaPxuExiTgZ601djVJqra/E4XAQDQZxt7d0u8B6Hi4//8R6Vx09hSE7gxh/ciFGtovVUA+aYKHJmlZCYk45Grxv04F6d0cD8K85HluVxcU41Hj/Jjjc3EgoGKV2ziKAvgLWuCY/DSeOJGoyRZnwuD2Xrlg1p/+NpwdAvqywgyzKyDAkRRs4rGbmWKVmWCQUCyCGJJquLXVVNBDRaEiMNpMdM6fN1CoViTKfeq9RqdEY9SpUancGASvPV16OMTDDUUYgzJEkEJWlYx+q1y8vm69Hl5TpVR/Xb76E26Mm8ZB26qKg+9+k8eQrHiSqkYJC2Lw6KBEgQzmLACZBer+e6667juuuu4/jx4zz33HPceeedBINBfvWrX3HzzTezcuVK0To0BnQmIwaLCZ/biykmsmvAcNAfQKFU9FucDzoKD86+eBVumwNjZPcpmrlzSvF7fEQlxxGdcmZXhUyd1Ynd46etzUlFnRVVRQU1+49giYtm0dcvHlB9nN5IoRAKpXLAyU/QH+DUwWOo1CpSi6b0uVDnULmsNjwOJ1JIwmW1k1Y8hbj0ZOytVvweLwqlkqDfTygYPOvnPd7lzpmGWqtBrdWQNgrjbNRaDTPOX0bD0SpcpgiO1TnxBUMkRYS/9et0Gp2WOZeuofVUA7HpSd1mQaqUSq6ek8e+Uy1kxFhIHEbsg+nyat69F+uBQyjUKiLzckmYOwtZlntdUsKckYYlJwu/zU7MNDEmUxDORiF3VtkbAkmSeO+993jmmWd46623MJvNtLa2jmR8Y85utxMZGcn+f7yJxTSys65GkrOtHVtjKzFpSbTVNtBa00D9kUp0JgOzL1mNOWboUwpDgSDBQKCjlUKhoLrVSb3NRVFyNJs+3cfWHRVokhL5twvnU/XGu7TU1KM3G1ly3aXEpCZSd7iSqj0HictMIW/u9LPO6KraW8HhT3cRk5pI2bplAypSeGTbbr7Y+CkqtZqZF60ko5clNIbD43DyxcZthAIBpi6fT0R8DAGfHzkUovFEDYe37sTV7iA+K425l60ZF1WeJ4pTVie+QIjsuIgBdY+eS3p0edn67/JqKt9F9T/fRaXVkr5uNc079hBwOMm8+Hyi8nu2nokxQMJk5nI6WL+8FJvNRkTE2QsqDuvWValUsm7dOtatW0dLSwv/93//N5zdCaeRQhJSKNTnhdUcE4U5JorqfYfZ/a+PaK1tRKlQYI6JpLm6dsgJUNAfYNfbH3F42y68TjcJM0rYGZdBo9PLjPQ4blo6HUtaEinRZnITIjEsncvx8n3EpicRlRSPFApx4ONttNU20nqqnsTs9LMuKHls+z7aG5pw2x1kzSjqMbakqfIUx3fsIyopnoKFs1CqlF/W0QkhyxAKBIb0XvtjsJiZe0bNo85lPZLzsznw8ed4nS5aqmtxWm3dKigL/UsbwdmME0Vnq0/ynGJaEnPZd/pyFv3M8oqfXYYxMQGlVovrVC22Q0eRgkFa93zRawKk0ulQ6XrvXpUlicbPynHXNRA/ZyaWzLNXi59IpEAAT3ML+rhYVNpza906YXQMuN/AarXy5JNPYrfbezxns9n4y1/+wm233TaiwZ3u4YcfZs6cOVgsFhISErjssss4fPhwt21kWeaBBx4gJSUFg8HA8uXLOXDgwKjFNFrcdief/uUtNv7pb9Qdrux324DXS8AXQK1VozMZiUpOIDrlq8HJTl+Ag3Vt2D0DWyfL0WLlVMUxGo+dpO1UIwe376Ottb2jJL7Xz+u7qnhrbzX/3FuFw+snpSCbJddfSvGyeV2rupuiIlFpNOjNJrRnjAXyOt0d1aZPk5CdhsFiJiohrtcutIObPufk/iMc3rqLttoGAHJmlVCyYj4lKxeQVtx7YUVZlqned4idb22k8cTJAb3/gVBrNaSX5GGJjSYxNwPLELv9JoqQJCENYVag0OH0Lq+WxFy2NKkGvJaXQqHAnJGGMSkBY0oSxpQk9HGxRORkDToOZ00tNe9uoP6TrZx8+70hvJPxSw6FOP7yqxz8w7Mc+8srSMFguEMaU1IwiKelFTkUCncoE8qAW4Ceeuop9u3bx/e+970ez0VGRvLJJ5/gcDj46U9/OqIBdtq0aRPf+c53mDNnDsFgkPvuu4+1a9dy8OBBTF92VT366KM8/vjjPP/88+Tn5/PLX/6SNWvWcPjwYSwTqEm45WQdDcerCQVD1Ow/0rUye2/SS/I7FnOUZFILczFHR3bNXAmEJJ7/9BCH6q1MSYjk28tL0Gn6H6NljokkNi2JUweOEfD5iTJqmTkji+aQgjlZCby8/RgOr586K7Q6fVj03e+0FAoFsy5aSebJOiISYjBYvupGrNl/hP0fbkNnNjL3srWYoix4nG6Kl84lfWoexghLV+xnxtT6ZTdb52wgvdlI8bJ5/b4Xl9XG/o3bcLS101bbyMpbr+42sHU4ipfNI3d2KVqDfsTHHw2Vp+rYiO+zst3Dq4ea0KmUfK04kXhT33fWgZDEe8dbaXEHWJEdTWakAZfSiKvdTlJuZq+/23NJr5//lwOdR2KWlyklmaJv3kzI60UfP/gWR7VBj0qvR+lyozGfW61wAZcbe9VJ/HY7zuqTBBzOSbP4qBQMcvyvr2A7VknM1EKyr7hELL0xQAO+Grzyyis89thjfT5/++23c88994xaAvTuu+92+/m5554jISGBnTt3snRpxxoiTzzxBPfddx/r168H4IUXXiAxMZGXXnqJ22+/fVTiGg3RSfFEJyfgdblJyOm/kJxWryNrxlQMFlOPi7s3EKTB5sIbCNJod+P0BbolQN5AkH2nWjHrNBQlR6NQKNDodSy65mJyZk2j5WQtpqhIQl4nMzOSiU+KZmVhCu/tOUFhaiyp0b2PkdKZDL0Wras7UomtuQ2V1UbrqXqObd9LbcVxEnLSmXXRCpQqFfKXs2tO/wMuXbuE5Pzsrm6/gVJrtWgMOlQqFTqTcUBfCrIs0+72E2HQoOpne4VCMS6msHfqbGVImfvVgrD2FhuhYIioxOghz6zb9FklNQEZVVCi2WJm+tS+q4Pvrm7js/Y6PIEQZo9MlOMU2z/eh19SkDWjmNmXrBpSDL1x+QJ8dqIRrUrJvJxEtOrwTb7o7bPvJMvSoLq8zkYbYYEhLKzp9fk52GQjuHgpOXoV0YVjvxzNaNJYzMTPmkHrni+ImTYVbeTYLagZbv52G7bjlfisVtoPHyXoPvcS3NEy4ATo+PHj5OX1/UeTl5fH8ePHRySogbDZbADExMQAUFlZSUNDA2vXru3aRqfTsWzZMrZu3dpnAuTz+fD5vlqKorcuvsHyBUJ4AkEiDdohXXgscdEsue5SAj4fpui+x/LIssy+DZ9Ss/8IMalJzL18bdeYISkkoQ4EWFOURnl1M2XpccSYuo8NeP9ADe/uP4lZp+GWxUUUJncUt1RrNaRPzSNpSiabXniFpqpadAYD865eR2Dbbkqr60gOZcLsXFANvK89pSCHttpG9GYj5thoDnz0GU5rO9JxCbfNgd/rY8+7mzsGNl+4HEtsRzxava5HUbqB0JuNzL18Le31zcRnpZ61pUaWZV7ZeZyd1c3kJ0Zx/YICNOOkdac/p68YHsrqKGTYeLiST//xCVIgyOyvrSNrbumQ9p3pNpDU5EerVpNWWkKon6rlEXorEftaCTk8xGZnow+ZCPxrGwGvH69r6CuK92bzkTre2F2JRqVEo1YyP2fgiwCPpN4++9PVEDlmK7j3p3zfUTZt349WrSZi1VwSz7HVyRUKBRnr1pC6ahlKjWZclNIYK7roKGKmFtF++CixpSWox/HknfFmwAmQSqWirq6OjIze64PU1dWhHKNmN1mWufvuu1m8eDElJR13XQ0NHWNDEhO7T91OTEykurq6z309/PDDPPjggyMWm9Xl49ktFbS5vFxYmsnCKYNfTws6WlFO7zIISRLHmmyYdJquQaRSMET9kSpc7XakkNS1qnUoGGTXPz+iqaqW9JI8frh2IVIwhNfpQm82dX05OLx+AiEJtz+A2993n7mj1Uq7v5kP//Q37I0tdEwclHG32886wPl06VPzOhIRpRKZjsHE0iGJhOx0jJEWqvZU0HSiBoVKScOx6q4EaDiiEuMGPEDZEwixp6aFZoeHYEiixekhOXL8fpn0vnxCRzJv3VVPw4lmZClE+65aEhKGVlxSNqQwY6kFtUpFRchERVV/YwwiKJw/D5fLgyY1kYboGUy9XYt89BBROg2eqmMYsvqu+zNoYb7G9ZjRVdXbmn7jYy2vYEhCCkmElB11jM5VYzH42enycODoScwmA0W56WGfyahQqchefzFBtwe1yTipkr/hGnACVFZWxuuvv878+fN7ff61116jrKxsxALrz3e/+1327dvHli1bejx35i//bIX17r33Xu6+++6un+12O+npQ58dUd3q4FhTO4GQxK6TLUNOgM70UUUtb39RhVHb0Vqjb22h+otD6IwGzLHRxGemYImNpuFYNfs/3EbdkUq0Bh21B4+RXVbM7nc24WxtJ3/BTKZ82RqwurjjfUYZdUxNjelxTI1Oy8wLV+JoacfR1o7X7kSj0xIMBIlOScASN7QE5fNX38dpbado8VwKFs5EbzahVCmJSo7vWjvr9GUUThf0B9j/4Tacbe0ULJo14GrEA2HQqJieFkcw1Ex+YiRx5vExZqXPsT391JKJmlaAfLQQye8na9Y0zMPodkk2DPz3nJT+1e+tssWDoWQxi1cuwHTqKO17Dg1qnFJ/ydLS/BR0ahUalZKZGb2fKyOhv8++1xldvRnAZy8FArTuO4BCoSCmdGqvdX6GY05pHhq1Cp1WQ8FZutX7I8sypxpaCQSCZKYl9NtNfK7aXH6AnV8cw2DQYdBryUkPT+vj6RRKJRrz+L1ZG68G/Ff23e9+l2uuuYa0tDS+/e1vdxU8DIVC/P73v+e3v/0tL7300qgF2ul73/seb775Jps3byYt7as/5KSkjpOwoaGB5OSvko6mpqYerUKn0+l06PqYNjoUWXEW8hOjaHV5mdXHwp+9kWWZ4zu+oOVkHVnTi3qsr9TgcOP0BvAGJBrbnTg+2kZ7QzOmqAgWXHUBMamJKJRKKj4pp6WmrmMl7ggzyfnZuKx2WqrrCPj81Bw40pUA7dh3jM2fHSI7zsLK/GToZRxFTGoii75+ER899w+C/gCm6AhyZ0+jdPUiFEolracaCPr8xGelnbWLye/1sfudTRzfsQ+dycjJ/YfJmlHY9Xxa0RQi4mJQqlWY++j6a66u5cTO/XgcTqx1TSy98fKuasGSJHO0qR2tSkVWnGXQd0IKhYIrZuWyqjiNCL0W9Tjo/upsZehtfIknIPW5Yrg+Lpaib9wEshy2AZHZUXoq271sadKQHD+d0hlg0Awslrrt+/FU7MZQ1PtNlUmnYWXR0C/kA9HZvdXXZ985o2skureayndR/ca/QKFACgZJmDtrWPs7k9moZ/Hs4RdHPFHTwFsbt+P3B1mxoJQ5pXnUNbbh8wfISI2fFAmRJMlIsowsSQyjjJ4wDgw4Abriiiv40Y9+xJ133sl9991HTk4OCoWC48eP43Q6+fd//3euvPLKUQtUlmW+973v8dprr/Hxxx+Tnd19ZlR2djZJSUl88MEHXS1Rfr+fTZs28cgjj4xaXGeKMur4zspp+IKhHjOkziSFQtiaWjFFReBxuKjYXI7bZsfx5Srapy9vsSQvBZvbT6RBS0laHHsjI3C0WDFYzJhjorouchHxsVjrmkgvjie9pACFSolSrSI+MxVHqxVjbjZ/3X4Uk1bN29sqqLG6aLW5+OJgJXNnFvYapzHSgvHLQYWW2Gimrfr/7P13cFx3eueNfs7pnDPQjZwzQTBHMSiSyhqNRhppNDNezzju3nfLtbu1rq1ba+9btv+wveVa37LLvq937Lu2x/YkaUbSaJQjKYk5gyByRjfQOZ8+59w/QEIEEQiQAJPwqWIVie4+/esmus/3/J7n+X53ojcZmegd5Mir71DI5Wndv536bR2Lvt6BUxcYONVJJp5CbzISaKiacx+7b+5O1LVrMVjMTPQOkYmnOPrzd9nz8tPoDHoO9Yzz02M96LQiL+9opK10doxCMhwjPDKOu8y/oMASRQG35faWK2BueWvAPFdMj0dSiyaGC4IAq7AdPl+j+kJcEQa9E0koXo9/gcb5a7EU1+Kd6GHsyAkw2Va2dLYErghP//PPMcDc35XxSIqx4NzoihtFyUsokgSCiJxfmmXFrWYyHOfTo+cZnQhjNuqJJVL0D0/w6jufk8tL7Nu2jq3rV9aQ9E7kvi0tuBxWrGYjVWVLC/Zd485kWfusf/RHf8RTTz3FP/3TP9Hd3Y2qquzZs4cXX3yRrVu3rtYaAfjd3/1d/vmf/5lXX30Vm8020/PjcDgwmUwIgsB//I//kT/+4z+mvr6e+vp6/viP/xiz2cyLL764qmu7Fr1Ws6SplKO/eI8LHx3B4raz79vPYLSayKXSc+IpACo9Nn73/nUz/9785ANMDY/hLPbO6hVqf2gXpU01qKrK8dc/IBmO4iopouPgXiKjQT7tGeezzCQ6kxGPUcuUCEVGLaVFc8schbxEz9EzFHJ5/HUVTA6NUbmuCb1p+qSWjiXJJlLIBZlU5PrN49MJ8yreigCt+7ZRt2X+xtxCXiI+Gcbmcc2YD17BUeRh69MPkU2nySfTFPL5mRNyKJEmkZMQ8wLh1Ox+DCmX54tX3mJqaAxvRQn3vfTUHevePH9UwsS8973VvSXp8Qn6fvJzVBWqn3kcS+nSSrzVTiO9E8lpIbQETEYdu4trcXYoRE6cX/n+oQW41rDwSERL78Tqv/e+zRtQ8nkQBHwb16/YcVeSdw+d4lL/GLKsUFVWTEdzDSMTUySSGWRZIRJb2v/t3Y7DZmHXpubbvYw1VoBlF5q3bt266mJnPv76r/8agH379s36+Q9+8AO++93vAvBf/st/IZPJ8Du/8ztEIhG2bdvGW2+9dUd6ACmyQs/R00RGJ4iHphjp7GXb1w4Qm5jEV1V23fKNyWahrHnuCUFn0OOvqyQeCgOQT2cYOttFeGQCOS+RLqjYnUUIjQ08c3AHY0MTpEUNBZOZnmCMT7vHKHdb2dtQytC5S5x99xByQabt/u1sOLhvlmgoaagmsqmNfCZL9XUS3PPZHGNdfcgFGU9ZgIYdG+d9jYosc+TVdwj2DuKrLmPb1x6Zk7Xlqypl53OPEuwbwl9bOSPIttf6mUxmMWg1rC+fvfsjSwVyyTRyQSabTCNLhTtSAK1kOrisKKTTOSxm44o1akYudBHt6gYVIhcuLlkAwfIEw6zS2QamRdCFEzey5EWRCzLB4RBanQZviRdQcW1oWdHy1lLQWS2UPXz/qj/PzaDRiGh1GircPg7s3YTXbcdsMrChtZZMNseG1prbvcQ11lgWSxZA6XSa//yf/zOvvPIKkiTx4IMP8r/+1//C6701EQBLqbUKgsAf/MEf8Ad/8Aerv6CbRNSIlLXUERkNYrSYsfvcM39WArvPzcZH99L12QlGLvSSTaRQFBmvy0lFfYBIqZufnuxnMJJEp9HQk5TQigIXx6M4zHoqPTa0Ou10M6YwnZR9rWAwWExsfGz/ktaTisSITkyi1WmRC/KC/UK5dIbwyDjZVJrISJBcKjMrkf4KgfoqAvVVs3/msPD9PfMLMaPVTNv9Oxjt6qOkseaGTPlykowgMLO7J2VzjHUPYLJZbroZe6np4EtFlhVef/8o/cPjNNaW8/DujhWZDrGUBjAVFYGqYClZvebPa0tntU/UU+Fa+ab0U298zMVPLqAzGSg5+CDupjqORLQrWt66lciywtEzl4gm0mxqrcXrXjk/nAd3dVBR4sPtsOJ22ugfnsBhs/DY/s0r9hw3i6qqHD/bQ99IkPbGShqql/65TI2OgaJiLg2sTVJ9RViyAPrv//2/8/d///e89NJLGI1GfvjDH/Lbv/3b/OhHP1rN9d3T7HzuMcpb6tFotfMaB94sgYZq7EUetLoPyaYzeMr8GK0WStsa+bMPzjMSSzMez+CzmpAVFZtWIDERQlVlsutKaLq8JlmS5o2bUFWV08NTjMfStJd7Fh0Zt/vclLXUExoYpnbLuln9TVdjtFqo3tDK4NkuylvqMNlXztCrvK2B8hsMTe2aiPJvR7rRa0S+taOREqeF8x9+QfcXpzDaLGz/+kE8ZTcmCJaTDr5UYokUPYNjxBIpunqHuW9zC2bT8pv9VVUlOTiMIknYa6pwNtTR8pvfRVVVTDfgRrxcrpTOxow6NphX3tytZzJPOFVAIwlcnJLRRrRLjqm4E+kbGuf9z86QyWTJpLM8/ciOFTu2026Z6fF5+9OTHD/bjdNm5blHd+F23hm77FPRBB8fPUc0nmIyHKO63I9uCe0IkfOd9P7k56CoVD3zOJ72G7ONuBuIxJLIioLX9dUxi1yIJQugn/70p/zd3/0dL7zwAgDf+ta32LVrF7Isz0yErbE8NDotVR03P5mxGBannW3PHkBRlOl0d6ZPak1+J8lsnnK3lY2VRbSXecgNDpHOhLEpedLdfYgtNTMp64nJCOGRcbzlJTOO06PRFP/yxSWCiQwXxyP8vx5cuHchHgqj1Wtp2L5h0XKZIAi07N1K0+7NM7tEqqqiKuptjZw4MzxFTzCGViPSNR6lxGkhk0hRKBTIpbPkM9kbOu5KlryuxmGzUFPhp39ogvqqEkzXachfiOiFi/T86BXUQoHKJw5StHUTRq/n+g9cQa5Mkx3qnL8X52aQyuqRWyeRBejGjv4OFD+qqtI/HCSVyVJfVYJhkdKtXq9DjcVIj4wTzyUo7OlAa1r5nbOJUJRsTiKiJokmUneMADIZ9FjNJpKpLE6bZclTaZngJLmpMKqqkgmGVnmVt4/+4Qlee+8IiqLyyJ4NN2WJcC+wZAE0NDTEfffdN/PvrVu3otVqGR0dvSnfnDVWDlVRmBoeR2vQz5j/JcNRjv78XXLpLOsf3o2/rhJBEPj65jp21QfwWk2Y9dO/BpFCjvVFVvKZ3KxA1XgozOF/e4N0LEHtlnbaH9o163mXsll8+u1PGe/ux2S34Qz4cJcsPj1xRexkU2mOv/4B6Wictvt3zLEHuJpkJMbw+W4sDhtlrfUruo1dX+Sg1GWZGbEHaLpvMzqjHrPDRlH18r5Irm62vRAVef9X50g4Iqx/aBeC8eZPwBqNyOP3byGZymC7CXO0XCRGPhYHRSE7Fb7pdd0oqyZKnKVE8uvof+V1sq+MU/r8M+BcuGwiJVMIGnFVRMVCDIyGePWdz0hncuzY2Mz+7esWvG95wMtG0kwqKSoiEqmRMRx1s3tz5Hye0NETqLKMb/OGG3otOzY2oqoqxV4n5f5b0waxFCxmI888soOJUISKEt+Se99cbc3Ee/pQFRn3utW9KL2dTExGmYzEUVWV8cnomgBa6h1lWUZ/jcumVqul8BVL3b2T6T1xjrPvHkar17Pl6QcpqiojNDBCqH8YuSAzerF3RkDoNCIV7tlXba6SIna/+CRSNjfLiDAdS5CKxaens0JTMz8vcVp4YWv9TAlsMXRGA6KoQavTotUtvfk41D/CyIUeFLlA/8nzFNdWEAtOodFoSIajXDx0HKffx7oHdnLu/c8YOHUBo82KcQX6cq6mvdxLmduKVhSxm6Y/B85iL5seX37j6tUlr5Cvml/91d+R6OnH5XOTbq1dVmPxYmhEEYft5szR3G3NJIeGUfJ5fJs6VmRddxrx7j7So2MIGg3J/iGsZfP/3kQ7L9H3ymto9Hpqn//aiv0/XY9MNkc6m0cqyKTSi+80CoJA66Z1jGdTmHxeTMVz7ROmTpym/5XXUWUFVZYp2XffPEdanNqKALUVt+b1LxeP04ZnmTtSJq+Hpl9/eZVWdOdQWxmgrjJAQVZoXEZ/1L3KkgWQqqp897vfnWUamM1m+a3f+q2ZNHaYLpWtcXtITEbIJtOImiypcAyqynCXFOMMFCHl8hRVX3+nbj5/HG9FCTUb20hMRmjY8aUxnSAIrC/3sn4JG4Adj9yHv7YCq8e5rEZvR5EHR7GHbDKNpzzA8LlLnHrrYwSNhlQkTnIqgs3roqSp5sqiZta20qyEP9C1Ja/RUBbVbMVq0qO1mNCa7wz36SvoHXbqXnj2di9jVXE2NxDpvIhGr8deW7Xg/WKXekiPjCJoNCT6BlZVAGVCk0weP4XB7aK2vY3dm1tIpbNsWXf9ENPSB/bi6ViHzmpBu8BuoiAIqALc9jyRO5CzXQN0D4zRXFtOY829JRK8LjsvPrkP4LZHeNwJLFkAfec735nzs29961srupg1bo6q9c0kp6LoTUb8lyekHMVe9rz8NLJUmHea6noossz5Dz5ncmiM+m3rKaouR1VVssk0BrNpyX05ZoeNmk1zHXWvh93nZveLT5JPZ3AUeTj3weckI3FkqUAyHCObTKHRarA47RjbmhmeSOErcmENFF3/4KuEqihMjUyg1Wln7aRl+rsJbGlBqW5mCAe9nRNUO43YvvEkXcfOUFRZhsHlvG3r/qriqKuh7T/8JoIgoFnEFd7RWEfkQicavR5bzcKl2JVg6JdvEzp+Cr3NhtHtYs+WpTflCoKAaZE+Le/G9dN9dQUZ7+aOFVjtvUMskeb9w6eZjMQZmwhTWerDaFj9fLFbyZrw+ZIlC6Af/OAHq7mONVYAp9/Hhkf3kYrEZxkIGpa5q5BJpKYNFANFJCYj9J08TzaZQikUKG9t4MJHX9B/qhNPuZ8tTz440xS9WpjtVsyXp8HKWuqYHBpDyuYw2i2kwjFKm2qwOO18dKyfE1ob2WAOb+cIB9et7klqIfpPXeDMO4fQ6LRseerBOTtvssNPLPiladz7p7o51xvEG8nyjVI/dqv5Vi/5K89COyVX42yoo/V3f2O6B2gF+rQWQ9RpEQURQatBWOEhE1Gno3j7lhU95r2CXqfFbDaijaewWoxo1wZ87mlW98y1xrIIDYyQDMcINFRhtCx8EpQLBaaGxzHbbVjdX5as0rEEh/71dZLhKFXrm9nw6L5lryGXzvDZj35JdCJEaXMt7Q/uxu51oyoK7lI/iiwzdO4SyXCEQj5PYiqyYHDpauD0+9j77WdQVZWxi30kpiKUNE6Xv4rsJsbjaXIFmfcuDLO9xo/LsnI5b0slMRkhk0ghiiLJcGzR0qOqqgQnI2RzeSLxJPFkekYA5aIxRt/7CEQR67bNOLwe9KssNtdYHN0in8uFSKYyjIUiBHwurEv0nyo/+DCW8jIMLhfWyrUhk1uFyajnqQe3MRYMUx7woV3CCP0ady9r36Y3iSIrJMNRTHbrnNiG5RAdD/HFz94mHYtT1dHClqceXPC+597/nJ5jZ7A4bOx8/jGsbidwuVk5EiOfyREZu7FRzkwiRWIqQj6TJTIaRGfUs+Mbj5IMR3H6fWh0WkqbaihIEp5S/8xz30oEQUAQhDneSY+tq+RIX5CxaAqTXovKjQcV5lIZRi/2YrJbKa6tWHJPUS6dQdBosPvcuEqK5s07uxpBENi9uYUvTnVR6vcSuKo/avLYScY+PsQFSUOwc5SK5nqeeXjHDfn5rHF7kKQCr7z9GYOjISpKfDz/2H3oliBiDU4Hgd0r5+GzxtLxuuxrHjlfEdYE0E1y9v3DDJy6gLPYx7avH5jx2lkuUi5PIZdDkRXy6cyi942Oh8hnsqiKSioSnxEhRpsFs9OGKIo07Nw4c39VVQmPjKPICt6KkkVP5navm+pNrQR7hqjd2o5Gq0Vj1WK8qizTdv8Oajavw2g1z4mpuFkUWUEQhRtqYrYa9fz7+9s5Pxam2mu/qabl8x9+Ts+RMxhsZnZ8/SDeipIlPe7CR0fo/uIUBouZmk1tmGzTpbsryeIZqZRgLEPvWGzmMY01ZfOOo2otFrQmE+MypCSZobFJguEYVaWr29+UGh4lG47gqK+5pePe9yK5vEQkliQvFYjEU+Ty0pIE0BprrLH6rH0SbwJVURjr6iMdSyAXZJJTUdyli/vbJMMx+k+ex2S3Ur2hdaaJ2FMWoHX/junyVcfCQXuyVKCqowVFkXEUefGUfzmJcvHT40THJzFazOivMr4bvdjL8dc/QFUU1j9yH5Xt86e+w7T/zrr7d8Ii092CKGJxrvwV0kTPIGfePYTZYWPjY/tnia6lUuW1zfj03Az5bA5FkSnkJQp5acmPk/J55IJMIZdHvvy4OWaH/eElmR0WbdmAzmYlNTDOuckERR4Xfq/zZl7WdUmPT9D1f/6FbDhC8bYt1Hz9yVV9vqvJhCZJDgxhq6q45WaLq4XFbGTX5hYudA/RXFe+5BLY3YCUTJGPxTH7i1a8TymdzXH4WCcFWWb7hiYctrW+uDVWnjUBdBMIokjNxja6j5zGU+Zf0nj3hU+O0HvsLHqTEYvTPuPLI2pE6rbOn45+hUwiOVMma9m7bY6QURUFVBVVUS4nr0+TjiXIJpIoikIqOn9q+/RkVwqdwXBbQkJVVaXn2Fkmh8bQjoemYytarz/yu1q07NmKyW7FbLctyT7gCk27NmEwmzDZLNg1EpkLJ2aSxU/nzF/GLCwhY0rQaNBXV1Fpd7LeZsFhs6BZZTdsKZlCSiRRpQK5yK0zPixks3T/849JDAxir6mi+Te+i0Z/90/fCILAxtZaNraufNTN7SQfT9D1Dz8kEwpRvH0LFY8+vKLHv9A9xOETnciKgsmoZ8/W5U+QrrHG9VgTQDdJ/fYOqja0oNVpEZZgu67V6RBF8XLQ6PKumsLDE5dNDQsMn7s0RwA179mC1e3AaLPMciYubaolMhpEkWUq2hqQsjn6Tl5AVRTqtrSj0WnpP3mBCx99gdlhY+szD9/QyPzVqKpK3/FzjHT2UFxTSd3WhfO/VFXl7HuHGTzdSS6TxVVXOUdMqqpKsG+IbDJNoKH6hkuNS8XmddH+4K7r3/Hax3mmH3el5OW8Jlm81KLl+LkeREGgtaFy0ZyiXF7iZ786xPD4FLUVfp49uPz1LHv9VRWU3L+HzPgE/t3bV/35rqDkJaRUCrVQQEqmUKTCPSGAYFosTB4/hc5qwbtx/ZK+J+4UVFUFVZ2z5mxoktToGIV0mlh374o/r9lowGjQUZCVe7bnTZEk4n0DGJwOTEW3bpBkjS9ZE0ArwHKan5v3bMFR5MFoNS/bqdhVUoS3ooR0LEFJ09wrSovTTtPuucnMV0TNFU7+8kM++8mbyAWZUP8Iu198gtHOHhJTEdLxJJGx4A0JoPDoBMPnu3H6fXjK/Fz4+Chjl3o598HnTPQNsuPrB2d2l9KxBGOX+shnsljdTgZOd4IANo+TzU88gKNodglkcnCUI6+8TTaVpn5bB+sfXr577bUosgKw4hljV0pe/uefm5Ms/rPXP+Kddz/DJMDXntzHzr1bFzxOOpMjHE2Sy0uEwnEkqYBmlT1JRK2Wsgf3repzzIfebqPy0YeJXOzC3dp8Q9NWdyoj737I2MeH0JpMaC1mXM2Nt3tJwLQwmzp5Bp3diqe9bY7IyUVj9P30F0iJJJVPHMBeUzVzm6WsBE97K8nhEfw7t93Y80sFOnuG0ek0NFSXzsrtaqwpQ6fVUJAV6quW1n93tzH05juMH/oCg8tB2fNf58TQJHmpwK5NzTjtN+fgvsbSWBNAtxjj5ebYq1FVlbFYGr1GxGubv0dAVVXCoxP466sprim7qdHzZCRGLpNFlWUGTl2g48B9lLXWEw+FMTuns7pO/PJDpobGaNm7dWbMfDFUVeXUrz5moncQq8vB9q8fxGgzk0tlEUWRqaExElMRXIEiVFXlxBsfcPHwcbKJNP76SuxeN0pBpqi6DFdg7muTsnny2RxyQSZ3uUk8lskRSeUoc1nRLlPExIJTnHjjAxRFYcPBvbhWwDjx6nyvyeJajkS0dJ7uJaBXUSvLmYol+eyLs4QSaYyoTF3ogkUEkNNuYcv6Bi71jdDeVHXHGrLJ2RyR851ozWYcjXU37MLt6ViHp2PhnKu7FVVVkbPZaYGh3vhk4koz/Nb7jB/6DJ3FgtZsxtlQN+v22KUeImcvoMgFJo+fmiWANAYDtS88iyrLiDc4CHHsbDfvHz6DTqvh8fuhue7LUrMoCtTdo8LnCunxIHI2Sy6scv58L5/3jCHLChaTgX2L5L2tsXKsCaA7gCP9QX56rAe9VsN3dzVR45sbRxHqH+b4a++TS2fIbGmf5fFTyEtM9A5itJrxlF3fnn/dgzsJDYwy2tWHlMvzxc/eYvdLT1FcW4FOr6f/1AUO/+iXSNkc4ZEJnvlvv002mUHO57l46DgarZbW/dtmJpyuoNXrEUUNGq0Wg8XEjq8fRG80EB6doKiqHJvHNXPfXCZLIV9AlgrkUhlqHmnDU+bHaLPS/cVpMokktZvXzUy4FdeW07p3G+n49M8jqRx/8+E5gvE0u+oDPLtpeT0W490DTPQOTYvPS/2zBJAsFVBVddFeqNGLfUQnQpQ01uAs9s6UvFxXlbwiXRfI/OJVLmazlD3yINqWZtwuO+HQFC5Rpb2petE1CoLAzo1N7Ny4cNP6atI9MMZkOE5Ddcmiad8j73/E6HsfoTWbqXvpuTkn0q86Ro8LVVFRZQWN4c5JmldVGRRlundQmSvMzP4iTEVeCtkslnny0QRBQLiJKdBcXrqcJamSk5Y+aHCvULJvN6qqYvYXka4pxzQyRUFWsK5A5M4aS2NNAN0BDEwmCCayaESB4UhqXgGkyAqKLKMoKnJBnnXbxU+P0fnpMYxWM9uePYC3fHER5Cjy8uj/9R3e/X/+jXgoTDaZppCXZtyWM/EkqiJPN1QDf/ePv2LyzAWKDRqsmuk+JqffR93WdmRF4Yu+IMmcROv+7RTXluMKFM2Ind0vPkkmkcJoMc30AAmCwPqHd2OyWYmHwvjrKilrrUdvNDB8vptjv3gXKS+Rz+Rm/JA0Wi2NuzbNvIau8Shj0RSpvERPMMZycQV82H0uVJVZ4iceCnPsF+9RyOdZf2APRVVzx9MTkxFO/PJDEpNhJnoG2bZ3PWTj+J9/jiEcnOgP4zdq0OSTdIcjKLJMZiJI9a5tPPXEPoZ7qqn2OalYv/C03+1mIhTmZz99h2gyTdv6Rr55OT9oPgqpNIokUchmkTOLh3V+FclFotP9TML0pNtieWO3krIH92N0u9HZbTga5l5AWMvLaPr+d5CzOcwl/hV//k2tdaiqik6rpbn2q2f26KivxVE//b6rqorRZKIgyzccMjs4GiKRylBbEcBouPWDLHcjawLoDmBTlY/eyTgmnZbWkvknyYqqy1n/8H1kEikq18/eEUjHEshSgWwyTTaZWtJzGswm1j+0m+EL3QTqq2bEz0hnD/2nLmBxOjA7rJQ9sp9TP30XIRYnJKjYAh6MNgumyzXqcyNh/vVIN6lsnrp8guZ4EH9tJaKoweZzoTcaZo59NZ6yADuem/tBD49MEB4LIksy8dDCU0iVXhubq4oYCCe4v3muSLkeRdXl3Petp0Fllpt2qH+Y0MAwiqww1tU/rwASROHyH3Gmb6JkaxvS5YiLTFYCowZnUz2+zR3kEymKtm5EEASaastoql3+em814QsXifb0kZQVEq7F+xECe3chaDTo7FaczQ0rug45m0NKpzG4nKsScHsr8HasIzU0gtZkwtl45+yOGVxOSh/Yu+h9jJ6lBxcvF5vVxP7ti0++flUQBIGaihsXmSPjU7zy1mES6Sxb2+t5aPeG6z9ojTUBdCdQ43Pwnx/ZgCAsnGIuakSqN84fiFi/vQMVFZPNir926flXpc21s9yUh85d4pN/+jmR8SAgIGpF4t29WKsryEh5fOV+dj+2C4PZNMcYUMrmmBodZ7D/En3Hz3H2/cNUdbSw/esH5xVAC2GyW7B73RSkAoqqcOy196jqaJ5T2jNoNby8sxFVVW/4xGh1zd1pc5UW4wwUIeclfJXz9yBY3U42Pbaf6MQkgfoqhNT8Qk1ntVL3zeduaG23G5dWpEMrEUNla9n8njyKok7/3vm8VD/z+IqvIReNcemf/o1cOELp/Xvx77qxZtvbja2qktbf/T4IN2bwuRhKoYCSz6M13ztN41eIJdKc7uzDYjayvqn6pi0gVEUhF46gs9vumQnDK2SyOdLZPIVCgURqbRd2qawJoDuEm0nodfp9bH16cR8OKZdH1Igzzs2qqjJ6sZdcKkNpUy0Gi4nBMxcpSNJlUQGiqKEwFebXvvkUSWkPlcVO9Nf0xbSWunl+Sx2RaJLMJyHGh0RUSSUTTzI1PE5sYnJZAqi8tYHkVJTEVITQwCjhoXGS4Sh7v/21ee+/0icUd0kxe15+GqUgLzoJV1xbQXFtBQCZBQTQ3Yy3Yx3bYnEUSSKwZ+ec2yOxJG98cJRcvsAj922g1L/yxoXp0TGS/UPI+TzhcxfuWgEELGn0PRMMMfbhp2itFkr370FzjdWDqqqkhkcQdTrM/mLyiQTdP/wJuakwZQ/fj29Txyqt/kukZIpEXz8mfzEmn3dVn+uzE518dvIiRoMei8lIY83ypmavZfit9wh+fgxzaYD6l567p1zOq8qK2b25hUg8xZZ1d84u453OmgD6CjB2qZ+Tb35IdHwST6mf9QemR8iP/eI9cpks8VCYjgN78NdVEhkL4q+vxFtWwuTgCKUt9fiL3QsKDY0osqN2eus221jCxU+rGTjXxdDpi4xd6ufQB0fZ4fVQ4lraWL3RambDo/uIh8J8+i+/IBmJY7QuXIJRFJXjgyHS+QKbKn1Y5ql95zNZeo+dBUGgZlPbdT2EFgui/aqgNZupOPjQgrf3DI7RPTCGoihc6BlaFQFkKS/F0VBLdnIK38b1K378O42xjw8z/unniHod5kAx3o7Z5aHJYycZ+MWbiDottS88i5zNEbvUg5LPM3n81KoLIFVV6f3Jq4TPnMcc8NP8/e+gty/+uZZSacY++hS1IBPYu+u6978aURTRiCIaUbj53R9VJXzmPNlwGDmfIzMRwlZVcVPHvJPQajXs3tyyIseSZYXz3YMUCjIt9RUYboMx7q1iTQB9Beg7fo7hCz2kInFy6QxWr4vqjmbkQgFFVpALBQBqNrVRXFOB3mRAbzJet7wU7Bti5GIvmVgSm9c17c/zyH2YnTYGT3WSSqQ58+4hzhmd/O4zu/FYlz7dYPe52frMIyTD0Zmdlvk4MzLFP3/WRUYqEElleWrD3JH9gVOdnHn3MIIAWp2Wuq1zT6aqqtJz5AyjF3upWNe4aBzJnUZ6PEisqxtLeSn26koudA9xqrOPmnI/W9rrV6V3ptjjxOuyU5BlSopWp09Eb7PR+Gsv3bMlnmvR26yIBj1aswmdZa7oT49PkItEETQimWAIV0sjtspycpEortbVnxRUZZnsZBhFkpDiCaRk8rqCZurkGUbemY7h0ZiMy/KYuuKHYzYZqCm/uSZsQRDwbdmAnJewlpdgDiweWfRV5kLPEG98cIxCoUAmm2fnprvnu3C5rAmge5x4KEzv8XNEx0KoikoyHCUxGcZXVUb7Q7vJJlJUXj7ZC4IwqyF4sRNnLpXh2GvvM3zuEvlsDk+5H53RQNOuTTgDRRjMRuLhGEI+T2ZgiEQ2v6AAymeyjHcPYHHZZ/X6eMr8eMoW/+IryAqSolBQVKTLxobXImo1aLQiICwY3pqOJbh46BjJcIxUNEagoQqDefYWeS6VYaJvCJvbiatkYd+gsfFJDv/8KLZ8hv1PPIi1ePVcXpVCgd4fv0LsUi+WEj/1v/4yH35xlvFQhLFghJoK/6okW5eX+Hjxyb3IsoJnibt7N4Ko1d6wz8zdRmDfbkz+YrRmE/bauRYJ3g3rSY2MoTEacLU0YnA6afretymkMxhczmU/XySW5ItTXRgNerZvaLzulb6o1VJx8EGCnx/DVlOF2X99EaE1GdEYjaiyjNa8vJKT2WRgS/vKxeEE9u7Gt3kjWpNxxbPL7iVkWZn+o6gUZPn6D7iL+Wp8s3yFiYfCpKJxNFoNsiyjN5tIJDOkIjFqN9+42ZaiKoT6h0lGYggIaHW6mdKSr6KEnS88xoc/+hWJgkpNkY1y98J9QGfePUzf8bOYHTZ2Pv/Yskwe28u9PLuxllROYmfd/OOjVeubp4WPAOUt83+hXslmyyZTWF3OeT2ATr31MYNnLmJxOdj94hOzfI2u5tBbH9F37DT6fBax8yIH/uj30RhWz85fLRRQFQWlUEBEwGW3MhVJYLeZMa9iZIjLMfv/VM7nyUdjGD3ur8wJJp5M8+mxCwDct7nlpsJONXo9nvb5Bx0ALKUBWn7z12b9TGs0ojXemG/M0TPdfHbyIjqNBpfDSntT1XUf42ppwtWy9N0mz/o2RL0OVVZuyS7VYgiCgG6Rcvoa07TUlZPN5ZEKBTa03FsZdteyJoDuEVRFIR4KY7RaMFz1JeytLKGirYHh892oWg2nbEVIqo3KeI4ti1zAKbJCdCKE0WqZaWJWZAVVVdBotSgFGYvbgZTPozdbkFvb+CKvxTAZRw0Gcfi87HrifrKpNE27Ns2yuQem88zOd6OqKulYHEWWyWey5JfpI6PTiOxrWrw5UqPTXrekpTPo2fbsI0THQrhKi+fdKUrHk8iF2eu8YoCYkUoJxjL0jsUwFCSEXBZNPkumpwcplbphASTn8wz8/E1SIyOUPrAXd9vsOr+o1VL19ONELlzEWlGOyevm8fu3MDw+RZHHcctylORcjkv/9COSg0N4OtZR9dRjd+3Y+nI42zXIkVNdIAi4HVa2ddwZMRdLwWwyoNdp0eu1mIyrMxUlaDRzfmfXuLPR6bR31e/xzbAmgO5CIqNBMokUGq2GyFgQX1UpEz1DdB85fTmG4sDMBJPRYubAv3+ZTCLFyeEpPvv4AqpGw6mxKFvqFxYOFw8d49JnJzHZrex47iCCKPL5T94kOj5J+0O7qd3cRv22DkY7e8mUlfNeSiTbNcZw7zA1/V1o9To2P/kgJY3zux0Pnr7IiTc/AlWldss6TDYrNo9zznj9rcRks864WyeyefRaDYarwkrb9m/H4rDh8HtxlxTPyfwaOjeELTLJsw9u5a0vDqFPh/FVBFBy+WWtI97bT7y7F9vl6IHQsRMU0hkE7afznkxsVRWzGjot5pufmFku2akwif4B8rE40QtdKI8+fEeNGkdiST49dgGDXsfuzS0rdsK3mg3TxxIELOabc/BNj08w+Mt30JqMVDz2MHrb6pUWAba21+O0WzDoddTehAfNGmvcrawJoLuM8OgEn/34TVKROFI+jygKuEv9aHQaMvEkhVyexGRk1gi3IstodVrK3Tbqy3zEs3maFzBcvMLk0BiZRArp8vEyyRSXPj9FJp4kFUvgDHip2dRG695t9ISTfPbReWRVRSvnKOQlFEVZdDenIEnIkgQImO026h/uWKF36Ob5rHec107147YY+bVdzbgs07so3ooSvBUlZPq7yV48hbOjiVRZPUciWroHp8j+7Cf0HD2JUpBoqStHNNTirK/FuIxx4UImQ99Pf0FyYBBLeSl1L34Dk89LdiqMrXJ13XJVVSU5OIycyWKvq15W742pyIerpYl4bz++zRvuKPEDcPx8D8fOdqPRiPjcdjparp9vdzVKoUDw82NIiQS+rZswuqfLn60NlZhNRgQBqq/Tr3Y9gkeOM3XyDKJGg62qkuLtc4ONVxKdTktr/b0zCbXGGstlTQDdZWQTKTLxJLIkUcjm0F++6qze0EohV8BR7MFd+mVta/BsF6fe/IjoRAhPeYDnH9qDrSyA9zoTWbWb1pFLprF5XXgqSkiGo+gMOvI6Laos8+kPX0NnNLDhwB7q66v47u5mYpkctRYdw8eM6IwGSpsWPslUtjdRyE/n/1zrbH27OT4QYjyWZiqZpX8qjsvyZU/S1ZlfwYadnOgPk8km8aYiXBweITMRRFFkjEU+6l96Dmdj/YIeMNlcnkw2j9Nu+bJcJEw7TCOICKIGg8tJ4797iXw0Nm8e00oS7+mj+59/TCGTofzAA5Ts3b3kx4paLbXfeAY5m0VzE/4qqqqSj8Wnm2dXsG/KZjZh1OvQ6bRzyoK5aIz+V1+nkMlS+fgjWOd5n6Odlxh47U3kTBYpmabm608C0zYQdZU3Fl1wLUaPG53Nisagx3A5A2+NxZFSadRCAb1j5Rv917j3WRNAdxlF1eU0bO8gGY1TVFlGPpujqLoUT1mAyvYmRI1m5mTaF4rz7hufkOsfphCNosgKZcNj1DTPL0zGuwdITEYINFRT0lhNoL5yxr3WXVLMQ7/9EgOnOpELBcYv9c+YHQYaqmkOfNkQ7LsqqHUh9CYjtZvXcfJXH/Hpv7xG677tFFXfGRERGyp8jERSWI06imwmVEWZJWJKtrYhdeyfib1wjQ/R89Ofk4/FMQWKEbQa7DVVWCvKFxQ/sUSan711iFg8zY6NTbR4LIhaLWZ/MTXPPUW8pw9bdRU6ixkwY3A6AVAkiZF3P0SWJEr27l6Wr8r1yEdj5ONx1EKBXDi66H1VRUHO52c14AqieNPj6hOfHWH03Q8xuF3Uv/SNFTuxbWqrw2GzoNdpqSqbPcEX7exi6tRZ1IKMpcQ/rwASddPTaIpGg6hfna/N4u1bMBX50Bj0WMvvjM/CnUxqdIyeH/6EQi5H1ZOP4m67d8e111gd1gTQXYZWr2Pdg7vmve3qxt2sVOCfP+9iPANeQUfA48ZbXkJxzfxllFhwimOvvUd4eBxXaTEP/9aL6E2zd4nKW+opb6mfDgwtyCgFmUBD1Q2/lmD/MINnupALBUzHztxyARSMpzk1NIXPZiSaznF2JMzWmmJ21Pox6TT85Isu/uR//5LdZoX7D+6aNxcMIN4/QHpsAkHUUPfNr+NqaUTvsC86nTMxGWF0IkxeKnD6sxOIY70Il3dRnA11C54Ae3/8Kt0//DGqopAaHKH1d7+3pNc6NBpiNBimuryYIo9z3vs4mxvx79yGlEpTvGPLgseSczl6fvQKqaER/PftJLB7+5LWsBTCp8+RCU2RjyVIjYzOEkBKoUCifxC93YapaHnWAhqNuGBflMnnxehxI+fzC452OxrqqP3G00jJFO72tmU991IRRBFH3fJKc19lkgNDJIdHUAsyse6eNQG0xrJZE0D3OKnySrw1FTz5wHpcTuscbxuA4QvdnP/gcyZ6h0iGo6Ricc5/+AUdB/bMe0xFUTCYTRitZqweF4osI2o0jF7s5eKh4zgDRTRs68DssC4aAWBzO7G6HeRSmVmJ7IshZXNoDfoVmTD6ybEejg9OYtFrkVWVTL5AMJFBUeHVE32c7Q8iRxK4IxlqT3cuKIBcTfVEz19E0GgwFfmInL2A3unAu3H9gussLfZQU+4nHEtQrWTJhacN7rLBSWhY2Mo+OxWe7p1SVHKx+JJeZyKZ4bX3jzA+GaWqtIiXn96PVjt3TF1nMVP9tSeue7z02DjRCxeRkimCnx/Bv2vbik18edavIzsZxuh1zyn5jbz3EWMffILebqPhO9/EHFiZxl17bTVN3/s2Sj6/YJlREATc6xYeUV/j1mOrqcJeU0Uhk8XV/NWYWlpjZVkTQPcoRp2Wl7Y30DkepcZnx1/snPd+iqxw4cMvCI8GEUURi8OGqNMS7B9GyuXRGeY2s/YcOcPQ+UuIoobQwCig0rhrE33HzhHsH6LvxHl6j56hvK2eTY/dj0Y3/6+Zo9jL7m8+SS6dxrUEZ9aLnx6j9/g5fJUlbHh034KmhktFUUFRVTSCgNWoQ5ZV7CY9r53sozcUI6dCwKinQq9OT331d0MmAcDo5ZF3uBJ2+T0EUaTn314hdOQ4OpsVvcO+4BW9xWzkucd2I0ky8tQkA5k4ol6Ps2XxL/KqJx8lF4mCqlL34rNLfJ0qsqKgKiqyrKAu/S2aF6PPh7WinPTYOK6WphUddy/evhl3WxMagwFRN9uLKT06TiGdRpEKZCZCmIqLlpSxtRiqohDr7kUQRey11Ut6LbKicKazn1QmR1tDJQ7bve9SfSdiKvLR9BvfBVW9YS+kNb7a3JMC6K/+6q/40z/9U8bGxmhtbeUv/uIvuO+++273sladQl4iE09icTkQNSJVXjtV3sV7KARRwF7kITEVxV3mx+Z2cOnzU4RHJrjw0RHaH5pbbrO67OiNBhRZJjIaRBCh54vTeMoDTI2MU8jniYxOEOofIZtMs/Mbj6HV61BkBUGcnYhtdTtmuU8vhFwo0HfiPPHQFPlMlrqt65dlmDgfz26qpcZnp9hupsJtZSSawu8w84NPOnGY9bSWuvnuxkrsGgF9JgqZBM6OJiaLaxmPpMhkJaqd01+8Vxp2BVEAYbqccb2Ts0YU0RhEKJlrcLcQ1ooyNv2//8uyXqfDZubAnk2MjE9SWxlAN8/uz3LQWcw0fudF8vE4Ru/KZ4DprPObZvp3b0fOZpFzOQZ++Rah46eo/cbTC95/KYSOnqD/1TcQtBpqnn1qUSPCK/QNjvPWxyfI5PLEEike3be601przCXW3cvg62+hd9qndy3XBNAaN8A9J4D+9V//lf/4H/8jf/VXf8WuXbv4m7/5Gw4ePMj58+epqLh3Rz6lXJ4vfvorwqNBylvrWf/IfUu6mhUEgQ2P7qOyvQmb10VsYoqxrn6kfJ5MIklBVkhkJZzmL8tO9ds7cBR7URSFzk+OkpyKUlRTTsuerZQ0VHPpyCnOvnsYQSMwNTRGdGKSVCTOxU+P4i7103Fgz7xOy4shajQUVZcRHplAEAX015TyVFUll8qgM+rn7AwNne1i8NwlAnWVVG9snXkdboOG7R4Tdp8LjU6L1zZ9zO/saqQvFKfG58DvME9PfmXiOK+Z/LoifmC6P2Xq5BlMxT4qHj+AyevBVl25rNe4mtRVBlZsWglAYzRgMq5exMd8OOpqcNTV0Pm//w/x3n5y4SiJ/sGbMtrLRWMUUmkEUSAfX1pJURAFxJk/N7cDdTtRVZXohYtkJ8O42ppnRvtXAkkqIAjCvKXWlSB05Djx3j5ErRbPula8X4Gw3DVWnntOAP3P//k/+fVf/3W+973p5tC/+Iu/4Fe/+hV//dd/zZ/8yZ/c0rUkw1HSsQTuUv+yT/jLJRWJMTU8TiaRZLx7gNZ920Fg3hLWteiNBvx10ydro8VM0+7NpGJxqjat4+8PddITjLG1upinN0yXCESNBovTzsk3PwJgw6P7KG2qRdSIFNWU460sxWgxM9LZi7PYi83j5OSbHxEZC5KKJahc34Svcnkj3YIg4Cj2otFpyaUyjFzopn5bx8ztPUfO0HX4ODavm61PPzTjhp3P5jj7wWfEg1NEx4IU11ZgcdqRsjk+//GbhEcnKG2qYdMTD8wIo4DDQsBhIdPfTXo4TjqZwvbcc5xW7Iz1h/EbNWCc/cU+eeI0fT/9BWpBpvKpg3jWr06j7BrgqKslOTSC3m5bUh7VYvg2dZCeDINGxLPE5ubqMj8H920mlc7Schf76KRHxuj98c/JhSMk+gdo+PY3V+S4AyNB3vr4BHqdlsf2b8HrXvkRdWtFOZHOLnQWM6bipfUPrjGXRP8gox99isnnpezBfXPKzvc695QAyufzHDt2jP/6X//rrJ8//PDDHDp0aN7H5HI5crnczL/jS7wKvB7JcIxD//o6qUic6o2tCzYUrxQ2r4tAQzWTgyOUNNVy5NW3iYfCNO/ZQmX70n12NDot9ds7GDh1ga5LQ5wfyxDPSZwYDPHoukoMuukT/+jFXka7ekGFQH01omb2lXDdlnZqNrVhdTvRGfQUVZaSisSweV1Yb8DjRFUUYsEpFEVB1Iio6uxOlqGzXSSmomSTaaITIYprpk9MGq0Gi8NOKhzDZLOiu1y66zt5gdFL/aiKTGhwFFkqzBGpqqoyFk3Sc2mCwt+/gbr/YWqL5v8yVwsFVKmAqsgoUmHZr++rTj4WR1VVDM7rl0P99+3A0ViHzmK56WynpKDlsMGFJBUwJjJULsFWQBSFe8JAUFUUVFlGVZXr/s7KsoKiKOgW6Oe7mkv9owyNTaIRRfpHJlZFABXv3IqtshyN2bSiO1dfNUbe/5jw6bNoDAZs1ZW4mhpu95JuKfeUAJqcnESWZYqLZ18VFhcXMz4+Pu9j/uRP/oQ//MM/XPG1pGNxUtE4Ui5HLDi1rMeqioIiKws2D8+HRqtl8xP3I+UlwsPjXPr8BIWcRP+J88sSQAADpy5w8lcfIwPFtc0YbGY2VPjQa78UOXafe1rIqGD3zf4COvvuIQbOdOIs9rHt6wcAqNrQgjPgw1ddhukGTlo9R88ycKoTVJXqDS1UdUyXPWSpwMXDJ4hPhSnkJXyVpTiKv3Re1mi1bHn6QaaGx3EFitAbDfQcOc3Z9w6TiSewe13UbW6fd4dOURQGz/YSzwjksz2Y103BAgLIu2E9hVwOVZYp2rpp2a/vepy60Mfxcz3UVgTYvbkFURSmc9TGxtGaTDeUBn6nEO/po/dHr6CqKtXPPolzkSk4mN4NNK/QVX/f8AQDw0EUVeFS/yiVpV+d3QRLeSlVTz9GNjSJe5Edy1gixS/ePUI6k+WBXeuprVi8lFoe8OLzONBrNQSKFnecv1EEQcBSdvtic+4VTF43ok6Hzm5bUU+xu4V7SgBd4dreF1VVF+yH+f3f/31+7/d+b+bf8Xic8vKbjxzwlAWo2dRGdHySxp0bl/y4TCLFsdfeJR1N0Hb/Dkoal+4LIogieqNh2g26pJhUJDZT2loKV5qUr6AVBJ6p8+FrbZzVAwQQaKhmt9MOqoq96MtGWFVRGOvuJx1LoBRkklNRFFnmyKvvIEsF2h/eTUXb8q8yEpNh8pksWr0Ob0UpusuCZbxngLPvHiLYP4TOaMBgMc0Z9TfZrJQ1f3lSzSbT5DNZjFYL6x7aTf3W2f0DV5rJRUGguqMeqT+O4i9BXqThV2M0ULpvdRrt83mJT4+cIxiJE4klaa4rw+d2EPz8KENvvovWbKT+peexlK5cj89CKIUC+Vgcg8t50xNYV0gMDpMaHZ+J4rieAFoJZEVBkmRKit34fU6kgkx54Nb2NN1uBEHAu6H9uvcbGAnSNzROQZY53z18XQHUWFOG3+dCI4pYLTfuCr7G6lP28P3YaqoxOOxYSlb/++NO454SQF6vF41GM2e3JxgMztkVuoLBYMCwgpb7V9DotKx/ePknxKmhMca6BlDkAgOnO5clgK5gslnZ9c0nyKXSs8pNhbzESGcPoihS2lyLqPmyj2VyaIzTb32MzmBg3UO72HBgDwgCle1NC/YvOYo8RMdDjF/qx1dVhlavQxBFqje20nPkDJ7yAHafm4HTnSQmIyiKTHQseEMCqGpDC6loHIPZRCaZ4u2/+SHFtRUUVZeRz2SRshIGs4lcKg1AOpYAQUDW60lkJfx2M+JlcedvqOLMe4fJZ7LEE2n+8fBFElmJx9ZXErAYZprJ/X4nD3z/UWpqttCbUbkwGFn2updCPpFg9L2PUVWF0v175pj/Df7iDeRzF1CtDjzlxVgvC7zEwBC5cIR8XEN6bHzVBZAiSXT/8MfE+wbwrG9bscR3Z0Md9tpqUJVbIn5S6Sy/ePcLwrEke7a28tLT+5FlGYft5spp9yp+n4tir4tsLkdlydJE4tp7eXegMRhwt95ZUUS3kntKAOn1ejZt2sTbb7/NM888M/Pzt99+m6eeeuo2rmzpOIo9uAI+sskUvgWM95aC3mhAb5wt7PpPnufUW58gajQoikpl+5eeM8PnLxHsH5kRR7VbFr8yVBWFi4eOTx9Pq6Fx+wbaH57OjmrYvoHqDa1odVoEUaS4toJAfRVSPk9ZS/0NvR5XoIjdLz6JLBV4+29/SGxikmwyjaDRkEmkUBQZrV5H0+4tBHuHOP7G+yQUgbNFlWS1Oh5qKeeh1umdvUI2j95oQBAELpzu4lNvJQVZxWnWc7DSxeTQGNlkiol8BkVWMDntiPnkDa17KUweP83Yh5+iqgoGp4OSq3aSsqFJIqfOsS4TI2PSsPP+LTNJ5u7WZiJnz2MqKsJYWUFwKorHaUejWZ3JpOxUhFhPH/lojMj5i5QfeHBF/FcspQFaf+fXAW5JE+bw+BQ9Q+NIUoEzFwdoa7hzpvXuRIo8Tl58ai/5vITLceOWA0uhfyTIWDBMbYV/QcfyNdZYKe4pAQTwe7/3e7z88sts3ryZHTt28Ld/+7cMDg7yW7/1W7d7aUvC5nGx+6UnkTI5rCv8BSDl8siFwrQhniTNus1dUozV7UCr0+Eovr63y3j3AMdff5+x7gFMVguBy6W2ycFRxnsG8VWUUFw73ShqdTnY/dKToKrLKpvkM1kKeWlWsr2o1eAtD5BNpnEUexAFgWwiOdM3ZbSamegdJDYxxQg6+omgd9i5MBaeEUBOvw9fVRmJyTDWlgbOxyGdL1BkN2HzuChprJluJi91o9VpkRZa4Aqhs5jRXI4d0VpmXzlntQbyviLMikJFaz32y++FqqpMnjiNnMuTyeX52QdHCcXTtNVX8siepZdcl4PR68bV3Ei8uxdvx7oVDSu9ldMnfp+TkiI38USausqVcZO+k8hFY8Qu9WAOFM+ba3Y9rgwYzPLrMhvBvLpeO7FEmtffO0IoHKOqrJiXn96/amJ+jTXgHhRAzz//PFNTU/yP//E/GBsbo62tjTfeeIPKyjvzKi8ZidF/4jwGi4maTW1otFqMFjNGy8q7y1ZvbEUpyIhaDeWts3diytsacPp9aHRaLM7rT23IBZlMMoUiK8gFCVegCCmX58QbHxAaGmfc5aVs5xb2tlVSbDdPf5kuo1ySmIzwxc/eIhWLU7u5HX9dBa5AMaJGZMPBfdRsWofFZaeQz/PZj63ks3lAQNRqKK6twFdZih0B0R8grgrsqvuyPGSwmNj5/KNI2TwGi4mqSJJMvkBdkQONKM40kxfGBmceUyjInD53iV4UNrTW4HbefMNgIpkhlcniW78OrdmEqk7HagCosszEVIyfvf05aYOLbQ+so+q+TTMnJVWWyQSDyLk8sUiMUd0kWQR6h8aRFQXNKvjTXEl8L6TTaC2WFXWAvpU4bBa++cQeMtk8Tvu9VapRVZW+H79K5HwnJn8Rzd//7rIa5OPJNG9+eIxUJseDuzooD3iv/6AVQlXV6T+KiqIocyY911hjpbnnBBDA7/zO7/A7v/M7t3sZS6Lr0HEufXEavUGP2WGjtKl2xY49dO4SfSfOEairom7beowWM6375w+uFAQBu2/pExuBhioq25un/Xl8HuxFbhKTERBFJkQtX2REzl4YIanAv9u9/JDCqZEJRrv6iIxO0H/iAoGGKlr376BlzxY0Oi3u0umeLp1BT83mdYx3D+D0+9AbDZgdNvb92nRMxAFRQ0FR0F9jyKbRatFYp3/9K9yzxcyVZnI5+2XZ64MjFzl6/DxaVSGTy/P4/QuHhS7p9UUT/PTNQyRSGXZsaGLHxi/r8KmRMfp+9gsmI3FiOicZk5mwPC1AriBqtZQ9dD8Th7+gtKqSnMbC8PgUm9fVrYr4uYIgiuisVkYnwrx3+BRGg56H79uA3Xp3xUEYDXqMS/DIuutQFKRkEqUgU8hkkbPZZT28d2ici70jyIrC2a6BFRdAqiwTPnsBVVFwr2uZ9TvttFs4sHfT5RJYYNVMFNdY4wr3pABaLaLjIVLROEVVZeiMK7P9r9Xp0GhENDot2mWWASYHRwkNjOKrKsVbPrsBVsrl+fgfXyU8Ms7gqU6K6yqwe1duJFWj1bL7xScYOFWPwWxi9GIvEz1D2DxOWndtpn8iTU7UYtBe/2Q83j1A7/luvJWl1LbUcertTxi/1I9cKKAoKopcIBmOERmdmPNYUaNh0+P3M9EziKukaKZcdrUbtF5c2hdpMhLjwsdHkCNTNLZVYDDpmSyupad/Ep1Oi8tsIJPNYTDcfLlmMhwjGI4hSQUGx0Ls4EsBFLlwkVhXD4KsUFttJ17io72pas4xPO2tM9ENlapKoSAvyadlJTjTNcCl/jE0GpHaCj8bWldOuK9x4wgaDRWPH2DqxGmsleWYlmkU6XM5cLts5PMSgaKV99eZNgz9OaqiUshk8O/cNuv2lXYsX2ONxVgTQEskFpzi8I9+SToWp2bTOjYc3Lsix23cvQmrx4nBYqKoZunj97l0huOvv094dAJ3qZ993312VtNzLpUhm0whSwUyyTSKrKzIeq+gyDLnP/yCiZ5BSppqmBycdqEWNRr2PdNKIFUgks7RUb74FaSUy/P2Gx/z1nga/alhvpfMMnG6k1w6g9Pvw1tRQmxiCndpMbWb1817DEeRB8dVo/ij0RQnBifx201srPQtuVQzePoi3R9/jqAqBNprKH3iKT4Jashkk2yuCeDUbCWVydJYfePN6VcoL/HRVFNGOJpgQ8vsST9LaQBTsQ8EgfVP7MdeXzczwbYQgiDcMvEDUOxx4LCZ0eu0eFwrb3S3xo1zJTLkRij1e3jxib3k8hLFXufKLgyQc3nknISqKMjZ3PUfsMYaq8iaAFoiuVSabDKNLMmkIrEVO67BPN37s1yu11Njsluo27aerkMnMFhNJCYjOItXbjs7GY4xfL6bTDyBqqqUNtUwdqmfkoZqLA4b61zTOz+qqjJw+iLR8SDlrQ0zpasriBqRoKBngjzJvIYfXQxxv8MOgkDV+mZa9m1DFMVlRYn85FgPJ4cm8VqM+OwmKtw2cgWZqWSWIpsJ7QKNlUJklDGtEclux+1toi+omRV4Wl91Y8ZrqqqS6O1HSqVxNtWj0esxGw187ZEd02n015SsXM2NGH/TiwCrEja6EqxvrsbncWDQ6VbF6XeN28dqTnp5N6xDSiZRZRnflg2r9jxrrLEU1gTQEvGUB2jcuYF4KEzd1tsfvKc3Gdn42H4mB0bwVZXOGXnXaLU079nCRM8QBUmi85MjM3ldK4HZYcNTWsyUqlJcU077w7tp3b992gvoKmEWC05x5p1PSEXihEcm2PfdZ2fdrtFqefjATk7/5BMikTihZBZhxybuCzhw+r1zgk2XgkYUEIXLYZWCQK4g878/vkBvKMb6Ci8vbq2nfzLBO+eHkRSFg+sqCKRC5L0+hjZ6CWUhGcrw0jyZXzdCvKeP7n/6EVI6TdkDeyl7+H5gWsRqFhCxpjtU+FxBEARK55kWjMSSdPWNYjDoaKkrR38Ld6XWuPPRms2UP/LA7V7GqqMoKuOhCBazYc0T6Q5m7dtpiWi0Wlr2brv+HW8AKZsjFgpj97nnCJnF8JYH5vT+XI3V5cQV8BELTmHzume5PN8sWr2Obc8eIBWNY/M4EUURcZ6mUq1Oi+ayH5Dusn/N1PAYZ987jMlmpf3h3dSXuLlfSNIbGUXR5PF7t+Ipu7GQS1VV2ec1kQmCbNQymciiFUV6J2NE0jk6xyJ83hfkf398ga6JKCVOC0adhhfL9XjX1aHLRyGcIJdbuTyvQjKFlEoh5/PkYyuTNXcnoqoqv/zwGJ+d6CSbk9jaUc9LT+6f8S1aY417GVVVUfJ5NAYDn528yOHjF7CaTTx7YOfaLukdypoAus1ciYkI9g3hqyxl+9cPLisDbDFMNgvbv36QxGQYT3lgxceWtXrdrN6bawn2DRMaGKF2SztanY7i2goEQaDv+HnGuwfRaDQU11biKSvGoxeRXWZsXgvtpTfefBkemaDz7Y84FVZI2ezE8zL/14PtbKzwcX40wvbaYkKJNMmchKKqqKj4HWagQHPAwTcfa+HM0BQG6/VDOZeKs7mBkv33ISWS+O/buWLHvR3kolHGP/4MjUGPf8/OWUaIqXSWaDxFIpVFURRGx8NMRuIrMklUSKcR9fpZU0NfdWRZIZpI4bCa7+qJqcj5TuJ9A7iaG7HXVN3u5dwQqizT//NfEu3swrepg5GCnkQqQzYnMRmJrwmgO5S1b5PbTC6dJToeIpfOEJ2YJJfOzDL+u1msbgdW98qdzJdKLpXhxC8/IHKlSfvXvj6zu+Uo9mC0mtGbDNg8TiwuB237dxDsG6K8rQGdfuEdA1kqIOWm/XvmE3SyJKHkJXKKSDBTwBVLo9doeGFrPbmCjFGnZTCc4NJEnNZSN/c3lbKlupjCUC+iKLC7oxFPeZJzfZMr9l5oDAYqDj60YsdbKVRV5fi5HkaDEdoaKhgZn2JwNMSmtloaa+Zv9J44dISR9z5E0GrROx0zwa+RWJKf/uoQ0XiCmvJiEKClrnxFGmlDx04y/NZ7GDxu6r75LHrb/J+PWHcv0Qtd2GurcLU0IRVkLvWNoNfrqK3w3zbfIlVRiF68hCIVcLU0roiIUxSV198/Ss/gKNVlfp54YOtdaRqYi0bpe+V10mMTxDov0foffgPNIp//O5VsOMLUqTPkIlGCR0+w/tmvEU9lcDuslPocpEbGMPo8d+Vru5dZE0C3CFVRmBwaQ28yzto1MVrN1G5ex8CZi5S31mOyr67V/K2gICscGQxxPqPiyEm4FIWrTz11W9pxlRSjNxpmvIeqOpqp6pjfL0hVVSJjQaRcnq5Pj5OYitC4a9O8U2HeilI6HtjBR5/3ki1oEAWBUDKLw2zAqPvS9+f3Hp7u47pyUly5gteNMTgaIhSOUVcZWNGegUI6TSGbmw4vvUYATExG+eiLs0QTafqHxsnlJZLpLKl0lvqq0nknz7RmExq9HkGnQ3PV7k8oHGN8MookyTTVlPH0w9vR63TXnV5bCpMnTpMenyAbjpAcGMbdNvf3RM7l6H/1dZL9g5gCfswlAY71jPLhF2fR67U8cf9WGqoXd0VOpbNc7BvBbjFRW7lyO6bhM+fp/fErKFKBiscfIbB7x00fM53J0j88QSyRZmAkSDKduSt7TQSNBlGrRdSIiNf0D95N6B12rJXlqIqKvbaa2vpK6huqUGWZ7n/+EbFLvTjqa6h78bm1Xcw7iLX/iVtE95HTnP/wC3RGA1ufeXimd0cQBBp3baJh58YV//BHRoNkkymKqstXrKw2H6qi0PnpMUIDI9RsamPYYOVfj/czlhZpxECZKM6KwBBEEW95gKFzl+g5cprS5jqKFhktHzrbxam3PiGbmk5x1+p0DJ3tmlcAiRqRui3tbJb0FHomKLKbsBvnTpAt9b3ORaOkhkexVpSjt6/cztzVTEUT/PydzwnHkjRWl/KNx3avyO9CZnKK7n/6N/LxJOUHHqBoy+yIjCtmgNp0FpfdSiaXJy/JeFz2BQcMi3duRe+wI+p0uFq+zJIrC3hpqCphKppgfUv1TZsMqqpKz+A4yXQGZ30txrFxDC4nlrL5e94EUZwWZhoNGr0eUashnc2Rl6a9pLK5/HWf88MvznLsbA9Ws5GvH9hJ+RKDP69HIZOhkMmiFGRikThF8zh1p8fGGXj9LTR6PZVPHsDgdC54PFWWiR8/Qe3UKFqjjdraMmyr4Bx/K9DbbNQ+/zWSQ8M46mpvaSTKSqLR66l/8Tly4QhGn3fm+y6fTJEYGCIfj5MYGEJKpjA4b/2O/BrzsyaAbhHxUIRsMk0+myMVic1pXl5p8RMemeCzH/+SbDJN486NCzpArwSxUJhLn58iE0+STaQw3b8PqVCgIMuIej35bI5sKo1V/+UHPxmJcfrtT0lMhQkODBOoryYeCtOwvQOLy8HgmS6MFhOV65uJT0ZIhaNk01ksThtmh/26oapf31zHujIPRTYTRfalnxzOXhricOcI6M1UGAUu/eO/kegfxFFfS9Ovv7wqV2+SVEAqyMiyTC4/O3lMVVVGJqbI5iSqy4qXVeZIDY+QHBxGKRSIdnZRtGUjsqzMHMNpt/DMwzsITsWoLiumIMtMReIEit0zbsCN1aWz+ks0ej3eDXODcs1GA88e2IWiKCvSjzI4GuIX735BOpNl87p69v7u99GaTQuGr4o6HTXPPUO8uxdrZRk6q5VNbXXIsoJBr6NhCd5NubyErCgz/x8rhae9lexUmM/7JvhiLMH5tz/nifu3zPJtmjx+ivDpcwgaEXttNf5dCw9cxLp7Gf7lOzhTKao62mm5b8Ndu3MCYKssx1a5dA+0OxWNwYA5MDtbTu+w49u8galTZ/Gsb0PvWOsFupNYE0C3iOoNLaSjcYw2y0xI6EqjyDKCICCIIplEkkwihSxJJFfQt2g+jBYzFocNKZfD7nPTUV1MTlYYtGrwBkeoaambky+m0WrR6rXkszmi45Mkp6LIkoycl7B6XPQcOY3WqCfYN0wsNEUuk0PKZjHa/Gx95iG8FYt78pj1WjZUzH8FP949QDwUJtBQhc3zZcP1eCzDP7z1EZdGpnC6XDQ/splcJIYiSeTCEeRcflUEULHXyYO71jMxGaWlrmLWyWxgJMir73yOFImwtaaEXQf3zuojiF68ROR8J/bamhlX6CvYqioxl5UgxRN41q/jk6PnOdPZT0NNKfu3tyOKAn6fC7/vy/fA5bBytmuANz44iiyrPLR7PZvXLS42ryCKAuISXbevR14qkMtLFGSFXF7C6L5+Y7zZX4TZXzTzb5fDuqxg2Pu2tGK3mXHaLFSWFS14PzmbY/SDj5HSaQJ7dl3XskBrNlPyyINM/subxKZi9A2NMxVNzHrfTcVF6J0ORJ0W43Uc2zUGAxqDATmfx2Sz3dXi515HEAQqDj5E2YP77trdrXuZNQG0yiQjMQq5PK6SIu771lOr9jyhgRFOv/UJOqOBjY/vp7imgvptHaRiceq3d6za88J0H9P25w4SD01Pm+n1Wh5sKYeWha/qTDYLtZvXMTU8TuGyO6zBasbmdSGIIoIooBRkBs9evBy4WsDmdVPI5meE3kIMne2i6/AJPOUB1j24c5aXUDwU5thr75MMR5joqWH3S09+GTCqfhnIqKgKeoeDsof2ETl3AU9HO7ollBlCx04SOnoCV2sT/l3bF1xnPhZH1GnRmqeDYtc1VrGuce794skMmckw7pNHCZ/VMChnqf7aE8D0iXjg578kOTRM5HwX1orSWaWT1PAo4UiCoKQiTyU4MRhiKpogJ0lsbK1d0PAul5fI5wsoskwmc3vcemvK/ezfvo54MsPGtlsTs+F12Xlgx/U9vsLnLjDy7ocokoQoaqh6+rHrPkarEWmsKUMqyJT5vXiuCdP1burA6PMiarVYShePgrBWllP7wtfIR2O4Wpefs7fGrWdN/NyZrAmgVSQ8MsEXP3sLKZen7f7tVG9ovf6DbpDh892EBkcQNRpCfcNUb2yl/aFdq/Z812Jx2hdMkY+mcwTjGSo9Ngy6L3cITHYrRqsZKZenrKmOmk2teCtLkaXCtLeQVkv/yfNERoOUNlZjtFpwBnx4y0sYjiQ53DNOsd3M7rrATLOtqqpcPHScqeExEuEo5W31eK7qG1EVBVVVQAVFmY4HkS8nT5c4TXzryd0cvjiKaLCg0YgUb9+CpTRA+PQ5pk6ewb2+bUFRU8hkGH7rPdLjQTITIVxNDbOcnJPpLOlMFnFkhMHX3kRrMlL3wrMz2+b5WBxBMx02erZrgM6eYarLi1lf7iNzTsRh0JEa/zIPTdCIaExGBI0WjdGAqJ39JRsZHOLDiSQ9igbTa5/Q0FSL1Wwk4HNjtZiQkklGP/gUVJXAvl0z01UtdRXEJibJfPgR5g8mibnNOOpqyMcTxHv6pndartnqX2k0GpFtHfMowjsArcWM1mymkMmitS6t8VgQBO7f0c7mdXVYTMY5ZUJBEOYtA0lSgXcOnWJ0YoqdG5tpritHEAScjUvblVNVlUIqhcZoXNLuZTKVYTISJ1DkxrAM9/U11rgbWRNAq0gsOEV8MoIiy0TGQlSvovO7p8yP1e1Ep9fj8K9sgvPNkMjm+ZsPzzEaSbGx0se3dzbOCAh/XSVt+3eQSSSp3bwOq9sJTCe8X3Hb9tdVEg9O4QoUYbCYZo776ok+TgyGsJv0BBxm6ounHysIAp4yP8lwFJvHhfmamru9yMOGA3uJhaYobazhvQsjfHxplAZDgd9sLaejuQqDxzszBq8qCv2vvE60qweTz4vJXzxTZlEKBbKhSQwu17QA0ekw+bzkwlEMbifaq3aMIrEkP3nzEPFkmvZ4EOPYBKJWQ2JgGHPAT+TCRfpfeR1BqyXw5GN88PkFJiNxxkMRvv30PiIWDanhUQL7ds8cU9TpqH3+a8R7+rFWlKK75mRsq68jazmOlJYQEbCajTz10DbcThs6rYax46cZff8jVEVFZ7NQsu8+AExGPescBrqTMbLRKSaPn8JeW03vj14hcq4TU6CY5u9/5yvbzOlsrKfuxa8jZ7I4W5Yu0gRBWPak1mgwzJnOftLZHJ+dvEhz3fJ6ZcY+OsT4J4cxlwSo++azC/ZQAaSzOX785qeMh6I01pTy9EML72AuRiab54vTXaiqytb2BsymlQmOXmONlWZNAK0ixbUVlDZWk8tkqWhrWNJjUtE4kbEg7pLiZfkBlbc14AoUodFpMTtsJCMxpobGcJcWz+pzWYh0LMFE7yB2nwdP2cpd3Ucu7/6k8hIDU4np7KvLX6oarZaGHYurQrPdinkeawCzXotGFDFqNTPj7Vdof2g3Za31WN0OTNeccARBoLS5ltLmWnKSzIeHjzIaTRGTUjwZzVAM9I7Frn4AosGAqNUgaDWIl6/cVVWl/2evMXXmHLaKcupffh6NwUDtC18jOTiMucSP1vSlYAuFYwSnouSlAlMWO43lJWhNJozlZbx3+BSRDz7GPTCMwagnPzaGzWoiEk9iz6cZ/dlrWIq9NP36ywjXXMUbvR5iXT2Mvv8xvs0bZu0MFNXX8MKvP8er73yORqthW0cDgaIv+0u0ZhOi3sBkQcWjzD7RmQN+TH4fhUx2emdCUcjH4ihygUIqhZzJwFdUAEnJJFqTCXtt9aqPNLscVjxuO0IkTtkSL2wS/QOkRsdxNtYzefQEmWAIKZkiPTq+qNFgMpUhHE2SzeYI9g2RS3fQNTTB6c5+6qsCbF3fsCRBdLarn4+/OIeKilGvZ/uGO3Mnb4011gTQKmK2W9n5wuPA0qa8CnmJI6+8zeTgKN7KUnZ/84klh4AKgoDN65o5ztFX3yHYP4KnzM9933pq0YgNVVU5/sb7jF3sw+Z1s/Gx/Riv9OPcZINlqdPCffUBuiai7GsqnTP+e6N8bVMN9cVOfDYj5e4vBVIuleHS5ycBFZu3Y9Fj5AoyaiKGnEzRuK4CtaaJ4/2TswJQBUGg5mtPEO1swlzinylpKbk8se5e8rE4iaFhcpEoZn8xOqsVV0vTnOcqC3hpqC5lKpJg/bY26ko8CBoNpy4N8aM3PkUzOcXmvMqm5io8jXU8bbUxMj5F/t13CZ/rImYwMFQQOJuQqK0IsG/HOjSiSGZ8guG33yMXiZKZCOGoq0HQfFle6WitZV1zNZJUmDOa7t3QzsmRSU52DdM/HMURisw05lpKAzT/xneRszlMxUXTzZyPP0Lo6AlsVRWY/EuPKikUZC72jSAAjTVlN2TYlxodI3r+IubSAPbqKkSD/rY0/+ZjcS7+wz+TCU5SvG0TlU8cXNXns1vNfOPgbqKJFAHf9S9kslNhun/4EzLBEM7mRlztrUipNObA7Abx+fC6HGxqq2PozXcoHpjk0j8k+MToJpjIMBWJ01BduqSgVJ1Oi06nRVVV9Pq1U8wady5rv52rzHK+pKVcnnQ8iVwokIklKEjSslLQr6DIMtlkGkWWyaUzyJIEi2WMqSr5dBZZVkiEoxz+0etodDrWP3wf5a1L6zVYCBF4or0CjbZmgbVO9+EsN6TVYTKwu35us+jgmYtc+PgIqgp6k2nRHaafvX+EsXgau8fJrv3bORYzkskmZ8RPPp5g4tPPEPQ6Art2oLnqPdQYDRRt20Tw82M4Guuum9o+PSa+E1mePSaey0nTTccmK33Vlbz0m98EjYZcOktTbTmD54vJ9vahsVg4NTDBaGG6l2hdUyUep528qEFrsSAlkuhdDrhGYKqqSvT0ObLhCJ721lnrFDQa0mY7kt5AJJ6aM5l0rReNs6EOZ0Pdoq9zPk5f7Oetj08gCAJSQWZ9c/WyHq8qCn0/fY1o1yXkTBZzwE/xji2UH3jwpkVQNicxPD6Jx2lb0sk9OzlFejxIIZUi3tt/U8+9VGxWEzar6fp3BBRJQpEkVFlGyeUovX8Pvk0d6KyW67oQi6LAnq2tnP74PZJhifTwCJ56F1GdDqfDsuRMt3UNVei00wKoaQFH8aVSSKfJBEOY/f5Zn7/bjaqqwMrbl6xxa1kTQDdINpUm1DeM3efGUbwyPTcmm4WWvVsZ7eyltLkO4w2am+lNRtY9uJPRzl78dZWYbIt/sQuiSPvD9zF05iKZRIqhc12oikp0PHRTAigdT3Ls5++STaVY98Au/HWVs26Ph8Icf/19FEVhw4G9uErmXqEG+4a49PkpnH4vDTs2MjU0hqjV4KssRRAEJnoG6Tl6BldJMY07N6I16NHp9aio6BYx48tcOEEylUTrD5DQGjgREfFpvtz5AQh+doSht95D0GrRWawUb9886xil9+/Fv3sHci7P+KefozUa8G7qWLAsIgjCnObXTW21nLvUzFgwzP072pEFkVd/dZixUJj2pmr2PvIA9ppKdA4HI10jRHuH8bntaDUafvTGJ0xFE2zasYt6iw57bfWcL+TkwBB9P3uNfCxGaniEhm9/c9btG1priCaSOGwWqm8wgPZ65PISeamAKAjkJen6D+BysKSqzuwYCgKoUoHsVBhBq2Hy2EkC9+1AZ71x53RVVfnVx8c5f2kQn9vB84/dd12hYSkvxbehncTgMIE9t27IYDFUWZ5uyLaYMRUXUfnEQZLDI3ja2xA1miVZCFxBEAR8WzZN21GUl9HyxENMRBMUeZ1LNrfUaERa62/e6kPO5bj0T/9Gom8QZ1M99S99Y9bu5u1iPBThrY9PoNdpeWTPxiUJ5zXuTNYE0AJkk2nkRBpHkWeWizFMf3GeeONDRi50Y/O62P3ikwtOQC2XqvXNVK2/+dHW0qZaSpuWPj58JVk+GY4hSwUKkkRp882NH4f6RxjvGUAuyAyd7ZojgMa7B5joHURVVMYu9c8rgC58dITx3kF6OvsYDMXJXOpFZ9Cy6fEHCDRUce6DzwgNjBAaGKGouozK9kZ0Bj2qqlLaNHfXSZYKDB46TFl7FS/ve5CfnRgjmCqwqSYwpzwn6vWIOh2iVotmgS9/jV7PyDsfMPLOB4gGAxqjEc/6tiW/R3q9jn/33EPkpQJGg47RiTCDY6HpWIbeYfZua8O9bnp68NGAn42ttXicNsZCYfqGJ4gnM2RzedpePIjevECDq8C0gmDu1WpFiY/vfO2BJa/3RmhvrCKbkxAEaG2ovO79M9k8v/zgKJOROHu3tdFYU0b1s0/iaKhj6tRZ8vEE9tpqtOblXSBEL14idOQ41qoK/Du3oSIQmoqRy0tEEykSqcx1BZBGr6fmuadRFWXO98LtQM7n6fm3n5EcGKJ4+xZKH9iLd0P7vGaVS6Vk7y6KtmxAYzQiiCI25+o4oF8PKZEkNTqOlEqRHB6lkM0tyYpitTnfPUTP4BiiKFJbGWBL+83tkq9x+1gTQAvw2U/eRE1lqd/eQfN9W+bcnoknkAsFcqkM+XR2xQTQ7cbqdrD7pSdBVW/6C97p9+L0e8mls3gr5+YwOf0+7D43qqLi9M9vWmjzuui80MdwVuKzvgj1GYmygkQ2mUIQBKxuJ5HRICabBaPVjKjRUNYyt0yTL8icGJwkdOwU6RMn6Tnbxc4/3ML+fZs51zc5b29S8c6t6KwWRK0W97qWm3ovFkMUBYyG6VKnz22ntiLA6MQU7U3Vs9al02nxuR28/elJJoJhtBotkViCbD7Pmx8e49kDO+fsAFkry6l+5omZEtjtwGI2sn/73NiShRgen6Szd5i8VODEuV4aa8ow+4sx+4sJ7N01HTfgnXthshiqojD0y7eJ9w0Su9SLvboKS2mA+7a0cPRMN+UBL8U+55KPdyeIH4DMRJBo5yWkRILQ0ROU7Nu9IrskyxWXq4HB7aJ422bCZ8/j27LpjhA/AEUeBy6HFY1Gg28t5f2uZk0ALUA8OIVWgdDAKM33zb5NEATa7t9B34nzCKLAeM8AokZcsVLY7UYQBBYMg1oGjiIPu198ikIuj9XjnHN7UXUZ933raVDVmRH4a1n34C4uyFqCwzFkvQFbsZW6IuvM7lbHgT2UNtdi87gWFaGfdo/xk6O9WLt6qUxmMCZSpMNRcC7cGKrR6/Ftvr53QWDPLrQWC1qTEVfrdAO0oqicvthHPJGmraES91VX0bm8hCgIs6IQrqDTaXnqoW3k8hKmeXadBkaCnOnsQyrIlBS5qSotIp3LE09l5l2bIAgL7kgVMhmSA8OYin0YXM7rvs5bhddlp8jjJJ5Mz8nj0uj1mJfRgD2DIKB3ORGHR9FaLWgvWyo01pTReJN9KrcTo8+LvbqS1PAo7nUtd0SJaKUQRJHyAw9S9sgDd1SvTWt9BT63A41GxOtaE0B3M2sCaAECjdXIsRS1m+Y/eRRVl2N22PnoH1+h79g5xrsH2Pvtry27mfdex2SzwCLeJ1bX4qPUOoOe/Xs2kjzZh1Gn5emN1Tiu8hXRm4xLKvVlJZm8LJMMlGK1aWneVkfJ+ha6EzefA6+zWijZO7sfZHA0yDufnCSZzjIVTfDMwzsu/zzEmx8eQ6vV8Nj+LRR7nXOOpxFFzAs0fLqdVlwOK8lUlsaaMkxGPWPBMO3Nc/t/FkNVVXp/8nPCZ85jKfHT9Osv31Q/zUriclh54fH7SKazFM0jnG8EQRCoefZJvOvXYfIXLRo2ejehNRqpf/l5osEpHMUrE956p3EniR+YXs98n9s17j7WBNACbH7yAaxG85qguQMocVr4zX1L76uZj111ASRZRidq2GbKUrOhCslkhEQSmDY1zEdjGFzOFbmK1ogiGs3lP6pKdiqMweWkZ3CM4YkpNIJI//DEol+kqqoSOnqC9Og43g3tWCvK8LkdvPD4HpKpDE67Fa1Wc0M9CKoskxmbQM7myIYj5OOJO0YAAVgtJqyXd2mkgowoCjdtoaCzWvF0LL0Ud7dw5FwfR053Uex18uSD25bcrLzGGl911gTQAggI1xU/VreDjY/uIzoewl9fdU+IpdDACGNdfXjKAjfdBH0thbzEhY++IB1L0rBzA67A4r4kN0I2maYgSXN2luwmPU92TDdFZ/q7Z92myjK9P3qNaFc3zqYGar/+1E2LoLKAl0f3bSE6FcZ45AjnPvsY39aNVLS2UexxotVoKAssXjJNj4wx+PqvyIWjJIdHaP2d7yEIAi6HlVgyzT+++gEaUeCx/Vso9S8+hn8tolZL2UP7GT/8BY66mhsrK90CuvtHee/waawWE4/fvwW79c7oA7mTOHOxn6lognQ2T3AqRkXJvbkTtMYaK82aALpJ/HWVc6ab7lZkqcCpX33M5ODo9Hi/33vdEtW1JMNRClJhenruqq1rRZb54mdvcf7DzzHaLAiiwNZnHl7R9UfGghx55W2knET7gzspX6L7diGRIHGpl1w4QqyrGymZQu+4udq+IAg0VJcQEwp0jYwgJZOEz55n/SMP8J2v3Y8gCFgWmtq6jGjQI+r1CFrNLFdpgMGREGPBMKIoMDgWWrYAAvB0rJuzIyIVZEJTMVwOKyajnkgsSSyZprTYg0576/tLzl4aZGQijFarYXA0RNsSpshulFgihaqC0768uIrbTXN9OZlsDp/Hgc+9Mu7csqIwPDaJyWigyPPVdPxe495nTQAtgKoqt3sJtxxBFNDqdYgaDRqdFs0yT3iTg6McefVtClKB9gd3UdnedNVtYwydu3TZoFFZlam56FiI6MQkiiwzOTi6ZAGktdtxtTUTPd+Jq7UZ3WXfJFlWOHyik8lInM3r6pYcRQDTJ5D3Dp2mq3cIv8dPtTmGb/NGBFGcKe1cD5PPS903v05mIoizqX6WoKws9VFS7EYjilSWFKGqKpPHTpIYHMLb0b5o5MFCqKrKLz84xsW+YUqL3ezfvp6fv/kJ6rGjlFoM7Pl3L+Com9/QcrWoKi1iYDiI2WRY1b6LvqEJ3vjgKKqqcnDfJmorFk9kv5PYtbGZdQ1VmE2GFROpR05d4uMj5zAZ9Tzz8I4bEthrrHGnsyaAFmCksxf75vW3exkzSLk80fEQdp8bg3lpJ9DlImo0bHrifoK9QzgDRdc1ULyWeChMYiqKKitExoKzBJDebMTmdSEXZPy1FTTu2rQia07Hk4T6R3D6vfiqyiiqLkfKZpdVvhNEkapnHqfw8H60FsuM0BgcDXHo2AUyuTzZXJ4XHt+z5GNGoknOXOwnnkwTMzhofmQ/7tpyPjtxEUGAjpaaJaVt26srsVfP3fWoLC3iO1+bno4xGnSkxycYeP1X5KYipAZHaPsPvwGiSKJ/ELlQwFFThXidsl40keLSwCjJVIbxUJSx0BSZ/gEcgwNkDDrGD32+ogIon0gwdeoseqsVd3vrvKPl65urKS/xYdDrsF5nx+xqMqFJohcvYQn4sdde33l6LBgmOBW7/PfIXSWApkNWV7Y0GIrESWVy5CSJSDw5SwDJikIiOe2ZtFLRNmuscTtYE0ALkFtgrPh2oMgKR3/+LuM9A3hK/ex8/rEbishYiGDfEFPDE/hrK3CVFC0pPHU+imsrKGmsRsrmKW+dvfviLPay7WuPkI7GKa6tWJH1K7LCscvvi9Pv5b6XnmbPt55CkRW0eh2JbJ54Jk/AYUEUF58kEQRhThOwxWzAbDIgFeRl957YbWYCRW7GghEuBUcZGA2ydX0Do8Ewoiii1WrY1LZwrIQkFejsHUar0VCiUYh1dmEtL8Xd9qUf0dXRBBqDAa3RSF6jmU6hF0UiZ8/z9j/+jM6MQsPGNr7+racW3CEIhWO88tZnRKIJjAY96xqraKmrYKK9idhwPx6TDktg5UJyAUbe/ZCxjw6hs1jQmIyzglyvIAgCniUa8U2G4/QNTxDwOYm/+guinV2Yioto/o3vYvS4F31sbWWAqr4RVBXqKu8e8bNabGytIZFMY7Oaqan48v9dVhRef+8ofUPj1FUFOLh383U/W2uscaeyJoAWYD4zvdtFIZ8nOh4kn84QD02RTaYW9M1ZLul4kmOvv09sYpLRilL2ffdZNPP40ywFi9POrheeAOYfXfWU+Vc0aV5VFLLJFHJBJpfOImVzM2aI4VSW/+9H55lMZNjfVMqj7VXLPn6Rx8nXHtlJLJGiunx5TcJ6nZZnHt5BaCrK8HiIRCrLWDCCrKioqsKl/lHyUoH1zdXzjrwfO9vNu4dPo9OINE2N4h4bxlzsw+wvnjd3zOByUvfi10mPjuNoqEMQBDJTETrjecKyQNfgBBOTkVllPDmfZ+TdD8lNRYhXVDEeiqDRiLQ1VvLQ7g4ADj79IJldHUjxBNbK8uW9gdegKgqZYAidzYbOYkYtyKCqyJKEIss3dexCQea194/QPxzE73WwNZVBkRWUQgGlcH2rg2Kvk28/cz/ADYW13muUFnt48cm9c36eSGboGxonEk/SMzBOOpNdckl3jTXuNNYE0AKsVpnpRtCbjNRv20DfiXOUNtWsSv+MgICwAldyt9KzQ6PTsu7BXQyd7cJbWTrLbHEslmYonCQrFegcj/LoDSYDlBS7KSlefPdgIYwGHQ/u6mD4Yi9iPEa9tsC5jEpWKnDh0jCX+kZRFIVdm2a7TE+GY7zz6Ul6Biewmg3YFBmPKCJotaTHJxj/9HPMJX58mzfMer+t5WVYy6dN/WRFQa2spKqmDCWSpry2ArfDRi4SJXapB3OJn3w0zugHnyDn8thyeWoqykimsrRdk+Nk8nkx+W7e5HP4nQ+Y+PRzjF4PDd9+gdIH9pIanyDR08fUqbNoS0ux2Cw3VFZRVRVJKqCqCgVZIfDYw0i9fVhKSzAVLW0qak34XB+b1URdVYCegXEaa0oxm5ZellxjjTuNNQF0l1C3tZ26rTee77MQZruVTY/dT3hknOLaihve/bldLDSFV+2101HuZTSaYk9DybyPzUsFLvWOEI5kqXYaSaWzZPMSbod1xYRcQ3kR37DJpBNJJr74AlVnJStoUcvLsTvtaMTZJampaIIf/ORd+oeDSIUCqQyES3xoNjZTu76ZoV++TbTzEgaXE3OgGGvZ3IgRgA8+O8OpC314a+v47tZWir1OTHod53/wfwgeOYG52EfdS8+ht1nJqwmcgSJeOLAHRVbmdai+HhOTUQZHQ5QHvLMS5a8m1tVNLhpDzuVITwRx1NUgpzOoisLFjz7j7WAaf1Mdj9+/Ff0y16C7HEx5qX+UMr+XQE0pNK1lNK00GlHk4N7NpDNZzCbjWvlrjbuau+tst8aqUFRdRlH1ysUBKLLM2XcPMzk0Rv229UuexpoPWSow1t2PVqfDUezFaDVfV5yoqspwJMl99QGqfXb0C/S9vPb+cf7t3eMUZDAVNvDp8U7SmRx7trayoXVlPJBErRaTy4k0OYUpmaa8/xIaVOwVXmr27psz1n2pb5SpSJyCJKEvSNgMWrQGI8aGBt6+OMLARJo6QUuZXo9GP7/hnaqqdA+MEU+mKcgyOq0Gk05LvKePyROnSY+Mko9EKKQyNHz7m+TjcRz1tdPmjVftvoSOnmDqzDk861oXjQTJ5SVeefszRifClPk9vPzM/nnN+Ip3bKWQzmAO+LFWlCGIIs7GevKJJOFwkklJJTU4zmQ4PmfXLTU6Rry3H3tVJZay+QVtRYlvzQPnGvpHgsTiKeqrSjCb5ncXXy6iKKyVvda4J7grBFB/fz//9//9f/Pee+8xPj5OSUkJ3/rWt/hv/+2/ob/qJDA4OMjv/u7v8t5772EymXjxxRf5sz/7s1n3WWP1iYyF6Dtxjmwqg1woUNZaf8M7Kl2fneD8B58TC4Wx+9w0795M6/7tiz7m2ECIf/niEgDPb6lnS/X8hotjk1EK0SjWs2fovniSsCtA2mJjYCS0bAGkFAqMDo8Ty8tUV/hn+npErZa6F54l0TeA8/gphJ+9BipUOky0zdME7fPYKSn2oIyO4QqNoE0Y2XBfBypwvnsQyeYgVVlC7Z6NGBcoSwmCwIYqP5r+XrxFFRR7nIx98hnDb72HlEqjtVgwFXnRWs1YK+YXvvl4gqFfvUcmGCQ9OoGjsQ69bW4zcjKV4VzXAKcvTOeTeVw2FEWd95i+TR142lsRtFoEQSCfSOBsqsfd3kJyaIpIzwiBIjce1+znkbM5ev/tZyT6B7GWl9Hy2//ujgjrvFWoqnpDn5+xYJifv/058WSa9S01PHH/3FDnNdb4KnNXCKDOzk4UReFv/uZvqKur4+zZs3z/+98nlUrxZ3/2ZwDIssxjjz2Gz+fjk08+YWpqiu985zuoqspf/uVf3uZXsHKoqsroxV4SU1FKm2pueGJrqcSCUwyc7sTmdlLV0bykFGyzw4bV40JRVNylxTdVTsom02RTaVKROKJGZPBcF427NqHV6wj2DdF34jzu0mLqtrTPrC2SyhHL5Kf/ns7OOl6mvxsyCTKSQkd7Axc/OII5n8aWVKm0O4kWVdDaUDFnHYshZ3Oc/vt/5txnJ5jyBah6+H6eemjbzO0GlxODy4m1uhI5k6GQyVL15IF5j1VbEeCbT+zhl+fPoEYnkW02PE4bRR4HboeNrMlASYmHgZ//Ep3DTtVTBzF5vaiqSiGVnp4AA+znz9A8MYRZyCEndpENhpBSKYxuF47GOjztbbiaFt6Z0xj06J12cuEIBqcdjWHu7sHJC718fOQ8gyNBjEY9ekWho7l60Z0GUTc9/VfIZrn0f/6V5OAwzqZ69r70PBs7mrCYjXMm1VRFRs5LKAUZWZJQlaV7dKmqSiabx2DQ3ZUj2/3DE7z/2RkcNgsH9mxc1i5OLi+Ry+eRFZlMJreKq1xjjbuTu0IAHThwgAMHvjxh1NTUcPHiRf76r/96RgC99dZbnD9/nqGhIUpKprfI//zP/5zvfve7/NEf/RF2+72R2hsdD3HijQ9JReNMDY6y65tPrOrznX3/M4bPdWG0WrB6nPgq5+85uRqTzcKObzxKKhK76biLuq3tSLk8wxe60Wq1lDbUoNFpUVWVs+8dJjQwwkTPIN7yElwlRUwNj2EZGWS904jF42RT5ZfPn+nvRk3HcG1oIdiwk2h/mK0P7SGbjxFP59BUV1NT7qe0eHmmb+nxCWJd3ajxGEZJJhZPzns/o8tJ23/4zesez+u0UWLSEhRFtEYDxWV+Soo9fPOJPWRzEsl33yXUN0BmcpLIuQtUPPoQhVSG8NnzOJsbqXryIFIyBaqCnM0hZ7MUbd9MLhZDZ7NS8egj6K/j8aQxGKh/6TmSgyNYK0rnLbd1dg9Pl+tkBYfNTFVZERtalrZzJiWSZEKTFDJZ0mMTqHJhQQdmrdlM9TOPE+3qxlFbs2hmmawos4TOoeOdHD/XQ2mRm8cfWH5v0e3mxLleBkaCaLUammpKaalfujgvL/Gxd9s6wtEEHS035t8kywqKcmN9YWuscadz1/5Wx2Ix3O4v+wQOHz5MW1vbjPgBeOSRR8jlchw7doz9+/ffjmWuEiq3athKp9chihq0Oh1a3dK9e8x2K2b7zYdrWl0OimsqsHmceCtL8Zb5EQQBVVUx2W1otFoMFhN6s5FCXuLEGx8wOThGbbGXvfu/htlqnNn1UVUF/RNPcTpnZqw/jN+owd9ez69GtvDqO5+TPNlDdTiF22ll87qlN9Cain0UNTeQkVUy5RVs3nFzzeqqLOO1GNBUBDB63DgN0x9T92U/nPHqSsKnzqLkJbKTYQZ+8SY6ux0pHkeVZeTmFsLNbTi8XgK1VZgD0+9Zw7deoO/V1+n8f/6Bsof2z/IUmg+D07loanpjbSmhcIya8mLu29JGsc+5YIr9tRg9bgK7dxA5fxHflo1ojYtPEznqa3HULyyuCgWZtz89ycDItN/SxtZaFEXlTGc/U5E42WyeUDi2bHF7uwkUuekdGsdsMuBxLe8iTiOKbF1/4/130XiK1977glQ6x4O7199V5pBrrLEU7koB1NPTw1/+5V/y53/+5zM/Gx8fp7h4tleLy+VCr9czPj6+4LFyuRy53Jfbw/F4fOUXvII4/T42HNxHIjxdAltt1j24E29FCRanHVfJyoeXXo+J3iFO/vIDcpksdVva8VVMC1xBENjw6F7Kmmux+dxYnHZkqYCo0SCI00G2oijOiB9nRxOpsnp6cmZ6J5JUO6dPuIWCzLunupnMFSjICplMbtlp2lqTiabvvkhNIjmdJr9MdSorCrKszOxOiDodFQcfxnT0BPa6GtJ6I+++dwS9TsvmdbUUbduMkpfo/cmrJPoHyedy5AQdJpsTQ3k5v/riPFOxJPVVJazftmlmPYmBQaaOn6KQzTH+8eHrCqDFyEVjGA8for53COP2bRR5HEsWPzDtvl36wF5KH5jrNXMjhMIxznUNkExn+eJkF+ubq9GIIk21ZWTzeQI+N55VsI9Ybbaub6C8xIvZaMDluPkLiuUwOBqkb2iCgixzvnvolgmgfCJBPhLDXOJH1N6Vp6g17hJu62/XH/zBH/CHf/iHi97nyJEjbN68eebfo6OjHDhwgOeee47vfe97s+4734nneg2Ef/Inf3LdNdxJCIKw4inti2GyWanZ1HbLnm85GC3mWRNmGp2WjY/fz1hXH3afB6PVTGYSAltakDr2MxpM0jsxOSN+AERRpKTITXAqikGv4/EHtlImyAQ/P4qzuRG9fWEX4kI2S6yrB4PLgbW8DKN7uh8r2tVNNjiJs6Vx5mfXMhVNTO9iGfS89t4RwrEEe7e2zZQ4tFWVDEZzaLUa0icvcuRUF8GpGJ+duMAD7bWYPjmEnEwj6nXE0BDMFKC9iYP7tyK/fwxJkukeGOO9w6fZ1tGI1WzE6PVg8heRnYpgraqgkMkQ7byE3mlHozegMRkxul2oisLQr94lev4iRTu24N+5bdbak6kMb/3Tz0m//z6FvEQimkH2eHlg5+2LjnHYLdNZYZNRKkp9qOp0I/aerW2sb67GajHdljDXm0UUhdu2a+X3ufH7XGSyOapKb83FTz6e4OLf/xOZ4CRFWzdS9eSjt+R51/hqclsF0L//9/+eF154YdH7VFVVzfx9dHSU/fv3s2PHDv72b/921v38fj+ff/75rJ9FIhEkSZqzM3Q1v//7v8/v/d7vzfw7Ho9TXn5zjrf3MoW8hKqq6Ja5S3KjFNeU03FwH9lkaknj9DqDnomeQfpOnKeQz1NkX/xXXBQFvvf8w5zvHqK02I1LLdD5v/+R7FQY38YOSp99irNnutDnsrRtXof2KuO3oTfeZvzQ5whaLdVPP0bRts1kJoL0/NvPyE2FcV9qo+6FryEIIhqjgXQ2RzKVJZZI8eaHxwBorquge3AMSSpw+mL/jAA6eb6XQ8cvoNGIVJUWo6gquXyeVDrH+Z5RNuTzaMwmbF4346qeqMOLXdTgdNh4cHcHn53opHdonE+Pnsdk0LNzUzNGj5v6l19g4BdvEuvuJdbdS3JgCDmbQ2MyYPJ5qX/peQSthuDnR8lFosj5PL6NHWiu2t3pHhzjUjSNVdQialQkux3xFhpgXktyeIR8NM7T929hZDLG0TOX+P/99D0e2tVBeYnvlu+c3CsUeRy8+ORe8tLC/VkrQS4vceh4J6l0lla3mcx4ECmVItE7sGrPucYacJsFkNfrxetdmsPsyMgI+/fvZ9OmTfzgBz9AvGaiY8eOHfzRH/0RY2NjBALTW7VvvfUWBoOBTZsWDt40GAwY5plwWWMuseAUx37xLgWpQMeBPRRVrZx30EIIokhle+OS7x8ZDRIaGEWRC4x09lC09fqPtVpMM70Sif4B5GwOZIVCJs17Hx/jozc/QpfLkey8yK7vvTSzo5iZCpMJTZGbCiNns2j0eoxFXiRJIlFQMYyNc/b/87eIWi3Fjx/kjVO9RGJJ7FYzU5EECKAoCgGfi3gyTU35lzEhJqMeg16HRiOyvqmK1vpyfvarQyTTOXxlfirXVZAaGyc7GaZ4aBy9z8G6netxO214XHZkWWEqkkBRVQyGL3u3pHiCeHcPUjJNIT09NZYNR9CZjKCo08nzLY2YiouQ8xKW8lLEa3LbPA4blvJSclYL5T475c0NtDddP3B0NUgOj9D1Dz8kH4sT2LuLdFUdvUPjyLLC+e4hyu9wXyD1cgSIcJ2g2tuFxWxkNaSPVJA5fPwCkVgKp93M4eMXkAoyQmsNzRvaSQwOE9izcxWeeY01vuSuKLCOjo6yb98+Kioq+LM/+zNCodDMbX7/9Enj4YcfpqWlhZdffpk//dM/JRwO85/+03/i+9///j0zAXa7CfWPEBocRZUVxi8N3BIBtFxcJUX4KkvIxJOUNc/12VFVFVlWFow9sFaU43tgL1P9w/j37uTM0QtIuTxqQSYxHkSVZQStFqVQQC0UkBLJ6QgRRSUXiWJpaeJcSR1jminqjDpKey6AICKfucB4KE0uL2Ey6qmt9KOq0NFSze4tLWSyedxX7VRsaKnFYjKi1WqorQhw9pU3kAcHwWAiOBXF/cDDWCcnOffXf4ctGqPYoKG5YrrZOZnKMDw+icdlo62xivVN1aSzOcLRBE67FYPbjZTK4F7XgtlfjCIVyASDGFxO7HU1aI1GGl5+gUxoEkuJf471QXmJjxce30MuL1FS7F5Sz9P1StFT0QQXe0f+/+39d3Rc13nof3+n9wYM2qD3QrD3XkWqWLKqJUuyxbgkiiNbem2v3Ov4rmsly77yurazkusbJ+smjn5O4li2I1lWFyVREiWxihVsIArRMWgDTO/nvH+AHHIEkARIECSI/VlrbGHOnjN7H4CYB2fv/Tw4HRYqS1wTXkcV9/mJ+fxI8TiRIQ85i+04HTZi8fhVlzCZLqFeN60vvgrIlN5/NybX7Flk3N7Vx+5Dp4nG4uRlZ2DQ6yAaw2I1U7b5XmRJmlDKDUG4FjMiANqxYwfNzc00NzdTUJD+oXt+rl+lUvH666/zjW98g9WrV6clQhSmRmZBLo68bJLxBFklY7fDS0mJnjOtSIkkruqyKa1YP1Em+OhKcAAAVE9JREFUu5U1j95DIh4nKCv5+NBx5jttlDJaYf2jPYd5e3iE5QuqWXQu2eHFRUEzVi7jo+EYPVENlWe62bBhGfLgIMqhIRbfvi61KDMyOETI3YfObiMeDJIxt47MhfMYHPEzpFCRsNkYjIfJGvEiJyUKzQaqjQ76PV5WL65lTmUxsiynArHPLiBWq1Wp6bB4METgxCm0kTCRhIRBpUCpVKJz2LEUFeKXwVZRhvLctOTJ5k4OHm9GkmSqywpIJJO8+OZu3AMeqssKWLp8Md4eN3u7PegdLjZtXUdFlgMUilTgEQ8G6Xn/I5RqNcV3347OYU/rnzNj9I+KcP8AnW+9i1KjpvCOrejstrR2yaTEe7uP0t7dz/IF1cyrKRn3+7bjo0M0tnbjsJmxWc6t55kAa0UZrg1riAwO4Vq/BnNuJo99fnTaxjnJXVPTbfjUGbxnmgGZkZONsyoAMhn1mAw6JEmipCCbqtJ8wpEoFecWWovgR5gOMyIA2r59O9u3b79iu6KiIl577bXr36FZyuHKZv2X7kOSkhjGySPTfaqZg6+9j5RMMndLmMrlC6atb8lEgq6TLUjJJIVzKtEZDfzL+8c53Ohmry/G/2+JF/fAMK1nu1Ek4hw42sSC2jKUSgXeptZUUdBAMMygxkY4EqV3wIPNZubhP3+MRCTC4MGj9O8/iHPRfHQZDow52QwfP4VSp0OlH11AnB1PUFGUR0+/h7kqI6r2DORkEsnn574HNpJISqiVCrp2vIfnxCmyly4mb90qBg4ewf3JPmyVZRRu3ZQ2JaI26MmtqWBN7BTxnFxWbls1WoNJp6Py8S8QHR5B78xMBS8mox6DfvTDxWzS4wuE6PeMEAxH6XIPMTdTgzuS4HQigq6lC8uxJu69LT279tCRBgaPNCArlVjKipEqqujsHaQ4P4u87At3VgYPH6N//0HkpIQpP3/MtEXf4AjHTp8lEIqw59Bp6quKx60fJZ9PHn1REul4IEjM68OYm33JKSKVVkvRHbelPWezXP2kTTIaxb1nP3I8QfaKJeNmv54qpvw8DDmji4tNl6jpdqvKy87g/m2r8AVHp351N+CPJUGYEQGQcPPQXaYGUDwaIxGPIyWTxCOx696XWDiCWqtFqVLSeaKJw69/gCRJJONxypfOIxJLkJRlYgmJWDxBht2CM8NGNBikpCA79UGstZpTRUEdrhwWZRfQ1NbDwjllqV/MfXsO0PH62yjVahRKJVlLFlKwdTP+sx0kolFiIyMAaNQq1rpshE0K7IX5tA/0EA+FsVdXoFAo0KhVhAeH6Nv3KcGubgKdPVgryujZuYtAVw+RwUEy59Vjyr9wN0ChVFJ6/924NqxB57CnsinDaMJCY276Iv/a8kIMei2SJFNaOHpsXk0pTWe7qSjOw17oJOdUM7b+ECqHDYvJQFt3P5k2Cxbz6PdXZbNxWG3GIymIekK0vH+ALvcg+TmZ/MmDW1LXRaXTEe4bJBmLMtLYNCYAspoNOB1WJFmmIC8zLfjxB8I0NLah12vZvHI+xfnZOB2jWa9jPj9nfvUbwgMD5KxYStGdW6fiR+aKho4ep/ONd5DicZBlCrZuum7vZa+upO7PtgOgd86s/ERTIT83k3xm37iFm4cIgIQpUzinkmgwRCKeoHTRnCk7bywcQZbktOBr55sfceD9A9hynDz+Zw+OlklIJpGSEsl4AoVCwYNLynERZv78IgpyMwgMBNmycTkOlURWxoWpGnNhQVpR0BKdjvXL07f+y5KU9gCwlhVT9LmtBLt6yF4+mqphpLGJtt+/TDIcgU1rqf2zP0GKJ9K202stZtQmE+H+QVRaHz0ffoypwEXEM4zemYnWNjp1k5QkAsEIFpNhtKhq9sQW9CqVirQF1QAbls/FM+w7dzcmzD1P/ylVQ14CoQjHG9v57Wu7yM608YU712Iy6kkUFeErKCEej3PGFyEcidHVO8SIN0B7dz9VpaN3LEz5eRhys4mHwwSGR9Le09/WTvurbzFfq8O6cR1FZemFX/ceaWTPoVPodFo+v2U5qxfXpo6F+wcI9vSSCIXwNrdOaNzB7l5ifj+28tK0IHEylBoNSrUKZBnFOOcIhiK4B4fJdTowGS+fvHEiZmPgIwg3CxEACVNGo9dRu27ZlJ7T09PHwVd3IiWSLLhjHTllo+tiDn5yBN+gh4AvQMOpNpbMrSQeiY6uKVgwmuCvxGklpyabvMos4uemh/R6Hbn2sR9clyoKel7OiqUoVSqUajWZC+YCo3dmXOvXpLWTYnGkeBwpkSARiaI2GOCim2bJWIz+A4cwZGViLsxHoVCSDIWpfOwLZC1dhCHLicZsIpFI8vr7B2jr7qemvJCtaxZcU021YChCU1svPf1DBMNRtq5ZSF52BklJYufuY4QjMYZGAvgCIXoHhtl3uBGlQYfDaqa6rIBgKEJbdz8GnZaePk8qADIXFWCaP5eT+44QSGgwt3RSWz6aRmLg0DG8Ta0oVCryF9SjUacn7lQqFCiUChSKsTm8zIX5ZM6bQ6Cre0weovEEOrs4828vEPcHcG1cS+G2zVd1nTLm1oEsI8XjZM6fm3YsHk/w8jt76egZoDg/m4fuXDMjcwsJgjBKBEDCTW2ooxdPdx9SUmKgrTsVAGVXlOAb8aN12CkozEWj11G9+tLpDq6VxmTEtWHNFds56qopvHMriUCA7BVjq297jp2g/ZU3keJxbFUVmAryyVm+BJVeh63iQoDgDYRo7XTj9YdoOtvN2sW1GPTaMYtDu91DnO3qoyDPmZasTkokRguZnpsyM+p1xOMJwpEYkWiMSCyO2WRApVSyekkt+440otdp8QZCfLT/BN19Qxj1OratW0hNWQGtew8xaFIRzXZSfNH7qHQ6kgsWMni0Gbq6aTvVkgqAzAUudBkOVDothtyxubhWLqrBajGg12mpKElfAKzS6Sh/5AHkZHJC2YBjI15iI16kRILI4NAV21+KUq3GuWj8hI6RaBzPiJ9oLM7QsI9oNIZGfekpYUEQbm4iABJuas5iF5mFeSTjCbJLLySo/OLjd3J65XycmTZcTttlzjC9lGo1rsvkL1GoVKMPScIxp4aCzRvGbWe3mCgryqO9q48Sp5XWX/0akklK7r0L87kFs7F4gjc++JRO9yB5WQ6+dN8mzEY9sizT9vLreBpOYiwtYqC6nr5hP1mZNpQqJblOB7qLpnfqq4oJR2K8t/sovf0ezCY9GrUam9VEYV423pONDP3hj5QMe3EVbkmtKzrP5vWQO+RGiifIGh5MPZ+1dBGmfBcqnXbcqR6jQceSuZX4Ws7iOXQUR101aqPxwrVSKFBMsBSCrbKCnDUriA2PkLd2FbF4gl37T+DzB1m5qCZt4fbVMpv0rFhYw6nmTuZUFk3JFJggCDeOCICEaRcJhFAoFeiMV/7r2ZGXzfov34csSWgvysKsVauYV33pyth7WtzsbnZTrY3y2Jzpz1eUTErsOXyagSEvS+ZWUJDnBEkiY24dcjJJoKsH/9kO2l97i4LbNqK6KBlnMhYj2NnNbYuqSKyYi//gYdpON4EkMXzidCoAOk9x7n9laXQLVSIcpnX/YbxdPSRGQrT6FMRQ4MrO4PNblpOb5Ugtdj4vGIoQjcVJKJWsXlKHw2rGmWHFZjHS4/Xia2kjEQwy+Mke+ooLGD51mow5tWQtXURmjpOSskKkWIz8kgvFiBUKRdpi7vNC4ShajRq1WkWgvZPm//wvYj4fuauWU3r/3Vd1vVV6HSX33MmAx4es09La4Wb/0TPEEwmUKuWYXW5XQ6FQsHReJUvnTbxQriAINy8RAAnTqrepjSNv70Kt0bDkns048q5cY2gyZTdkWeborgP8YucJoiYLPVlmtvgiqPwhTjS244sC46wBGk80FicYimC3msfdun05ne5Bdh86RTgcJeAZZnncS2TQQ+Gdt5G1ZCHDpxoZPn4K75lmLCXFZNTXIp1LrNi5YydDRxow5mZT/ZXHkfPzMORkISeTmFwXFjdrNWpuXzOf9t4hhkYC/PqPH1BTXsCCulLa1EZkWUlMrUUjJfD3DWG16plfW0oyEiE6MpJW6X3hnDLC0RhatZr5taVpeYkctTUY83OJDAyhs9no2vEekSEPoe5ebFUVOObUUv34w0jxGPbay2fePna6jV0HjuOwmvn8luUkI1ES4fBoUslgaFLX+LMOHm/mowMnMRn0rFxUjcWkJxCK4LCKUhiCIIwlAiBhWg20deN1D6JQKhnqdE8oAJqMaCjMkVffhYCSgDGM2anHqFXxD79/n70n2tAbTVQ/tCmt4rsvEEKlVKZNaYTCUV56ezeDwz4W11ewdumFXW2yLONtaiEZCmOvq0alHRugmQ16DFo1npY2YqeP0RMPojEZ6d/7KY6aKvTOTFQ6LRqrFa3dihSP0/zCS/ha2wj3D6BQKQkPDBEb9mKrKKPuT7cjJZMYcy5cr54PP2Fwz34yCws4HNMy5AsSjcWpKS9EtXAhbY4cilxO6tqaGPT1UdAew3umhc633iHuD1B4x21kLV4AjObOuWP9+GuoDM4M5n7rSbxnWrCUFdP70R5iXj9auw21Xo9CocBeM7G7IieaOhj0+PD6QnT3eaisKKVw2yYinhFyV13bAvrOnkFGfEGCoQhKpZIHbl9NIBSm9DM74qaalEgQGRhE67Cj1otpMUGYKUQAJEyr3IoiepvaUGs142aTvhIpKdHX0o5CqSSnrHDMomCtXodKoWSef4CIKsG9RXNQq5QMDvtJJJIEQ2HCkRh6nZZgVw8f//YVPh2O4Kgo5d471qbKJ/R7vHT3DRGOxDhztofVC6vp3/sp8WAIXYaDjtfeIhGOUHDbBgpu20h0eIR4MIjJlYdCqcSZYWVbbRENxw5hl6JIsTgRq4a2mIyxd5D8zeuxlBShtVgwFbgIufvwNrUQ83pR6XWY8vOwV1VgPHfH57NraKREgr69Bwj1uokFgjgLKwgoFeRmOc6VwCim0z1EIJ5EbTaRr1NiNJuIDA0SaO9CSiQYOX2GjIXz+OTTU7R397NkbgW1FaPrrJKSRFfvIDqtBqfDir26Env1aJBjyncR6OjCVOBKK5I6EVWlLgY8XmwWI7lZjtE1UxvWjv+9jscZOnocgMwFc6+4GHpuTQmDAx5szY3E33oL0+2bcVWWp7U5nzn+WnbUffZ87a+9xeChY5jy86j68iOjO/+mUCIUwv3xXmRJInfNSjTm61eYVBBmExEACdMqu7SQjV95EKVSeVWlMtqPneLI2x+hVCpZeOcGij5TIV6pUrH+ifs58cFecsqLKS3NxahVc/9tS3ll9wm0BnOqsvXA4aOcbe6gT9IQVOvo7hsiU6vE19qGPSeb8qI83IPD1GRZU4kQk9EoltISEqEwUiJOPBAk5O7jzL//lrjfT/7m9amt8cXVZcRK84kM6tHNqeWjvgDuoEzXR4f48v2bcVw0XaTPzMBeXYGvtR3nonkU3bk17UN6xBfkk4OnUCtg7fK5GPRa7FUVJIKj66mKu5rJVOlYuG0ZGrWKEV+QRDLJiC+IZtlSylcvGQ1YdDqGKo4T8/nJnDeHgSEvB46dwR8ME45EqSrLR6VUcrChmZ17jjHg8ZLrtLNt3aJUwVOd3Tam5MVELZpTTkWxC71Og06rIdDVTd/u/eiznOStXZkW5PQfOET7H98AhQI5mUzlWrqUiuI8HP5ymhr2E2oZoHfXbmwXBUB9gyO8vesQKpWS29cvJtM+BVmeJQlvYzMxrxdZkogMedLWaMmyTKC9g2Q0hq2i7KqKng4eOkbn2++BJKPS6y4ZMAqCMDkiABKmnXaSdw0uFg2GiYcjKJRKopdYM1JUX5UKjMJtzQAsm1eOJTeHE2cHU4GFMTeHQoeZwQg487Moys2k+Tf/ha/5LOaifO7+2pdxf3qU7j/+keM9PSg1WgzZWVhKCrFVlpEIhcldu5JQdy9hdz9SIkGgoyvVD53dRvVXHifuDxA3GlG8ugvVoBeVSoXyM3cgpESCzPn15K5ajrmkaMwdiqOnWmn64xuYBvo40LyKdV99lOK7bydnxRLcu/fR++FuzKog0tAQUE5liYuznX3otBoqaspSdbGGRvzE1q4nN9NKhiuHQCiC3WYmFk+QnWlP9WtoxM+w18/AkBdk+LSheUoqvisUCmyWCzu9ut75gKGjDaiNxtRdr9Q1iSdIJhIoUJCMxyd0fkNWBvpMB9FhL8a89N1qja3dtLT3olAqqCjOI3PB5dcrTWg8KhU5K5fh3r0PS2lx2hQlgPdMMy0vvEQyGqXwztvIW7Ny0u+h1GlRarUgy6P/LwjClBABkDCjFM2tJuwLoFAqKZxTdcX2siwTGPahio4tzZG1ZCHrc7JZrVBiystBkYjT6w+QjMeJeEaQozHifW58rW0kw2EM2VnkrVlBwZYNadu11Xo9mfPriXqGx9yl0JiMaEyjbT+3aRm9/R5KC3PSqtHLsszZl15l6OhxjDnZ1Hzty6ls0OcZpATW3i7U4RCJ043EfX60NivGvFycC+YR6OxFazZirxm9JiUFOfzJg1tQKBSozyXri8UTvPLuPjp7B3FlZ7B17UIsJgMP3r6KoWE/rpwL9cQW1JbSNziCRq3GajaOySw9VbQWCyqNBo3RgOaiawqQvXQhUiIOKFJrla7EmJNN9Z88TmzEi6X0QubpSDROMpnEajGi1ajTMoFfq7x1q8hesQSlRjMmcI2NeIn5/UjxBNHPZMqeKOfCeSg1apDk0USNgiBMCREACVclGU/gG/RgzrBPapfWtTLaLCy8c8OE25/Ze5iBIR/WfV0E1m8D5YUfeYVCkZ4BWq2i8M6tNP/n74n5fHS/9yHOhfPp/XA3kaEh7DWV5K1blRb8AGjMJiq/9HDqnJdSmOekMM+J58RpGv7jN5hcLorv3oZSoyHcN0AyGiN67gPzfAAUHRmh9b9eIXr0OPaAF2QZq8mA+lxQFezqof3VN5GTEq7N61NV26VEgt533yfU4yZv/WpsFWUkkknCkRjJZJLuviFeeG0XZqOBz9+2nLKi9AAnLzuD7Q9sJhSJ4g+EU9Xfr0ZSkgiFophN+jHXp+jOLVjLS9A5bJgKXGnH1EbjJfMkXY4hy4khy5n6WpJk3njhVTqb2zCVlvK5basoyJ3aEhTjLYQHcMypJaezh0Q4TPayiSfqjETjtHf3YbOYyM1y4Fwwb6q6KgjCOSIAEiZNliQ+ffU93M3tOItcrHjgdlSam+tHKdzWDGE/PWd78Cn19B48SWbNArR2Gy2+YUry0+/CnGcpKURtMpIIhRg+1Uj+5vWs+NkP8be0oXdmXrJ203iBj5RIkIxEUZuM+FvbkGUZa3kp7l2f4GttI9TjJmNeHfaqCgq2baZvz34sJUWY8i4EI/37DtL55jtEh0fQIGPMz8dRU5laK+NtbsF3th0kGV9zK9Zzdz38bR30frSHZCg8mnW6ogyjXseW1fM5fKIVjzdA3+Aw0WicAY+X/Jzxx2XU69K2xE9WIpHktZ0H6OjpZ05lMZtWzUu7VmqjEefCqftwT0oSChRpaQt8HZ2Edn6A1ecl4fehu/f6FTj9LI3ZRNmD90z6dR/sa+Dg8WZsFiNfuHMN2Zn2qe+cIMxyN9enljAjxMJRhrrcRAJBhnv6CPuDmKdwSuFanQ9+7AtqKNVn8slbB1BnZZPUqHnxrU+IxRJsWDGXZfPHTqFpTCYcNVV4kknsVRVobVaUajUZ9bXjvNPotFIimcSo1+Fv72TgwCGMeblkLqin5Xd/INTTh6kwD19zGyBTet/dmIoKCHR1o3E4OOYeob91N4vqyqj92pfxB8JE4kkM5xbLKg0GwioNUa0eq82Mc2E9uatXkEgk8QfDGIsKMeXnIUsy5uILmbK1Nis6m5VIMok++8LdkEg0Tu+Ah1g8QYbNQo7Tfs3TW7Is09rpJhiKUFWan5ZiYNgXoLXTjS8Q4lRrJ6uX1KHXXV2h0ivp7BngnU+OoNdpuXPDktRid0UiQZZFj3egH8PwADq/Hy76eQ0PDqFQKNBnXnu26Kky4guc27UYIRCKkC1qpgrClBMBkDBpWqOekgV1dBw7jaumDNNU7KaZIuFTh5FlCcfCOo5lzcetiZCbP5eyHBvHmjoIBCP4g2FONnUwv7YU3Wd2oimUSkrv+xyujWtTwc+lDHi8vPrefqLROLetXUj09bcZaWxCa7UiS0m8Z1pIhEJEPB5ISqCA6IiXwm2bsVeV0+8NsvNwC/5QBK8vSCQWZ+fuo+h1Wu7ZspzsTBuDGVm01s4nGo6wYstq5m9dQzyR5I/v7qOzd4C6yiLWP/kVFCjSKs4bspxUPfEoUY8Ha9mFxcs9fUMMewOolCq2rFrA3OpiDp1oIRSJsmhOOTbL5LdYt/cM8Mq7+wmFoyxb4OW21QtSx+xWMyUFOXT2DlBdWoBOO/Z6yrI8JdvSTzZ30t7dj0ql5Gynm4VzRneAWctKKF+znA6vF7VBS+/7H2Ld/hgAnhOnafvDq6BUUv6F+9Lqsd1IqxfXoVWrcWZYKcrLutHdEYRbkgiAhElTKBTUrVtK9aqFKFWqKcupcq3Cbc3kLa1DKq2lExutp/soteshf/TP56rSfEoLOvj0eBNnu/r45OApNq0cO/2iUKkmdDegs3eQzt5BJEmiub2XMosFpVqNyqDHVJiPpaSIcN8AmfPrSYSCAGgqyjlwrInAnj2o3W4krQO1IwO71cSZk810NLai0evonlNGdqYNSaEknJNHUpLQnOvTsDdAe3c/vkCIM82drJpThtkxdo2OMTcbY276rqQ5lUX09A9j0GsoL86luaOX9/c2EInGOHa6DZNBz+L68lTwMOYaR2L0DY2QnWlLFVg92+HGHwwjyzKRSPpic41axee3LCcQimAxGcb8rAweOUbPzo8wFxdScs8dKDVXf3fIlZOBw2ZGq9GkTRkplEry1qzE13KW2IgX7UVb+EPdPYT7BlAolQS7erBVlOH1B4nHk2Q6LDfsZ/v8ejFBEK4fEQAJV001wUKV0y1py8XbHyA+MkLAn8CU70KhVGLU61g8t4KO3gFi8QTBcPSa3qcg10l+TibhUAiXQU3xPbfjqK1Cn+XEUlxI9fZH6e/p50TvaGX1xfUVvP7+pxxtOIPU0c1yOciSLA2OFWuorCln769+i2FoALVWw5GDxznR3MWaJbVsXjWfRDKZCkoybGbKi/NobW7H2tbCqb8/gXN+PblrV2G4xBqlEV+Q9u5+MvVq1qvDKKUoRoWMWqWCSIRoKEJXOILJoCcWT1BfVYzmM+u6kkmJV97dR+PZbsxGPV+8ex1HTp3lyMlWZFlmXk0pKxfVjHlvlUqZtvU9kUiSlCR0Wg29H3yCv70Db3MrsixRuHVz2p2syaivKiY3y4FWox5zJ8tU4KLy8YeJDY9guyhrtaOuhpHGJhRKJfaaKrrdQ7zy3j5i8QSbV82nvqr4s28jCMIt4ub8BBOEaxTsceP+j//EGwunJScsL85jzZI6AqEIS+deW1HL7EwbD21YSOOvf0fstVMMrF1JwZYNqeMxf4BXf/1HjgwGiGr1HKxvwW42glqNympFrdRi16pJvPEmPaeLKbQa2KRP0qvXc6pvBMVIiAy7mTs3pG+tV6tV3L1pGe1aie6TBxlq78Tb2Eygo4vaP90+JhNxUpJ4/f0DNLX3Yvf0U9fRhMlqRp/hwKrXU+1uI4gCX3E5fqUGV3ZGaus8QDIaxb17P0F/gB53kI6efhKJJHqtGp1OSywWx6DXsWjOhXxDlzLiC/Lqe/sIhqNsXjUfc2kRvrNthAcGcX/4CQqUl1w0LCUSxEa86Bz2cRMKKhSKy25vtxQXwkXrpGA0MJrzja+Nvl6l4vSJFgY8XpJJiW73kAiABOEWJgIg4ZolYnF8gx4smY5p3RJ/OaHePuIDA6iQ05ITatSqtLpeV5KURqu69/Z5WFxfMWa7uDQ8jNTXTzwSxdfcChcFQJ6Gk8R6egnG1SQT4O73sKiyAPXZFgwmJQu3bqX77Z1Eh4YYScSpfOwLWEqLyZRVDJ4dneKKxmL8x8sfoNWq2VhfijYWxVJciFKjIaeqHF9RPmF3H2q9npg/MLrr7LMBUFKisbWbrs5e5P5u/INuFFEHGpOJyJCH7LAfhVKJNj+DE3EVBp2WaCyRWqzsaThJ55vv4A4nGLLnEQmG0SdiDJ06wx0P3oFOqyE3K+OSO8ku1tHTz9mufpLJJKdburjrrm1orVY633wHKRZHSibGfZ2cTNL6+5cZOdOMvaaK8ofuHVMG5WpdHEyVFuRQXpRHJBqnrqLwMq8SBGGmEwGQcE2kpMSBP75Lf2sHWSUFLH9g27RMjUnJJJ6efgwWEyb72LsOtqpyTHPmYAr5r1hC4XLc/cPsPXSaQCiCPxgZEwBZigvJmFNLuK+fnBVL044ZspwszLYQ8yUYcWZSWuKiQI6j7G1HiifwnjxD5rx6Bg8dxVJSiKW0GHt1JXlAPLOVHR8dZu/hMySTEg61jOOj97EqZHJXLqXwjtuIh0LkrltN1vLFBNu7sNdUpda3SJKMe2AYo0GHWq1Cp1WjVasYVGpwq3REDRasc2ox+XyEet0oVGpOqvW0tXXT3TdEfl5m6u6HUqNBqdHQFlGQQEGGEmzJGFWhOOV6BUvu3Tjh65mXnYErO4NwJEppYc5oLbB1q9CYjMR8fpyL5o/7upjPj7ephahnGO+ZZuL+wJhkkVPBYTPzxbvXIyOjmqIASxCEm5MIgIRrEgtHGO7pIxIM4enpIxIIjRuQTLWTu/bTvP8YJruFlQ/dNWYbvtZiJucLD1Ji013VQlZ/WwfR4RF0LhcWk4FoPDFu7Si1wUDllx5GTibH7BhzzKlhgd3GPFkiaXNg0GtJDA7icWYSHPaid+VSuHEtuauXo7GY014fi8UJR6LE4gk0ahUZKlCFQiQUMr2799G371NCvX3o7HZcG1ZT+fjD+M620/zr32HIyaYzI4fdhxsxGfXce9tyaisK8QVCDA0M0K+3MJRdwEggTHaWk6ovfxGAvk9Pouvox6DTYjbqGfT4CITCFNRWU/6F+xhqbCfmCSF39xFLRuk1GcHuGPf6JaNRYv4A+gxH2p2arAwbj35+PfF4IrVOR6FSXTFJoNZmxTGnlpFTjTjqa9FYzBP7Rl6F0RxCN8fCfkEQrh8RAAnXRGcyULJwDp3HGymorcBom/wC1kF/GEmWybYar9z4HE93H9FQGCmRJOAZuWQeoqsJfoI9vTT9+ndEh0fIWbGU+2/fgGfET5Ere9z2CoUCxTh3vRQKRSq7cTQWp7N3kAybmf55izlzupWekAJrtxutVo3uM68vL8qjvCiXeCLJojnl5GVYCe3dS6Cji2B3D6H+QcJ9/Sg1atwdPXzyyofEjzWQ0ddDm0qPr7CEqFJJOBLDMxLg7k3LsJqNvB5L0hXMZVFtORk2M8mkRFKS0GrULF9QTVaGDaNei0aj5revf0QwFGHFwmrWLatn69w65riHePW9fbjdZkIGPV4JPhsCJUIhzvzH7wj1usletpiiO25LO27U62CSyRUVSiWl999NIrgJtck06e/roMdHNBYnLzsjLUniRMmyTDgSQ6/TXtXrBUG4+YgASLgm57fE16xejHKczMpX0uge5j/2nEGSZR5eWsG8wolt/a1cNp9ENI4tO4PMwrxJv+/lJIIhEsEQUiJJzOsjK8N2xdpRsiyz/+gZjp46S01FIWuX1KV9SO/46DDHz7STYTMTjsQYUWnxN7aS8eluHBoVZQ9+HkfNhcSMzgwrj31+Y/pUzL2fG60b9uIrDB4+ht6ZScbcOg5JeprbeoiFk+gkDcMKFbpYnAxnBuWFOZQU5KDRqNmwfC5ZGTaisTjza8sIhCK8tnM/3kCIDcvrmVNZTHVZPt6mFo7sP8pgrxf0evo9PgBUSiVFriyWzK1knySTlWEl22kfcy3C/QME2jqIB4MMnzxN4e1bpmQ7uUKhQGOe/J2fLvcgL+/Yi7e3j8U5VtbdsX5M0dLLkWWZ9/c2cKKpg7LCHG5ft3jcLOKCIMwsIgASpsTVBD8AHZ4Avd4gkizTORyYcACUV1VKXtXVVSeXZZlgVzdyMom5eGzldUtpMfm3bSTSP0DOqmUTOmc4EuPAsSYGPF6CgRBzq4px2C58WPd7vMRicXzBMFUlLjp7B7H4R9C2DxNRQtjdlxYAwfhTMQqFgqJ77sS5fAnGrEzUej2du4/SdqyJzKpSMhXFNA34sGbauW/rirS7Vmq1ivm1F67Z6ZZOGlu76en30N7Vz1ceuo3yHAdn//AqUkcPeVYnxsWLWDYvfbfcsvlVVJXmo9Nqxi2TYczNxV5bTaCzi+yli6/uLlwoglKpxKAff1F9KBylyz1IdqY9lfH5UoaG/Qz0DuDt6KG5vZUSKUrNVx6fcF/C0RgnmzoYGvaRSCRYsbBm3OlQQRBmFhEACTfUHFcGtXkZJCWJ+vzpyfc/cvoMrb9/GSmRpOSeO8hasjDtuFKtJn/j2kmdU6fTkGU14T5+GklOEDpViOOiRdHrls5h/9EzFOQ6Wb24llgigeQZpv2VGAqFAkfd2Pw54/bdF+SNDz4lHI2xdfUCCl161i2rp7QwB6vZiNVspLXDjcmgo9B1+QzCedkZGPU6JEkikZQ4c7abClcmSpUarUrJCqeJurvWoNbr0143NOzn1Z37SSSSbF27kOL89LspKr2OysceIhkduyPtSsKDQ+z93avs6fWSUV7K5+9cQ152elJKSZJ59b39NHf0kpfl4JG71122Xll5US61pXl09PVQnOSy2b3HY9BpKTs3HVnsysJmnvhUrSAINy8RAAk3lMtu4pnbRrMxX69dN8OnGhk60oCtshzn4gVEhjxEh71IiQSeE6ewlBRdssjpRKmUStaXZWP6yIcpHmPkSAP5K5aO5q7x+akozKGy5EK1c7VaBa5c6v7sT4CJr1U62+mmub2XZDLJyeZOCvKc+I6fRNPXj3HeHJLxKNlhP9a8DMKRGCebO9BpNdRWFI65vtmZNh6/bwOvvncASZKoKM5DbTBQ9vB9+FvbsZaVjAl+AM529dHRPYAkSzS19YwJgGB0zc5kgx+AoSMNnGhoojWpxp2QWbigekwAlEwm8XgDxOMJvP4QoXD0sgGQ2WTg4Ye2MTK3lMjgEBn1dVfshyxJhHrcqE1GdA4729YtYsWCaqxmY1qOJEEQZi4RAAk33PXcbpyMRml/7S2Cnd14m89iKCoglJmFaU4N4TPNDB1pINw/SPWfPIbGaGD4ZCNauw1reemkp24yigspKSsk6hkmY04NUiJBy29fwtd8drQgqVKJSqOhYOtGzAX5wOQXaWc77WRlWInFErhyMgj1uDn7x9eJDg0zfPoMcjxBuG+ARGUluyIqeod85Oc5wedDc/wYiXCE/M3rsVdVAFCYl8VXHrqNRCKB2TQasJgL8lP9G48rJ4PcLAfxRIKice4yyfLoFnxZhrxsx6TGqM9wENXriIRAkZRhnNdqNGrWL5vD0dNtlBXmTGg6SqFQ4KitnnA/3Lv30fXO+2jMJqoefxhjXi4ZYtpLEG4pIgASbmkKlQqNxYJCrUZjMrLvZDufnm5Dkg1UZeSQ29tFdMhD1DOMe9du3Lv3o7VZqPryF0czB0+C1mal9qtfJh4KoXPYiQwOjeauGR5huLEJKZEgEQzia26l/ltPpup0SZI84Z1F+TmZPHrPemLxBE6HlXBfPwqVCoVSiXxu0XYiGuHTQ6folNREUeAz6QmcbiT68V5C7j4G9h/EtXEtrk3rMBfkjyY8nESF9vycTB67dwPJpJRW4uK8xtZu3tp1EFmG29cvorZ84tcxc+E8Cpp66D7Vht3pwD7O+QHqKouoqyya8HknK9DeRWzESyIQJNTXjzEv98ovEgRhRhEBkHBLU6rVVDx8P76Ws5gK8jl54DTuwRE8I378dhOrCgqZU1mEpaSI/n0HkRNxEqEwyXDkqt5PpdehOjcdo3PYsddW421qQWO1MnyqEaVSSSIcITI4iLetg4MnWmhXGnBk2qgsyWNBbdm4Nbh6+j2YjXrsVhOxxjOE+wcIL5yHMS+X8gfvJdw/gL2mEvfhBs4cP4PmbA+mqIxZIbNmTgmlOXYaP/oYKZ4g2N1L51vvEfUMU/eNr6HSTj57t0at4mRTB7IsM7+2LJU1GsDjDeD1B5FlBZ6RwKTOG40l8MlKFBotVpOR0oIbE3hkL1tEZGAQrcN201SIFwRhaokASJhWkiTTPuRHr1WRZ7v87p2ponPYUwudl82XaOnoJRaPo7dayNu0lNL60emggi3rUZsMozWyKq5uh9nFlGo15Q/dSzwYRKFW4961h5HGJqzlJUQ9wzS++BpDvQO0u8o4pDPT1tWHVqNJ26kF8MnBU+w72ojVZOT2uSX0v/omsWEvwZ5e8h95iJAjk5yqclRKJSe1Vo4aMlBlJVkWHqGovJhl29agUKlQKrbT/uqbjJxpQWM2IUsyyPJVja2hsY13Pj6MzGiOI7VKhUajYkFtGTVl+XS5B0GWqSkvmNR5A6HwaOV4swGNRoXM1fXvWtkqy6n/1p+BQnHDKsILgnB9iQBImFYfN/XwytE29BoVf7K6lvLsy+fXmWplRbl884m72XO4EbVKSe1F9Z6MebmU3T9+Ic6rpVAq0VpG144UbttE4bZNAPR88DEqZPRqFTq1CqNRh1KpHHcqrKffQzAUGV30G4mhVGtQqJQEJHj+X17EFwyxZu1iNq5bwoDHSzyeQJ2bw8K1WymvKk3tespavADnwnl4m1oIdHZjqyxHpZtcQsLUuBQKFAolCmRaOtx09g6iUanQaTXMqynlC3euuarzZtgsLJ5bQXNbDwvqytBpJz41N9WmqtbYVAgEw3xy8BQAqxfXptZrCYJw9UQAJEyrHm+IkWAUlUpJny80rQFQIBjGHwyT7bSzbe3CK7/gOspauggpmcAVS7C4sgpPMDK6W2uc9TJL51UQiUbJtFupmldLxGYkMjBE25Cfzrd2E08mOb1PxcZ1S1i7tA69VkNuloOy6vIx+ZkUSiX26krs1ZVj3gdGK653vfM+gbYOcteuIqO+dtx286pLUCgUyLKMPxCmu28IpUqJ8hqDBqVSwbqlc1g3iYK1s0HDmXb2HWkEhQKbxcSKhRNf0C0IwvhmXAAUjUZZvnw5R48e5fDhwyxYsCB1rKOjg7/4i79g586dGAwGHn30UX7605+ivYo1DsL1saIsB7c3hFmvYU5+xpVfMEW8/iC/f+MTRvxBls6tZP3y+ml77/FoTEYKNm+YUNvRshgXsl3rqyqgqgL5yHGKtOCNStSdCyQ/23aygl09uD/eSzwQJBmNYqmuJBiOYrMY06aCNBo1i+aUAxCJxkenrNTqVAAnyzIxrxe1wXDVd5mEC4x6HXqdFoUCjAZxPQVhKsy4AOgv//IvcblcHD16NO35ZDLJXXfdRVZWFh9//DFDQ0M88cQTyLLMz3/+8xvUW+GzSpxWnrlt/Irf19PQsJ8Bj5doLE5Hz8C0v//1kDu3li8+fjfRQBB7VTktv/sDyUiEgm2bJ1Xq4WJauxV9hgM5mUSVncN/vbWb/sERFtaXX/KujF6nYfG5dVTn9e3eT/fOXegzHVQ+9oVU5fahET9tXX3k52SSm3WhipgUj6NQKlGopi/HjizLnDnbw9Cwj6qyfJyO61/E92rVVxenAp+yIrEjTRCmwowKgN5880127NjBiy++yJtvvpl2bMeOHZw8eZLOzk5crtGEcz/72c/Yvn07P/rRj7Bab95fbsLExKMxGt79BN+gh9o1S8kpn/g26PzcTOoqCunu6GVBuevKL7iJSJJMMpkcsztMoVKlFnf37dlP/75PkZMS+swMiu7adlXvpbPbqdr+6OgWfp2Jzrf3EIpEOd3cOaa+2XmjgUQ3QyMBassLcNjMeI6fJDI4RNznJ9jdg9ZmJZFI8vrOA5zt6iM3y8Fjn9+A2ahnpLGJ9tfeRmMxU/6Fe9HZ7VfV98nqGxzhrV0HGfYGaO8Z4It3rxu3Xf+QF58/SFF+NlrNjfmVqVIq0xJpCoJw7WZMANTX18fXv/51Xn75ZYzGsblB9uzZQ319fSr4Adi2bRvRaJSDBw+ycePGcc8bjUaJRqOpr30+39R3XrgkWZbpa+kgGU+QW1mM6jJlCgY7ejh75CSJWBy1RjOpAEin1bDMAJ0dp5FGugnnZmDIvnypiJtBLJ7gjfc/paffw4qF1SyaU05kcAh/eyeW4kL0zkzCkRheSYHKbIZEAl3mtU0t6jMz0GdmYIjFKSvKpXdgmLnn1vyMxz0wzJsfHsTrD9HlHuQLd67BuWg+kSEPemcmpsLRpIqyLBOJxkhKErFYnEQiCcDQ0eME2jtRqtX4ms+OKU1yXV1hk9mAx8t/vfkJXn+QxfUVbL3Ba8cEQZg6MyIAkmWZ7du38+STT7JkyRLa2trGtHG73eTk5KQ953A40Gq1uN3uS577ueee46//+q+nusvCBPWeOcunr7xHMp5gzqaVVK1YcMm2ZocNS4adkNePLXdiRVMv5m9tIz4yQjIQINTjvqkCoJ4+D/uONGK3mlizpC51t8c9MMyZs92EIlEOHW9hfkUBzb95Ed/ZNqylxZQ98Rgv7fyU3v4hqmvnsm5xLbbya9/CD6NB433bVhKJxC677kSWzz8ubKvPXroIR201Kr0utQtNo1Gzde1CGlu7KcrPShUxtZaVMHK6CbXRgCn/6tYvybI86e3qOU47t69fxOCwn+qy8TNf+wNhfIEQsXiCoRH/VfVNEISb0w0NgJ599tkrBh8HDhxg9+7d+Hw+vve971227aVuz1/uF+P3vvc9vv3tb6e+9vl8FBZOLgOwcPWioTCxSIRkQiIaDF+2rcXpYNXDnyPsD5CRn3PZtuPJWrKA8MAAOrsdS3nJVfZ4rFg8QW+/h0yHFbNxbO2sidh7pJGGxja0GjWunMzUB3Km3UJetoMBj4/yolykeJx4IEAsnmBP9zB7X/0Q93CARDJJl9GAqaR4Srdvq5RKTFcYU162g9vXLcLjDaTl/dGYx+Z5KinIoaQg/XvnXLwAc3EhKp0OrdVCZMiDUqNBa51Y6YnjZ9rZc+g0BXlOtqxegGaCtboUCgXVZQVcbj9VoSuLZfOrGPT4WL6gakLnFQRhZrihAdBTTz3FI488ctk2JSUl/PCHP2Tv3r3oPrObZMmSJTz22GP86le/Ijc3l3379qUdHx4eJh6Pj7kzdDGdTjfmvML0ya8pJzA0QjwWp3TRlYtUmjNsmDOubuu8o64GW1XF6GLbKQgSBj49jPuTvTTH4IzZSU52Bl+4a824hTkT4TA9H3yMFI2Rt341Ooc97bjdakKjVmM26rFclOPFZNTz0J1r8AfDZNqtKJUKiu7cyqefHKRrJIZi0IvRoMNpsrJ4bsWYdUIXkyUJz8lGIv39xMMRTLk5OBfNv+ZEf75AGI1GzcI5ZZctSnpeqNeNt7kVS3ER5qICFAoFhqzRO3pDRxpoe+0tVDodFV984JI1ySRJ5tOGJvqGvDS3deP1hxj2BaivKqYwb/J3By9Fo1axaeW8KTufIAg3jxsaADmdTpzOK/+y+j//5//wwx/+MPV1T08P27Zt47e//S3Lly8HYOXKlfzoRz+it7eXvLzR2+g7duxAp9OxePHi6zMA4ZppDXrmblk9be+nvMwao8mQEgm6d+4i0NVDaDhAomYeQ1o1/kB43CDAc+wEPe/tQkokUGq1FN6+md62LkbiSYoKclmzpI78nEzMJj1OvZrm3/weKZ6g8PYtGLKz0OsupHLInF9PfU4eZ97eTTAcZdWiWlYtqr1kPTFJkvEFQhx84136Xn0LdcBPpsWErbwEQ7YTc+HlszUHQxH8wTBZmbYxhWvDkRgvvb2b3v5hKkryePD21Zeta5aMxWj53cv4WtswF+ZT9+RX0u4U+draifQNoFCrCHb1XDIA6ukfYteBEwSCYUCByaDHmWHBYZ2e7OKCIMx8M2INUFFR+mJXs9kMQHl5OQUFo7+8t27dSl1dHV/60pf4yU9+gsfj4bvf/S5f//rXxQ4wYcopVCpMBS6iwyPkZWQSKc6nrLwIZ8aFnzVZkvA0nCQZjaJQq1AZdChiStQmI41/eJ2XPjqKV6tn3spFPPL5Dalpr5Z3PqDx3Y/QqJTonU6K7rxtzPvn52by0J1rCIYjFLuyLxl0yLLMOx8fpuFMG6Gjx8ka9kIsjmQ0YFerLxkQhnrd9B84RMJsYddQmGHv6CLgDSvmprULhiOM+ILE4nGGPD4SySRa5WV+rUgyUjyOLEmj/59Mph3OqK/D19KG2qDHepkaXHqdFoNOSzgSY05lIcvnV2Ozmq56ClIQhNlnRgRAE6FSqXj99df5xje+werVq9MSIQrCVFMoFJTdfw/ZyxZjyM5i0zjrVYZPnKLl939AisbIv20jFV98ECmewFpRStPf/iOBcJRoXMIz6CGRSOI5dhTP8VN82jtMOBBBp1JSqLp0KYiL8+hcSjgS40xbD/5AmAGTjbAjB51SgWpeHeX3rL9klfOzf3yDwYNH8Toy6c4uJqnR0NbdP6Zdpt3CigXVtHS4WVBXesVt4iq9jtL7PsdIYxOWspJUfqDzbBVlzD1Xg+tyd+ucDiv3bl2BZ8RPWWHuFdcpCYIgfNaMDIBKSkpGd5x8RlFREa+99toN6JEwG6n0ustWCk/G4kixOFIigRSP46irSR0rW7aQ+ZFPGTbbWLduCYpwmM633yPcP8CA1k6wZh5WswHz3LHrogY9Phoa27BbTcyvLbvslJNBr6WqxIUkSZSX5DFQUUQikaR2ce0ly2HEAwE8x04Q7OpGn0xQvXQ5nrjEkrkVY9oqFApWLqph5aKacc40Pmt5KdbL7FRTaiZW/ys/J5P8nMwJv68gCMLFZmQAJAgXcze303WyGZtBQe6cyVUfv54y5tYR8/uRwhFyVi1PO1awdRP3r1mJ2qBHoVSSjETR2qxEPcMsy88gsWIlGRk2CvLGbtX/cP9xGs60YzbocNgtlORfOuuzQqFg1aJaivKzKC3IIRpLEAiFL3v3KOoZQWM1Y8hyYnLlsuX+LcgoUKlunuKggiAI10oEQMKMlojFOfbOx3h6+jDqVNSsn8vNMhmi0mrJ37B23GMKhQKN6UJCT5VeR8WjDxHs7MZcXHDZbMhajRqVQoFarUJzhdIRoUiUl3bspm9ghNqKQj63aSk2y9hEohczunLJWbEUX0sbrvWrUU5jeYrZKJmUiMbiosaXIEwzEQAJM5pSpURnMqJSqdHoNKi1E5s+uRnpMxzoM668rmfjirm4cjKwmAw0nGljx8eHWbWodtxkfj5/iEGPj1AkSpd7EEmSUakuv+1dqVZTeu/nkGWZeCBA59s7Uem05KxcKgqbTrFwJMYr7+5jwONl+YJqls4bf1pSEISpJwIgYUZTqlQsuWczA+3dGJIhDGYD8RvdqevMbDKwuL6C3QdP8eKbu4nFE/QPjvDtr903JglgVoaNebWltHX2sXReZdo0ViIcpuud90mEwrg2rh1TQFWhUND3yT46334PpUaDxmya3jIVs0Df4DBnu/qIRGM0NLaJAEgQppEIgIQZz2S3YrJbCbc13+iuTKvwubpayaSEUqkYk6MHQKVSctvqBeNmRB8+cZreXXtIhENEPcNUPv7wmOzLSo0Gxbnt8ooJZlgWJi47005hnpPBYR815SIDvSBMJxEACcIMtaCujM7eQYKhCJ/fsvyyu8HGy/assZhRG/X429rpD4ZQqFTUfOXxtF1YuatXoDGbUGq1ZM6dc13GcSmyLNPQ2EZ3n4e6ikKKL7PY+7Pau/sZ8HgpL8rDYTNfx15eG6NBxxfuXEMoEsVqvvzaLEEQppYIgARhisR8fvo+2YtSqyV39QpUEygLcbU6ewbo6fdw54YlZGdeXWkQW1UFpfffQzz4AnI8QWTIQzIaTQuAVHod2cuXXHU/e/s99PR7KCnIIdM+sdpe5w0O+9i55xjD3gA9fR62P7h53LtcnzU04ufV9/bjGfFTWerikc+tu+ZyH9eTRqPGdoX8SYIgTD3xr04QpkjfngN07tiJUq1GYzZdU+AwHn9bB3179oPdzo6BCH3DPkrys/nSvRtRT2B6SpJkDh5vxjPiZ35tKblZDqx1NbBsOfHWVso3rUFjnrq7JYFQhFfe2497YJiSgmweu2fDJfs54PEyOOyj2JWd2g2l1ajRaTWoVSqMBi0KJhbEJBJJEskkSUkiFktM2XgEQbi1iABIEKaIUqdBqdGgVKtRXlS7a6p07tjJ8MnToNMhZxURiI3W6RqbEvQSr+8d4IN9DQRDEYZ9AR6+cw0f7/iIj84OoLPnk2HLZPy80FcnmUwSiydIShLRaHzc5KUAXn+Ql97azcCwj7qKIu7fthIAm8XE57esoH9ohNLCnMtO8V0sO9PGltUL6Bscoa6i8Ka++yMIwo0jAiBBmCK5K5ehNZtRqtVkjJPB+Vrp7DaUajU6qxWVyUQy4ieRSBKNxcfs/hr39VoNOq2GSDSOUa9j6EgDXe9/zEhYxpKXQzyRvOI5JsNmMXHb6gV09AxQVeq6ZKX6YChKIBQhkUgy7AukLdh25WTgysmY1PsqFArqq4qpryq+5jEIgnDrEgGQMOOF25oh7EeWJQZzNtDSNkivN0qpfXpTIqp0uuu6Tbzorm3YqspRW20c2HsKe0xCBsKR6ISKgOZmOfj8luUM+wJUFrvwHTpMoRwlroScQidzKq8tYJBlGW9TC1HPCBn1NWjMZmrKC6gpv3x27twsB6sX19HVN8SiujJxx0YQhGkhAiBhRjsf/NgX1BAsqOTjfhXhSGDag5+rMeILEonGyHHaJ/ShrzEZcS6YB8AG1Bw73UZJQRZOh/UKr7ygOD87tZtKu2AeZcNeSpIJ8jeuQ6u7tiSSwc5uWl54iZjXS6BjCeVfuG9Cr1MqFaxYWH1N7y0IgjBZIgASZqxwWzNyyItjYR39Vas43OYhHInPiOCnt9/Dy+/sJRKNsX75XBbNKZ/U66vL8sfN/Hw5Xe5BfP4QZUV56HWjiQ2L7759Uue4nGQsRjIaRUokSYTDU3be6eJpOMHI6SbsdTVkzJl4cVdBEGYmEQAJM9L54Cf34YfoxMbhNg+5ehXor7wWZtgbYMQXpCA385LrUq6Xjp4BjpxsJRKNMeDxkpRkevs9MMkACCAeT9Bwph2AuVXFlx1Lb7+HP7y9B18gzJK5FWxbt+iqx3Ap1tJiiu7cSsTjIXvp1J//eor5/bS/9jbBHjfelrNYSorSarUJgnDrEQGQMGO5ltUTt+Xi7Q8QjsQnFPyM+IL815ufMHRuK/gd6xdPQ08veH/PMc529aHXaXFlZ6JUKq96se7R02fZ8dFhQIEsyyyur7hk21AkSjAcJZFM4g9en7szCpWK3NXLr9zwJqTUaFAbDSjVKjQmI0qR9VoQbnkiABJmFV8gxLA3QDQao29weNrf32I2olapsJqN3Ld1BQ6bZcLbuz9LlmUkWQZkJOnym+GLXdmsWVLHsDfAkrmXDpRuZklJwucPYTEZJpT3aDLUej3ljzxAoL0TS2mxKPoqCLOACICEWcWVncGi+gp6+4dYvmD6F95uW7uQqlIXmXYLmZNYvDyeudWlqcBnbnXJZduq1SrWLBm7NX+8GmE3I1mWeffjI5xq6aQwL4t7Ni+b8ulLY072mIKwgiDcukQAJMwqarWKLavn37D3Nxn1U5afRq/TXHUQJ8sy3e+8z1DDCbKWLCRv3eqrDoRkWWbv4UZONndSX1XEsvlVUx5UxeIJmtt7GfEFkSSZEX+QrIyrKwEiCIIAcOXCOoIg3HKinmH69h4g0NGF++N9JIKhqz6XPxjmwLEmOnsH2H/0DMFQZAp7OkqrUTOnsohMu4WKYhcO681b4FQQhJlB3AEShCkWDEU4eLwZpVLJkrmV6K8xv871oLGYMeblkohEMRXkoTZcfeoAg15HVqaVUCRKVoYN/XUoA6JQKFi/vJ5l86vQ67TjrpuK+fwo1SrURrF7SxCEKxMBkCCMQ5Zl+vYeINTdS9aSBVhKJj5tdfhkCx/sO45KqcRo0E06x890UGm1VD72EKG+AYx5OShUV7+oWKNW8fnbVtA/5CUn045arSIai3PoRAvJZJJFcypSBU6vhUKhuOR5PCdO0/7KG6h0OsofuR+TK++a308QhFubCIAEYRzB7h4633qX2IiXkLufOX/xtQmva9FqNGhUKlRq5YRqdN0oaqMRa+nUrEcy6nWU5F9YQHyyqYP39xwjkZQAxbgLsKeSt6mFUI8bhUpFoL1TBECCIFyRCIAEYRwqvR61Xk9CFURjMU1qUe/CujL0Og0qlYqassvXwbpVqdUqVOfuKk1HEOioqcJ7pgmVTo+ltOS6v58gCDOfCIAEYRwGZyaVj32BUF8/9urKSb1Wo1Ezr6b0OvVsZqirKAIgmZSoqyy67u9nr6mkvvjPUCiVIoePIAgTIgIgQbgEc1EB5qLZeQfnWqlUyivmJppqaoNhWt9PEISZTWyDFwRBEARh1hF3gARBmHKRwSH69x9EY7WQs2IpSrX4VSMIws1F/FYSBGHKde/chXv3PtQGA/oMB466mhvdJUEQhDRiCkwQhCmn1GlRqtSotFqU2qlPjCgIgnCtxB0gYVaRZZm4P4DaaBDTMtdRweYNGHOy0VgsWMtn9444QRBuTuITQJhVunbspP/AISxFBZQ/fL/YMn2daMwmclYsvdHdEARBuCQxBSbccmRZJh5PjHleSiQYOtJAZGCQkTMthAcGb0DvBEEQhJvBjAqAXn/9dZYvX47BYMDpdHL//fenHe/o6ODuu+/GZDLhdDr51re+RSwWu0G9FW6EZFLirV2H+Offvs3uQ6fTjinVajLmzUHvzMRaXoohy3mDeikIgiDcaDNmCuzFF1/k61//Ov/rf/0vNm3ahCzLNDQ0pI4nk0nuuususrKy+PjjjxkaGuKJJ55AlmV+/vOf38CeC9NpaMTPqaYOfP4gh0+0sGRuBVrNhR/zwtu3kLNyKRqzWawBEgRBmMVmxCdAIpHg6aef5ic/+Qlf/epXU89XV1en/nvHjh2cPHmSzs5OXC4XAD/72c/Yvn07P/rRj7BardPeb2H6mZRQ0HySYN8Azg1rx9ShUigU6Oz2G9M5QRAE4aYxI6bADh06RHd3N0qlkoULF5KXl8cdd9zBiRMnUm327NlDfX19KvgB2LZtG9FolIMHD17y3NFoFJ/Pl/YQZq5odw/58TAlBhVlscCkipgKgiAIs8eMCIBaW1sBePbZZ/kf/+N/8Nprr+FwOFi/fj0ejwcAt9tNTk5O2uscDgdarRa3233Jcz/33HPYbLbUo7Cw8PoNRLjuDLnZWPLzMGdlYq8ou9HduWaSJCPL8o3uhiAIwi3nhgZAzz77LAqF4rKPTz/9FEmSAPj+97/PAw88wOLFi3n++edRKBT8/ve/T51vvL/2ZVm+7F2A733ve3i93tSjs7Nz6gcqTBuDM5Oar32Zuj/9E1zrV9/o7lyT9u5+/r8X3+N3r3+MPxC+0d0RBEG4pdzQNUBPPfUUjzzyyGXblJSU4Pf7Aairq0s9r9PpKCsro6OjA4Dc3Fz27duX9trh4WHi8fiYO0MX0+l06EQumFuK1mpBa7Xc6G5cs4bGdtp7+lGrlNR2FTCvRiQUFARBmCo3NAByOp04nVfeirx48WJ0Oh2NjY2sWbMGgHg8TltbG8XFxQCsXLmSH/3oR/T29pKXlweMLozW6XQsXrx4wn06P90QCIUmOxxhGkXCYXzBEAmfj6A/SDgYIKiO3+huTakMqw6zTolOq8GsVxEM+G90lwRBEG5aoWAAYOLLBuQZ4umnn5bz8/Plt99+Wz59+rT81a9+Vc7OzpY9Ho8sy7KcSCTk+vp6efPmzfKhQ4fkd999Vy4oKJCfeuqpSb1PZ2enDIiHeIiHeIiHeIjHDHx0dnZO6PN+RmyDB/jJT36CWq3mS1/6EuFwmOXLl7Nz504cDgcAKpWK119/nW984xusXr0ag8HAo48+yk9/+tNJvY/L5aKzsxOLxXJT7CDy+XwUFhbS2dk5K7fyi/GL8Yvxi/GL8YvxT2T8sizj9/vTdoNfjkKWxRaTm5nP58Nms+H1emftPwAxfjF+MX4xfjF+Mf6pNiO2wQuCIAiCIEwlEQAJgiAIgjDriADoJqfT6fjBD34wa7fqi/GL8Yvxi/GL8YvxXw9iDZAgCIIgCLOOuAMkCIIgCMKsIwIgQRAEQRBmHREACYIgCIIw64gASBAEQRCEWUcEQDeJtrY2vvrVr1JaWorBYKC8vJwf/OAHxGKxtHYdHR3cfffdmEwmnE4n3/rWt8a0aWhoYP369RgMBvLz8/mbv/mbiddGuYF+9KMfsWrVKoxGI3a7fdw2t/L4x/OLX/yC0tJS9Ho9ixcv5qOPPrrRXbpmu3bt4u6778blcqFQKHj55ZfTjsuyzLPPPovL5cJgMLBhwwZOnDiR1iYajfLNb34Tp9OJyWTinnvuoauraxpHcfWee+45li5disViITs7m3vvvZfGxsa0NrfyNfjHf/xH5s2bh9VqxWq1snLlSt58883U8Vt57ON57rnnUCgUPPPMM6nnbuVr8Oyzz6JQKNIeubm5qePTOvZJFcoSrps333xT3r59u/z222/LLS0t8h//+Ec5Oztb/s53vpNqc77e2caNG+VDhw7J77zzjuxyudLqnXm9XjknJ0d+5JFH5IaGBvnFF1+ULRaL/NOf/vRGDGtS/uf//J/y3/7t38rf/va3ZZvNNub4rT7+z3rhhRdkjUYj//M//7N88uRJ+emnn5ZNJpPc3t5+o7t2Td544w35+9//vvziiy/KgPyHP/wh7fiPf/xj2WKxyC+++KLc0NAgP/zww3JeXp7s8/lSbZ588kk5Pz9ffuedd+RDhw7JGzdulOfPny8nEolpHs3kbdu2TX7++efl48ePy0eOHJHvuusuuaioSA4EAqk2t/I1eOWVV+TXX39dbmxslBsbG+W/+qu/kjUajXz8+HFZlm/tsX/W/v375ZKSEnnevHny008/nXr+Vr4GP/jBD+Q5c+bIvb29qUd/f3/q+HSOXQRAN7H//b//t1xaWpr6+o033pCVSqXc3d2deu43v/mNrNPpZK/XK8uyLP/iF7+QbTabHIlEUm2ee+452eVyyZIkTV/nr8Hzzz8/bgA0W8Z/3rJly+Qnn3wy7bmamhr5v//3/36DejT1PhsASZIk5+bmyj/+8Y9Tz0UiEdlms8n/9E//JMuyLI+MjMgajUZ+4YUXUm26u7tlpVIpv/XWW9PW96nS398vA/KHH34oy/LsvAYOh0P+l3/5l1k1dr/fL1dWVsrvvPOOvH79+lQAdKtfgx/84Afy/Pnzxz023WMXU2A3Ma/XS0ZGRurrPXv2UF9fn1bobdu2bUSjUQ4ePJhqs379+rTEUdu2baOnp4e2trZp6/v1MJvGH4vFOHjwIFu3bk17fuvWrezevfsG9er6O3v2LG63O23cOp2O9evXp8Z98OBB4vF4WhuXy0V9ff2MvDZerxcg9W99Nl2DZDLJCy+8QDAYZOXKlbNq7H/xF3/BXXfdxZYtW9Kenw3XoKmpCZfLRWlpKY888gitra3A9I9dBEA3qZaWFn7+85/z5JNPpp5zu93k5OSktXM4HGi1Wtxu9yXbnP/6fJuZajaNf3BwkGQyOe5YZtI4Juv82C43brfbjVarxeFwXLLNTCHLMt/+9rdZs2YN9fX1wOy4Bg0NDZjNZnQ6HU8++SR/+MMfqKurmxVjB3jhhRc4dOgQzz333Jhjt/o1WL58Of/2b//G22+/zT//8z/jdrtZtWoVQ0ND0z52EQBdZ+Mt+Prs49NPP017TU9PD7fffjsPPfQQX/va19KOKRSKMe8hy3La859tI59bADzea6+3qxn/5cy08V+r8cYyE8cxWVcz7pl4bZ566imOHTvGb37zmzHHbuVrUF1dzZEjR9i7dy9//ud/zhNPPMHJkydTx2/lsXd2dvL000/zH//xH+j1+ku2u1WvwR133MEDDzzA3Llz2bJlC6+//joAv/rVr1Jtpmvs6km1Fibtqaee4pFHHrlsm5KSktR/9/T0sHHjRlauXMn/+3//L61dbm4u+/btS3tueHiYeDyeiphzc3PHRMH9/f3A2Kh6Okx2/JczE8d/tZxOJyqVatyxzKRxTNb53SBut5u8vLzU8xePOzc3l1gsxvDwcNpfgf39/axatWp6O3wNvvnNb/LKK6+wa9cuCgoKUs/Phmug1WqpqKgAYMmSJRw4cIC///u/57/9t/8G3NpjP3jwIP39/SxevDj1XDKZZNeuXfzf//t/UzsCb+VrcDGTycTcuXNpamri3nvvBaZv7OIO0HXmdDqpqam57OP8XwHd3d1s2LCBRYsW8fzzz6NUpn97Vq5cyfHjx+nt7U09t2PHDnQ6Xeof08qVK9m1a1fa1vAdO3bgcrkmHGhMpcmM/0pm4vivllarZfHixbzzzjtpz7/zzjsz7hfcZJSWlpKbm5s27lgsxocffpga9+LFi9FoNGltent7OX78+Iy4NrIs89RTT/HSSy+xc+dOSktL047PhmvwWbIsE41GZ8XYN2/eTENDA0eOHEk9lixZwmOPPcaRI0coKyu75a/BxaLRKKdOnSIvL2/6v/+TWjItXDfd3d1yRUWFvGnTJrmrqytti+B557eBb968WT506JD87rvvygUFBWnbwEdGRuScnBz5i1/8otzQ0CC/9NJLstVqnRHbwNvb2+XDhw/Lf/3Xfy2bzWb58OHD8uHDh2W/3y/L8q0//s86vw3+l7/8pXzy5En5mWeekU0mk9zW1naju3ZN/H5/6nsLyH/7t38rHz58OLW9/8c//rFss9nkl156SW5oaJC/+MUvjrsNtqCgQH733XflQ4cOyZs2bZoRW4BlWZb//M//XLbZbPIHH3yQ9u88FAql2tzK1+B73/uevGvXLvns2bPysWPH5L/6q7+SlUqlvGPHDlmWb+2xX8rFu8Bk+da+Bt/5znfkDz74QG5tbZX37t0rf+5zn5MtFkvq99p0jl0EQDeJ559/XgbGfVysvb1dvuuuu2SDwSBnZGTITz31VNqWb1mW5WPHjslr166VdTqdnJubKz/77LMzYgv4E088Me7433///VSbW3n84/mHf/gHubi4WNZqtfKiRYtSW6Vnsvfff3/c7/MTTzwhy/LoVtgf/OAHcm5urqzT6eR169bJDQ0NaecIh8PyU089JWdkZMgGg0H+3Oc+J3d0dNyA0Uzepf6dP//886k2t/I1+MpXvpL6mc7KypI3b96cCn5k+dYe+6V8NgC6la/B+bw+Go1Gdrlc8v333y+fOHEidXw6x66Q5RmaIlcQBEEQBOEqiTVAgiAIgiDMOiIAEgRBEARh1hEBkCAIgiAIs44IgARBEARBmHVEACQIgiAIwqwjAiBBEARBEGYdEQAJgiAIgjDriABIEARBEIRZRwRAgiDc1LZv345CoUChUKDRaCgrK+O73/0uwWAwrd2LL77Ihg0bsNlsmM1m5s2bx9/8zd/g8XjS2oXDYRwOBxkZGYTD4Su+/4kTJ3jggQcoKSlBoVDwd3/3d1M5PEEQbhARAAmCcNO7/fbb6e3tpbW1lR/+8If84he/4Lvf/W7q+Pe//30efvhhli5dyptvvsnx48f52c9+xtGjR/n3f//3tHO9+OKL1NfXU1dXx0svvXTF9w6FQpSVlfHjH/84ValdEISZT5TCEAThprZ9+3ZGRkZ4+eWXU899/etf57XXXqO3t5f9+/ezfPly/u7v/o6nn356zOtHRkaw2+2przdu3MgjjzyCLMv87ne/Y+fOnRPuS0lJCc888wzPPPPMNYxIEISbgfpGd0AQBGGyDAYD8XgcgF//+teYzWa+8Y1vjNv24uCnpaWFPXv28NJLLyHLMs888wytra2UlZVNR7cFQbiJiCkwQRBmlP379/Of//mfbN68GYCmpibKysrQaDRXfO2//uu/cscdd6TWAN1+++3867/+6/XusiAINyERAAmCcNN77bXXMJvN6PV6Vq5cybp16/j5z38OgCzLKBSKK54jmUzyq1/9iscffzz13OOPP86vfvUrksnkdeu7IAg3JzEFJgjCTW/jxo384z/+IxqNBpfLlXa3p6qqio8//ph4PH7Zu0Bvv/023d3dPPzww2nPJ5NJduzYwR133HHd+i8Iws1H3AESBOGmZzKZqKiooLi4eEyQ8+ijjxIIBPjFL34x7mtHRkYA+OUvf8kjjzzCkSNH0h6PPfYYv/zlL6/3EARBuMmIO0CCIMxoy5cv5y//8i/5zne+Q3d3N/fddx8ul4vm5mb+6Z/+iTVr1vDoo4/y6quv8sorr1BfX5/2+ieeeIK77rqLgYEBsrKyxpw/Fotx8uTJ1H93d3dz5MgRzGYzFRUV0zJGQRCmntgGLwjCTW28bfDj+d3vfsc//MM/cPjwYSRJory8nAcffJBvfvOb/PKXv+SHP/wh/f39Y+4gJRIJcnJy+P73v8+3v/3tMedta2ujtLR0zPPr16/ngw8+uJahCYJwA4kASBAEQRCEWUesARIEQRAEYdYRAZAgCIIgCLOOCIAEQRAEQZh1RAAkCIIgCMKsIwIgQRAEQRBmHREACYIgCIIw64gASBAEQRCEWUcEQIIgCIIgzDoiABIEQRAEYdYRAZAgCIIgCLOOCIAEQRAEQZh1RAAkCIIgCMKs8/8H9BaWTX5Op/YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a grid of points to plot the decision boundary\n",
    "X = pca.transform(df.loc[:, mask])\n",
    "y = df['PCR']\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary and the training points\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu_r, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu_r, alpha=0.5, s=2)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('Decision boundary of an SVM classifier with an RBF kernel')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6d67b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "K = 5\n",
    "kfold = StratifiedKFold(n_splits=K, shuffle=True, random_state=0) #fix the divisions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "39b0543d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_id_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trees_set \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(cluster_id_test)\n\u001b[1;32m      2\u001b[0m trees_label \u001b[39m=\u001b[39m {tree: label \u001b[39mfor\u001b[39;00m tree, label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(cluster_id_test, y_test)}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_id_test' is not defined"
     ]
    }
   ],
   "source": [
    "trees_set = set(cluster_id_test)\n",
    "trees_label = {tree: label for tree, label in zip(cluster_id_test, y_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c57fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of trees and labels\n",
    "trees = list(trees_set)\n",
    "labels = [trees_label[tree] for tree in trees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd810072",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kfold = StratifiedKFold(n_splits=K, shuffle=True, random_state=0) #fix the divisions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7291556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  7  9 10 11 12 13 14 15 16 17 19 20 21 22 23 24 25 26\n",
      " 27 28 29 31 33 34 36 37 38 39 41 42 44 45 46 47 48 49 50 52 54 55 56 58\n",
      " 59 62] [ 4  8 18 30 32 35 40 43 51 53 57 60 61]\n"
     ]
    }
   ],
   "source": [
    "for train, validate in kfold.split(trees, labels):\n",
    "    print(train, validate)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d155286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = np.isin(cluster_id_test, np.array(trees)[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcabef59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06095947, -1.52389024, -1.55644798, ...,  2.13646192,\n",
       "         1.6776804 , -1.65720489],\n",
       "       [ 0.52034057,  0.09743728, -0.02021897, ...,  0.17571513,\n",
       "         0.15807483, -0.07834646],\n",
       "       [-0.27030945, -0.55881433, -0.6272772 , ..., -0.25173985,\n",
       "        -0.43248375, -0.2752477 ],\n",
       "       ...,\n",
       "       [ 0.35485568,  0.15534184,  0.09128153, ..., -0.2648523 ,\n",
       "        -0.25460927, -0.23597692],\n",
       "       [ 1.55002432,  1.23622685,  1.56556582, ..., -0.95765505,\n",
       "        -0.45231523,  0.58883662],\n",
       "       [ 0.66743825,  0.71508586,  0.3390604 , ..., -0.76252772,\n",
       "        -1.21279918,  0.23349832]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c2225d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  target\n",
      "0         0        50       0\n",
      "1         1       487       1\n",
      "2         0        70       0\n",
      "3         0       479       1\n",
      "4         0        47       0\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random dataset with 1000 rows and 2 features\n",
    "feature1 = np.random.randint(low=0, high=2, size=10000)\n",
    "feature2 = np.random.randint(low=0, high=500, size=10000)\n",
    "\n",
    "# Generate random binary target variable\n",
    "# all rows with same feature2 value will have the same target value\n",
    "target = np.where(feature2 > 250, 1, 0)\n",
    "\n",
    "# Combine features and target into a pandas DataFrame\n",
    "df = pd.DataFrame({'feature1': feature1, 'feature2': feature2, 'target': target})\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3e3392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby feature_2 and train test split on each group\n",
    "def groupby_split(df, feature_1, feature_2, test_size):\n",
    "    # Given df and feature_2, groupby feature_2 and split each group into train and test sets\n",
    "    # feature_1 is the feature to stratify the split\n",
    "    # test_size is the size of the test set\n",
    "    # Return a list of tuples (train, test) where train and test are dataframes\n",
    "    \n",
    "    # Create new dataframe with the first row for each unique value of feature_2\n",
    "    df_new = df.groupby(feature_2).first().reset_index()\n",
    "    # Stratify the split on feature_1\n",
    "    train, test = train_test_split(df_new, test_size=test_size, stratify=df_new[feature_1])\n",
    "    # From the original dataframe, select the rows that have the same values of feature_2 as the train and test dataframes\n",
    "    train_df = df[df[feature_2].isin(train[feature_2])]\n",
    "    test_df = df[df[feature_2].isin(test[feature_2])]\n",
    "    # Return a list of tuples (train, test) where train and test are dataframes\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9039cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = groupby_split(df, 'target', 'feature2', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbe76485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  8015\n",
      "Test set size:  1985\n",
      "Original dataset proportions:  {0: 0.5013, 1: 0.4987}\n",
      "Training set proportions:  {0: 0.5010605115408608, 1: 0.4989394884591391}\n",
      "Test set proportions:  {0: 0.5022670025188917, 1: 0.49773299748110833}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "feature = 'feature1'\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print('Training set size: ', len(train_df))\n",
    "print('Test set size: ', len(test_df))\n",
    "\n",
    "# Ensure that the proportion of samples in each set is the same as the original dataset\n",
    "# Print the proportion samples in each set by dividing the counter by the total number of samples\n",
    "print('Original dataset proportions: ', get_class_proportions(df, feature))\n",
    "print('Training set proportions: ', get_class_proportions(train_df, feature) )\n",
    "print('Test set proportions: ', get_class_proportions(test_df, feature) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26adf8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2  target\n",
       "2            0        70       0\n",
       "6            0       261       1\n",
       "7            0        83       0\n",
       "10           0       106       0\n",
       "12           0       303       1\n",
       "...        ...       ...     ...\n",
       "9964         0        96       0\n",
       "9973         1       209       0\n",
       "9977         1       327       1\n",
       "9982         1       181       0\n",
       "9993         1        45       0\n",
       "\n",
       "[1985 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e581c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that, given a counter, returns the proportion of each class\n",
    "def get_class_proportions(df, feature):\n",
    "    counter = Counter(df[feature])\n",
    "    total = sum(counter.values())\n",
    "    new_dict = {cl: count / total for cl, count in counter.items()}\n",
    "    # Sort the dictionary by key\n",
    "    new_dict = {k: new_dict[k] for k in sorted(new_dict)}\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9307840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the features you want to use for stratification\n",
    "stratify_cols = ['feature1', 'target']\n",
    "\n",
    "# Split the dataset into a training set and a test set, stratifying based on the specified features\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[stratify_cols], random_state=42)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "feature = 'feature2'\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print('Training set size: ', len(train_df))\n",
    "print('Test set size: ', len(test_df))\n",
    "\n",
    "# Ensure that the proportion of samples in each set is the same as the original dataset\n",
    "# Print the proportion samples in each set by dividing the counter by the total number of samples\n",
    "print('Original dataset proportions: ', get_class_proportions(df, feature))\n",
    "print('Training set proportions: ', get_class_proportions(train_df, feature) )\n",
    "print('Test set proportions: ', get_class_proportions(test_df, feature) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1155ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  80\n",
      "Test set size:  20\n",
      "Original dataset proportions:  {0: 0.56, 1: 0.44}\n",
      "Training set proportions:  {0: 0.5375, 1: 0.4625}\n",
      "Test set proportions:  {0: 0.65, 1: 0.35}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9369127a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:44:15.740330Z",
     "start_time": "2022-08-15T16:44:15.736699Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create dir to save figures\n",
    "classification_path = 'Classification figures'\n",
    "os.makedirs(classification_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99207867",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089cdb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:44:19.009056Z",
     "start_time": "2022-08-15T16:44:16.591080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>RE</th>\n",
       "      <th>N</th>\n",
       "      <th>N2</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>NPQI_4</th>\n",
       "      <th>NPQI_5</th>\n",
       "      <th>CLR</th>\n",
       "      <th>CLG</th>\n",
       "      <th>BNDVI</th>\n",
       "      <th>CTR1</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>Lats</th>\n",
       "      <th>Longs</th>\n",
       "      <th>PCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66182</th>\n",
       "      <td>89.024270</td>\n",
       "      <td>82.382104</td>\n",
       "      <td>72.421320</td>\n",
       "      <td>72.491339</td>\n",
       "      <td>60.264723</td>\n",
       "      <td>70.815202</td>\n",
       "      <td>76.478698</td>\n",
       "      <td>46.799628</td>\n",
       "      <td>0.118572</td>\n",
       "      <td>-0.125766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067519</td>\n",
       "      <td>0.077052</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.037161</td>\n",
       "      <td>0.676947</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66183</th>\n",
       "      <td>119.044081</td>\n",
       "      <td>106.998271</td>\n",
       "      <td>92.017678</td>\n",
       "      <td>94.714961</td>\n",
       "      <td>74.777452</td>\n",
       "      <td>95.569189</td>\n",
       "      <td>103.451830</td>\n",
       "      <td>65.193512</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>-0.068471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092949</td>\n",
       "      <td>0.106111</td>\n",
       "      <td>0.082481</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>-0.016852</td>\n",
       "      <td>0.628149</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583515</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66184</th>\n",
       "      <td>143.888064</td>\n",
       "      <td>126.691204</td>\n",
       "      <td>106.714946</td>\n",
       "      <td>112.529134</td>\n",
       "      <td>85.846483</td>\n",
       "      <td>116.719747</td>\n",
       "      <td>126.477675</td>\n",
       "      <td>82.306809</td>\n",
       "      <td>0.191364</td>\n",
       "      <td>-0.021050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.126643</td>\n",
       "      <td>0.083601</td>\n",
       "      <td>0.185192</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.596620</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66185</th>\n",
       "      <td>156.655110</td>\n",
       "      <td>138.835180</td>\n",
       "      <td>116.939132</td>\n",
       "      <td>124.875591</td>\n",
       "      <td>95.931600</td>\n",
       "      <td>128.783398</td>\n",
       "      <td>139.964241</td>\n",
       "      <td>92.551503</td>\n",
       "      <td>0.186661</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105269</td>\n",
       "      <td>0.120206</td>\n",
       "      <td>0.086819</td>\n",
       "      <td>0.196898</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.612375</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583526</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66186</th>\n",
       "      <td>160.450719</td>\n",
       "      <td>148.025216</td>\n",
       "      <td>129.719365</td>\n",
       "      <td>135.987402</td>\n",
       "      <td>112.166178</td>\n",
       "      <td>134.893560</td>\n",
       "      <td>146.378584</td>\n",
       "      <td>96.044013</td>\n",
       "      <td>0.132327</td>\n",
       "      <td>-0.077432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070320</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.085141</td>\n",
       "      <td>0.128425</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>0.699069</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583532</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778154</th>\n",
       "      <td>99.375929</td>\n",
       "      <td>95.838942</td>\n",
       "      <td>82.858511</td>\n",
       "      <td>66.847244</td>\n",
       "      <td>71.825711</td>\n",
       "      <td>79.745438</td>\n",
       "      <td>98.517721</td>\n",
       "      <td>67.638269</td>\n",
       "      <td>0.156695</td>\n",
       "      <td>-0.030025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>0.235403</td>\n",
       "      <td>0.188987</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>0.722768</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778155</th>\n",
       "      <td>98.340763</td>\n",
       "      <td>97.480020</td>\n",
       "      <td>85.414557</td>\n",
       "      <td>71.962205</td>\n",
       "      <td>77.483215</td>\n",
       "      <td>78.022059</td>\n",
       "      <td>94.899374</td>\n",
       "      <td>63.680091</td>\n",
       "      <td>0.101032</td>\n",
       "      <td>-0.097781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.216315</td>\n",
       "      <td>0.111044</td>\n",
       "      <td>-0.013414</td>\n",
       "      <td>0.787905</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778156</th>\n",
       "      <td>92.474823</td>\n",
       "      <td>92.885002</td>\n",
       "      <td>82.219499</td>\n",
       "      <td>71.785827</td>\n",
       "      <td>76.745280</td>\n",
       "      <td>73.008593</td>\n",
       "      <td>87.827150</td>\n",
       "      <td>57.742825</td>\n",
       "      <td>0.067337</td>\n",
       "      <td>-0.141295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003857</td>\n",
       "      <td>-0.004402</td>\n",
       "      <td>0.202970</td>\n",
       "      <td>0.068203</td>\n",
       "      <td>-0.027988</td>\n",
       "      <td>0.829905</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779120</th>\n",
       "      <td>95.580320</td>\n",
       "      <td>91.900356</td>\n",
       "      <td>79.237445</td>\n",
       "      <td>61.379528</td>\n",
       "      <td>69.857883</td>\n",
       "      <td>75.358655</td>\n",
       "      <td>88.649502</td>\n",
       "      <td>64.727844</td>\n",
       "      <td>0.118554</td>\n",
       "      <td>-0.038117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>0.176368</td>\n",
       "      <td>0.118783</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>0.730881</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614764</td>\n",
       "      <td>2.585013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779121</th>\n",
       "      <td>108.002312</td>\n",
       "      <td>107.326487</td>\n",
       "      <td>93.508705</td>\n",
       "      <td>74.255118</td>\n",
       "      <td>85.600505</td>\n",
       "      <td>83.975549</td>\n",
       "      <td>97.859840</td>\n",
       "      <td>70.315859</td>\n",
       "      <td>0.066823</td>\n",
       "      <td>-0.098031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.165337</td>\n",
       "      <td>0.046532</td>\n",
       "      <td>-0.046137</td>\n",
       "      <td>0.792580</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614764</td>\n",
       "      <td>2.585019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40332 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C           B           G           Y           R  \\\n",
       "66182    89.024270   82.382104   72.421320   72.491339   60.264723   \n",
       "66183   119.044081  106.998271   92.017678   94.714961   74.777452   \n",
       "66184   143.888064  126.691204  106.714946  112.529134   85.846483   \n",
       "66185   156.655110  138.835180  116.939132  124.875591   95.931600   \n",
       "66186   160.450719  148.025216  129.719365  135.987402  112.166178   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "778154   99.375929   95.838942   82.858511   66.847244   71.825711   \n",
       "778155   98.340763   97.480020   85.414557   71.962205   77.483215   \n",
       "778156   92.474823   92.885002   82.219499   71.785827   76.745280   \n",
       "779120   95.580320   91.900356   79.237445   61.379528   69.857883   \n",
       "779121  108.002312  107.326487   93.508705   74.255118   85.600505   \n",
       "\n",
       "                RE           N         N2    NDVI_1    NDVI_2  ...    NPQI_4  \\\n",
       "66182    70.815202   76.478698  46.799628  0.118572 -0.125766  ...  0.067519   \n",
       "66183    95.569189  103.451830  65.193512  0.160885 -0.068471  ...  0.092949   \n",
       "66184   116.719747  126.477675  82.306809  0.191364 -0.021050  ...  0.110915   \n",
       "66185   128.783398  139.964241  92.551503  0.186661 -0.017933  ...  0.105269   \n",
       "66186   134.893560  146.378584  96.044013  0.132327 -0.077432  ...  0.070320   \n",
       "...            ...         ...        ...       ...       ...  ...       ...   \n",
       "778154   79.745438   98.517721  67.638269  0.156695 -0.030025  ...  0.031586   \n",
       "778155   78.022059   94.899374  63.680091  0.101032 -0.097781  ...  0.007663   \n",
       "778156   73.008593   87.827150  57.742825  0.067337 -0.141295  ... -0.003857   \n",
       "779120   75.358655   88.649502  64.727844  0.118554 -0.038117  ...  0.034213   \n",
       "779121   83.975549   97.859840  70.315859  0.066823 -0.098031  ...  0.005473   \n",
       "\n",
       "          NPQI_5       CLR       CLG     BNDVI      CTR1  cluster_id  \\\n",
       "66182   0.077052  0.079976  0.056025 -0.037161  0.676947         285   \n",
       "66183   0.106111  0.082481  0.124260 -0.016852  0.628149         285   \n",
       "66184   0.126643  0.083601  0.185192 -0.000843  0.596620         285   \n",
       "66185   0.120206  0.086819  0.196898  0.004050  0.612375         285   \n",
       "66186   0.080300  0.085141  0.128425 -0.005593  0.699069         285   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "778154  0.036052  0.235403  0.188987  0.013783  0.722768        2685   \n",
       "778155  0.008746  0.216315  0.111044 -0.013414  0.787905        2685   \n",
       "778156 -0.004402  0.202970  0.068203 -0.027988  0.829905        2685   \n",
       "779120  0.039049  0.176368  0.118783 -0.018005  0.730881        2685   \n",
       "779121  0.006248  0.165337  0.046532 -0.046137  0.792580        2685   \n",
       "\n",
       "             Lats     Longs  PCR  \n",
       "66182   39.618106  2.583509  1.0  \n",
       "66183   39.618106  2.583515  1.0  \n",
       "66184   39.618106  2.583520  1.0  \n",
       "66185   39.618106  2.583526  1.0  \n",
       "66186   39.618106  2.583532  1.0  \n",
       "...           ...       ...  ...  \n",
       "778154  39.614768  2.585019  0.0  \n",
       "778155  39.614768  2.585025  0.0  \n",
       "778156  39.614768  2.585031  0.0  \n",
       "779120  39.614764  2.585013  0.0  \n",
       "779121  39.614764  2.585019  0.0  \n",
       "\n",
       "[40332 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = file_management.load_lzma('Processed Data/QPCR_labelled_df.lzma')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dbb77",
   "metadata": {},
   "source": [
    "## Save real data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55e5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "n_test = int(len(df)*0.05) # 5% of tree pixels for testing\n",
    "n_train = len(df) - n_test\n",
    "test_df = df.iloc[:n_test]\n",
    "train_df = df.iloc[n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0dfec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fd5357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:44:29.270934Z",
     "start_time": "2022-08-15T16:44:29.222782Z"
    }
   },
   "outputs": [],
   "source": [
    "#Data preprocessing: Normalization of spectral bands\n",
    "# spectral_bands = ['C', 'B', 'G', 'Y', 'R', 'RE', 'N', 'N2']\n",
    "# X_train = train_df.loc[:, spectral_bands] # only spectral bands\n",
    "X_train = train_df.iloc[:, :-4] # spectral bands + indices\n",
    "#X_train = train_df.iloc[:, 8:-4] # indices\n",
    "X_test = test_df.iloc[:, :-4] \n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "Y_train = train_df['PCR'].values\n",
    "Y_test = test_df['PCR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0481dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 28731, 1.0: 9585})\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train.shape[1]\n",
    "\n",
    "print(Counter(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfb35c",
   "metadata": {},
   "source": [
    "## SVC with penalization for the minority class"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e796a7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T16:51:16.777445Z",
     "start_time": "2022-08-10T16:15:18.567555Z"
    }
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# we can add class_weight='balanced' to add panalize mistake\n",
    "svc_model = SVC(class_weight='balanced', probability=True)\n",
    "svc_model.fit(X, Y)\n",
    "svc_predict = svc_model.predict(X)# check performance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e59ce2fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T16:51:16.874860Z",
     "start_time": "2022-08-10T16:51:16.781267Z"
    }
   },
   "source": [
    "cm=confusion_matrix(Y, svc_predict)\n",
    "print(cm)\n",
    "\n",
    "print('Accuracy score:',accuracy_score(Y, svc_predict))\n",
    "print('F1 score:',f1_score(Y, svc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b72e2",
   "metadata": {},
   "source": [
    "## Balance the dataset using oversampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a302aeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T17:48:35.931999Z",
     "start_time": "2022-08-11T17:48:35.660277Z"
    }
   },
   "outputs": [],
   "source": [
    "#random.seed(42)\n",
    "#\n",
    "#c = list(zip(X_train, Y_train))\n",
    "#random.shuffle(c)\n",
    "#X_train, Y_train = zip(*c)\n",
    "#X_train = np.array(X_train)\n",
    "#Y_train = np.array(Y_train)\n",
    "\n",
    "file_management.save_lzma(X_train, 'X_train.lzma', '')\n",
    "file_management.save_lzma(Y_train, 'Y_train.lzma', '')\n",
    "file_management.save_lzma(X_test, 'X_test.lzma', '')\n",
    "file_management.save_lzma(Y_test, 'Y_test.lzma', '')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "233fd26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T12:57:30.919773Z",
     "start_time": "2022-08-11T12:57:30.816545Z"
    }
   },
   "source": [
    "X.shape\n",
    "pca = PCA(n_components=8)\n",
    "X1 = pca.fit_transform(X)\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d86d93",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8d5ae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:51:42.935613Z",
     "start_time": "2022-08-11T21:51:35.428857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgalvan/.conda/envs/xylella_tf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b8b57e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:52:10.060042Z",
     "start_time": "2022-08-11T21:52:10.052063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15833, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X[5000:, :]\n",
    "Y1 = Y[5000:]\n",
    "\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c416870d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-12T10:21:42.217903Z",
     "start_time": "2022-08-12T10:21:39.275627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import plotly.express as px # for data visualization\n",
    "import matplotlib.pyplot as plt # for showing handwritten digits\n",
    "\n",
    "def chart(X, y):\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # This section is not mandatory as its purpose is to sort the data by label \n",
    "    # so, we can maintain consistent colors for digits across multiple graphs\n",
    "    \n",
    "    # Concatenate X and y arrays\n",
    "    arr_concat=np.concatenate((X, y.reshape(y.shape[0],1)), axis=1)\n",
    "    # Create a Pandas dataframe using the above array\n",
    "    df=pd.DataFrame(arr_concat, columns=['x', 'y', 'z', 'label'])\n",
    "    # Convert label data type from float to integer\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    # Finally, sort the dataframe by label\n",
    "    df.sort_values(by='label', axis=0, ascending=True, inplace=True)\n",
    "    #--------------------------------------------------------------------------#\n",
    "    \n",
    "    # Create a 3D graph\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z', color=df['label'].astype(str), height=900, width=950)\n",
    "\n",
    "    # Update chart looks\n",
    "    fig.update_layout(title_text='UMAP',\n",
    "                      showlegend=True,\n",
    "                      legend=dict(orientation=\"h\", yanchor=\"top\", y=0, xanchor=\"center\", x=0.5),\n",
    "                      scene_camera=dict(up=dict(x=0, y=0, z=1), \n",
    "                                            center=dict(x=0, y=0, z=-0.1),\n",
    "                                            eye=dict(x=1.5, y=-1.4, z=0.5)),\n",
    "                                            margin=dict(l=0, r=0, b=0, t=0),\n",
    "                      scene = dict(xaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='#f0f0f0',\n",
    "                                              title_font=dict(size=10),\n",
    "                                              tickfont=dict(size=10),\n",
    "                                             ),\n",
    "                                   yaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='#f0f0f0',\n",
    "                                              title_font=dict(size=10),\n",
    "                                              tickfont=dict(size=10),\n",
    "                                              ),\n",
    "                                   zaxis=dict(backgroundcolor='lightgrey',\n",
    "                                              color='black', \n",
    "                                              gridcolor='#f0f0f0',\n",
    "                                              title_font=dict(size=10),\n",
    "                                              tickfont=dict(size=10),\n",
    "                                             )))\n",
    "    # Update marker size\n",
    "    fig.update_traces(marker=dict(size=3, line=dict(color='black', width=0.1)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba2530ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:27:19.863963Z",
     "start_time": "2022-08-11T22:24:57.113480Z"
    }
   },
   "source": [
    "reducer = UMAP(n_neighbors=5, # default 15, The size of local neighborhood (in terms of number of neighboring sample points) used for manifold approximation.\n",
    "               n_components=3, # default 2, The dimension of the space to embed into.\n",
    "               metric='euclidean', # default 'euclidean', The metric to use to compute distances in high dimensional space.\n",
    "               n_epochs=1000, # default None, The number of training epochs to be used in optimizing the low dimensional embedding. Larger values result in more accurate embeddings. \n",
    "               learning_rate=1.0, # default 1.0, The initial learning rate for the embedding optimization.\n",
    "               init='spectral', # default 'spectral', How to initialize the low dimensional embedding. Options are: {'spectral', 'random', A numpy array of initial embedding positions}.\n",
    "               min_dist=0.1, # default 0.1, The effective minimum distance between embedded points.\n",
    "               spread=1.0, # default 1.0, The effective scale of embedded points. In combination with ``min_dist`` this determines how clustered/clumped the embedded points are.\n",
    "               low_memory=False, # default False, For some datasets the nearest neighbor computation can consume a lot of memory. If you find that UMAP is failing due to memory constraints consider setting this option to True.\n",
    "               set_op_mix_ratio=1.0, # default 1.0, The value of this parameter should be between 0.0 and 1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy intersection.\n",
    "               local_connectivity=1, # default 1, The local connectivity required -- i.e. the number of nearest neighbors that should be assumed to be connected at a local level.\n",
    "               repulsion_strength=1.0, # default 1.0, Weighting applied to negative samples in low dimensional embedding optimization.\n",
    "               negative_sample_rate=5, # default 5, Increasing this value will result in greater repulsive force being applied, greater optimization cost, but slightly more accuracy.\n",
    "               transform_queue_size=4.0, # default 4.0, Larger values will result in slower performance but more accurate nearest neighbor evaluation.\n",
    "               a=None, # default None, More specific parameters controlling the embedding. If None these values are set automatically as determined by ``min_dist`` and ``spread``.\n",
    "               b=None, # default None, More specific parameters controlling the embedding. If None these values are set automatically as determined by ``min_dist`` and ``spread``.\n",
    "               random_state=42, # default: None, If int, random_state is the seed used by the random number generator;\n",
    "               metric_kwds=None, # default None) Arguments to pass on to the metric, such as the ``p`` value for Minkowski distance.\n",
    "               angular_rp_forest=False, # default False, Whether to use an angular random projection forest to initialise the approximate nearest neighbor search.\n",
    "               target_n_neighbors=-1, # default -1, The number of nearest neighbors to use to construct the target simplcial set. If set to -1 use the ``n_neighbors`` value.\n",
    "               #target_metric='categorical', # default 'categorical', The metric used to measure distance for a target array is using supervised dimension reduction. By default this is 'categorical' which will measure distance in terms of whether categories match or are different. \n",
    "               #target_metric_kwds=None, # dict, default None, Keyword argument to pass to the target metric when performing supervised dimension reduction. If None then no arguments are passed on.\n",
    "               #target_weight=0.5, # default 0.5, weighting factor between data topology and target topology.\n",
    "               transform_seed=42, # default 42, Random seed used for the stochastic aspects of the transform operation.\n",
    "               verbose=False, # default False, Controls verbosity of logging.\n",
    "               unique=False, # default False, Controls if the rows of your data should be uniqued before being embedded. \n",
    "              )\n",
    "\n",
    "# Fit and transform the data\n",
    "X3 = reducer.fit_transform(X)\n",
    "X_trans = reducer.transform(X1)\n",
    "#X_trans = reducer.fit_transform(X1, Y1)\n",
    "\n",
    "# Check the shape of the new data\n",
    "print('Shape of X_trans: ', X_trans.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1ae8195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:27:20.426937Z",
     "start_time": "2022-08-11T22:27:19.867963Z"
    },
    "scrolled": true
   },
   "source": [
    "chart(X_trans, Y1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a8ddeee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:30.302793Z",
     "start_time": "2022-08-11T16:21:48.617930Z"
    }
   },
   "source": [
    "X2 = X[:5000, :]\n",
    "Y2 = Y[:5000]\n",
    "\n",
    "X_test = reducer.transform(X2)\n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "\n",
    "chart(X_test, Y2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75cf2a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:30.620338Z",
     "start_time": "2022-08-11T16:22:30.307172Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# KNN\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier().fit(X_trans, Y1)\n",
    "\n",
    "y_pred = np.round(knn.predict(X_test))\n",
    "\n",
    "print(confusion_matrix(Y2,y_pred))\n",
    "#### OJO CON COMO DEFINE LA MATRIZ DE CONFUSION PYTHON ####\n",
    "accuracy = accuracy_score(Y2, y_pred)\n",
    "recall = recall_score(Y2, y_pred)\n",
    "precision = precision_score(Y2, y_pred)\n",
    "f1score = f1_score(Y2, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5131de57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:30.903697Z",
     "start_time": "2022-08-11T16:22:30.623121Z"
    }
   },
   "source": [
    "chart(X_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64af5d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:31.182586Z",
     "start_time": "2022-08-11T16:22:30.906453Z"
    }
   },
   "source": [
    "chart(X_test, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12489a",
   "metadata": {},
   "source": [
    "## Explore the differences between the two classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e420cb41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T12:57:41.872253Z",
     "start_time": "2022-08-11T12:57:41.486817Z"
    }
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents2 = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "512a770d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T12:57:44.420999Z",
     "start_time": "2022-08-11T12:57:41.942991Z"
    }
   },
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "for label in [0, 1]:\n",
    "    ax.scatter(principalComponents2[Y==label, 0], principalComponents2[Y==label, 1], s = 2, alpha=0.2, label=label)\n",
    "# ax.scatter(principalComponents2[original_labels==0, 0], principalComponents2[original_labels==0, 1], s = 2, c='k', alpha=0.5, label='Joan trees')\n",
    "ax.legend()\n",
    "path = 'Classification figures'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "plt.savefig(os.path.join(path, 'positive_vs_negative_smote.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005683a3",
   "metadata": {},
   "source": [
    "## Train a simple neural network usign 7-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac06948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T17:48:34.091925Z",
     "start_time": "2022-08-11T17:48:33.491774Z"
    }
   },
   "outputs": [],
   "source": [
    "## Since there exist an unbalance in the dataset we perform some \n",
    "# over_sampling techniques (SMOTE)\n",
    "from imblearn.over_sampling import ADASYN, RandomOverSampler\n",
    "\n",
    "#ros = RandomOverSampler(random_state=42, ratio=1.0)\n",
    "#X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "# X_train, Y_train = adasyn.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee85d619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T18:29:35.336333Z",
     "start_time": "2022-08-11T18:29:35.323010Z"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANN: 1 pixel = 1 tree\n",
    "# =============================================================================\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 7\n",
    "#n_features = 27\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=0) #fix the divition\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "#Set the training parameters\n",
    "num_epochs = 15000\n",
    "verbosity = 1 #0:silent, 1:to show a progress bar during the training, 2:show results after each epoch\n",
    "\n",
    "#initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "\n",
    "# Define the model architecture\n",
    "def model():\n",
    "    classifier = Sequential()\n",
    "    # First layer\n",
    "    classifier.add(Dense(units = 128, input_dim = n_features, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "    # Second layer\n",
    "    classifier.add(Dense(units = 64, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "    #classifier.add(Dropout(rate = 0.2))\n",
    "    # Third layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "    #classifier.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    classifier.add(Dense(units = 8, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = initializer,  activation = \"sigmoid\"))\n",
    "\n",
    "    # Compilar la RNA\n",
    "    classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "# def model():\n",
    "#     classifier = Sequential()\n",
    "#     # First layer\n",
    "#     classifier.add(Dense(units = 1, input_dim = n_bands, kernel_initializer = \"uniform\",  activation = \"sigmoid\"))\n",
    "    \n",
    "#     # Compilar la RNA\n",
    "#     classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "#     return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce324db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:34:05.005748Z",
     "start_time": "2022-08-11T18:29:46.066951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:07:59.538688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /common/amd/aocl/2.1/amd-fftw/lib:/common/amd/aocl/2.1/libs:/opt/AMD/aocc-compiler-2.1.0/lib:/opt/AMD/aocc-compiler-2.1.0/lib32:/usr/lib/x86_64-linux-gnu:/usr/lib64:/usr/lib32:/usr/lib:/common/opt_intel/oneapi/vpl/2021.2.2/lib:/common/opt_intel/oneapi/tbb/2021.2.0/env/../lib/intel64/gcc4.8:/common/opt_intel/oneapi/mkl/latest/lib/intel64:/common/opt_intel/oneapi/itac/2021.2.0/slib:/common/opt_intel/oneapi/ipp/2021.2.0/lib/intel64:/common/opt_intel/oneapi/ippcp/2021.2.0/lib/intel64:/common/opt_intel/oneapi/ipp/2021.2.0/lib/intel64:/common/opt_intel/oneapi/dnnl/2021.2.0/cpu_dpcpp_gpu_dpcpp/lib:/common/opt_intel/oneapi/debugger/10.1.1/dep/lib:/common/opt_intel/oneapi/debugger/10.1.1/libipt/intel64/lib:/common/opt_intel/oneapi/debugger/10.1.1/gdb/intel64/lib:/common/opt_intel/oneapi/dal/2021.2.0/lib/intel64:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/x64:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/emu:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/oclfpga/host/linux64/lib:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/oclfpga/linux64/lib:/common/opt_intel/oneapi/compiler/2021.2.0/linux/compiler/lib/intel64_lin:/common/opt_intel/oneapi/compiler/2021.2.0/linux/compiler/lib:/common/opt_intel/oneapi/ccl/2021.2.0/lib/cpu_gpu_dpcpp:/common/amd/aocl/2.1/amd-fftw/lib:/common/amd/aocl/2.1/libs:/opt/AMD/aocc-compiler-2.1.0/lib:/opt/AMD/aocc-compiler-2.1.0/lib32:/usr/lib/x86_64-linux-gnu:/usr/lib64:/usr/lib32:/usr/lib::/common/MATLAB/MATLAB_Runtime/v910/runtime/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/bin/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/sys/os/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/extern/bin/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/runtime/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/bin/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/sys/os/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/extern/bin/glnxa64\n",
      "2023-03-06 19:07:59.538760: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-06 19:07:59.538827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (salmunia): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6933 - accuracy: 0.4789 - val_loss: 0.6910 - val_accuracy: 0.6293\n",
      "Epoch 2/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6928 - accuracy: 0.5157 - val_loss: 0.6900 - val_accuracy: 0.6213\n",
      "Epoch 3/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6924 - accuracy: 0.5319 - val_loss: 0.6867 - val_accuracy: 0.6944\n",
      "Epoch 4/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6922 - accuracy: 0.5211 - val_loss: 0.6831 - val_accuracy: 0.7280\n",
      "Epoch 5/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6920 - accuracy: 0.5091 - val_loss: 0.6803 - val_accuracy: 0.7340\n",
      "Epoch 6/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6918 - accuracy: 0.5061 - val_loss: 0.6791 - val_accuracy: 0.7256\n",
      "Epoch 7/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6915 - accuracy: 0.5097 - val_loss: 0.6790 - val_accuracy: 0.7119\n",
      "Epoch 8/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6913 - accuracy: 0.5164 - val_loss: 0.6797 - val_accuracy: 0.6810\n",
      "Epoch 9/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6910 - accuracy: 0.5256 - val_loss: 0.6803 - val_accuracy: 0.6474\n",
      "Epoch 10/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6908 - accuracy: 0.5340 - val_loss: 0.6803 - val_accuracy: 0.6240\n",
      "Epoch 11/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6905 - accuracy: 0.5366 - val_loss: 0.6796 - val_accuracy: 0.6195\n",
      "Epoch 12/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6903 - accuracy: 0.5384 - val_loss: 0.6782 - val_accuracy: 0.6255\n",
      "Epoch 13/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6900 - accuracy: 0.5393 - val_loss: 0.6769 - val_accuracy: 0.6281\n",
      "Epoch 14/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6898 - accuracy: 0.5385 - val_loss: 0.6761 - val_accuracy: 0.6222\n",
      "Epoch 15/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6895 - accuracy: 0.5385 - val_loss: 0.6759 - val_accuracy: 0.6085\n",
      "Epoch 16/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6893 - accuracy: 0.5421 - val_loss: 0.6760 - val_accuracy: 0.5955\n",
      "Epoch 17/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6890 - accuracy: 0.5443 - val_loss: 0.6759 - val_accuracy: 0.5820\n",
      "Epoch 18/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6887 - accuracy: 0.5446 - val_loss: 0.6752 - val_accuracy: 0.5791\n",
      "Epoch 19/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6885 - accuracy: 0.5447 - val_loss: 0.6742 - val_accuracy: 0.5798\n",
      "Epoch 20/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6882 - accuracy: 0.5435 - val_loss: 0.6733 - val_accuracy: 0.5780\n",
      "Epoch 21/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6879 - accuracy: 0.5433 - val_loss: 0.6733 - val_accuracy: 0.5670\n",
      "Epoch 22/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6876 - accuracy: 0.5445 - val_loss: 0.6739 - val_accuracy: 0.5528\n",
      "Epoch 23/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6873 - accuracy: 0.5466 - val_loss: 0.6736 - val_accuracy: 0.5477\n",
      "Epoch 24/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6871 - accuracy: 0.5469 - val_loss: 0.6725 - val_accuracy: 0.5493\n",
      "Epoch 25/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6868 - accuracy: 0.5469 - val_loss: 0.6719 - val_accuracy: 0.5462\n",
      "Epoch 26/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6865 - accuracy: 0.5474 - val_loss: 0.6720 - val_accuracy: 0.5406\n",
      "Epoch 27/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6862 - accuracy: 0.5489 - val_loss: 0.6725 - val_accuracy: 0.5300\n",
      "Epoch 28/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6859 - accuracy: 0.5493 - val_loss: 0.6722 - val_accuracy: 0.5269\n",
      "Epoch 29/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6857 - accuracy: 0.5494 - val_loss: 0.6713 - val_accuracy: 0.5303\n",
      "Epoch 30/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6854 - accuracy: 0.5496 - val_loss: 0.6714 - val_accuracy: 0.5263\n",
      "Epoch 31/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6851 - accuracy: 0.5503 - val_loss: 0.6725 - val_accuracy: 0.5183\n",
      "Epoch 32/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6848 - accuracy: 0.5532 - val_loss: 0.6728 - val_accuracy: 0.5174\n",
      "Epoch 33/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6845 - accuracy: 0.5546 - val_loss: 0.6722 - val_accuracy: 0.5183\n",
      "Epoch 34/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6842 - accuracy: 0.5549 - val_loss: 0.6728 - val_accuracy: 0.5139\n",
      "Epoch 35/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6839 - accuracy: 0.5546 - val_loss: 0.6735 - val_accuracy: 0.5097\n",
      "Epoch 36/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6836 - accuracy: 0.5551 - val_loss: 0.6726 - val_accuracy: 0.5119\n",
      "Epoch 37/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6833 - accuracy: 0.5553 - val_loss: 0.6731 - val_accuracy: 0.5066\n",
      "Epoch 38/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6831 - accuracy: 0.5554 - val_loss: 0.6746 - val_accuracy: 0.4998\n",
      "Epoch 39/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6828 - accuracy: 0.5555 - val_loss: 0.6734 - val_accuracy: 0.5035\n",
      "Epoch 40/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6825 - accuracy: 0.5564 - val_loss: 0.6745 - val_accuracy: 0.4980\n",
      "Epoch 41/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6823 - accuracy: 0.5557 - val_loss: 0.6754 - val_accuracy: 0.4962\n",
      "Epoch 42/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6821 - accuracy: 0.5556 - val_loss: 0.6743 - val_accuracy: 0.5004\n",
      "Epoch 43/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6819 - accuracy: 0.5557 - val_loss: 0.6781 - val_accuracy: 0.4868\n",
      "Epoch 44/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6817 - accuracy: 0.5563 - val_loss: 0.6740 - val_accuracy: 0.5037\n",
      "Epoch 45/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6815 - accuracy: 0.5561 - val_loss: 0.6815 - val_accuracy: 0.4720\n",
      "Epoch 46/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6814 - accuracy: 0.5551 - val_loss: 0.6754 - val_accuracy: 0.4998\n",
      "Epoch 47/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6812 - accuracy: 0.5569 - val_loss: 0.6795 - val_accuracy: 0.4848\n",
      "Epoch 48/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6811 - accuracy: 0.5561 - val_loss: 0.6814 - val_accuracy: 0.4797\n",
      "Epoch 49/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6810 - accuracy: 0.5562 - val_loss: 0.6776 - val_accuracy: 0.4947\n",
      "Epoch 50/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6809 - accuracy: 0.5567 - val_loss: 0.6849 - val_accuracy: 0.4697\n",
      "Epoch 51/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6808 - accuracy: 0.5552 - val_loss: 0.6790 - val_accuracy: 0.4903\n",
      "Epoch 52/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6807 - accuracy: 0.5572 - val_loss: 0.6829 - val_accuracy: 0.4795\n",
      "Epoch 53/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6805 - accuracy: 0.5559 - val_loss: 0.6835 - val_accuracy: 0.4784\n",
      "Epoch 54/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6805 - accuracy: 0.5563 - val_loss: 0.6801 - val_accuracy: 0.4896\n",
      "Epoch 55/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6804 - accuracy: 0.5576 - val_loss: 0.6863 - val_accuracy: 0.4713\n",
      "Epoch 56/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6803 - accuracy: 0.5559 - val_loss: 0.6800 - val_accuracy: 0.4914\n",
      "Epoch 57/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6802 - accuracy: 0.5582 - val_loss: 0.6848 - val_accuracy: 0.4763\n",
      "Epoch 58/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6801 - accuracy: 0.5571 - val_loss: 0.6828 - val_accuracy: 0.4828\n",
      "Epoch 59/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6800 - accuracy: 0.5582 - val_loss: 0.6803 - val_accuracy: 0.4914\n",
      "Epoch 60/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6800 - accuracy: 0.5586 - val_loss: 0.6862 - val_accuracy: 0.4719\n",
      "Epoch 61/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6799 - accuracy: 0.5577 - val_loss: 0.6767 - val_accuracy: 0.4996\n",
      "Epoch 62/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6798 - accuracy: 0.5590 - val_loss: 0.6863 - val_accuracy: 0.4720\n",
      "Epoch 63/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6797 - accuracy: 0.5575 - val_loss: 0.6790 - val_accuracy: 0.4945\n",
      "Epoch 64/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6796 - accuracy: 0.5588 - val_loss: 0.6799 - val_accuracy: 0.4912\n",
      "Epoch 65/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6794 - accuracy: 0.5584 - val_loss: 0.6840 - val_accuracy: 0.4799\n",
      "Epoch 66/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6794 - accuracy: 0.5581 - val_loss: 0.6758 - val_accuracy: 0.5024\n",
      "Epoch 67/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6793 - accuracy: 0.5598 - val_loss: 0.6828 - val_accuracy: 0.4839\n",
      "Epoch 68/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6792 - accuracy: 0.5583 - val_loss: 0.6786 - val_accuracy: 0.4932\n",
      "Epoch 69/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6790 - accuracy: 0.5596 - val_loss: 0.6765 - val_accuracy: 0.5013\n",
      "Epoch 70/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6789 - accuracy: 0.5610 - val_loss: 0.6822 - val_accuracy: 0.4865\n",
      "Epoch 71/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6788 - accuracy: 0.5598 - val_loss: 0.6733 - val_accuracy: 0.5122\n",
      "Epoch 72/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6787 - accuracy: 0.5623 - val_loss: 0.6806 - val_accuracy: 0.4898\n",
      "Epoch 73/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6785 - accuracy: 0.5608 - val_loss: 0.6746 - val_accuracy: 0.5095\n",
      "Epoch 74/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6784 - accuracy: 0.5637 - val_loss: 0.6753 - val_accuracy: 0.5084\n",
      "Epoch 75/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6782 - accuracy: 0.5639 - val_loss: 0.6776 - val_accuracy: 0.5004\n",
      "Epoch 76/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6781 - accuracy: 0.5643 - val_loss: 0.6710 - val_accuracy: 0.5230\n",
      "Epoch 77/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6779 - accuracy: 0.5631 - val_loss: 0.6822 - val_accuracy: 0.4900\n",
      "Epoch 78/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6779 - accuracy: 0.5634 - val_loss: 0.6644 - val_accuracy: 0.5459\n",
      "Epoch 79/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6778 - accuracy: 0.5653 - val_loss: 0.6883 - val_accuracy: 0.4717\n",
      "Epoch 80/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6779 - accuracy: 0.5619 - val_loss: 0.6682 - val_accuracy: 0.5343\n",
      "Epoch 81/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6774 - accuracy: 0.5667 - val_loss: 0.6694 - val_accuracy: 0.5323\n",
      "Epoch 82/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6772 - accuracy: 0.5669 - val_loss: 0.6853 - val_accuracy: 0.4836\n",
      "Epoch 83/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6773 - accuracy: 0.5638 - val_loss: 0.6664 - val_accuracy: 0.5433\n",
      "Epoch 84/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6770 - accuracy: 0.5674 - val_loss: 0.6719 - val_accuracy: 0.5290\n",
      "Epoch 85/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6767 - accuracy: 0.5681 - val_loss: 0.6826 - val_accuracy: 0.4967\n",
      "Epoch 86/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6767 - accuracy: 0.5652 - val_loss: 0.6653 - val_accuracy: 0.5486\n",
      "Epoch 87/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6766 - accuracy: 0.5674 - val_loss: 0.6764 - val_accuracy: 0.5197\n",
      "Epoch 88/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6763 - accuracy: 0.5666 - val_loss: 0.6772 - val_accuracy: 0.5181\n",
      "Epoch 89/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6762 - accuracy: 0.5669 - val_loss: 0.6659 - val_accuracy: 0.5486\n",
      "Epoch 90/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6762 - accuracy: 0.5680 - val_loss: 0.6804 - val_accuracy: 0.5079\n",
      "Epoch 91/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6760 - accuracy: 0.5669 - val_loss: 0.6710 - val_accuracy: 0.5389\n",
      "Epoch 92/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6758 - accuracy: 0.5675 - val_loss: 0.6698 - val_accuracy: 0.5420\n",
      "Epoch 93/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6757 - accuracy: 0.5684 - val_loss: 0.6802 - val_accuracy: 0.5093\n",
      "Epoch 94/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6756 - accuracy: 0.5674 - val_loss: 0.6656 - val_accuracy: 0.5564\n",
      "Epoch 95/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6755 - accuracy: 0.5698 - val_loss: 0.6793 - val_accuracy: 0.5121\n",
      "Epoch 96/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6753 - accuracy: 0.5681 - val_loss: 0.6701 - val_accuracy: 0.5449\n",
      "Epoch 97/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6751 - accuracy: 0.5700 - val_loss: 0.6720 - val_accuracy: 0.5398\n",
      "Epoch 98/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6750 - accuracy: 0.5699 - val_loss: 0.6774 - val_accuracy: 0.5230\n",
      "Epoch 99/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6749 - accuracy: 0.5691 - val_loss: 0.6658 - val_accuracy: 0.5590\n",
      "Epoch 100/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6749 - accuracy: 0.5707 - val_loss: 0.6836 - val_accuracy: 0.5047\n",
      "Epoch 101/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6749 - accuracy: 0.5692 - val_loss: 0.6620 - val_accuracy: 0.5676\n",
      "Epoch 102/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6748 - accuracy: 0.5707 - val_loss: 0.6838 - val_accuracy: 0.5046\n",
      "Epoch 103/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6747 - accuracy: 0.5698 - val_loss: 0.6674 - val_accuracy: 0.5568\n",
      "Epoch 104/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6744 - accuracy: 0.5717 - val_loss: 0.6730 - val_accuracy: 0.5418\n",
      "Epoch 105/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6742 - accuracy: 0.5714 - val_loss: 0.6785 - val_accuracy: 0.5252\n",
      "Epoch 106/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6741 - accuracy: 0.5709 - val_loss: 0.6642 - val_accuracy: 0.5672\n",
      "Epoch 107/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6742 - accuracy: 0.5716 - val_loss: 0.6852 - val_accuracy: 0.5042\n",
      "Epoch 108/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6742 - accuracy: 0.5707 - val_loss: 0.6635 - val_accuracy: 0.5685\n",
      "Epoch 109/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6740 - accuracy: 0.5722 - val_loss: 0.6799 - val_accuracy: 0.5237\n",
      "Epoch 110/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6738 - accuracy: 0.5723 - val_loss: 0.6734 - val_accuracy: 0.5435\n",
      "Epoch 111/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6736 - accuracy: 0.5731 - val_loss: 0.6683 - val_accuracy: 0.5575\n",
      "Epoch 112/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6736 - accuracy: 0.5733 - val_loss: 0.6835 - val_accuracy: 0.5163\n",
      "Epoch 113/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6736 - accuracy: 0.5722 - val_loss: 0.6631 - val_accuracy: 0.5692\n",
      "Epoch 114/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6736 - accuracy: 0.5741 - val_loss: 0.6839 - val_accuracy: 0.5144\n",
      "Epoch 115/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6735 - accuracy: 0.5726 - val_loss: 0.6684 - val_accuracy: 0.5574\n",
      "Epoch 116/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6732 - accuracy: 0.5737 - val_loss: 0.6738 - val_accuracy: 0.5446\n",
      "Epoch 117/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6731 - accuracy: 0.5734 - val_loss: 0.6791 - val_accuracy: 0.5305\n",
      "Epoch 118/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6730 - accuracy: 0.5744 - val_loss: 0.6654 - val_accuracy: 0.5634\n",
      "Epoch 119/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6731 - accuracy: 0.5750 - val_loss: 0.6845 - val_accuracy: 0.5157\n",
      "Epoch 120/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6731 - accuracy: 0.5730 - val_loss: 0.6644 - val_accuracy: 0.5663\n",
      "Epoch 121/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6730 - accuracy: 0.5753 - val_loss: 0.6804 - val_accuracy: 0.5263\n",
      "Epoch 122/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6728 - accuracy: 0.5747 - val_loss: 0.6724 - val_accuracy: 0.5493\n",
      "Epoch 123/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6726 - accuracy: 0.5751 - val_loss: 0.6706 - val_accuracy: 0.5539\n",
      "Epoch 124/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6725 - accuracy: 0.5752 - val_loss: 0.6812 - val_accuracy: 0.5254\n",
      "Epoch 125/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6726 - accuracy: 0.5745 - val_loss: 0.6645 - val_accuracy: 0.5658\n",
      "Epoch 126/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6726 - accuracy: 0.5759 - val_loss: 0.6847 - val_accuracy: 0.5183\n",
      "Epoch 127/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6726 - accuracy: 0.5741 - val_loss: 0.6652 - val_accuracy: 0.5650\n",
      "Epoch 128/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6724 - accuracy: 0.5762 - val_loss: 0.6799 - val_accuracy: 0.5292\n",
      "Epoch 129/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6722 - accuracy: 0.5757 - val_loss: 0.6718 - val_accuracy: 0.5504\n",
      "Epoch 130/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6721 - accuracy: 0.5768 - val_loss: 0.6720 - val_accuracy: 0.5502\n",
      "Epoch 131/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6720 - accuracy: 0.5771 - val_loss: 0.6792 - val_accuracy: 0.5325\n",
      "Epoch 132/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6720 - accuracy: 0.5754 - val_loss: 0.6663 - val_accuracy: 0.5627\n",
      "Epoch 133/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6720 - accuracy: 0.5764 - val_loss: 0.6840 - val_accuracy: 0.5216\n",
      "Epoch 134/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6720 - accuracy: 0.5755 - val_loss: 0.6634 - val_accuracy: 0.5694\n",
      "Epoch 135/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6720 - accuracy: 0.5765 - val_loss: 0.6855 - val_accuracy: 0.5174\n",
      "Epoch 136/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6719 - accuracy: 0.5751 - val_loss: 0.6647 - val_accuracy: 0.5658\n",
      "Epoch 137/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6717 - accuracy: 0.5769 - val_loss: 0.6794 - val_accuracy: 0.5331\n",
      "Epoch 138/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6715 - accuracy: 0.5769 - val_loss: 0.6727 - val_accuracy: 0.5473\n",
      "Epoch 139/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6714 - accuracy: 0.5783 - val_loss: 0.6705 - val_accuracy: 0.5530\n",
      "Epoch 140/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6713 - accuracy: 0.5782 - val_loss: 0.6806 - val_accuracy: 0.5309\n",
      "Epoch 141/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6714 - accuracy: 0.5771 - val_loss: 0.6644 - val_accuracy: 0.5658\n",
      "Epoch 142/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6714 - accuracy: 0.5774 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
      "Epoch 143/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6715 - accuracy: 0.5769 - val_loss: 0.6623 - val_accuracy: 0.5692\n",
      "Epoch 144/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6713 - accuracy: 0.5776 - val_loss: 0.6840 - val_accuracy: 0.5225\n",
      "Epoch 145/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6712 - accuracy: 0.5775 - val_loss: 0.6678 - val_accuracy: 0.5579\n",
      "Epoch 146/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6710 - accuracy: 0.5776 - val_loss: 0.6739 - val_accuracy: 0.5427\n",
      "Epoch 147/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6708 - accuracy: 0.5785 - val_loss: 0.6775 - val_accuracy: 0.5356\n",
      "Epoch 148/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6708 - accuracy: 0.5786 - val_loss: 0.6660 - val_accuracy: 0.5614\n",
      "Epoch 149/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6708 - accuracy: 0.5783 - val_loss: 0.6842 - val_accuracy: 0.5225\n",
      "Epoch 150/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6709 - accuracy: 0.5780 - val_loss: 0.6630 - val_accuracy: 0.5672\n",
      "Epoch 151/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6708 - accuracy: 0.5778 - val_loss: 0.6842 - val_accuracy: 0.5232\n",
      "Epoch 152/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6707 - accuracy: 0.5782 - val_loss: 0.6660 - val_accuracy: 0.5596\n",
      "Epoch 153/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6705 - accuracy: 0.5789 - val_loss: 0.6772 - val_accuracy: 0.5360\n",
      "Epoch 154/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6703 - accuracy: 0.5791 - val_loss: 0.6737 - val_accuracy: 0.5459\n",
      "Epoch 155/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6702 - accuracy: 0.5789 - val_loss: 0.6696 - val_accuracy: 0.5533\n",
      "Epoch 156/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6702 - accuracy: 0.5798 - val_loss: 0.6809 - val_accuracy: 0.5292\n",
      "Epoch 157/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6702 - accuracy: 0.5790 - val_loss: 0.6638 - val_accuracy: 0.5645\n",
      "Epoch 158/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6703 - accuracy: 0.5784 - val_loss: 0.6869 - val_accuracy: 0.5168\n",
      "Epoch 159/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6704 - accuracy: 0.5797 - val_loss: 0.6602 - val_accuracy: 0.5734\n",
      "Epoch 160/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6703 - accuracy: 0.5776 - val_loss: 0.6880 - val_accuracy: 0.5146\n",
      "Epoch 161/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6703 - accuracy: 0.5801 - val_loss: 0.6634 - val_accuracy: 0.5661\n",
      "Epoch 162/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6700 - accuracy: 0.5787 - val_loss: 0.6778 - val_accuracy: 0.5371\n",
      "Epoch 163/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6697 - accuracy: 0.5799 - val_loss: 0.6739 - val_accuracy: 0.5449\n",
      "Epoch 164/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6696 - accuracy: 0.5801 - val_loss: 0.6675 - val_accuracy: 0.5603\n",
      "Epoch 165/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6696 - accuracy: 0.5794 - val_loss: 0.6830 - val_accuracy: 0.5247\n",
      "Epoch 166/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6697 - accuracy: 0.5798 - val_loss: 0.6625 - val_accuracy: 0.5669\n",
      "Epoch 167/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6697 - accuracy: 0.5792 - val_loss: 0.6848 - val_accuracy: 0.5205\n",
      "Epoch 168/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6696 - accuracy: 0.5801 - val_loss: 0.6647 - val_accuracy: 0.5643\n",
      "Epoch 169/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6694 - accuracy: 0.5796 - val_loss: 0.6786 - val_accuracy: 0.5345\n",
      "Epoch 170/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6692 - accuracy: 0.5798 - val_loss: 0.6713 - val_accuracy: 0.5497\n",
      "Epoch 171/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6691 - accuracy: 0.5808 - val_loss: 0.6715 - val_accuracy: 0.5484\n",
      "Epoch 172/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6690 - accuracy: 0.5806 - val_loss: 0.6780 - val_accuracy: 0.5358\n",
      "Epoch 173/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6690 - accuracy: 0.5807 - val_loss: 0.6654 - val_accuracy: 0.5625\n",
      "Epoch 174/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6690 - accuracy: 0.5803 - val_loss: 0.6852 - val_accuracy: 0.5192\n",
      "Epoch 175/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6691 - accuracy: 0.5812 - val_loss: 0.6601 - val_accuracy: 0.5734\n",
      "Epoch 176/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6692 - accuracy: 0.5790 - val_loss: 0.6893 - val_accuracy: 0.5086\n",
      "Epoch 177/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6693 - accuracy: 0.5800 - val_loss: 0.6615 - val_accuracy: 0.5700\n",
      "Epoch 178/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6689 - accuracy: 0.5799 - val_loss: 0.6807 - val_accuracy: 0.5292\n",
      "Epoch 179/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6687 - accuracy: 0.5811 - val_loss: 0.6711 - val_accuracy: 0.5486\n",
      "Epoch 180/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6685 - accuracy: 0.5813 - val_loss: 0.6697 - val_accuracy: 0.5526\n",
      "Epoch 181/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6684 - accuracy: 0.5812 - val_loss: 0.6809 - val_accuracy: 0.5289\n",
      "Epoch 182/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6685 - accuracy: 0.5817 - val_loss: 0.6631 - val_accuracy: 0.5665\n",
      "Epoch 183/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6685 - accuracy: 0.5804 - val_loss: 0.6854 - val_accuracy: 0.5186\n",
      "Epoch 184/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6685 - accuracy: 0.5819 - val_loss: 0.6629 - val_accuracy: 0.5669\n",
      "Epoch 185/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6684 - accuracy: 0.5801 - val_loss: 0.6811 - val_accuracy: 0.5287\n",
      "Epoch 186/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6682 - accuracy: 0.5826 - val_loss: 0.6690 - val_accuracy: 0.5532\n",
      "Epoch 187/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6680 - accuracy: 0.5820 - val_loss: 0.6730 - val_accuracy: 0.5451\n",
      "Epoch 188/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6679 - accuracy: 0.5823 - val_loss: 0.6768 - val_accuracy: 0.5382\n",
      "Epoch 189/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6679 - accuracy: 0.5827 - val_loss: 0.6661 - val_accuracy: 0.5596\n",
      "Epoch 190/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6679 - accuracy: 0.5815 - val_loss: 0.6836 - val_accuracy: 0.5217\n",
      "Epoch 191/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6680 - accuracy: 0.5823 - val_loss: 0.6614 - val_accuracy: 0.5705\n",
      "Epoch 192/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6680 - accuracy: 0.5799 - val_loss: 0.6883 - val_accuracy: 0.5079\n",
      "Epoch 193/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6681 - accuracy: 0.5833 - val_loss: 0.6603 - val_accuracy: 0.5729\n",
      "Epoch 194/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6680 - accuracy: 0.5799 - val_loss: 0.6851 - val_accuracy: 0.5179\n",
      "Epoch 195/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6678 - accuracy: 0.5830 - val_loss: 0.6660 - val_accuracy: 0.5585\n",
      "Epoch 196/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6675 - accuracy: 0.5820 - val_loss: 0.6750 - val_accuracy: 0.5404\n",
      "Epoch 197/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6674 - accuracy: 0.5831 - val_loss: 0.6751 - val_accuracy: 0.5400\n",
      "Epoch 198/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6673 - accuracy: 0.5832 - val_loss: 0.6666 - val_accuracy: 0.5575\n",
      "Epoch 199/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6673 - accuracy: 0.5825 - val_loss: 0.6837 - val_accuracy: 0.5197\n",
      "Epoch 200/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6674 - accuracy: 0.5830 - val_loss: 0.6608 - val_accuracy: 0.5712\n",
      "Epoch 201/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6675 - accuracy: 0.5810 - val_loss: 0.6886 - val_accuracy: 0.5088\n",
      "Epoch 202/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6676 - accuracy: 0.5840 - val_loss: 0.6612 - val_accuracy: 0.5694\n",
      "Epoch 203/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6673 - accuracy: 0.5813 - val_loss: 0.6824 - val_accuracy: 0.5236\n",
      "Epoch 204/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6671 - accuracy: 0.5834 - val_loss: 0.6687 - val_accuracy: 0.5535\n",
      "Epoch 205/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6669 - accuracy: 0.5840 - val_loss: 0.6722 - val_accuracy: 0.5453\n",
      "Epoch 206/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6668 - accuracy: 0.5838 - val_loss: 0.6778 - val_accuracy: 0.5325\n",
      "Epoch 207/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6668 - accuracy: 0.5843 - val_loss: 0.6646 - val_accuracy: 0.5617\n",
      "Epoch 208/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6668 - accuracy: 0.5824 - val_loss: 0.6865 - val_accuracy: 0.5137\n",
      "Epoch 209/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6670 - accuracy: 0.5847 - val_loss: 0.6588 - val_accuracy: 0.5711\n",
      "Epoch 210/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6670 - accuracy: 0.5816 - val_loss: 0.6914 - val_accuracy: 0.5004\n",
      "Epoch 211/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6672 - accuracy: 0.5856 - val_loss: 0.6599 - val_accuracy: 0.5692\n",
      "Epoch 212/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6668 - accuracy: 0.5824 - val_loss: 0.6824 - val_accuracy: 0.5230\n",
      "Epoch 213/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6665 - accuracy: 0.5850 - val_loss: 0.6702 - val_accuracy: 0.5484\n",
      "Epoch 214/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6663 - accuracy: 0.5851 - val_loss: 0.6692 - val_accuracy: 0.5504\n",
      "Epoch 215/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6662 - accuracy: 0.5850 - val_loss: 0.6826 - val_accuracy: 0.5217\n",
      "Epoch 216/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6663 - accuracy: 0.5854 - val_loss: 0.6605 - val_accuracy: 0.5663\n",
      "Epoch 217/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6664 - accuracy: 0.5832 - val_loss: 0.6889 - val_accuracy: 0.5064\n",
      "Epoch 218/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6666 - accuracy: 0.5868 - val_loss: 0.6609 - val_accuracy: 0.5661\n",
      "Epoch 219/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6663 - accuracy: 0.5832 - val_loss: 0.6815 - val_accuracy: 0.5245\n",
      "Epoch 220/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6660 - accuracy: 0.5858 - val_loss: 0.6707 - val_accuracy: 0.5486\n",
      "Epoch 221/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6658 - accuracy: 0.5852 - val_loss: 0.6699 - val_accuracy: 0.5497\n",
      "Epoch 222/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6658 - accuracy: 0.5855 - val_loss: 0.6812 - val_accuracy: 0.5241\n",
      "Epoch 223/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6658 - accuracy: 0.5864 - val_loss: 0.6625 - val_accuracy: 0.5612\n",
      "Epoch 224/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6659 - accuracy: 0.5834 - val_loss: 0.6856 - val_accuracy: 0.5133\n",
      "Epoch 225/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6659 - accuracy: 0.5873 - val_loss: 0.6624 - val_accuracy: 0.5612\n",
      "Epoch 226/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6658 - accuracy: 0.5836 - val_loss: 0.6810 - val_accuracy: 0.5237\n",
      "Epoch 227/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6656 - accuracy: 0.5869 - val_loss: 0.6690 - val_accuracy: 0.5499\n",
      "Epoch 228/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6654 - accuracy: 0.5858 - val_loss: 0.6729 - val_accuracy: 0.5417\n",
      "Epoch 229/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6653 - accuracy: 0.5861 - val_loss: 0.6766 - val_accuracy: 0.5334\n",
      "Epoch 230/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6652 - accuracy: 0.5873 - val_loss: 0.6660 - val_accuracy: 0.5568\n",
      "Epoch 231/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6653 - accuracy: 0.5846 - val_loss: 0.6830 - val_accuracy: 0.5188\n",
      "Epoch 232/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6653 - accuracy: 0.5876 - val_loss: 0.6614 - val_accuracy: 0.5627\n",
      "Epoch 233/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6654 - accuracy: 0.5842 - val_loss: 0.6866 - val_accuracy: 0.5100\n",
      "Epoch 234/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6654 - accuracy: 0.5878 - val_loss: 0.6599 - val_accuracy: 0.5652\n",
      "Epoch 235/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6653 - accuracy: 0.5851 - val_loss: 0.6859 - val_accuracy: 0.5121\n",
      "Epoch 236/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6652 - accuracy: 0.5884 - val_loss: 0.6635 - val_accuracy: 0.5594\n",
      "Epoch 237/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6650 - accuracy: 0.5850 - val_loss: 0.6788 - val_accuracy: 0.5280\n",
      "Epoch 238/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6648 - accuracy: 0.5886 - val_loss: 0.6708 - val_accuracy: 0.5451\n",
      "Epoch 239/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6646 - accuracy: 0.5872 - val_loss: 0.6705 - val_accuracy: 0.5460\n",
      "Epoch 240/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6646 - accuracy: 0.5869 - val_loss: 0.6778 - val_accuracy: 0.5309\n",
      "Epoch 241/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6646 - accuracy: 0.5886 - val_loss: 0.6651 - val_accuracy: 0.5561\n",
      "Epoch 242/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6646 - accuracy: 0.5859 - val_loss: 0.6829 - val_accuracy: 0.5205\n",
      "Epoch 243/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6646 - accuracy: 0.5893 - val_loss: 0.6607 - val_accuracy: 0.5619\n",
      "Epoch 244/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6647 - accuracy: 0.5848 - val_loss: 0.6876 - val_accuracy: 0.5095\n",
      "Epoch 245/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6648 - accuracy: 0.5892 - val_loss: 0.6585 - val_accuracy: 0.5650\n",
      "Epoch 246/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6647 - accuracy: 0.5845 - val_loss: 0.6873 - val_accuracy: 0.5104\n",
      "Epoch 247/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6647 - accuracy: 0.5894 - val_loss: 0.6616 - val_accuracy: 0.5612\n",
      "Epoch 248/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6644 - accuracy: 0.5858 - val_loss: 0.6795 - val_accuracy: 0.5265\n",
      "Epoch 249/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6641 - accuracy: 0.5898 - val_loss: 0.6697 - val_accuracy: 0.5462\n",
      "Epoch 250/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6639 - accuracy: 0.5875 - val_loss: 0.6710 - val_accuracy: 0.5418\n",
      "Epoch 251/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6639 - accuracy: 0.5886 - val_loss: 0.6770 - val_accuracy: 0.5305\n",
      "Epoch 252/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6639 - accuracy: 0.5901 - val_loss: 0.6644 - val_accuracy: 0.5564\n",
      "Epoch 253/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6639 - accuracy: 0.5869 - val_loss: 0.6831 - val_accuracy: 0.5186\n",
      "Epoch 254/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6640 - accuracy: 0.5908 - val_loss: 0.6600 - val_accuracy: 0.5630\n",
      "Epoch 255/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6640 - accuracy: 0.5852 - val_loss: 0.6871 - val_accuracy: 0.5084\n",
      "Epoch 256/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6641 - accuracy: 0.5900 - val_loss: 0.6588 - val_accuracy: 0.5639\n",
      "Epoch 257/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6640 - accuracy: 0.5852 - val_loss: 0.6858 - val_accuracy: 0.5110\n",
      "Epoch 258/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6639 - accuracy: 0.5904 - val_loss: 0.6619 - val_accuracy: 0.5596\n",
      "Epoch 259/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6636 - accuracy: 0.5866 - val_loss: 0.6785 - val_accuracy: 0.5261\n",
      "Epoch 260/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6634 - accuracy: 0.5908 - val_loss: 0.6697 - val_accuracy: 0.5464\n",
      "Epoch 261/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6633 - accuracy: 0.5896 - val_loss: 0.6697 - val_accuracy: 0.5469\n",
      "Epoch 262/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6632 - accuracy: 0.5895 - val_loss: 0.6780 - val_accuracy: 0.5272\n",
      "Epoch 263/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6632 - accuracy: 0.5909 - val_loss: 0.6626 - val_accuracy: 0.5592\n",
      "Epoch 264/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6633 - accuracy: 0.5875 - val_loss: 0.6852 - val_accuracy: 0.5115\n",
      "Epoch 265/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6635 - accuracy: 0.5912 - val_loss: 0.6582 - val_accuracy: 0.5667\n",
      "Epoch 266/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6635 - accuracy: 0.5870 - val_loss: 0.6877 - val_accuracy: 0.5058\n",
      "Epoch 267/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6635 - accuracy: 0.5901 - val_loss: 0.6600 - val_accuracy: 0.5627\n",
      "Epoch 268/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6632 - accuracy: 0.5879 - val_loss: 0.6800 - val_accuracy: 0.5234\n",
      "Epoch 269/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6629 - accuracy: 0.5920 - val_loss: 0.6683 - val_accuracy: 0.5468\n",
      "Epoch 270/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6627 - accuracy: 0.5901 - val_loss: 0.6697 - val_accuracy: 0.5417\n",
      "Epoch 271/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6627 - accuracy: 0.5903 - val_loss: 0.6773 - val_accuracy: 0.5263\n",
      "Epoch 272/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6627 - accuracy: 0.5928 - val_loss: 0.6627 - val_accuracy: 0.5575\n",
      "Epoch 273/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6627 - accuracy: 0.5888 - val_loss: 0.6847 - val_accuracy: 0.5095\n",
      "Epoch 274/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6629 - accuracy: 0.5914 - val_loss: 0.6578 - val_accuracy: 0.5661\n",
      "Epoch 275/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6629 - accuracy: 0.5879 - val_loss: 0.6884 - val_accuracy: 0.5058\n",
      "Epoch 276/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6630 - accuracy: 0.5913 - val_loss: 0.6590 - val_accuracy: 0.5621\n",
      "Epoch 277/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6627 - accuracy: 0.5890 - val_loss: 0.6814 - val_accuracy: 0.5157\n",
      "Epoch 278/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6625 - accuracy: 0.5922 - val_loss: 0.6662 - val_accuracy: 0.5488\n",
      "Epoch 279/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6622 - accuracy: 0.5906 - val_loss: 0.6711 - val_accuracy: 0.5353\n",
      "Epoch 280/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6621 - accuracy: 0.5917 - val_loss: 0.6747 - val_accuracy: 0.5287\n",
      "Epoch 281/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6620 - accuracy: 0.5938 - val_loss: 0.6641 - val_accuracy: 0.5541\n",
      "Epoch 282/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6621 - accuracy: 0.5905 - val_loss: 0.6809 - val_accuracy: 0.5157\n",
      "Epoch 283/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6622 - accuracy: 0.5923 - val_loss: 0.6602 - val_accuracy: 0.5597\n",
      "Epoch 284/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6621 - accuracy: 0.5903 - val_loss: 0.6840 - val_accuracy: 0.5091\n",
      "Epoch 285/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6622 - accuracy: 0.5918 - val_loss: 0.6600 - val_accuracy: 0.5588\n",
      "Epoch 286/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6620 - accuracy: 0.5906 - val_loss: 0.6806 - val_accuracy: 0.5157\n",
      "Epoch 287/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6619 - accuracy: 0.5923 - val_loss: 0.6642 - val_accuracy: 0.5502\n",
      "Epoch 288/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6617 - accuracy: 0.5908 - val_loss: 0.6727 - val_accuracy: 0.5323\n",
      "Epoch 289/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6615 - accuracy: 0.5929 - val_loss: 0.6710 - val_accuracy: 0.5343\n",
      "Epoch 290/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6615 - accuracy: 0.5931 - val_loss: 0.6663 - val_accuracy: 0.5446\n",
      "Epoch 291/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6615 - accuracy: 0.5922 - val_loss: 0.6770 - val_accuracy: 0.5232\n",
      "Epoch 292/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6615 - accuracy: 0.5935 - val_loss: 0.6619 - val_accuracy: 0.5544\n",
      "Epoch 293/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6615 - accuracy: 0.5913 - val_loss: 0.6812 - val_accuracy: 0.5146\n",
      "Epoch 294/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6616 - accuracy: 0.5928 - val_loss: 0.6595 - val_accuracy: 0.5581\n",
      "Epoch 295/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6615 - accuracy: 0.5913 - val_loss: 0.6822 - val_accuracy: 0.5117\n",
      "Epoch 296/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6615 - accuracy: 0.5926 - val_loss: 0.6605 - val_accuracy: 0.5554\n",
      "Epoch 297/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6613 - accuracy: 0.5914 - val_loss: 0.6789 - val_accuracy: 0.5190\n",
      "Epoch 298/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6612 - accuracy: 0.5930 - val_loss: 0.6638 - val_accuracy: 0.5482\n",
      "Epoch 299/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6610 - accuracy: 0.5924 - val_loss: 0.6744 - val_accuracy: 0.5281\n",
      "Epoch 300/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6609 - accuracy: 0.5934 - val_loss: 0.6669 - val_accuracy: 0.5407\n",
      "Epoch 301/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6608 - accuracy: 0.5939 - val_loss: 0.6712 - val_accuracy: 0.5340\n",
      "Epoch 302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6607 - accuracy: 0.5944 - val_loss: 0.6695 - val_accuracy: 0.5365\n",
      "Epoch 303/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6606 - accuracy: 0.5945 - val_loss: 0.6693 - val_accuracy: 0.5374\n",
      "Epoch 304/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6606 - accuracy: 0.5945 - val_loss: 0.6716 - val_accuracy: 0.5311\n",
      "Epoch 305/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6605 - accuracy: 0.5943 - val_loss: 0.6669 - val_accuracy: 0.5402\n",
      "Epoch 306/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6604 - accuracy: 0.5937 - val_loss: 0.6750 - val_accuracy: 0.5254\n",
      "Epoch 307/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6604 - accuracy: 0.5942 - val_loss: 0.6604 - val_accuracy: 0.5541\n",
      "Epoch 308/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6605 - accuracy: 0.5928 - val_loss: 0.6882 - val_accuracy: 0.4984\n",
      "Epoch 309/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6611 - accuracy: 0.5930 - val_loss: 0.6418 - val_accuracy: 0.5890\n",
      "Epoch 310/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6625 - accuracy: 0.5879 - val_loss: 0.7242 - val_accuracy: 0.4357\n",
      "Epoch 311/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6669 - accuracy: 0.5842 - val_loss: 0.6534 - val_accuracy: 0.5683\n",
      "Epoch 312/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6609 - accuracy: 0.5925 - val_loss: 0.6487 - val_accuracy: 0.5751\n",
      "Epoch 313/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6613 - accuracy: 0.5910 - val_loss: 0.7163 - val_accuracy: 0.4426\n",
      "Epoch 314/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6653 - accuracy: 0.5859 - val_loss: 0.6603 - val_accuracy: 0.5568\n",
      "Epoch 315/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6604 - accuracy: 0.5942 - val_loss: 0.6382 - val_accuracy: 0.5939\n",
      "Epoch 316/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6627 - accuracy: 0.5886 - val_loss: 0.7173 - val_accuracy: 0.4454\n",
      "Epoch 317/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6659 - accuracy: 0.5855 - val_loss: 0.6782 - val_accuracy: 0.5214\n",
      "Epoch 318/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6609 - accuracy: 0.5940 - val_loss: 0.6197 - val_accuracy: 0.6312\n",
      "Epoch 319/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6693 - accuracy: 0.5721 - val_loss: 0.7209 - val_accuracy: 0.4306\n",
      "Epoch 320/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6666 - accuracy: 0.5847 - val_loss: 0.7176 - val_accuracy: 0.4326\n",
      "Epoch 321/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6660 - accuracy: 0.5838 - val_loss: 0.6336 - val_accuracy: 0.6007\n",
      "Epoch 322/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6654 - accuracy: 0.5857 - val_loss: 0.6529 - val_accuracy: 0.5661\n",
      "Epoch 323/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6608 - accuracy: 0.5943 - val_loss: 0.6953 - val_accuracy: 0.4790\n",
      "Epoch 324/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6631 - accuracy: 0.5907 - val_loss: 0.6825 - val_accuracy: 0.5066\n",
      "Epoch 325/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6622 - accuracy: 0.5908 - val_loss: 0.6417 - val_accuracy: 0.5871\n",
      "Epoch 326/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6626 - accuracy: 0.5881 - val_loss: 0.6539 - val_accuracy: 0.5564\n",
      "Epoch 327/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6605 - accuracy: 0.5928 - val_loss: 0.6817 - val_accuracy: 0.4956\n",
      "Epoch 328/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6613 - accuracy: 0.5920 - val_loss: 0.6766 - val_accuracy: 0.5047\n",
      "Epoch 329/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6612 - accuracy: 0.5933 - val_loss: 0.6525 - val_accuracy: 0.5585\n",
      "Epoch 330/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6610 - accuracy: 0.5922 - val_loss: 0.6630 - val_accuracy: 0.5415\n",
      "Epoch 331/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6602 - accuracy: 0.5942 - val_loss: 0.6788 - val_accuracy: 0.5064\n",
      "Epoch 332/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6606 - accuracy: 0.5933 - val_loss: 0.6665 - val_accuracy: 0.5327\n",
      "Epoch 333/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6601 - accuracy: 0.5945 - val_loss: 0.6550 - val_accuracy: 0.5581\n",
      "Epoch 334/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6603 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.5267\n",
      "Epoch 335/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6598 - accuracy: 0.5958 - val_loss: 0.6772 - val_accuracy: 0.5119\n",
      "Epoch 336/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6600 - accuracy: 0.5945 - val_loss: 0.6634 - val_accuracy: 0.5451\n",
      "Epoch 337/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6596 - accuracy: 0.5943 - val_loss: 0.6628 - val_accuracy: 0.5431\n",
      "Epoch 338/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6593 - accuracy: 0.5936 - val_loss: 0.6745 - val_accuracy: 0.5177\n",
      "Epoch 339/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6597 - accuracy: 0.5934 - val_loss: 0.6707 - val_accuracy: 0.5263\n",
      "Epoch 340/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6595 - accuracy: 0.5945 - val_loss: 0.6616 - val_accuracy: 0.5490\n",
      "Epoch 341/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6590 - accuracy: 0.5944 - val_loss: 0.6686 - val_accuracy: 0.5349\n",
      "Epoch 342/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6590 - accuracy: 0.5960 - val_loss: 0.6742 - val_accuracy: 0.5256\n",
      "Epoch 343/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6593 - accuracy: 0.5957 - val_loss: 0.6670 - val_accuracy: 0.5391\n",
      "Epoch 344/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6590 - accuracy: 0.5965 - val_loss: 0.6649 - val_accuracy: 0.5413\n",
      "Epoch 345/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6588 - accuracy: 0.5965 - val_loss: 0.6720 - val_accuracy: 0.5267\n",
      "Epoch 346/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6589 - accuracy: 0.5956 - val_loss: 0.6701 - val_accuracy: 0.5314\n",
      "Epoch 347/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6588 - accuracy: 0.5951 - val_loss: 0.6647 - val_accuracy: 0.5446\n",
      "Epoch 348/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6586 - accuracy: 0.5951 - val_loss: 0.6703 - val_accuracy: 0.5338\n",
      "Epoch 349/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6586 - accuracy: 0.5963 - val_loss: 0.6711 - val_accuracy: 0.5338\n",
      "Epoch 350/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6585 - accuracy: 0.5965 - val_loss: 0.6650 - val_accuracy: 0.5451\n",
      "Epoch 351/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6584 - accuracy: 0.5957 - val_loss: 0.6701 - val_accuracy: 0.5329\n",
      "Epoch 352/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6584 - accuracy: 0.5965 - val_loss: 0.6727 - val_accuracy: 0.5283\n",
      "Epoch 353/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6584 - accuracy: 0.5968 - val_loss: 0.6661 - val_accuracy: 0.5440\n",
      "Epoch 354/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6582 - accuracy: 0.5972 - val_loss: 0.6700 - val_accuracy: 0.5358\n",
      "Epoch 355/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6582 - accuracy: 0.5979 - val_loss: 0.6701 - val_accuracy: 0.5353\n",
      "Epoch 356/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6581 - accuracy: 0.5972 - val_loss: 0.6658 - val_accuracy: 0.5415\n",
      "Epoch 357/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6580 - accuracy: 0.5967 - val_loss: 0.6699 - val_accuracy: 0.5342\n",
      "Epoch 358/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6580 - accuracy: 0.5968 - val_loss: 0.6694 - val_accuracy: 0.5351\n",
      "Epoch 359/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6579 - accuracy: 0.5973 - val_loss: 0.6652 - val_accuracy: 0.5446\n",
      "Epoch 360/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6578 - accuracy: 0.5978 - val_loss: 0.6696 - val_accuracy: 0.5354\n",
      "Epoch 361/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6578 - accuracy: 0.5986 - val_loss: 0.6685 - val_accuracy: 0.5371\n",
      "Epoch 362/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6577 - accuracy: 0.5985 - val_loss: 0.6662 - val_accuracy: 0.5396\n",
      "Epoch 363/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6576 - accuracy: 0.5976 - val_loss: 0.6700 - val_accuracy: 0.5307\n",
      "Epoch 364/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6576 - accuracy: 0.5979 - val_loss: 0.6672 - val_accuracy: 0.5384\n",
      "Epoch 365/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6575 - accuracy: 0.5980 - val_loss: 0.6651 - val_accuracy: 0.5424\n",
      "Epoch 366/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6575 - accuracy: 0.5983 - val_loss: 0.6705 - val_accuracy: 0.5340\n",
      "Epoch 367/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6574 - accuracy: 0.5981 - val_loss: 0.6655 - val_accuracy: 0.5417\n",
      "Epoch 368/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6573 - accuracy: 0.5976 - val_loss: 0.6682 - val_accuracy: 0.5353\n",
      "Epoch 369/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6572 - accuracy: 0.5980 - val_loss: 0.6688 - val_accuracy: 0.5356\n",
      "Epoch 370/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6572 - accuracy: 0.5984 - val_loss: 0.6650 - val_accuracy: 0.5442\n",
      "Epoch 371/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6571 - accuracy: 0.5985 - val_loss: 0.6700 - val_accuracy: 0.5325\n",
      "Epoch 372/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6571 - accuracy: 0.5979 - val_loss: 0.6661 - val_accuracy: 0.5420\n",
      "Epoch 373/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6570 - accuracy: 0.5976 - val_loss: 0.6673 - val_accuracy: 0.5384\n",
      "Epoch 374/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6569 - accuracy: 0.5979 - val_loss: 0.6693 - val_accuracy: 0.5347\n",
      "Epoch 375/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6569 - accuracy: 0.5980 - val_loss: 0.6650 - val_accuracy: 0.5449\n",
      "Epoch 376/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6568 - accuracy: 0.5990 - val_loss: 0.6691 - val_accuracy: 0.5347\n",
      "Epoch 377/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6568 - accuracy: 0.5985 - val_loss: 0.6662 - val_accuracy: 0.5415\n",
      "Epoch 378/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6567 - accuracy: 0.5990 - val_loss: 0.6671 - val_accuracy: 0.5387\n",
      "Epoch 379/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6566 - accuracy: 0.5987 - val_loss: 0.6681 - val_accuracy: 0.5364\n",
      "Epoch 380/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6566 - accuracy: 0.5987 - val_loss: 0.6651 - val_accuracy: 0.5435\n",
      "Epoch 381/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6565 - accuracy: 0.5992 - val_loss: 0.6693 - val_accuracy: 0.5345\n",
      "Epoch 382/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6565 - accuracy: 0.5988 - val_loss: 0.6642 - val_accuracy: 0.5471\n",
      "Epoch 383/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6564 - accuracy: 0.5993 - val_loss: 0.6694 - val_accuracy: 0.5343\n",
      "Epoch 384/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6564 - accuracy: 0.5991 - val_loss: 0.6642 - val_accuracy: 0.5448\n",
      "Epoch 385/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6563 - accuracy: 0.5990 - val_loss: 0.6688 - val_accuracy: 0.5360\n",
      "Epoch 386/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6562 - accuracy: 0.5994 - val_loss: 0.6644 - val_accuracy: 0.5442\n",
      "Epoch 387/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6562 - accuracy: 0.5996 - val_loss: 0.6681 - val_accuracy: 0.5360\n",
      "Epoch 388/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6561 - accuracy: 0.5996 - val_loss: 0.6646 - val_accuracy: 0.5426\n",
      "Epoch 389/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6560 - accuracy: 0.5999 - val_loss: 0.6688 - val_accuracy: 0.5354\n",
      "Epoch 390/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6560 - accuracy: 0.6001 - val_loss: 0.6637 - val_accuracy: 0.5444\n",
      "Epoch 391/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6559 - accuracy: 0.6006 - val_loss: 0.6697 - val_accuracy: 0.5338\n",
      "Epoch 392/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6559 - accuracy: 0.6006 - val_loss: 0.6617 - val_accuracy: 0.5466\n",
      "Epoch 393/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6558 - accuracy: 0.6005 - val_loss: 0.6727 - val_accuracy: 0.5280\n",
      "Epoch 394/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6558 - accuracy: 0.6011 - val_loss: 0.6587 - val_accuracy: 0.5535\n",
      "Epoch 395/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6558 - accuracy: 0.6002 - val_loss: 0.6771 - val_accuracy: 0.5186\n",
      "Epoch 396/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6559 - accuracy: 0.6015 - val_loss: 0.6533 - val_accuracy: 0.5599\n",
      "Epoch 397/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6561 - accuracy: 0.5992 - val_loss: 0.6849 - val_accuracy: 0.5009\n",
      "Epoch 398/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6565 - accuracy: 0.6000 - val_loss: 0.6495 - val_accuracy: 0.5663\n",
      "Epoch 399/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6563 - accuracy: 0.5998 - val_loss: 0.6849 - val_accuracy: 0.5016\n",
      "Epoch 400/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6564 - accuracy: 0.6000 - val_loss: 0.6537 - val_accuracy: 0.5605\n",
      "Epoch 401/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6557 - accuracy: 0.5994 - val_loss: 0.6713 - val_accuracy: 0.5289\n",
      "Epoch 402/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6553 - accuracy: 0.6022 - val_loss: 0.6649 - val_accuracy: 0.5418\n",
      "Epoch 403/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6551 - accuracy: 0.6017 - val_loss: 0.6596 - val_accuracy: 0.5473\n",
      "Epoch 404/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6551 - accuracy: 0.6013 - val_loss: 0.6753 - val_accuracy: 0.5203\n",
      "Epoch 405/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6554 - accuracy: 0.6021 - val_loss: 0.6516 - val_accuracy: 0.5658\n",
      "Epoch 406/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6555 - accuracy: 0.6000 - val_loss: 0.6846 - val_accuracy: 0.5004\n",
      "Epoch 407/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6560 - accuracy: 0.6009 - val_loss: 0.6487 - val_accuracy: 0.5689\n",
      "Epoch 408/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6558 - accuracy: 0.6011 - val_loss: 0.6835 - val_accuracy: 0.5037\n",
      "Epoch 409/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6558 - accuracy: 0.6012 - val_loss: 0.6549 - val_accuracy: 0.5559\n",
      "Epoch 410/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6550 - accuracy: 0.6009 - val_loss: 0.6668 - val_accuracy: 0.5364\n",
      "Epoch 411/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6546 - accuracy: 0.6029 - val_loss: 0.6692 - val_accuracy: 0.5327\n",
      "Epoch 412/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6547 - accuracy: 0.6040 - val_loss: 0.6531 - val_accuracy: 0.5592\n",
      "Epoch 413/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6549 - accuracy: 0.6013 - val_loss: 0.6847 - val_accuracy: 0.5016\n",
      "Epoch 414/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6557 - accuracy: 0.6016 - val_loss: 0.6451 - val_accuracy: 0.5744\n",
      "Epoch 415/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6557 - accuracy: 0.6008 - val_loss: 0.6884 - val_accuracy: 0.4949\n",
      "Epoch 416/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6560 - accuracy: 0.6010 - val_loss: 0.6528 - val_accuracy: 0.5616\n",
      "Epoch 417/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6548 - accuracy: 0.6021 - val_loss: 0.6669 - val_accuracy: 0.5345\n",
      "Epoch 418/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6543 - accuracy: 0.6040 - val_loss: 0.6702 - val_accuracy: 0.5294\n",
      "Epoch 419/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6543 - accuracy: 0.6040 - val_loss: 0.6515 - val_accuracy: 0.5639\n",
      "Epoch 420/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6546 - accuracy: 0.6015 - val_loss: 0.6841 - val_accuracy: 0.5015\n",
      "Epoch 421/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6552 - accuracy: 0.6020 - val_loss: 0.6463 - val_accuracy: 0.5742\n",
      "Epoch 422/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6550 - accuracy: 0.6016 - val_loss: 0.6841 - val_accuracy: 0.5002\n",
      "Epoch 423/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6551 - accuracy: 0.6027 - val_loss: 0.6536 - val_accuracy: 0.5568\n",
      "Epoch 424/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6542 - accuracy: 0.6024 - val_loss: 0.6672 - val_accuracy: 0.5329\n",
      "Epoch 425/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6538 - accuracy: 0.6049 - val_loss: 0.6689 - val_accuracy: 0.5294\n",
      "Epoch 426/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6538 - accuracy: 0.6052 - val_loss: 0.6522 - val_accuracy: 0.5596\n",
      "Epoch 427/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6541 - accuracy: 0.6022 - val_loss: 0.6842 - val_accuracy: 0.5015\n",
      "Epoch 428/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6548 - accuracy: 0.6033 - val_loss: 0.6438 - val_accuracy: 0.5776\n",
      "Epoch 429/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6549 - accuracy: 0.6011 - val_loss: 0.6898 - val_accuracy: 0.4889\n",
      "Epoch 430/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6554 - accuracy: 0.6020 - val_loss: 0.6485 - val_accuracy: 0.5672\n",
      "Epoch 431/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6542 - accuracy: 0.6028 - val_loss: 0.6740 - val_accuracy: 0.5208\n",
      "Epoch 432/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6537 - accuracy: 0.6060 - val_loss: 0.6629 - val_accuracy: 0.5404\n",
      "Epoch 433/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6533 - accuracy: 0.6054 - val_loss: 0.6537 - val_accuracy: 0.5574\n",
      "Epoch 434/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6534 - accuracy: 0.6029 - val_loss: 0.6811 - val_accuracy: 0.5064\n",
      "Epoch 435/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6541 - accuracy: 0.6042 - val_loss: 0.6436 - val_accuracy: 0.5798\n",
      "Epoch 436/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6544 - accuracy: 0.6016 - val_loss: 0.6903 - val_accuracy: 0.4901\n",
      "Epoch 437/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6551 - accuracy: 0.6029 - val_loss: 0.6479 - val_accuracy: 0.5681\n",
      "Epoch 438/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6539 - accuracy: 0.6030 - val_loss: 0.6703 - val_accuracy: 0.5256\n",
      "Epoch 439/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6531 - accuracy: 0.6067 - val_loss: 0.6685 - val_accuracy: 0.5292\n",
      "Epoch 440/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6530 - accuracy: 0.6070 - val_loss: 0.6489 - val_accuracy: 0.5659\n",
      "Epoch 441/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6535 - accuracy: 0.6030 - val_loss: 0.6871 - val_accuracy: 0.4958\n",
      "Epoch 442/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6546 - accuracy: 0.6032 - val_loss: 0.6423 - val_accuracy: 0.5802\n",
      "Epoch 443/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6542 - accuracy: 0.6008 - val_loss: 0.6796 - val_accuracy: 0.5097\n",
      "Epoch 444/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6535 - accuracy: 0.6054 - val_loss: 0.6571 - val_accuracy: 0.5519\n",
      "Epoch 445/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6528 - accuracy: 0.6058 - val_loss: 0.6606 - val_accuracy: 0.5451\n",
      "Epoch 446/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6526 - accuracy: 0.6059 - val_loss: 0.6730 - val_accuracy: 0.5219\n",
      "Epoch 447/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6528 - accuracy: 0.6072 - val_loss: 0.6491 - val_accuracy: 0.5661\n",
      "Epoch 448/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6530 - accuracy: 0.6037 - val_loss: 0.6783 - val_accuracy: 0.5102\n",
      "Epoch 449/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6531 - accuracy: 0.6066 - val_loss: 0.6493 - val_accuracy: 0.5676\n",
      "Epoch 450/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6529 - accuracy: 0.6047 - val_loss: 0.6758 - val_accuracy: 0.5153\n",
      "Epoch 451/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6527 - accuracy: 0.6074 - val_loss: 0.6538 - val_accuracy: 0.5585\n",
      "Epoch 452/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6525 - accuracy: 0.6059 - val_loss: 0.6687 - val_accuracy: 0.5272\n",
      "Epoch 453/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6522 - accuracy: 0.6078 - val_loss: 0.6612 - val_accuracy: 0.5435\n",
      "Epoch 454/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6520 - accuracy: 0.6076 - val_loss: 0.6593 - val_accuracy: 0.5475\n",
      "Epoch 455/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6520 - accuracy: 0.6082 - val_loss: 0.6694 - val_accuracy: 0.5267\n",
      "Epoch 456/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6520 - accuracy: 0.6086 - val_loss: 0.6506 - val_accuracy: 0.5628\n",
      "Epoch 457/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6523 - accuracy: 0.6058 - val_loss: 0.6832 - val_accuracy: 0.5040\n",
      "Epoch 458/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6530 - accuracy: 0.6070 - val_loss: 0.6424 - val_accuracy: 0.5822\n",
      "Epoch 459/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6532 - accuracy: 0.6039 - val_loss: 0.6922 - val_accuracy: 0.4879\n",
      "Epoch 460/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6541 - accuracy: 0.6048 - val_loss: 0.6449 - val_accuracy: 0.5762\n",
      "Epoch 461/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6528 - accuracy: 0.6045 - val_loss: 0.6752 - val_accuracy: 0.5177\n",
      "Epoch 462/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6521 - accuracy: 0.6084 - val_loss: 0.6600 - val_accuracy: 0.5482\n",
      "Epoch 463/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6515 - accuracy: 0.6077 - val_loss: 0.6550 - val_accuracy: 0.5575\n",
      "Epoch 464/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6516 - accuracy: 0.6068 - val_loss: 0.6790 - val_accuracy: 0.5106\n",
      "Epoch 465/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6523 - accuracy: 0.6080 - val_loss: 0.6392 - val_accuracy: 0.5888\n",
      "Epoch 466/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6531 - accuracy: 0.6033 - val_loss: 0.6982 - val_accuracy: 0.4794\n",
      "Epoch 467/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6549 - accuracy: 0.6038 - val_loss: 0.6447 - val_accuracy: 0.5744\n",
      "Epoch 468/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6526 - accuracy: 0.6049 - val_loss: 0.6665 - val_accuracy: 0.5331\n",
      "Epoch 469/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6513 - accuracy: 0.6085 - val_loss: 0.6725 - val_accuracy: 0.5197\n",
      "Epoch 470/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6516 - accuracy: 0.6101 - val_loss: 0.6425 - val_accuracy: 0.5815\n",
      "Epoch 471/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6525 - accuracy: 0.6038 - val_loss: 0.6932 - val_accuracy: 0.4863\n",
      "Epoch 472/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6542 - accuracy: 0.6048 - val_loss: 0.6420 - val_accuracy: 0.5798\n",
      "Epoch 473/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6526 - accuracy: 0.6030 - val_loss: 0.6669 - val_accuracy: 0.5309\n",
      "Epoch 474/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6511 - accuracy: 0.6097 - val_loss: 0.6686 - val_accuracy: 0.5265\n",
      "Epoch 475/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6513 - accuracy: 0.6100 - val_loss: 0.6473 - val_accuracy: 0.5703\n",
      "Epoch 476/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6520 - accuracy: 0.6054 - val_loss: 0.6885 - val_accuracy: 0.4942\n",
      "Epoch 477/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6530 - accuracy: 0.6069 - val_loss: 0.6425 - val_accuracy: 0.5817\n",
      "Epoch 478/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6524 - accuracy: 0.6045 - val_loss: 0.6690 - val_accuracy: 0.5296\n",
      "Epoch 479/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6511 - accuracy: 0.6097 - val_loss: 0.6633 - val_accuracy: 0.5365\n",
      "Epoch 480/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6508 - accuracy: 0.6095 - val_loss: 0.6487 - val_accuracy: 0.5689\n",
      "Epoch 481/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6515 - accuracy: 0.6058 - val_loss: 0.6878 - val_accuracy: 0.4934\n",
      "Epoch 482/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6526 - accuracy: 0.6075 - val_loss: 0.6389 - val_accuracy: 0.5849\n",
      "Epoch 483/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6525 - accuracy: 0.6033 - val_loss: 0.6812 - val_accuracy: 0.5079\n",
      "Epoch 484/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6518 - accuracy: 0.6095 - val_loss: 0.6566 - val_accuracy: 0.5532\n",
      "Epoch 485/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6506 - accuracy: 0.6081 - val_loss: 0.6496 - val_accuracy: 0.5685\n",
      "Epoch 486/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6509 - accuracy: 0.6073 - val_loss: 0.6894 - val_accuracy: 0.4901\n",
      "Epoch 487/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6526 - accuracy: 0.6078 - val_loss: 0.6379 - val_accuracy: 0.5891\n",
      "Epoch 488/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6523 - accuracy: 0.6037 - val_loss: 0.6841 - val_accuracy: 0.5033\n",
      "Epoch 489/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6519 - accuracy: 0.6095 - val_loss: 0.6530 - val_accuracy: 0.5616\n",
      "Epoch 490/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6505 - accuracy: 0.6086 - val_loss: 0.6523 - val_accuracy: 0.5628\n",
      "Epoch 491/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6505 - accuracy: 0.6073 - val_loss: 0.6833 - val_accuracy: 0.5002\n",
      "Epoch 492/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6515 - accuracy: 0.6096 - val_loss: 0.6418 - val_accuracy: 0.5824\n",
      "Epoch 493/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6516 - accuracy: 0.6060 - val_loss: 0.6830 - val_accuracy: 0.5046\n",
      "Epoch 494/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6515 - accuracy: 0.6099 - val_loss: 0.6492 - val_accuracy: 0.5709\n",
      "Epoch 495/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6505 - accuracy: 0.6085 - val_loss: 0.6579 - val_accuracy: 0.5491\n",
      "Epoch 496/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6500 - accuracy: 0.6098 - val_loss: 0.6739 - val_accuracy: 0.5172\n",
      "Epoch 497/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6504 - accuracy: 0.6114 - val_loss: 0.6449 - val_accuracy: 0.5776\n",
      "Epoch 498/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6511 - accuracy: 0.6070 - val_loss: 0.6878 - val_accuracy: 0.4940\n",
      "Epoch 499/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6518 - accuracy: 0.6094 - val_loss: 0.6434 - val_accuracy: 0.5806\n",
      "Epoch 500/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6509 - accuracy: 0.6063 - val_loss: 0.6681 - val_accuracy: 0.5311\n",
      "Epoch 501/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6500 - accuracy: 0.6109 - val_loss: 0.6651 - val_accuracy: 0.5365\n",
      "Epoch 502/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6497 - accuracy: 0.6122 - val_loss: 0.6470 - val_accuracy: 0.5754\n",
      "Epoch 503/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6504 - accuracy: 0.6077 - val_loss: 0.6884 - val_accuracy: 0.4931\n",
      "Epoch 504/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6517 - accuracy: 0.6098 - val_loss: 0.6380 - val_accuracy: 0.5899\n",
      "Epoch 505/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6513 - accuracy: 0.6058 - val_loss: 0.6806 - val_accuracy: 0.5095\n",
      "Epoch 506/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6507 - accuracy: 0.6112 - val_loss: 0.6546 - val_accuracy: 0.5586\n",
      "Epoch 507/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6496 - accuracy: 0.6099 - val_loss: 0.6533 - val_accuracy: 0.5603\n",
      "Epoch 508/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6496 - accuracy: 0.6092 - val_loss: 0.6812 - val_accuracy: 0.5060\n",
      "Epoch 509/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6505 - accuracy: 0.6112 - val_loss: 0.6396 - val_accuracy: 0.5868\n",
      "Epoch 510/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6508 - accuracy: 0.6071 - val_loss: 0.6857 - val_accuracy: 0.5009\n",
      "Epoch 511/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6512 - accuracy: 0.6097 - val_loss: 0.6460 - val_accuracy: 0.5765\n",
      "Epoch 512/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6499 - accuracy: 0.6084 - val_loss: 0.6616 - val_accuracy: 0.5418\n",
      "Epoch 513/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6491 - accuracy: 0.6116 - val_loss: 0.6710 - val_accuracy: 0.5259\n",
      "Epoch 514/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6494 - accuracy: 0.6134 - val_loss: 0.6445 - val_accuracy: 0.5775\n",
      "Epoch 515/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6501 - accuracy: 0.6083 - val_loss: 0.6877 - val_accuracy: 0.4962\n",
      "Epoch 516/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6512 - accuracy: 0.6099 - val_loss: 0.6398 - val_accuracy: 0.5886\n",
      "Epoch 517/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6504 - accuracy: 0.6066 - val_loss: 0.6725 - val_accuracy: 0.5241\n",
      "Epoch 518/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6494 - accuracy: 0.6129 - val_loss: 0.6600 - val_accuracy: 0.5475\n",
      "Epoch 519/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6489 - accuracy: 0.6115 - val_loss: 0.6517 - val_accuracy: 0.5639\n",
      "Epoch 520/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6493 - accuracy: 0.6098 - val_loss: 0.6824 - val_accuracy: 0.5060\n",
      "Epoch 521/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6503 - accuracy: 0.6125 - val_loss: 0.6365 - val_accuracy: 0.5926\n",
      "Epoch 522/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6506 - accuracy: 0.6061 - val_loss: 0.6850 - val_accuracy: 0.5027\n",
      "Epoch 523/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6507 - accuracy: 0.6108 - val_loss: 0.6487 - val_accuracy: 0.5689\n",
      "Epoch 524/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6491 - accuracy: 0.6093 - val_loss: 0.6603 - val_accuracy: 0.5469\n",
      "Epoch 525/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6487 - accuracy: 0.6112 - val_loss: 0.6721 - val_accuracy: 0.5248\n",
      "Epoch 526/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6490 - accuracy: 0.6134 - val_loss: 0.6417 - val_accuracy: 0.5831\n",
      "Epoch 527/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6496 - accuracy: 0.6077 - val_loss: 0.6853 - val_accuracy: 0.5022\n",
      "Epoch 528/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6505 - accuracy: 0.6112 - val_loss: 0.6419 - val_accuracy: 0.5828\n",
      "Epoch 529/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6495 - accuracy: 0.6078 - val_loss: 0.6716 - val_accuracy: 0.5261\n",
      "Epoch 530/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6488 - accuracy: 0.6139 - val_loss: 0.6596 - val_accuracy: 0.5499\n",
      "Epoch 531/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6484 - accuracy: 0.6118 - val_loss: 0.6524 - val_accuracy: 0.5634\n",
      "Epoch 532/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6485 - accuracy: 0.6102 - val_loss: 0.6759 - val_accuracy: 0.5166\n",
      "Epoch 533/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6491 - accuracy: 0.6135 - val_loss: 0.6408 - val_accuracy: 0.5866\n",
      "Epoch 534/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6494 - accuracy: 0.6076 - val_loss: 0.6821 - val_accuracy: 0.5071\n",
      "Epoch 535/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6497 - accuracy: 0.6124 - val_loss: 0.6443 - val_accuracy: 0.5764\n",
      "Epoch 536/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6491 - accuracy: 0.6090 - val_loss: 0.6741 - val_accuracy: 0.5201\n",
      "Epoch 537/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6487 - accuracy: 0.6136 - val_loss: 0.6545 - val_accuracy: 0.5588\n",
      "Epoch 538/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6482 - accuracy: 0.6114 - val_loss: 0.6573 - val_accuracy: 0.5539\n",
      "Epoch 539/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6481 - accuracy: 0.6132 - val_loss: 0.6683 - val_accuracy: 0.5318\n",
      "Epoch 540/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6483 - accuracy: 0.6140 - val_loss: 0.6459 - val_accuracy: 0.5775\n",
      "Epoch 541/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6486 - accuracy: 0.6091 - val_loss: 0.6822 - val_accuracy: 0.5064\n",
      "Epoch 542/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6495 - accuracy: 0.6127 - val_loss: 0.6385 - val_accuracy: 0.5891\n",
      "Epoch 543/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6495 - accuracy: 0.6082 - val_loss: 0.6859 - val_accuracy: 0.5027\n",
      "Epoch 544/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6499 - accuracy: 0.6122 - val_loss: 0.6466 - val_accuracy: 0.5731\n",
      "Epoch 545/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6485 - accuracy: 0.6103 - val_loss: 0.6632 - val_accuracy: 0.5426\n",
      "Epoch 546/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6479 - accuracy: 0.6144 - val_loss: 0.6662 - val_accuracy: 0.5367\n",
      "Epoch 547/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6479 - accuracy: 0.6139 - val_loss: 0.6448 - val_accuracy: 0.5809\n",
      "Epoch 548/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6485 - accuracy: 0.6098 - val_loss: 0.6857 - val_accuracy: 0.5018\n",
      "Epoch 549/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6498 - accuracy: 0.6118 - val_loss: 0.6355 - val_accuracy: 0.5972\n",
      "Epoch 550/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6497 - accuracy: 0.6075 - val_loss: 0.6864 - val_accuracy: 0.5015\n",
      "Epoch 551/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6497 - accuracy: 0.6124 - val_loss: 0.6499 - val_accuracy: 0.5674\n",
      "Epoch 552/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6481 - accuracy: 0.6108 - val_loss: 0.6581 - val_accuracy: 0.5530\n",
      "Epoch 553/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6477 - accuracy: 0.6129 - val_loss: 0.6740 - val_accuracy: 0.5186\n",
      "Epoch 554/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6482 - accuracy: 0.6146 - val_loss: 0.6383 - val_accuracy: 0.5904\n",
      "Epoch 555/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6490 - accuracy: 0.6084 - val_loss: 0.6895 - val_accuracy: 0.4947\n",
      "Epoch 556/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6503 - accuracy: 0.6105 - val_loss: 0.6388 - val_accuracy: 0.5901\n",
      "Epoch 557/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6488 - accuracy: 0.6084 - val_loss: 0.6721 - val_accuracy: 0.5228\n",
      "Epoch 558/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6479 - accuracy: 0.6148 - val_loss: 0.6601 - val_accuracy: 0.5495\n",
      "Epoch 559/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6475 - accuracy: 0.6130 - val_loss: 0.6495 - val_accuracy: 0.5701\n",
      "Epoch 560/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6477 - accuracy: 0.6111 - val_loss: 0.6797 - val_accuracy: 0.5110\n",
      "Epoch 561/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6487 - accuracy: 0.6140 - val_loss: 0.6381 - val_accuracy: 0.5919\n",
      "Epoch 562/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6487 - accuracy: 0.6084 - val_loss: 0.6792 - val_accuracy: 0.5115\n",
      "Epoch 563/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6485 - accuracy: 0.6140 - val_loss: 0.6494 - val_accuracy: 0.5705\n",
      "Epoch 564/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6476 - accuracy: 0.6115 - val_loss: 0.6630 - val_accuracy: 0.5427\n",
      "Epoch 565/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6472 - accuracy: 0.6146 - val_loss: 0.6641 - val_accuracy: 0.5406\n",
      "Epoch 566/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6472 - accuracy: 0.6155 - val_loss: 0.6480 - val_accuracy: 0.5729\n",
      "Epoch 567/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6475 - accuracy: 0.6114 - val_loss: 0.6755 - val_accuracy: 0.5185\n",
      "Epoch 568/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6480 - accuracy: 0.6148 - val_loss: 0.6413 - val_accuracy: 0.5853\n",
      "Epoch 569/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6481 - accuracy: 0.6105 - val_loss: 0.6821 - val_accuracy: 0.5084\n",
      "Epoch 570/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6486 - accuracy: 0.6143 - val_loss: 0.6432 - val_accuracy: 0.5798\n",
      "Epoch 571/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6479 - accuracy: 0.6107 - val_loss: 0.6717 - val_accuracy: 0.5237\n",
      "Epoch 572/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6474 - accuracy: 0.6151 - val_loss: 0.6567 - val_accuracy: 0.5566\n",
      "Epoch 573/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6470 - accuracy: 0.6140 - val_loss: 0.6551 - val_accuracy: 0.5579\n",
      "Epoch 574/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6469 - accuracy: 0.6137 - val_loss: 0.6711 - val_accuracy: 0.5252\n",
      "Epoch 575/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6473 - accuracy: 0.6156 - val_loss: 0.6416 - val_accuracy: 0.5851\n",
      "Epoch 576/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6478 - accuracy: 0.6105 - val_loss: 0.6844 - val_accuracy: 0.5055\n",
      "Epoch 577/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6487 - accuracy: 0.6136 - val_loss: 0.6397 - val_accuracy: 0.5868\n",
      "Epoch 578/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6481 - accuracy: 0.6100 - val_loss: 0.6775 - val_accuracy: 0.5168\n",
      "Epoch 579/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6477 - accuracy: 0.6147 - val_loss: 0.6522 - val_accuracy: 0.5645\n",
      "Epoch 580/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6469 - accuracy: 0.6126 - val_loss: 0.6590 - val_accuracy: 0.5541\n",
      "Epoch 581/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6467 - accuracy: 0.6153 - val_loss: 0.6669 - val_accuracy: 0.5343\n",
      "Epoch 582/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6469 - accuracy: 0.6159 - val_loss: 0.6439 - val_accuracy: 0.5782\n",
      "Epoch 583/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6473 - accuracy: 0.6111 - val_loss: 0.6825 - val_accuracy: 0.5088\n",
      "Epoch 584/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6482 - accuracy: 0.6143 - val_loss: 0.6386 - val_accuracy: 0.5897\n",
      "Epoch 585/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6481 - accuracy: 0.6096 - val_loss: 0.6831 - val_accuracy: 0.5082\n",
      "Epoch 586/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6482 - accuracy: 0.6147 - val_loss: 0.6477 - val_accuracy: 0.5714\n",
      "Epoch 587/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6470 - accuracy: 0.6115 - val_loss: 0.6603 - val_accuracy: 0.5504\n",
      "Epoch 588/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6465 - accuracy: 0.6159 - val_loss: 0.6675 - val_accuracy: 0.5316\n",
      "Epoch 589/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6467 - accuracy: 0.6159 - val_loss: 0.6412 - val_accuracy: 0.5842\n",
      "Epoch 590/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6475 - accuracy: 0.6109 - val_loss: 0.6880 - val_accuracy: 0.4991\n",
      "Epoch 591/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6490 - accuracy: 0.6130 - val_loss: 0.6366 - val_accuracy: 0.5934\n",
      "Epoch 592/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6482 - accuracy: 0.6092 - val_loss: 0.6781 - val_accuracy: 0.5161\n",
      "Epoch 593/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6474 - accuracy: 0.6151 - val_loss: 0.6551 - val_accuracy: 0.5588\n",
      "Epoch 594/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6465 - accuracy: 0.6139 - val_loss: 0.6536 - val_accuracy: 0.5616\n",
      "Epoch 595/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6464 - accuracy: 0.6141 - val_loss: 0.6738 - val_accuracy: 0.5230\n",
      "Epoch 596/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6471 - accuracy: 0.6151 - val_loss: 0.6376 - val_accuracy: 0.5904\n",
      "Epoch 597/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6477 - accuracy: 0.6098 - val_loss: 0.6847 - val_accuracy: 0.5027\n",
      "Epoch 598/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6482 - accuracy: 0.6140 - val_loss: 0.6425 - val_accuracy: 0.5776\n",
      "Epoch 599/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6473 - accuracy: 0.6111 - val_loss: 0.6721 - val_accuracy: 0.5243\n",
      "Epoch 600/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6467 - accuracy: 0.6155 - val_loss: 0.6564 - val_accuracy: 0.5566\n",
      "Epoch 601/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6462 - accuracy: 0.6151 - val_loss: 0.6513 - val_accuracy: 0.5639\n",
      "Epoch 602/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6462 - accuracy: 0.6140 - val_loss: 0.6746 - val_accuracy: 0.5177\n",
      "Epoch 603/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6469 - accuracy: 0.6157 - val_loss: 0.6381 - val_accuracy: 0.5875\n",
      "Epoch 604/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6475 - accuracy: 0.6102 - val_loss: 0.6872 - val_accuracy: 0.5009\n",
      "Epoch 605/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6485 - accuracy: 0.6128 - val_loss: 0.6407 - val_accuracy: 0.5853\n",
      "Epoch 606/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6473 - accuracy: 0.6103 - val_loss: 0.6667 - val_accuracy: 0.5349\n",
      "Epoch 607/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6462 - accuracy: 0.6166 - val_loss: 0.6658 - val_accuracy: 0.5364\n",
      "Epoch 608/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6462 - accuracy: 0.6151 - val_loss: 0.6449 - val_accuracy: 0.5762\n",
      "Epoch 609/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6467 - accuracy: 0.6125 - val_loss: 0.6828 - val_accuracy: 0.5088\n",
      "Epoch 610/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6480 - accuracy: 0.6143 - val_loss: 0.6360 - val_accuracy: 0.5954\n",
      "Epoch 611/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6477 - accuracy: 0.6089 - val_loss: 0.6750 - val_accuracy: 0.5208\n",
      "Epoch 612/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6466 - accuracy: 0.6163 - val_loss: 0.6547 - val_accuracy: 0.5596\n",
      "Epoch 613/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6463 - accuracy: 0.6140 - val_loss: 0.6623 - val_accuracy: 0.5418\n",
      "Epoch 614/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6459 - accuracy: 0.6161 - val_loss: 0.6614 - val_accuracy: 0.5442\n",
      "Epoch 615/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6459 - accuracy: 0.6164 - val_loss: 0.6489 - val_accuracy: 0.5650\n",
      "Epoch 616/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6461 - accuracy: 0.6138 - val_loss: 0.6689 - val_accuracy: 0.5278\n",
      "Epoch 617/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6461 - accuracy: 0.6165 - val_loss: 0.6477 - val_accuracy: 0.5718\n",
      "Epoch 618/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6464 - accuracy: 0.6127 - val_loss: 0.6789 - val_accuracy: 0.5113\n",
      "Epoch 619/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6468 - accuracy: 0.6164 - val_loss: 0.6389 - val_accuracy: 0.5864\n",
      "Epoch 620/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6471 - accuracy: 0.6103 - val_loss: 0.6801 - val_accuracy: 0.5152\n",
      "Epoch 621/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6471 - accuracy: 0.6159 - val_loss: 0.6499 - val_accuracy: 0.5689\n",
      "Epoch 622/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6458 - accuracy: 0.6145 - val_loss: 0.6577 - val_accuracy: 0.5561\n",
      "Epoch 623/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6456 - accuracy: 0.6157 - val_loss: 0.6717 - val_accuracy: 0.5237\n",
      "Epoch 624/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6460 - accuracy: 0.6168 - val_loss: 0.6374 - val_accuracy: 0.5890\n",
      "Epoch 625/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6470 - accuracy: 0.6104 - val_loss: 0.6905 - val_accuracy: 0.4982\n",
      "Epoch 626/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6486 - accuracy: 0.6125 - val_loss: 0.6398 - val_accuracy: 0.5851\n",
      "Epoch 627/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6469 - accuracy: 0.6104 - val_loss: 0.6657 - val_accuracy: 0.5389\n",
      "Epoch 628/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6456 - accuracy: 0.6169 - val_loss: 0.6675 - val_accuracy: 0.5338\n",
      "Epoch 629/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6457 - accuracy: 0.6162 - val_loss: 0.6440 - val_accuracy: 0.5754\n",
      "Epoch 630/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6462 - accuracy: 0.6126 - val_loss: 0.6828 - val_accuracy: 0.5110\n",
      "Epoch 631/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6476 - accuracy: 0.6145 - val_loss: 0.6367 - val_accuracy: 0.5913\n",
      "Epoch 632/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6472 - accuracy: 0.6101 - val_loss: 0.6728 - val_accuracy: 0.5210\n",
      "Epoch 633/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6459 - accuracy: 0.6171 - val_loss: 0.6568 - val_accuracy: 0.5574\n",
      "Epoch 634/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6460 - accuracy: 0.6148 - val_loss: 0.6630 - val_accuracy: 0.5409\n",
      "Epoch 635/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6454 - accuracy: 0.6164 - val_loss: 0.6587 - val_accuracy: 0.5510\n",
      "Epoch 636/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6454 - accuracy: 0.6173 - val_loss: 0.6492 - val_accuracy: 0.5649\n",
      "Epoch 637/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6457 - accuracy: 0.6149 - val_loss: 0.6680 - val_accuracy: 0.5314\n",
      "Epoch 638/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6455 - accuracy: 0.6170 - val_loss: 0.6464 - val_accuracy: 0.5718\n",
      "Epoch 639/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6462 - accuracy: 0.6125 - val_loss: 0.6846 - val_accuracy: 0.5027\n",
      "Epoch 640/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6470 - accuracy: 0.6148 - val_loss: 0.6364 - val_accuracy: 0.5888\n",
      "Epoch 641/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6471 - accuracy: 0.6109 - val_loss: 0.6798 - val_accuracy: 0.5142\n",
      "Epoch 642/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6467 - accuracy: 0.6162 - val_loss: 0.6531 - val_accuracy: 0.5641\n",
      "Epoch 643/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6452 - accuracy: 0.6162 - val_loss: 0.6479 - val_accuracy: 0.5714\n",
      "Epoch 644/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6456 - accuracy: 0.6139 - val_loss: 0.6887 - val_accuracy: 0.4954\n",
      "Epoch 645/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6476 - accuracy: 0.6139 - val_loss: 0.6298 - val_accuracy: 0.6007\n",
      "Epoch 646/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6479 - accuracy: 0.6083 - val_loss: 0.6917 - val_accuracy: 0.4969\n",
      "Epoch 647/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6485 - accuracy: 0.6130 - val_loss: 0.6507 - val_accuracy: 0.5643\n",
      "Epoch 648/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6457 - accuracy: 0.6154 - val_loss: 0.6415 - val_accuracy: 0.5787\n",
      "Epoch 649/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6462 - accuracy: 0.6121 - val_loss: 0.6989 - val_accuracy: 0.4788\n",
      "Epoch 650/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6493 - accuracy: 0.6104 - val_loss: 0.6385 - val_accuracy: 0.5835\n",
      "Epoch 651/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6472 - accuracy: 0.6101 - val_loss: 0.6681 - val_accuracy: 0.5329\n",
      "Epoch 652/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6455 - accuracy: 0.6164 - val_loss: 0.6571 - val_accuracy: 0.5519\n",
      "Epoch 653/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6457 - accuracy: 0.6154 - val_loss: 0.6459 - val_accuracy: 0.5722\n",
      "Epoch 654/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6455 - accuracy: 0.6135 - val_loss: 0.6737 - val_accuracy: 0.5164\n",
      "Epoch 655/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6457 - accuracy: 0.6167 - val_loss: 0.6507 - val_accuracy: 0.5623\n",
      "Epoch 656/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6461 - accuracy: 0.6137 - val_loss: 0.6703 - val_accuracy: 0.5243\n",
      "Epoch 657/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6453 - accuracy: 0.6172 - val_loss: 0.6446 - val_accuracy: 0.5751\n",
      "Epoch 658/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6457 - accuracy: 0.6132 - val_loss: 0.6634 - val_accuracy: 0.5438\n",
      "Epoch 659/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6452 - accuracy: 0.6170 - val_loss: 0.6588 - val_accuracy: 0.5519\n",
      "Epoch 660/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6447 - accuracy: 0.6169 - val_loss: 0.6536 - val_accuracy: 0.5597\n",
      "Epoch 661/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6453 - accuracy: 0.6151 - val_loss: 0.6753 - val_accuracy: 0.5155\n",
      "Epoch 662/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6455 - accuracy: 0.6173 - val_loss: 0.6400 - val_accuracy: 0.5846\n",
      "Epoch 663/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6458 - accuracy: 0.6122 - val_loss: 0.6738 - val_accuracy: 0.5230\n",
      "Epoch 664/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6456 - accuracy: 0.6169 - val_loss: 0.6528 - val_accuracy: 0.5638\n",
      "Epoch 665/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6447 - accuracy: 0.6159 - val_loss: 0.6532 - val_accuracy: 0.5634\n",
      "Epoch 666/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6448 - accuracy: 0.6147 - val_loss: 0.6765 - val_accuracy: 0.5146\n",
      "Epoch 667/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6455 - accuracy: 0.6173 - val_loss: 0.6377 - val_accuracy: 0.5868\n",
      "Epoch 668/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6460 - accuracy: 0.6118 - val_loss: 0.6808 - val_accuracy: 0.5108\n",
      "Epoch 669/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6462 - accuracy: 0.6161 - val_loss: 0.6483 - val_accuracy: 0.5676\n",
      "Epoch 670/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6449 - accuracy: 0.6150 - val_loss: 0.6542 - val_accuracy: 0.5605\n",
      "Epoch 671/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6446 - accuracy: 0.6162 - val_loss: 0.6773 - val_accuracy: 0.5133\n",
      "Epoch 672/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6455 - accuracy: 0.6172 - val_loss: 0.6376 - val_accuracy: 0.5860\n",
      "Epoch 673/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6461 - accuracy: 0.6111 - val_loss: 0.6854 - val_accuracy: 0.5042\n",
      "Epoch 674/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6469 - accuracy: 0.6153 - val_loss: 0.6450 - val_accuracy: 0.5769\n",
      "Epoch 675/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6454 - accuracy: 0.6137 - val_loss: 0.6542 - val_accuracy: 0.5599\n",
      "Epoch 676/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6445 - accuracy: 0.6170 - val_loss: 0.6786 - val_accuracy: 0.5128\n",
      "Epoch 677/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6456 - accuracy: 0.6168 - val_loss: 0.6398 - val_accuracy: 0.5813\n",
      "Epoch 678/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6465 - accuracy: 0.6110 - val_loss: 0.6875 - val_accuracy: 0.5018\n",
      "Epoch 679/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6471 - accuracy: 0.6147 - val_loss: 0.6401 - val_accuracy: 0.5853\n",
      "Epoch 680/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6464 - accuracy: 0.6115 - val_loss: 0.6579 - val_accuracy: 0.5524\n",
      "Epoch 681/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6445 - accuracy: 0.6177 - val_loss: 0.6730 - val_accuracy: 0.5225\n",
      "Epoch 682/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6452 - accuracy: 0.6167 - val_loss: 0.6454 - val_accuracy: 0.5716\n",
      "Epoch 683/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6463 - accuracy: 0.6121 - val_loss: 0.6855 - val_accuracy: 0.5024\n",
      "Epoch 684/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6465 - accuracy: 0.6153 - val_loss: 0.6360 - val_accuracy: 0.5890\n",
      "Epoch 685/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6468 - accuracy: 0.6107 - val_loss: 0.6661 - val_accuracy: 0.5385\n",
      "Epoch 686/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6448 - accuracy: 0.6174 - val_loss: 0.6652 - val_accuracy: 0.5365\n",
      "Epoch 687/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6445 - accuracy: 0.6177 - val_loss: 0.6446 - val_accuracy: 0.5723\n",
      "Epoch 688/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6460 - accuracy: 0.6124 - val_loss: 0.6908 - val_accuracy: 0.4931\n",
      "Epoch 689/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6472 - accuracy: 0.6136 - val_loss: 0.6357 - val_accuracy: 0.5901\n",
      "Epoch 690/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6462 - accuracy: 0.6114 - val_loss: 0.6617 - val_accuracy: 0.5433\n",
      "Epoch 691/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6446 - accuracy: 0.6175 - val_loss: 0.6709 - val_accuracy: 0.5239\n",
      "Epoch 692/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6446 - accuracy: 0.6182 - val_loss: 0.6378 - val_accuracy: 0.5824\n",
      "Epoch 693/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6466 - accuracy: 0.6107 - val_loss: 0.6955 - val_accuracy: 0.4896\n",
      "Epoch 694/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6480 - accuracy: 0.6129 - val_loss: 0.6418 - val_accuracy: 0.5815\n",
      "Epoch 695/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6453 - accuracy: 0.6133 - val_loss: 0.6460 - val_accuracy: 0.5736\n",
      "Epoch 696/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6447 - accuracy: 0.6143 - val_loss: 0.6876 - val_accuracy: 0.4980\n",
      "Epoch 697/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6465 - accuracy: 0.6151 - val_loss: 0.6388 - val_accuracy: 0.5813\n",
      "Epoch 698/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6464 - accuracy: 0.6110 - val_loss: 0.6761 - val_accuracy: 0.5141\n",
      "Epoch 699/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6450 - accuracy: 0.6178 - val_loss: 0.6526 - val_accuracy: 0.5590\n",
      "Epoch 700/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6444 - accuracy: 0.6172 - val_loss: 0.6453 - val_accuracy: 0.5747\n",
      "Epoch 701/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6446 - accuracy: 0.6144 - val_loss: 0.6777 - val_accuracy: 0.5122\n",
      "Epoch 702/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6450 - accuracy: 0.6175 - val_loss: 0.6465 - val_accuracy: 0.5689\n",
      "Epoch 703/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6451 - accuracy: 0.6136 - val_loss: 0.6682 - val_accuracy: 0.5294\n",
      "Epoch 704/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6442 - accuracy: 0.6187 - val_loss: 0.6544 - val_accuracy: 0.5585\n",
      "Epoch 705/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6440 - accuracy: 0.6175 - val_loss: 0.6498 - val_accuracy: 0.5649\n",
      "Epoch 706/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6442 - accuracy: 0.6161 - val_loss: 0.6698 - val_accuracy: 0.5265\n",
      "Epoch 707/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6442 - accuracy: 0.6189 - val_loss: 0.6481 - val_accuracy: 0.5680\n",
      "Epoch 708/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6446 - accuracy: 0.6153 - val_loss: 0.6726 - val_accuracy: 0.5223\n",
      "Epoch 709/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6443 - accuracy: 0.6189 - val_loss: 0.6496 - val_accuracy: 0.5676\n",
      "Epoch 710/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6440 - accuracy: 0.6166 - val_loss: 0.6583 - val_accuracy: 0.5519\n",
      "Epoch 711/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6438 - accuracy: 0.6184 - val_loss: 0.6634 - val_accuracy: 0.5418\n",
      "Epoch 712/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6438 - accuracy: 0.6190 - val_loss: 0.6491 - val_accuracy: 0.5676\n",
      "Epoch 713/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6441 - accuracy: 0.6158 - val_loss: 0.6738 - val_accuracy: 0.5208\n",
      "Epoch 714/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6443 - accuracy: 0.6189 - val_loss: 0.6457 - val_accuracy: 0.5733\n",
      "Epoch 715/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6441 - accuracy: 0.6152 - val_loss: 0.6654 - val_accuracy: 0.5380\n",
      "Epoch 716/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6439 - accuracy: 0.6180 - val_loss: 0.6582 - val_accuracy: 0.5521\n",
      "Epoch 717/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6436 - accuracy: 0.6189 - val_loss: 0.6518 - val_accuracy: 0.5634\n",
      "Epoch 718/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6438 - accuracy: 0.6166 - val_loss: 0.6736 - val_accuracy: 0.5212\n",
      "Epoch 719/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6442 - accuracy: 0.6197 - val_loss: 0.6435 - val_accuracy: 0.5762\n",
      "Epoch 720/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6443 - accuracy: 0.6149 - val_loss: 0.6729 - val_accuracy: 0.5265\n",
      "Epoch 721/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6443 - accuracy: 0.6182 - val_loss: 0.6502 - val_accuracy: 0.5685\n",
      "Epoch 722/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6437 - accuracy: 0.6167 - val_loss: 0.6590 - val_accuracy: 0.5526\n",
      "Epoch 723/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6434 - accuracy: 0.6186 - val_loss: 0.6668 - val_accuracy: 0.5364\n",
      "Epoch 724/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6436 - accuracy: 0.6198 - val_loss: 0.6473 - val_accuracy: 0.5696\n",
      "Epoch 725/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6438 - accuracy: 0.6162 - val_loss: 0.6729 - val_accuracy: 0.5254\n",
      "Epoch 726/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6442 - accuracy: 0.6185 - val_loss: 0.6449 - val_accuracy: 0.5742\n",
      "Epoch 727/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6440 - accuracy: 0.6156 - val_loss: 0.6671 - val_accuracy: 0.5354\n",
      "Epoch 728/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6435 - accuracy: 0.6188 - val_loss: 0.6569 - val_accuracy: 0.5572\n",
      "Epoch 729/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6434 - accuracy: 0.6176 - val_loss: 0.6577 - val_accuracy: 0.5550\n",
      "Epoch 730/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6433 - accuracy: 0.6180 - val_loss: 0.6635 - val_accuracy: 0.5431\n",
      "Epoch 731/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6434 - accuracy: 0.6186 - val_loss: 0.6487 - val_accuracy: 0.5691\n",
      "Epoch 732/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6435 - accuracy: 0.6168 - val_loss: 0.6684 - val_accuracy: 0.5323\n",
      "Epoch 733/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6435 - accuracy: 0.6191 - val_loss: 0.6500 - val_accuracy: 0.5669\n",
      "Epoch 734/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6436 - accuracy: 0.6166 - val_loss: 0.6694 - val_accuracy: 0.5305\n",
      "Epoch 735/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6435 - accuracy: 0.6194 - val_loss: 0.6499 - val_accuracy: 0.5681\n",
      "Epoch 736/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6434 - accuracy: 0.6169 - val_loss: 0.6643 - val_accuracy: 0.5406\n",
      "Epoch 737/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6433 - accuracy: 0.6190 - val_loss: 0.6543 - val_accuracy: 0.5590\n",
      "Epoch 738/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6431 - accuracy: 0.6180 - val_loss: 0.6602 - val_accuracy: 0.5515\n",
      "Epoch 739/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6431 - accuracy: 0.6186 - val_loss: 0.6601 - val_accuracy: 0.5499\n",
      "Epoch 740/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6431 - accuracy: 0.6186 - val_loss: 0.6554 - val_accuracy: 0.5566\n",
      "Epoch 741/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6431 - accuracy: 0.6183 - val_loss: 0.6630 - val_accuracy: 0.5429\n",
      "Epoch 742/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6431 - accuracy: 0.6192 - val_loss: 0.6527 - val_accuracy: 0.5627\n",
      "Epoch 743/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6431 - accuracy: 0.6172 - val_loss: 0.6664 - val_accuracy: 0.5371\n",
      "Epoch 744/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6431 - accuracy: 0.6196 - val_loss: 0.6501 - val_accuracy: 0.5654\n",
      "Epoch 745/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6432 - accuracy: 0.6170 - val_loss: 0.6696 - val_accuracy: 0.5312\n",
      "Epoch 746/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6433 - accuracy: 0.6188 - val_loss: 0.6463 - val_accuracy: 0.5723\n",
      "Epoch 747/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6434 - accuracy: 0.6169 - val_loss: 0.6725 - val_accuracy: 0.5243\n",
      "Epoch 748/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6435 - accuracy: 0.6193 - val_loss: 0.6461 - val_accuracy: 0.5720\n",
      "Epoch 749/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6435 - accuracy: 0.6168 - val_loss: 0.6738 - val_accuracy: 0.5223\n",
      "Epoch 750/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6435 - accuracy: 0.6196 - val_loss: 0.6447 - val_accuracy: 0.5738\n",
      "Epoch 751/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6435 - accuracy: 0.6163 - val_loss: 0.6721 - val_accuracy: 0.5254\n",
      "Epoch 752/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6434 - accuracy: 0.6193 - val_loss: 0.6477 - val_accuracy: 0.5687\n",
      "Epoch 753/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6432 - accuracy: 0.6172 - val_loss: 0.6689 - val_accuracy: 0.5318\n",
      "Epoch 754/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6431 - accuracy: 0.6191 - val_loss: 0.6504 - val_accuracy: 0.5659\n",
      "Epoch 755/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6429 - accuracy: 0.6175 - val_loss: 0.6644 - val_accuracy: 0.5404\n",
      "Epoch 756/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6428 - accuracy: 0.6187 - val_loss: 0.6541 - val_accuracy: 0.5607\n",
      "Epoch 757/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6427 - accuracy: 0.6182 - val_loss: 0.6616 - val_accuracy: 0.5466\n",
      "Epoch 758/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6427 - accuracy: 0.6187 - val_loss: 0.6570 - val_accuracy: 0.5559\n",
      "Epoch 759/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6426 - accuracy: 0.6191 - val_loss: 0.6604 - val_accuracy: 0.5493\n",
      "Epoch 760/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6426 - accuracy: 0.6193 - val_loss: 0.6564 - val_accuracy: 0.5554\n",
      "Epoch 761/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6426 - accuracy: 0.6187 - val_loss: 0.6610 - val_accuracy: 0.5479\n",
      "Epoch 762/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6426 - accuracy: 0.6188 - val_loss: 0.6548 - val_accuracy: 0.5585\n",
      "Epoch 763/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6426 - accuracy: 0.6184 - val_loss: 0.6645 - val_accuracy: 0.5384\n",
      "Epoch 764/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6426 - accuracy: 0.6194 - val_loss: 0.6501 - val_accuracy: 0.5652\n",
      "Epoch 765/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6427 - accuracy: 0.6178 - val_loss: 0.6720 - val_accuracy: 0.5248\n",
      "Epoch 766/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6430 - accuracy: 0.6193 - val_loss: 0.6418 - val_accuracy: 0.5775\n",
      "Epoch 767/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6434 - accuracy: 0.6168 - val_loss: 0.6852 - val_accuracy: 0.5031\n",
      "Epoch 768/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6445 - accuracy: 0.6180 - val_loss: 0.6352 - val_accuracy: 0.5868\n",
      "Epoch 769/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6444 - accuracy: 0.6137 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 770/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6448 - accuracy: 0.6174 - val_loss: 0.6417 - val_accuracy: 0.5780\n",
      "Epoch 771/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6434 - accuracy: 0.6166 - val_loss: 0.6685 - val_accuracy: 0.5320\n",
      "Epoch 772/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6427 - accuracy: 0.6193 - val_loss: 0.6559 - val_accuracy: 0.5561\n",
      "Epoch 773/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6423 - accuracy: 0.6189 - val_loss: 0.6521 - val_accuracy: 0.5623\n",
      "Epoch 774/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6424 - accuracy: 0.6188 - val_loss: 0.6706 - val_accuracy: 0.5278\n",
      "Epoch 775/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6428 - accuracy: 0.6195 - val_loss: 0.6400 - val_accuracy: 0.5820\n",
      "Epoch 776/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6434 - accuracy: 0.6165 - val_loss: 0.6857 - val_accuracy: 0.4996\n",
      "Epoch 777/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6445 - accuracy: 0.6180 - val_loss: 0.6384 - val_accuracy: 0.5837\n",
      "Epoch 778/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6438 - accuracy: 0.6151 - val_loss: 0.6766 - val_accuracy: 0.5146\n",
      "Epoch 779/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6432 - accuracy: 0.6197 - val_loss: 0.6497 - val_accuracy: 0.5643\n",
      "Epoch 780/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6424 - accuracy: 0.6187 - val_loss: 0.6590 - val_accuracy: 0.5490\n",
      "Epoch 781/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6421 - accuracy: 0.6195 - val_loss: 0.6616 - val_accuracy: 0.5435\n",
      "Epoch 782/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6422 - accuracy: 0.6199 - val_loss: 0.6479 - val_accuracy: 0.5669\n",
      "Epoch 783/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6424 - accuracy: 0.6176 - val_loss: 0.6729 - val_accuracy: 0.5217\n",
      "Epoch 784/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6428 - accuracy: 0.6199 - val_loss: 0.6419 - val_accuracy: 0.5765\n",
      "Epoch 785/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6430 - accuracy: 0.6170 - val_loss: 0.6797 - val_accuracy: 0.5111\n",
      "Epoch 786/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6435 - accuracy: 0.6189 - val_loss: 0.6413 - val_accuracy: 0.5784\n",
      "Epoch 787/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6430 - accuracy: 0.6176 - val_loss: 0.6727 - val_accuracy: 0.5223\n",
      "Epoch 788/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6426 - accuracy: 0.6201 - val_loss: 0.6506 - val_accuracy: 0.5627\n",
      "Epoch 789/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6422 - accuracy: 0.6192 - val_loss: 0.6624 - val_accuracy: 0.5429\n",
      "Epoch 790/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6420 - accuracy: 0.6196 - val_loss: 0.6560 - val_accuracy: 0.5555\n",
      "Epoch 791/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6419 - accuracy: 0.6193 - val_loss: 0.6554 - val_accuracy: 0.5570\n",
      "Epoch 792/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6419 - accuracy: 0.6190 - val_loss: 0.6635 - val_accuracy: 0.5418\n",
      "Epoch 793/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6419 - accuracy: 0.6200 - val_loss: 0.6505 - val_accuracy: 0.5632\n",
      "Epoch 794/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6421 - accuracy: 0.6187 - val_loss: 0.6721 - val_accuracy: 0.5247\n",
      "Epoch 795/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6424 - accuracy: 0.6201 - val_loss: 0.6411 - val_accuracy: 0.5789\n",
      "Epoch 796/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6428 - accuracy: 0.6172 - val_loss: 0.6833 - val_accuracy: 0.5046\n",
      "Epoch 797/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6436 - accuracy: 0.6187 - val_loss: 0.6370 - val_accuracy: 0.5855\n",
      "Epoch 798/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6435 - accuracy: 0.6150 - val_loss: 0.6861 - val_accuracy: 0.4991\n",
      "Epoch 799/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6440 - accuracy: 0.6182 - val_loss: 0.6404 - val_accuracy: 0.5813\n",
      "Epoch 800/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6429 - accuracy: 0.6169 - val_loss: 0.6708 - val_accuracy: 0.5272\n",
      "Epoch 801/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6422 - accuracy: 0.6205 - val_loss: 0.6532 - val_accuracy: 0.5599\n",
      "Epoch 802/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6417 - accuracy: 0.6191 - val_loss: 0.6562 - val_accuracy: 0.5543\n",
      "Epoch 803/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6416 - accuracy: 0.6203 - val_loss: 0.6648 - val_accuracy: 0.5374\n",
      "Epoch 804/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6418 - accuracy: 0.6208 - val_loss: 0.6448 - val_accuracy: 0.5705\n",
      "Epoch 805/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6421 - accuracy: 0.6183 - val_loss: 0.6781 - val_accuracy: 0.5137\n",
      "Epoch 806/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6428 - accuracy: 0.6203 - val_loss: 0.6389 - val_accuracy: 0.5828\n",
      "Epoch 807/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6429 - accuracy: 0.6159 - val_loss: 0.6830 - val_accuracy: 0.5037\n",
      "Epoch 808/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6435 - accuracy: 0.6190 - val_loss: 0.6390 - val_accuracy: 0.5824\n",
      "Epoch 809/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6427 - accuracy: 0.6170 - val_loss: 0.6733 - val_accuracy: 0.5205\n",
      "Epoch 810/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6422 - accuracy: 0.6208 - val_loss: 0.6503 - val_accuracy: 0.5617\n",
      "Epoch 811/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6417 - accuracy: 0.6188 - val_loss: 0.6612 - val_accuracy: 0.5442\n",
      "Epoch 812/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6414 - accuracy: 0.6207 - val_loss: 0.6573 - val_accuracy: 0.5533\n",
      "Epoch 813/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6414 - accuracy: 0.6197 - val_loss: 0.6528 - val_accuracy: 0.5603\n",
      "Epoch 814/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6414 - accuracy: 0.6197 - val_loss: 0.6650 - val_accuracy: 0.5384\n",
      "Epoch 815/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6415 - accuracy: 0.6214 - val_loss: 0.6484 - val_accuracy: 0.5661\n",
      "Epoch 816/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6416 - accuracy: 0.6191 - val_loss: 0.6723 - val_accuracy: 0.5228\n",
      "Epoch 817/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6419 - accuracy: 0.6206 - val_loss: 0.6417 - val_accuracy: 0.5767\n",
      "Epoch 818/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6421 - accuracy: 0.6182 - val_loss: 0.6783 - val_accuracy: 0.5128\n",
      "Epoch 819/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6425 - accuracy: 0.6207 - val_loss: 0.6402 - val_accuracy: 0.5817\n",
      "Epoch 820/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6424 - accuracy: 0.6172 - val_loss: 0.6806 - val_accuracy: 0.5079\n",
      "Epoch 821/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6427 - accuracy: 0.6196 - val_loss: 0.6400 - val_accuracy: 0.5820\n",
      "Epoch 822/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6423 - accuracy: 0.6178 - val_loss: 0.6746 - val_accuracy: 0.5206\n",
      "Epoch 823/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6420 - accuracy: 0.6212 - val_loss: 0.6469 - val_accuracy: 0.5683\n",
      "Epoch 824/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6415 - accuracy: 0.6185 - val_loss: 0.6654 - val_accuracy: 0.5367\n",
      "Epoch 825/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6413 - accuracy: 0.6218 - val_loss: 0.6526 - val_accuracy: 0.5614\n",
      "Epoch 826/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6411 - accuracy: 0.6203 - val_loss: 0.6591 - val_accuracy: 0.5495\n",
      "Epoch 827/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6410 - accuracy: 0.6206 - val_loss: 0.6578 - val_accuracy: 0.5519\n",
      "Epoch 828/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6410 - accuracy: 0.6208 - val_loss: 0.6555 - val_accuracy: 0.5554\n",
      "Epoch 829/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6410 - accuracy: 0.6207 - val_loss: 0.6622 - val_accuracy: 0.5422\n",
      "Epoch 830/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6410 - accuracy: 0.6212 - val_loss: 0.6503 - val_accuracy: 0.5630\n",
      "Epoch 831/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6411 - accuracy: 0.6197 - val_loss: 0.6692 - val_accuracy: 0.5292\n",
      "Epoch 832/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6413 - accuracy: 0.6218 - val_loss: 0.6431 - val_accuracy: 0.5762\n",
      "Epoch 833/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6417 - accuracy: 0.6178 - val_loss: 0.6817 - val_accuracy: 0.5064\n",
      "Epoch 834/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6426 - accuracy: 0.6201 - val_loss: 0.6335 - val_accuracy: 0.5908\n",
      "Epoch 835/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6431 - accuracy: 0.6146 - val_loss: 0.6928 - val_accuracy: 0.4909\n",
      "Epoch 836/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6444 - accuracy: 0.6166 - val_loss: 0.6359 - val_accuracy: 0.5877\n",
      "Epoch 837/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6426 - accuracy: 0.6165 - val_loss: 0.6720 - val_accuracy: 0.5267\n",
      "Epoch 838/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6415 - accuracy: 0.6215 - val_loss: 0.6547 - val_accuracy: 0.5561\n",
      "Epoch 839/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6409 - accuracy: 0.6205 - val_loss: 0.6509 - val_accuracy: 0.5619\n",
      "Epoch 840/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6409 - accuracy: 0.6205 - val_loss: 0.6714 - val_accuracy: 0.5274\n",
      "Epoch 841/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6415 - accuracy: 0.6204 - val_loss: 0.6366 - val_accuracy: 0.5848\n",
      "Epoch 842/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6422 - accuracy: 0.6172 - val_loss: 0.6863 - val_accuracy: 0.4978\n",
      "Epoch 843/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6432 - accuracy: 0.6188 - val_loss: 0.6372 - val_accuracy: 0.5844\n",
      "Epoch 844/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6424 - accuracy: 0.6155 - val_loss: 0.6783 - val_accuracy: 0.5121\n",
      "Epoch 845/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6421 - accuracy: 0.6212 - val_loss: 0.6461 - val_accuracy: 0.5701\n",
      "Epoch 846/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6411 - accuracy: 0.6200 - val_loss: 0.6575 - val_accuracy: 0.5495\n",
      "Epoch 847/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6406 - accuracy: 0.6214 - val_loss: 0.6652 - val_accuracy: 0.5351\n",
      "Epoch 848/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6409 - accuracy: 0.6217 - val_loss: 0.6413 - val_accuracy: 0.5773\n",
      "Epoch 849/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6415 - accuracy: 0.6180 - val_loss: 0.6838 - val_accuracy: 0.5027\n",
      "Epoch 850/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6429 - accuracy: 0.6188 - val_loss: 0.6338 - val_accuracy: 0.5908\n",
      "Epoch 851/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6428 - accuracy: 0.6163 - val_loss: 0.6796 - val_accuracy: 0.5091\n",
      "Epoch 852/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6420 - accuracy: 0.6209 - val_loss: 0.6494 - val_accuracy: 0.5627\n",
      "Epoch 853/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6411 - accuracy: 0.6192 - val_loss: 0.6580 - val_accuracy: 0.5480\n",
      "Epoch 854/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6405 - accuracy: 0.6218 - val_loss: 0.6615 - val_accuracy: 0.5418\n",
      "Epoch 855/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6407 - accuracy: 0.6211 - val_loss: 0.6441 - val_accuracy: 0.5731\n",
      "Epoch 856/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6410 - accuracy: 0.6197 - val_loss: 0.6738 - val_accuracy: 0.5179\n",
      "Epoch 857/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6413 - accuracy: 0.6213 - val_loss: 0.6420 - val_accuracy: 0.5756\n",
      "Epoch 858/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6416 - accuracy: 0.6170 - val_loss: 0.6800 - val_accuracy: 0.5080\n",
      "Epoch 859/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6420 - accuracy: 0.6205 - val_loss: 0.6387 - val_accuracy: 0.5809\n",
      "Epoch 860/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6418 - accuracy: 0.6179 - val_loss: 0.6710 - val_accuracy: 0.5237\n",
      "Epoch 861/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6410 - accuracy: 0.6222 - val_loss: 0.6522 - val_accuracy: 0.5583\n",
      "Epoch 862/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6407 - accuracy: 0.6205 - val_loss: 0.6599 - val_accuracy: 0.5457\n",
      "Epoch 863/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6403 - accuracy: 0.6220 - val_loss: 0.6567 - val_accuracy: 0.5513\n",
      "Epoch 864/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6403 - accuracy: 0.6206 - val_loss: 0.6515 - val_accuracy: 0.5596\n",
      "Epoch 865/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6404 - accuracy: 0.6199 - val_loss: 0.6647 - val_accuracy: 0.5378\n",
      "Epoch 866/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6404 - accuracy: 0.6225 - val_loss: 0.6482 - val_accuracy: 0.5658\n",
      "Epoch 867/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6407 - accuracy: 0.6202 - val_loss: 0.6742 - val_accuracy: 0.5197\n",
      "Epoch 868/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6410 - accuracy: 0.6214 - val_loss: 0.6383 - val_accuracy: 0.5809\n",
      "Epoch 869/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6415 - accuracy: 0.6186 - val_loss: 0.6814 - val_accuracy: 0.5049\n",
      "Epoch 870/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6418 - accuracy: 0.6204 - val_loss: 0.6393 - val_accuracy: 0.5800\n",
      "Epoch 871/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6414 - accuracy: 0.6175 - val_loss: 0.6785 - val_accuracy: 0.5108\n",
      "Epoch 872/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6414 - accuracy: 0.6215 - val_loss: 0.6419 - val_accuracy: 0.5771\n",
      "Epoch 873/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6408 - accuracy: 0.6192 - val_loss: 0.6682 - val_accuracy: 0.5298\n",
      "Epoch 874/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6404 - accuracy: 0.6221 - val_loss: 0.6500 - val_accuracy: 0.5623\n",
      "Epoch 875/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6401 - accuracy: 0.6209 - val_loss: 0.6607 - val_accuracy: 0.5438\n",
      "Epoch 876/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6400 - accuracy: 0.6225 - val_loss: 0.6569 - val_accuracy: 0.5512\n",
      "Epoch 877/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6399 - accuracy: 0.6227 - val_loss: 0.6554 - val_accuracy: 0.5535\n",
      "Epoch 878/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6399 - accuracy: 0.6217 - val_loss: 0.6604 - val_accuracy: 0.5433\n",
      "Epoch 879/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6399 - accuracy: 0.6227 - val_loss: 0.6511 - val_accuracy: 0.5601\n",
      "Epoch 880/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6399 - accuracy: 0.6210 - val_loss: 0.6664 - val_accuracy: 0.5314\n",
      "Epoch 881/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6401 - accuracy: 0.6223 - val_loss: 0.6452 - val_accuracy: 0.5709\n",
      "Epoch 882/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6403 - accuracy: 0.6199 - val_loss: 0.6765 - val_accuracy: 0.5152\n",
      "Epoch 883/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6409 - accuracy: 0.6216 - val_loss: 0.6369 - val_accuracy: 0.5848\n",
      "Epoch 884/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6413 - accuracy: 0.6179 - val_loss: 0.6852 - val_accuracy: 0.4989\n",
      "Epoch 885/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6420 - accuracy: 0.6194 - val_loss: 0.6363 - val_accuracy: 0.5862\n",
      "Epoch 886/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6414 - accuracy: 0.6175 - val_loss: 0.6804 - val_accuracy: 0.5060\n",
      "Epoch 887/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6414 - accuracy: 0.6208 - val_loss: 0.6422 - val_accuracy: 0.5769\n",
      "Epoch 888/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6404 - accuracy: 0.6199 - val_loss: 0.6656 - val_accuracy: 0.5356\n",
      "Epoch 889/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6399 - accuracy: 0.6227 - val_loss: 0.6539 - val_accuracy: 0.5548\n",
      "Epoch 890/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6397 - accuracy: 0.6218 - val_loss: 0.6541 - val_accuracy: 0.5543\n",
      "Epoch 891/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6396 - accuracy: 0.6222 - val_loss: 0.6631 - val_accuracy: 0.5398\n",
      "Epoch 892/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6397 - accuracy: 0.6226 - val_loss: 0.6458 - val_accuracy: 0.5698\n",
      "Epoch 893/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6400 - accuracy: 0.6202 - val_loss: 0.6744 - val_accuracy: 0.5163\n",
      "Epoch 894/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6404 - accuracy: 0.6223 - val_loss: 0.6392 - val_accuracy: 0.5807\n",
      "Epoch 895/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6407 - accuracy: 0.6184 - val_loss: 0.6837 - val_accuracy: 0.5000\n",
      "Epoch 896/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6417 - accuracy: 0.6200 - val_loss: 0.6338 - val_accuracy: 0.5886\n",
      "Epoch 897/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6415 - accuracy: 0.6170 - val_loss: 0.6823 - val_accuracy: 0.5020\n",
      "Epoch 898/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6414 - accuracy: 0.6207 - val_loss: 0.6420 - val_accuracy: 0.5747\n",
      "Epoch 899/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6403 - accuracy: 0.6194 - val_loss: 0.6663 - val_accuracy: 0.5331\n",
      "Epoch 900/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6397 - accuracy: 0.6231 - val_loss: 0.6530 - val_accuracy: 0.5555\n",
      "Epoch 901/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6394 - accuracy: 0.6219 - val_loss: 0.6520 - val_accuracy: 0.5574\n",
      "Epoch 902/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6394 - accuracy: 0.6220 - val_loss: 0.6660 - val_accuracy: 0.5329\n",
      "Epoch 903/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6396 - accuracy: 0.6225 - val_loss: 0.6428 - val_accuracy: 0.5740\n",
      "Epoch 904/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6400 - accuracy: 0.6198 - val_loss: 0.6800 - val_accuracy: 0.5055\n",
      "Epoch 905/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6410 - accuracy: 0.6214 - val_loss: 0.6342 - val_accuracy: 0.5875\n",
      "Epoch 906/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6413 - accuracy: 0.6180 - val_loss: 0.6853 - val_accuracy: 0.4980\n",
      "Epoch 907/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6417 - accuracy: 0.6201 - val_loss: 0.6390 - val_accuracy: 0.5818\n",
      "Epoch 908/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6405 - accuracy: 0.6183 - val_loss: 0.6714 - val_accuracy: 0.5236\n",
      "Epoch 909/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6399 - accuracy: 0.6232 - val_loss: 0.6491 - val_accuracy: 0.5627\n",
      "Epoch 910/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6394 - accuracy: 0.6217 - val_loss: 0.6549 - val_accuracy: 0.5519\n",
      "Epoch 911/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6391 - accuracy: 0.6230 - val_loss: 0.6634 - val_accuracy: 0.5378\n",
      "Epoch 912/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6394 - accuracy: 0.6228 - val_loss: 0.6436 - val_accuracy: 0.5722\n",
      "Epoch 913/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6397 - accuracy: 0.6204 - val_loss: 0.6777 - val_accuracy: 0.5121\n",
      "Epoch 914/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6406 - accuracy: 0.6216 - val_loss: 0.6356 - val_accuracy: 0.5857\n",
      "Epoch 915/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6409 - accuracy: 0.6192 - val_loss: 0.6829 - val_accuracy: 0.5035\n",
      "Epoch 916/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6410 - accuracy: 0.6212 - val_loss: 0.6412 - val_accuracy: 0.5765\n",
      "Epoch 917/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6402 - accuracy: 0.6196 - val_loss: 0.6712 - val_accuracy: 0.5245\n",
      "Epoch 918/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6397 - accuracy: 0.6230 - val_loss: 0.6469 - val_accuracy: 0.5667\n",
      "Epoch 919/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6394 - accuracy: 0.6214 - val_loss: 0.6587 - val_accuracy: 0.5460\n",
      "Epoch 920/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6390 - accuracy: 0.6240 - val_loss: 0.6582 - val_accuracy: 0.5473\n",
      "Epoch 921/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6391 - accuracy: 0.6232 - val_loss: 0.6517 - val_accuracy: 0.5575\n",
      "Epoch 922/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6390 - accuracy: 0.6220 - val_loss: 0.6644 - val_accuracy: 0.5353\n",
      "Epoch 923/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6392 - accuracy: 0.6234 - val_loss: 0.6453 - val_accuracy: 0.5714\n",
      "Epoch 924/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6394 - accuracy: 0.6220 - val_loss: 0.6717 - val_accuracy: 0.5234\n",
      "Epoch 925/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6395 - accuracy: 0.6235 - val_loss: 0.6424 - val_accuracy: 0.5762\n",
      "Epoch 926/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6398 - accuracy: 0.6199 - val_loss: 0.6799 - val_accuracy: 0.5090\n",
      "Epoch 927/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6405 - accuracy: 0.6217 - val_loss: 0.6328 - val_accuracy: 0.5871\n",
      "Epoch 928/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6411 - accuracy: 0.6183 - val_loss: 0.6877 - val_accuracy: 0.4954\n",
      "Epoch 929/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6416 - accuracy: 0.6203 - val_loss: 0.6364 - val_accuracy: 0.5868\n",
      "Epoch 930/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6407 - accuracy: 0.6174 - val_loss: 0.6769 - val_accuracy: 0.5139\n",
      "Epoch 931/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6401 - accuracy: 0.6221 - val_loss: 0.6450 - val_accuracy: 0.5705\n",
      "Epoch 932/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6393 - accuracy: 0.6223 - val_loss: 0.6572 - val_accuracy: 0.5471\n",
      "Epoch 933/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6387 - accuracy: 0.6245 - val_loss: 0.6623 - val_accuracy: 0.5398\n",
      "Epoch 934/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6389 - accuracy: 0.6235 - val_loss: 0.6447 - val_accuracy: 0.5714\n",
      "Epoch 935/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6392 - accuracy: 0.6213 - val_loss: 0.6764 - val_accuracy: 0.5161\n",
      "Epoch 936/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6401 - accuracy: 0.6219 - val_loss: 0.6349 - val_accuracy: 0.5864\n",
      "Epoch 937/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6405 - accuracy: 0.6193 - val_loss: 0.6824 - val_accuracy: 0.5038\n",
      "Epoch 938/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6406 - accuracy: 0.6219 - val_loss: 0.6404 - val_accuracy: 0.5786\n",
      "Epoch 939/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6400 - accuracy: 0.6193 - val_loss: 0.6724 - val_accuracy: 0.5192\n",
      "Epoch 940/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6394 - accuracy: 0.6234 - val_loss: 0.6456 - val_accuracy: 0.5700\n",
      "Epoch 941/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6392 - accuracy: 0.6214 - val_loss: 0.6589 - val_accuracy: 0.5440\n",
      "Epoch 942/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6385 - accuracy: 0.6244 - val_loss: 0.6590 - val_accuracy: 0.5442\n",
      "Epoch 943/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6387 - accuracy: 0.6233 - val_loss: 0.6506 - val_accuracy: 0.5601\n",
      "Epoch 944/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6387 - accuracy: 0.6225 - val_loss: 0.6653 - val_accuracy: 0.5332\n",
      "Epoch 945/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6388 - accuracy: 0.6236 - val_loss: 0.6443 - val_accuracy: 0.5712\n",
      "Epoch 946/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6391 - accuracy: 0.6218 - val_loss: 0.6696 - val_accuracy: 0.5256\n",
      "Epoch 947/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6389 - accuracy: 0.6240 - val_loss: 0.6458 - val_accuracy: 0.5696\n",
      "Epoch 948/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6391 - accuracy: 0.6207 - val_loss: 0.6717 - val_accuracy: 0.5208\n",
      "Epoch 949/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6391 - accuracy: 0.6236 - val_loss: 0.6402 - val_accuracy: 0.5789\n",
      "Epoch 950/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6393 - accuracy: 0.6210 - val_loss: 0.6738 - val_accuracy: 0.5201\n",
      "Epoch 951/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6393 - accuracy: 0.6234 - val_loss: 0.6413 - val_accuracy: 0.5767\n",
      "Epoch 952/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6393 - accuracy: 0.6200 - val_loss: 0.6777 - val_accuracy: 0.5111\n",
      "Epoch 953/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6396 - accuracy: 0.6229 - val_loss: 0.6379 - val_accuracy: 0.5833\n",
      "Epoch 954/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6395 - accuracy: 0.6205 - val_loss: 0.6778 - val_accuracy: 0.5124\n",
      "Epoch 955/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6397 - accuracy: 0.6226 - val_loss: 0.6412 - val_accuracy: 0.5762\n",
      "Epoch 956/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6390 - accuracy: 0.6212 - val_loss: 0.6692 - val_accuracy: 0.5285\n",
      "Epoch 957/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6387 - accuracy: 0.6244 - val_loss: 0.6490 - val_accuracy: 0.5603\n",
      "Epoch 958/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6383 - accuracy: 0.6236 - val_loss: 0.6587 - val_accuracy: 0.5453\n",
      "Epoch 959/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6381 - accuracy: 0.6244 - val_loss: 0.6553 - val_accuracy: 0.5493\n",
      "Epoch 960/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6381 - accuracy: 0.6245 - val_loss: 0.6530 - val_accuracy: 0.5537\n",
      "Epoch 961/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6381 - accuracy: 0.6244 - val_loss: 0.6624 - val_accuracy: 0.5387\n",
      "Epoch 962/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6381 - accuracy: 0.6252 - val_loss: 0.6489 - val_accuracy: 0.5592\n",
      "Epoch 963/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6382 - accuracy: 0.6229 - val_loss: 0.6668 - val_accuracy: 0.5298\n",
      "Epoch 964/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6384 - accuracy: 0.6245 - val_loss: 0.6439 - val_accuracy: 0.5705\n",
      "Epoch 965/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6385 - accuracy: 0.6221 - val_loss: 0.6735 - val_accuracy: 0.5183\n",
      "Epoch 966/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6388 - accuracy: 0.6240 - val_loss: 0.6390 - val_accuracy: 0.5806\n",
      "Epoch 967/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6392 - accuracy: 0.6205 - val_loss: 0.6839 - val_accuracy: 0.5018\n",
      "Epoch 968/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6403 - accuracy: 0.6219 - val_loss: 0.6302 - val_accuracy: 0.5917\n",
      "Epoch 969/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6405 - accuracy: 0.6169 - val_loss: 0.6898 - val_accuracy: 0.4940\n",
      "Epoch 970/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6412 - accuracy: 0.6206 - val_loss: 0.6367 - val_accuracy: 0.5846\n",
      "Epoch 971/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6395 - accuracy: 0.6189 - val_loss: 0.6703 - val_accuracy: 0.5239\n",
      "Epoch 972/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6385 - accuracy: 0.6241 - val_loss: 0.6522 - val_accuracy: 0.5530\n",
      "Epoch 973/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6379 - accuracy: 0.6237 - val_loss: 0.6475 - val_accuracy: 0.5619\n",
      "Epoch 974/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6380 - accuracy: 0.6230 - val_loss: 0.6734 - val_accuracy: 0.5170\n",
      "Epoch 975/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6389 - accuracy: 0.6241 - val_loss: 0.6334 - val_accuracy: 0.5919\n",
      "Epoch 976/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6397 - accuracy: 0.6190 - val_loss: 0.6920 - val_accuracy: 0.4901\n",
      "Epoch 977/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6418 - accuracy: 0.6189 - val_loss: 0.6338 - val_accuracy: 0.5848\n",
      "Epoch 978/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6402 - accuracy: 0.6194 - val_loss: 0.6695 - val_accuracy: 0.5239\n",
      "Epoch 979/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6383 - accuracy: 0.6249 - val_loss: 0.6581 - val_accuracy: 0.5433\n",
      "Epoch 980/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6382 - accuracy: 0.6243 - val_loss: 0.6442 - val_accuracy: 0.5685\n",
      "Epoch 981/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6381 - accuracy: 0.6237 - val_loss: 0.6728 - val_accuracy: 0.5201\n",
      "Epoch 982/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6393 - accuracy: 0.6219 - val_loss: 0.6356 - val_accuracy: 0.5826\n",
      "Epoch 983/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6394 - accuracy: 0.6201 - val_loss: 0.6771 - val_accuracy: 0.5113\n",
      "Epoch 984/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6391 - accuracy: 0.6231 - val_loss: 0.6449 - val_accuracy: 0.5709\n",
      "Epoch 985/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6391 - accuracy: 0.6210 - val_loss: 0.6687 - val_accuracy: 0.5254\n",
      "Epoch 986/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6382 - accuracy: 0.6240 - val_loss: 0.6432 - val_accuracy: 0.5701\n",
      "Epoch 987/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6388 - accuracy: 0.6210 - val_loss: 0.6627 - val_accuracy: 0.5356\n",
      "Epoch 988/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6378 - accuracy: 0.6252 - val_loss: 0.6527 - val_accuracy: 0.5550\n",
      "Epoch 989/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6381 - accuracy: 0.6239 - val_loss: 0.6629 - val_accuracy: 0.5349\n",
      "Epoch 990/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6378 - accuracy: 0.6249 - val_loss: 0.6490 - val_accuracy: 0.5603\n",
      "Epoch 991/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6377 - accuracy: 0.6234 - val_loss: 0.6588 - val_accuracy: 0.5435\n",
      "Epoch 992/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6378 - accuracy: 0.6242 - val_loss: 0.6531 - val_accuracy: 0.5519\n",
      "Epoch 993/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6374 - accuracy: 0.6243 - val_loss: 0.6593 - val_accuracy: 0.5422\n",
      "Epoch 994/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6377 - accuracy: 0.6251 - val_loss: 0.6589 - val_accuracy: 0.5426\n",
      "Epoch 995/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6374 - accuracy: 0.6255 - val_loss: 0.6499 - val_accuracy: 0.5594\n",
      "Epoch 996/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6376 - accuracy: 0.6237 - val_loss: 0.6627 - val_accuracy: 0.5378\n",
      "Epoch 997/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6376 - accuracy: 0.6250 - val_loss: 0.6456 - val_accuracy: 0.5665\n",
      "Epoch 998/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6377 - accuracy: 0.6228 - val_loss: 0.6733 - val_accuracy: 0.5181\n",
      "Epoch 999/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6381 - accuracy: 0.6251 - val_loss: 0.6376 - val_accuracy: 0.5795\n",
      "Epoch 1000/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6387 - accuracy: 0.6213 - val_loss: 0.6863 - val_accuracy: 0.4989\n",
      "Epoch 1001/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6402 - accuracy: 0.6214 - val_loss: 0.6292 - val_accuracy: 0.5948\n",
      "Epoch 1002/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6402 - accuracy: 0.6168 - val_loss: 0.6895 - val_accuracy: 0.4958\n",
      "Epoch 1003/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6404 - accuracy: 0.6205 - val_loss: 0.6393 - val_accuracy: 0.5802\n",
      "Epoch 1004/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6387 - accuracy: 0.6203 - val_loss: 0.6684 - val_accuracy: 0.5294\n",
      "Epoch 1005/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6377 - accuracy: 0.6254 - val_loss: 0.6498 - val_accuracy: 0.5592\n",
      "Epoch 1006/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6374 - accuracy: 0.6236 - val_loss: 0.6499 - val_accuracy: 0.5575\n",
      "Epoch 1007/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6372 - accuracy: 0.6241 - val_loss: 0.6676 - val_accuracy: 0.5267\n",
      "Epoch 1008/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6377 - accuracy: 0.6252 - val_loss: 0.6411 - val_accuracy: 0.5744\n",
      "Epoch 1009/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6381 - accuracy: 0.6220 - val_loss: 0.6806 - val_accuracy: 0.5090\n",
      "Epoch 1010/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6392 - accuracy: 0.6225 - val_loss: 0.6335 - val_accuracy: 0.5839\n",
      "Epoch 1011/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6393 - accuracy: 0.6193 - val_loss: 0.6797 - val_accuracy: 0.5058\n",
      "Epoch 1012/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6388 - accuracy: 0.6236 - val_loss: 0.6408 - val_accuracy: 0.5791\n",
      "Epoch 1013/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6386 - accuracy: 0.6219 - val_loss: 0.6742 - val_accuracy: 0.5161\n",
      "Epoch 1014/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6382 - accuracy: 0.6243 - val_loss: 0.6376 - val_accuracy: 0.5780\n",
      "Epoch 1015/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6386 - accuracy: 0.6206 - val_loss: 0.6717 - val_accuracy: 0.5239\n",
      "Epoch 1016/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6379 - accuracy: 0.6247 - val_loss: 0.6449 - val_accuracy: 0.5711\n",
      "Epoch 1017/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6378 - accuracy: 0.6220 - val_loss: 0.6680 - val_accuracy: 0.5278\n",
      "Epoch 1018/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6374 - accuracy: 0.6250 - val_loss: 0.6437 - val_accuracy: 0.5692\n",
      "Epoch 1019/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6375 - accuracy: 0.6231 - val_loss: 0.6636 - val_accuracy: 0.5338\n",
      "Epoch 1020/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6372 - accuracy: 0.6255 - val_loss: 0.6506 - val_accuracy: 0.5546\n",
      "Epoch 1021/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6370 - accuracy: 0.6245 - val_loss: 0.6590 - val_accuracy: 0.5415\n",
      "Epoch 1022/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6369 - accuracy: 0.6263 - val_loss: 0.6555 - val_accuracy: 0.5464\n",
      "Epoch 1023/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6368 - accuracy: 0.6259 - val_loss: 0.6515 - val_accuracy: 0.5550\n",
      "Epoch 1024/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6368 - accuracy: 0.6249 - val_loss: 0.6599 - val_accuracy: 0.5429\n",
      "Epoch 1025/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6368 - accuracy: 0.6260 - val_loss: 0.6488 - val_accuracy: 0.5586\n",
      "Epoch 1026/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6369 - accuracy: 0.6243 - val_loss: 0.6687 - val_accuracy: 0.5270\n",
      "Epoch 1027/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6372 - accuracy: 0.6252 - val_loss: 0.6411 - val_accuracy: 0.5744\n",
      "Epoch 1028/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6375 - accuracy: 0.6230 - val_loss: 0.6784 - val_accuracy: 0.5102\n",
      "Epoch 1029/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6383 - accuracy: 0.6240 - val_loss: 0.6322 - val_accuracy: 0.5935\n",
      "Epoch 1030/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6389 - accuracy: 0.6193 - val_loss: 0.6924 - val_accuracy: 0.4909\n",
      "Epoch 1031/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6405 - accuracy: 0.6207 - val_loss: 0.6301 - val_accuracy: 0.5930\n",
      "Epoch 1032/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6396 - accuracy: 0.6185 - val_loss: 0.6845 - val_accuracy: 0.5029\n",
      "Epoch 1033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6392 - accuracy: 0.6222 - val_loss: 0.6429 - val_accuracy: 0.5727\n",
      "Epoch 1034/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6373 - accuracy: 0.6227 - val_loss: 0.6531 - val_accuracy: 0.5515\n",
      "Epoch 1035/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6366 - accuracy: 0.6255 - val_loss: 0.6700 - val_accuracy: 0.5212\n",
      "Epoch 1036/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6373 - accuracy: 0.6258 - val_loss: 0.6329 - val_accuracy: 0.5904\n",
      "Epoch 1037/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6385 - accuracy: 0.6212 - val_loss: 0.6945 - val_accuracy: 0.4881\n",
      "Epoch 1038/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6412 - accuracy: 0.6201 - val_loss: 0.6302 - val_accuracy: 0.5919\n",
      "Epoch 1039/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6395 - accuracy: 0.6164 - val_loss: 0.6756 - val_accuracy: 0.5133\n",
      "Epoch 1040/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6378 - accuracy: 0.6242 - val_loss: 0.6535 - val_accuracy: 0.5491\n",
      "Epoch 1041/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6368 - accuracy: 0.6255 - val_loss: 0.6437 - val_accuracy: 0.5663\n",
      "Epoch 1042/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6369 - accuracy: 0.6243 - val_loss: 0.6748 - val_accuracy: 0.5155\n",
      "Epoch 1043/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6384 - accuracy: 0.6241 - val_loss: 0.6317 - val_accuracy: 0.5879\n",
      "Epoch 1044/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6386 - accuracy: 0.6190 - val_loss: 0.6809 - val_accuracy: 0.5046\n",
      "Epoch 1045/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6385 - accuracy: 0.6230 - val_loss: 0.6445 - val_accuracy: 0.5714\n",
      "Epoch 1046/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6377 - accuracy: 0.6228 - val_loss: 0.6611 - val_accuracy: 0.5380\n",
      "Epoch 1047/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6365 - accuracy: 0.6259 - val_loss: 0.6546 - val_accuracy: 0.5491\n",
      "Epoch 1048/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6368 - accuracy: 0.6249 - val_loss: 0.6476 - val_accuracy: 0.5603\n",
      "Epoch 1049/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6366 - accuracy: 0.6248 - val_loss: 0.6660 - val_accuracy: 0.5252\n",
      "Epoch 1050/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6369 - accuracy: 0.6264 - val_loss: 0.6450 - val_accuracy: 0.5680\n",
      "Epoch 1051/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6370 - accuracy: 0.6239 - val_loss: 0.6699 - val_accuracy: 0.5247\n",
      "Epoch 1052/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6372 - accuracy: 0.6248 - val_loss: 0.6402 - val_accuracy: 0.5751\n",
      "Epoch 1053/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6375 - accuracy: 0.6222 - val_loss: 0.6697 - val_accuracy: 0.5250\n",
      "Epoch 1054/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6368 - accuracy: 0.6264 - val_loss: 0.6467 - val_accuracy: 0.5654\n",
      "Epoch 1055/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6372 - accuracy: 0.6239 - val_loss: 0.6694 - val_accuracy: 0.5234\n",
      "Epoch 1056/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6368 - accuracy: 0.6264 - val_loss: 0.6398 - val_accuracy: 0.5758\n",
      "Epoch 1057/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6372 - accuracy: 0.6229 - val_loss: 0.6729 - val_accuracy: 0.5225\n",
      "Epoch 1058/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6373 - accuracy: 0.6255 - val_loss: 0.6416 - val_accuracy: 0.5751\n",
      "Epoch 1059/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6371 - accuracy: 0.6225 - val_loss: 0.6744 - val_accuracy: 0.5135\n",
      "Epoch 1060/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6371 - accuracy: 0.6257 - val_loss: 0.6394 - val_accuracy: 0.5762\n",
      "Epoch 1061/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6370 - accuracy: 0.6233 - val_loss: 0.6712 - val_accuracy: 0.5237\n",
      "Epoch 1062/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6370 - accuracy: 0.6259 - val_loss: 0.6433 - val_accuracy: 0.5705\n",
      "Epoch 1063/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6365 - accuracy: 0.6232 - val_loss: 0.6661 - val_accuracy: 0.5314\n",
      "Epoch 1064/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6363 - accuracy: 0.6259 - val_loss: 0.6503 - val_accuracy: 0.5570\n",
      "Epoch 1065/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6362 - accuracy: 0.6256 - val_loss: 0.6590 - val_accuracy: 0.5440\n",
      "Epoch 1066/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6360 - accuracy: 0.6261 - val_loss: 0.6526 - val_accuracy: 0.5530\n",
      "Epoch 1067/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6360 - accuracy: 0.6260 - val_loss: 0.6561 - val_accuracy: 0.5491\n",
      "Epoch 1068/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6359 - accuracy: 0.6265 - val_loss: 0.6573 - val_accuracy: 0.5449\n",
      "Epoch 1069/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6359 - accuracy: 0.6263 - val_loss: 0.6535 - val_accuracy: 0.5528\n",
      "Epoch 1070/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6359 - accuracy: 0.6263 - val_loss: 0.6585 - val_accuracy: 0.5444\n",
      "Epoch 1071/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6359 - accuracy: 0.6268 - val_loss: 0.6496 - val_accuracy: 0.5574\n",
      "Epoch 1072/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6359 - accuracy: 0.6250 - val_loss: 0.6641 - val_accuracy: 0.5343\n",
      "Epoch 1073/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6360 - accuracy: 0.6271 - val_loss: 0.6444 - val_accuracy: 0.5698\n",
      "Epoch 1074/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6363 - accuracy: 0.6234 - val_loss: 0.6747 - val_accuracy: 0.5174\n",
      "Epoch 1075/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6369 - accuracy: 0.6261 - val_loss: 0.6331 - val_accuracy: 0.5882\n",
      "Epoch 1076/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6378 - accuracy: 0.6209 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 1077/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6400 - accuracy: 0.6209 - val_loss: 0.6277 - val_accuracy: 0.5979\n",
      "Epoch 1078/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6392 - accuracy: 0.6185 - val_loss: 0.6904 - val_accuracy: 0.4929\n",
      "Epoch 1079/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6395 - accuracy: 0.6221 - val_loss: 0.6374 - val_accuracy: 0.5806\n",
      "Epoch 1080/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6370 - accuracy: 0.6221 - val_loss: 0.6576 - val_accuracy: 0.5448\n",
      "Epoch 1081/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6358 - accuracy: 0.6266 - val_loss: 0.6662 - val_accuracy: 0.5303\n",
      "Epoch 1082/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6361 - accuracy: 0.6271 - val_loss: 0.6350 - val_accuracy: 0.5866\n",
      "Epoch 1083/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6373 - accuracy: 0.6223 - val_loss: 0.6905 - val_accuracy: 0.4929\n",
      "Epoch 1084/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6397 - accuracy: 0.6213 - val_loss: 0.6291 - val_accuracy: 0.5910\n",
      "Epoch 1085/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6387 - accuracy: 0.6183 - val_loss: 0.6802 - val_accuracy: 0.5057\n",
      "Epoch 1086/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6375 - accuracy: 0.6245 - val_loss: 0.6479 - val_accuracy: 0.5608\n",
      "Epoch 1087/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6363 - accuracy: 0.6248 - val_loss: 0.6511 - val_accuracy: 0.5532\n",
      "Epoch 1088/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6357 - accuracy: 0.6269 - val_loss: 0.6647 - val_accuracy: 0.5318\n",
      "Epoch 1089/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6363 - accuracy: 0.6261 - val_loss: 0.6380 - val_accuracy: 0.5754\n",
      "Epoch 1090/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6365 - accuracy: 0.6228 - val_loss: 0.6746 - val_accuracy: 0.5130\n",
      "Epoch 1091/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6368 - accuracy: 0.6262 - val_loss: 0.6401 - val_accuracy: 0.5740\n",
      "Epoch 1092/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6369 - accuracy: 0.6221 - val_loss: 0.6740 - val_accuracy: 0.5166\n",
      "Epoch 1093/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6368 - accuracy: 0.6253 - val_loss: 0.6402 - val_accuracy: 0.5731\n",
      "Epoch 1094/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6366 - accuracy: 0.6237 - val_loss: 0.6644 - val_accuracy: 0.5314\n",
      "Epoch 1095/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6358 - accuracy: 0.6274 - val_loss: 0.6523 - val_accuracy: 0.5512\n",
      "Epoch 1096/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6359 - accuracy: 0.6264 - val_loss: 0.6562 - val_accuracy: 0.5446\n",
      "Epoch 1097/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6354 - accuracy: 0.6270 - val_loss: 0.6537 - val_accuracy: 0.5491\n",
      "Epoch 1098/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6356 - accuracy: 0.6262 - val_loss: 0.6512 - val_accuracy: 0.5533\n",
      "Epoch 1099/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6355 - accuracy: 0.6260 - val_loss: 0.6598 - val_accuracy: 0.5407\n",
      "Epoch 1100/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6354 - accuracy: 0.6278 - val_loss: 0.6514 - val_accuracy: 0.5544\n",
      "Epoch 1101/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6356 - accuracy: 0.6259 - val_loss: 0.6643 - val_accuracy: 0.5331\n",
      "Epoch 1102/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6356 - accuracy: 0.6264 - val_loss: 0.6433 - val_accuracy: 0.5701\n",
      "Epoch 1103/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6359 - accuracy: 0.6242 - val_loss: 0.6706 - val_accuracy: 0.5241\n",
      "Epoch 1104/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6360 - accuracy: 0.6268 - val_loss: 0.6411 - val_accuracy: 0.5753\n",
      "Epoch 1105/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6363 - accuracy: 0.6231 - val_loss: 0.6801 - val_accuracy: 0.5071\n",
      "Epoch 1106/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6371 - accuracy: 0.6255 - val_loss: 0.6298 - val_accuracy: 0.5901\n",
      "Epoch 1107/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6378 - accuracy: 0.6209 - val_loss: 0.6920 - val_accuracy: 0.4914\n",
      "Epoch 1108/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6392 - accuracy: 0.6226 - val_loss: 0.6322 - val_accuracy: 0.5908\n",
      "Epoch 1109/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6377 - accuracy: 0.6201 - val_loss: 0.6786 - val_accuracy: 0.5104\n",
      "Epoch 1110/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6369 - accuracy: 0.6249 - val_loss: 0.6452 - val_accuracy: 0.5654\n",
      "Epoch 1111/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6357 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.5532\n",
      "Epoch 1112/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6351 - accuracy: 0.6266 - val_loss: 0.6680 - val_accuracy: 0.5274\n",
      "Epoch 1113/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6358 - accuracy: 0.6278 - val_loss: 0.6348 - val_accuracy: 0.5859\n",
      "Epoch 1114/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6366 - accuracy: 0.6230 - val_loss: 0.6886 - val_accuracy: 0.4976\n",
      "Epoch 1115/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6387 - accuracy: 0.6219 - val_loss: 0.6317 - val_accuracy: 0.5866\n",
      "Epoch 1116/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6379 - accuracy: 0.6193 - val_loss: 0.6789 - val_accuracy: 0.5095\n",
      "Epoch 1117/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6368 - accuracy: 0.6255 - val_loss: 0.6480 - val_accuracy: 0.5634\n",
      "Epoch 1118/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6360 - accuracy: 0.6251 - val_loss: 0.6535 - val_accuracy: 0.5482\n",
      "Epoch 1119/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6350 - accuracy: 0.6283 - val_loss: 0.6592 - val_accuracy: 0.5404\n",
      "Epoch 1120/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6357 - accuracy: 0.6264 - val_loss: 0.6454 - val_accuracy: 0.5647\n",
      "Epoch 1121/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6353 - accuracy: 0.6251 - val_loss: 0.6662 - val_accuracy: 0.5287\n",
      "Epoch 1122/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6357 - accuracy: 0.6268 - val_loss: 0.6479 - val_accuracy: 0.5608\n",
      "Epoch 1123/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6354 - accuracy: 0.6250 - val_loss: 0.6611 - val_accuracy: 0.5374\n",
      "Epoch 1124/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6353 - accuracy: 0.6275 - val_loss: 0.6501 - val_accuracy: 0.5557\n",
      "Epoch 1125/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6353 - accuracy: 0.6260 - val_loss: 0.6563 - val_accuracy: 0.5464\n",
      "Epoch 1126/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6350 - accuracy: 0.6287 - val_loss: 0.6577 - val_accuracy: 0.5444\n",
      "Epoch 1127/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6352 - accuracy: 0.6278 - val_loss: 0.6530 - val_accuracy: 0.5501\n",
      "Epoch 1128/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6348 - accuracy: 0.6281 - val_loss: 0.6540 - val_accuracy: 0.5504\n",
      "Epoch 1129/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6351 - accuracy: 0.6270 - val_loss: 0.6547 - val_accuracy: 0.5486\n",
      "Epoch 1130/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6348 - accuracy: 0.6279 - val_loss: 0.6545 - val_accuracy: 0.5497\n",
      "Epoch 1131/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6349 - accuracy: 0.6275 - val_loss: 0.6605 - val_accuracy: 0.5391\n",
      "Epoch 1132/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6348 - accuracy: 0.6284 - val_loss: 0.6490 - val_accuracy: 0.5583\n",
      "Epoch 1133/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6349 - accuracy: 0.6270 - val_loss: 0.6624 - val_accuracy: 0.5382\n",
      "Epoch 1134/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6349 - accuracy: 0.6281 - val_loss: 0.6461 - val_accuracy: 0.5649\n",
      "Epoch 1135/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6350 - accuracy: 0.6251 - val_loss: 0.6701 - val_accuracy: 0.5245\n",
      "Epoch 1136/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6352 - accuracy: 0.6276 - val_loss: 0.6400 - val_accuracy: 0.5776\n",
      "Epoch 1137/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6356 - accuracy: 0.6239 - val_loss: 0.6797 - val_accuracy: 0.5104\n",
      "Epoch 1138/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6366 - accuracy: 0.6257 - val_loss: 0.6295 - val_accuracy: 0.5915\n",
      "Epoch 1139/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6372 - accuracy: 0.6213 - val_loss: 0.6952 - val_accuracy: 0.4883\n",
      "Epoch 1140/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6391 - accuracy: 0.6228 - val_loss: 0.6311 - val_accuracy: 0.5926\n",
      "Epoch 1141/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6374 - accuracy: 0.6203 - val_loss: 0.6786 - val_accuracy: 0.5100\n",
      "Epoch 1142/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6364 - accuracy: 0.6248 - val_loss: 0.6468 - val_accuracy: 0.5623\n",
      "Epoch 1143/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6348 - accuracy: 0.6258 - val_loss: 0.6461 - val_accuracy: 0.5654\n",
      "Epoch 1144/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6347 - accuracy: 0.6260 - val_loss: 0.6778 - val_accuracy: 0.5075\n",
      "Epoch 1145/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6363 - accuracy: 0.6267 - val_loss: 0.6261 - val_accuracy: 0.5968\n",
      "Epoch 1146/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6381 - accuracy: 0.6201 - val_loss: 0.7034 - val_accuracy: 0.4766\n",
      "Epoch 1147/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6415 - accuracy: 0.6196 - val_loss: 0.6361 - val_accuracy: 0.5791\n",
      "Epoch 1148/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6368 - accuracy: 0.6211 - val_loss: 0.6507 - val_accuracy: 0.5544\n",
      "Epoch 1149/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6348 - accuracy: 0.6270 - val_loss: 0.6837 - val_accuracy: 0.4971\n",
      "Epoch 1150/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6373 - accuracy: 0.6254 - val_loss: 0.6245 - val_accuracy: 0.5961\n",
      "Epoch 1151/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6384 - accuracy: 0.6190 - val_loss: 0.6914 - val_accuracy: 0.4929\n",
      "Epoch 1152/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6400 - accuracy: 0.6210 - val_loss: 0.6391 - val_accuracy: 0.5692\n",
      "Epoch 1153/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6376 - accuracy: 0.6196 - val_loss: 0.6499 - val_accuracy: 0.5544\n",
      "Epoch 1154/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6349 - accuracy: 0.6264 - val_loss: 0.6749 - val_accuracy: 0.5139\n",
      "Epoch 1155/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6371 - accuracy: 0.6246 - val_loss: 0.6460 - val_accuracy: 0.5596\n",
      "Epoch 1156/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6367 - accuracy: 0.6245 - val_loss: 0.6613 - val_accuracy: 0.5340\n",
      "Epoch 1157/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6355 - accuracy: 0.6257 - val_loss: 0.6408 - val_accuracy: 0.5691\n",
      "Epoch 1158/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6374 - accuracy: 0.6213 - val_loss: 0.6677 - val_accuracy: 0.5252\n",
      "Epoch 1159/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6356 - accuracy: 0.6266 - val_loss: 0.6441 - val_accuracy: 0.5639\n",
      "Epoch 1160/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6364 - accuracy: 0.6238 - val_loss: 0.6762 - val_accuracy: 0.5091\n",
      "Epoch 1161/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6362 - accuracy: 0.6259 - val_loss: 0.6419 - val_accuracy: 0.5687\n",
      "Epoch 1162/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6351 - accuracy: 0.6258 - val_loss: 0.6521 - val_accuracy: 0.5532\n",
      "Epoch 1163/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6349 - accuracy: 0.6259 - val_loss: 0.6639 - val_accuracy: 0.5329\n",
      "Epoch 1164/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6349 - accuracy: 0.6280 - val_loss: 0.6385 - val_accuracy: 0.5742\n",
      "Epoch 1165/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6359 - accuracy: 0.6233 - val_loss: 0.6853 - val_accuracy: 0.4963\n",
      "Epoch 1166/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6372 - accuracy: 0.6231 - val_loss: 0.6317 - val_accuracy: 0.5868\n",
      "Epoch 1167/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6363 - accuracy: 0.6213 - val_loss: 0.6700 - val_accuracy: 0.5258\n",
      "Epoch 1168/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6354 - accuracy: 0.6263 - val_loss: 0.6531 - val_accuracy: 0.5513\n",
      "Epoch 1169/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6345 - accuracy: 0.6281 - val_loss: 0.6441 - val_accuracy: 0.5667\n",
      "Epoch 1170/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6347 - accuracy: 0.6262 - val_loss: 0.6811 - val_accuracy: 0.5004\n",
      "Epoch 1171/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6364 - accuracy: 0.6253 - val_loss: 0.6317 - val_accuracy: 0.5873\n",
      "Epoch 1172/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6362 - accuracy: 0.6233 - val_loss: 0.6779 - val_accuracy: 0.5119\n",
      "Epoch 1173/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6361 - accuracy: 0.6266 - val_loss: 0.6427 - val_accuracy: 0.5714\n",
      "Epoch 1174/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6349 - accuracy: 0.6236 - val_loss: 0.6543 - val_accuracy: 0.5495\n",
      "Epoch 1175/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6340 - accuracy: 0.6294 - val_loss: 0.6679 - val_accuracy: 0.5234\n",
      "Epoch 1176/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6347 - accuracy: 0.6279 - val_loss: 0.6387 - val_accuracy: 0.5773\n",
      "Epoch 1177/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6351 - accuracy: 0.6250 - val_loss: 0.6791 - val_accuracy: 0.5075\n",
      "Epoch 1178/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6362 - accuracy: 0.6262 - val_loss: 0.6335 - val_accuracy: 0.5849\n",
      "Epoch 1179/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6358 - accuracy: 0.6228 - val_loss: 0.6755 - val_accuracy: 0.5117\n",
      "Epoch 1180/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6353 - accuracy: 0.6269 - val_loss: 0.6467 - val_accuracy: 0.5614\n",
      "Epoch 1181/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6348 - accuracy: 0.6262 - val_loss: 0.6575 - val_accuracy: 0.5449\n",
      "Epoch 1182/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6338 - accuracy: 0.6296 - val_loss: 0.6599 - val_accuracy: 0.5407\n",
      "Epoch 1183/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6343 - accuracy: 0.6285 - val_loss: 0.6412 - val_accuracy: 0.5725\n",
      "Epoch 1184/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6344 - accuracy: 0.6258 - val_loss: 0.6706 - val_accuracy: 0.5205\n",
      "Epoch 1185/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6348 - accuracy: 0.6274 - val_loss: 0.6421 - val_accuracy: 0.5703\n",
      "Epoch 1186/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6348 - accuracy: 0.6249 - val_loss: 0.6705 - val_accuracy: 0.5230\n",
      "Epoch 1187/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6345 - accuracy: 0.6280 - val_loss: 0.6460 - val_accuracy: 0.5659\n",
      "Epoch 1188/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6343 - accuracy: 0.6246 - val_loss: 0.6592 - val_accuracy: 0.5415\n",
      "Epoch 1189/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6338 - accuracy: 0.6293 - val_loss: 0.6549 - val_accuracy: 0.5460\n",
      "Epoch 1190/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6340 - accuracy: 0.6285 - val_loss: 0.6510 - val_accuracy: 0.5539\n",
      "Epoch 1191/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6337 - accuracy: 0.6281 - val_loss: 0.6624 - val_accuracy: 0.5391\n",
      "Epoch 1192/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6340 - accuracy: 0.6296 - val_loss: 0.6453 - val_accuracy: 0.5663\n",
      "Epoch 1193/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6341 - accuracy: 0.6248 - val_loss: 0.6659 - val_accuracy: 0.5329\n",
      "Epoch 1194/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6340 - accuracy: 0.6287 - val_loss: 0.6468 - val_accuracy: 0.5617\n",
      "Epoch 1195/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6340 - accuracy: 0.6276 - val_loss: 0.6647 - val_accuracy: 0.5343\n",
      "Epoch 1196/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6338 - accuracy: 0.6298 - val_loss: 0.6473 - val_accuracy: 0.5641\n",
      "Epoch 1197/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6338 - accuracy: 0.6262 - val_loss: 0.6613 - val_accuracy: 0.5417\n",
      "Epoch 1198/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6336 - accuracy: 0.6293 - val_loss: 0.6513 - val_accuracy: 0.5535\n",
      "Epoch 1199/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6336 - accuracy: 0.6281 - val_loss: 0.6576 - val_accuracy: 0.5464\n",
      "Epoch 1200/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6335 - accuracy: 0.6299 - val_loss: 0.6543 - val_accuracy: 0.5515\n",
      "Epoch 1201/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6335 - accuracy: 0.6286 - val_loss: 0.6530 - val_accuracy: 0.5517\n",
      "Epoch 1202/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6334 - accuracy: 0.6287 - val_loss: 0.6575 - val_accuracy: 0.5444\n",
      "Epoch 1203/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6334 - accuracy: 0.6290 - val_loss: 0.6529 - val_accuracy: 0.5490\n",
      "Epoch 1204/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6334 - accuracy: 0.6294 - val_loss: 0.6603 - val_accuracy: 0.5424\n",
      "Epoch 1205/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6334 - accuracy: 0.6299 - val_loss: 0.6482 - val_accuracy: 0.5610\n",
      "Epoch 1206/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6272 - val_loss: 0.6634 - val_accuracy: 0.5378\n",
      "Epoch 1207/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6336 - accuracy: 0.6292 - val_loss: 0.6454 - val_accuracy: 0.5670\n",
      "Epoch 1208/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6336 - accuracy: 0.6261 - val_loss: 0.6701 - val_accuracy: 0.5258\n",
      "Epoch 1209/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6339 - accuracy: 0.6293 - val_loss: 0.6397 - val_accuracy: 0.5775\n",
      "Epoch 1210/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6342 - accuracy: 0.6259 - val_loss: 0.6782 - val_accuracy: 0.5108\n",
      "Epoch 1211/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6350 - accuracy: 0.6273 - val_loss: 0.6328 - val_accuracy: 0.5842\n",
      "Epoch 1212/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6353 - accuracy: 0.6231 - val_loss: 0.6847 - val_accuracy: 0.5002\n",
      "Epoch 1213/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6358 - accuracy: 0.6268 - val_loss: 0.6345 - val_accuracy: 0.5859\n",
      "Epoch 1214/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6353 - accuracy: 0.6230 - val_loss: 0.6796 - val_accuracy: 0.5088\n",
      "Epoch 1215/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6353 - accuracy: 0.6263 - val_loss: 0.6382 - val_accuracy: 0.5751\n",
      "Epoch 1216/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6345 - accuracy: 0.6250 - val_loss: 0.6633 - val_accuracy: 0.5362\n",
      "Epoch 1217/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6334 - accuracy: 0.6298 - val_loss: 0.6540 - val_accuracy: 0.5532\n",
      "Epoch 1218/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6336 - accuracy: 0.6285 - val_loss: 0.6523 - val_accuracy: 0.5513\n",
      "Epoch 1219/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6331 - accuracy: 0.6297 - val_loss: 0.6590 - val_accuracy: 0.5406\n",
      "Epoch 1220/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6335 - accuracy: 0.6274 - val_loss: 0.6468 - val_accuracy: 0.5627\n",
      "Epoch 1221/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6333 - accuracy: 0.6279 - val_loss: 0.6640 - val_accuracy: 0.5331\n",
      "Epoch 1222/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6335 - accuracy: 0.6302 - val_loss: 0.6476 - val_accuracy: 0.5612\n",
      "Epoch 1223/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6334 - accuracy: 0.6270 - val_loss: 0.6659 - val_accuracy: 0.5289\n",
      "Epoch 1224/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6336 - accuracy: 0.6286 - val_loss: 0.6418 - val_accuracy: 0.5685\n",
      "Epoch 1225/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6337 - accuracy: 0.6266 - val_loss: 0.6691 - val_accuracy: 0.5270\n",
      "Epoch 1226/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6337 - accuracy: 0.6293 - val_loss: 0.6411 - val_accuracy: 0.5738\n",
      "Epoch 1227/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6341 - accuracy: 0.6252 - val_loss: 0.6767 - val_accuracy: 0.5122\n",
      "Epoch 1228/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6346 - accuracy: 0.6269 - val_loss: 0.6329 - val_accuracy: 0.5840\n",
      "Epoch 1229/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6352 - accuracy: 0.6233 - val_loss: 0.6841 - val_accuracy: 0.5024\n",
      "Epoch 1230/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6356 - accuracy: 0.6269 - val_loss: 0.6342 - val_accuracy: 0.5849\n",
      "Epoch 1231/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6355 - accuracy: 0.6228 - val_loss: 0.6816 - val_accuracy: 0.5044\n",
      "Epoch 1232/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6352 - accuracy: 0.6264 - val_loss: 0.6364 - val_accuracy: 0.5784\n",
      "Epoch 1233/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6350 - accuracy: 0.6252 - val_loss: 0.6681 - val_accuracy: 0.5296\n",
      "Epoch 1234/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6292 - val_loss: 0.6492 - val_accuracy: 0.5634\n",
      "Epoch 1235/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6338 - accuracy: 0.6267 - val_loss: 0.6582 - val_accuracy: 0.5437\n",
      "Epoch 1236/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6328 - accuracy: 0.6300 - val_loss: 0.6511 - val_accuracy: 0.5528\n",
      "Epoch 1237/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6335 - accuracy: 0.6278 - val_loss: 0.6569 - val_accuracy: 0.5449\n",
      "Epoch 1238/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6328 - accuracy: 0.6290 - val_loss: 0.6534 - val_accuracy: 0.5530\n",
      "Epoch 1239/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6332 - accuracy: 0.6285 - val_loss: 0.6601 - val_accuracy: 0.5400\n",
      "Epoch 1240/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6329 - accuracy: 0.6306 - val_loss: 0.6486 - val_accuracy: 0.5585\n",
      "Epoch 1241/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6330 - accuracy: 0.6289 - val_loss: 0.6620 - val_accuracy: 0.5384\n",
      "Epoch 1242/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6331 - accuracy: 0.6290 - val_loss: 0.6470 - val_accuracy: 0.5619\n",
      "Epoch 1243/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6329 - accuracy: 0.6268 - val_loss: 0.6663 - val_accuracy: 0.5323\n",
      "Epoch 1244/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6332 - accuracy: 0.6303 - val_loss: 0.6427 - val_accuracy: 0.5716\n",
      "Epoch 1245/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6331 - accuracy: 0.6272 - val_loss: 0.6712 - val_accuracy: 0.5221\n",
      "Epoch 1246/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6337 - accuracy: 0.6287 - val_loss: 0.6380 - val_accuracy: 0.5775\n",
      "Epoch 1247/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6336 - accuracy: 0.6256 - val_loss: 0.6776 - val_accuracy: 0.5133\n",
      "Epoch 1248/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6341 - accuracy: 0.6290 - val_loss: 0.6364 - val_accuracy: 0.5817\n",
      "Epoch 1249/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6341 - accuracy: 0.6244 - val_loss: 0.6811 - val_accuracy: 0.5077\n",
      "Epoch 1250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6348 - accuracy: 0.6270 - val_loss: 0.6337 - val_accuracy: 0.5820\n",
      "Epoch 1251/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6345 - accuracy: 0.6242 - val_loss: 0.6776 - val_accuracy: 0.5133\n",
      "Epoch 1252/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6342 - accuracy: 0.6290 - val_loss: 0.6398 - val_accuracy: 0.5762\n",
      "Epoch 1253/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6340 - accuracy: 0.6242 - val_loss: 0.6718 - val_accuracy: 0.5210\n",
      "Epoch 1254/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6335 - accuracy: 0.6286 - val_loss: 0.6407 - val_accuracy: 0.5718\n",
      "Epoch 1255/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6338 - accuracy: 0.6267 - val_loss: 0.6680 - val_accuracy: 0.5296\n",
      "Epoch 1256/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6330 - accuracy: 0.6302 - val_loss: 0.6432 - val_accuracy: 0.5714\n",
      "Epoch 1257/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6336 - accuracy: 0.6256 - val_loss: 0.6745 - val_accuracy: 0.5168\n",
      "Epoch 1258/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6336 - accuracy: 0.6289 - val_loss: 0.6329 - val_accuracy: 0.5826\n",
      "Epoch 1259/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6349 - accuracy: 0.6239 - val_loss: 0.6880 - val_accuracy: 0.4963\n",
      "Epoch 1260/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6357 - accuracy: 0.6262 - val_loss: 0.6308 - val_accuracy: 0.5891\n",
      "Epoch 1261/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6353 - accuracy: 0.6239 - val_loss: 0.6828 - val_accuracy: 0.5058\n",
      "Epoch 1262/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6349 - accuracy: 0.6272 - val_loss: 0.6385 - val_accuracy: 0.5738\n",
      "Epoch 1263/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6337 - accuracy: 0.6265 - val_loss: 0.6582 - val_accuracy: 0.5431\n",
      "Epoch 1264/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6323 - accuracy: 0.6313 - val_loss: 0.6612 - val_accuracy: 0.5402\n",
      "Epoch 1265/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6328 - accuracy: 0.6301 - val_loss: 0.6405 - val_accuracy: 0.5740\n",
      "Epoch 1266/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6330 - accuracy: 0.6277 - val_loss: 0.6775 - val_accuracy: 0.5126\n",
      "Epoch 1267/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6344 - accuracy: 0.6269 - val_loss: 0.6340 - val_accuracy: 0.5818\n",
      "Epoch 1268/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6346 - accuracy: 0.6243 - val_loss: 0.6808 - val_accuracy: 0.5075\n",
      "Epoch 1269/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6343 - accuracy: 0.6282 - val_loss: 0.6394 - val_accuracy: 0.5764\n",
      "Epoch 1270/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6345 - accuracy: 0.6233 - val_loss: 0.6732 - val_accuracy: 0.5179\n",
      "Epoch 1271/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6335 - accuracy: 0.6281 - val_loss: 0.6387 - val_accuracy: 0.5711\n",
      "Epoch 1272/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6342 - accuracy: 0.6258 - val_loss: 0.6647 - val_accuracy: 0.5327\n",
      "Epoch 1273/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6326 - accuracy: 0.6299 - val_loss: 0.6484 - val_accuracy: 0.5638\n",
      "Epoch 1274/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6334 - accuracy: 0.6267 - val_loss: 0.6645 - val_accuracy: 0.5309\n",
      "Epoch 1275/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6324 - accuracy: 0.6309 - val_loss: 0.6433 - val_accuracy: 0.5647\n",
      "Epoch 1276/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6330 - accuracy: 0.6279 - val_loss: 0.6668 - val_accuracy: 0.5307\n",
      "Epoch 1277/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6328 - accuracy: 0.6288 - val_loss: 0.6439 - val_accuracy: 0.5687\n",
      "Epoch 1278/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6327 - accuracy: 0.6276 - val_loss: 0.6700 - val_accuracy: 0.5243\n",
      "Epoch 1279/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6328 - accuracy: 0.6305 - val_loss: 0.6419 - val_accuracy: 0.5718\n",
      "Epoch 1280/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6327 - accuracy: 0.6276 - val_loss: 0.6681 - val_accuracy: 0.5280\n",
      "Epoch 1281/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6328 - accuracy: 0.6290 - val_loss: 0.6427 - val_accuracy: 0.5687\n",
      "Epoch 1282/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6325 - accuracy: 0.6280 - val_loss: 0.6642 - val_accuracy: 0.5342\n",
      "Epoch 1283/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6323 - accuracy: 0.6310 - val_loss: 0.6496 - val_accuracy: 0.5605\n",
      "Epoch 1284/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6321 - accuracy: 0.6287 - val_loss: 0.6607 - val_accuracy: 0.5406\n",
      "Epoch 1285/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6308 - val_loss: 0.6484 - val_accuracy: 0.5592\n",
      "Epoch 1286/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6304 - val_loss: 0.6610 - val_accuracy: 0.5415\n",
      "Epoch 1287/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6306 - val_loss: 0.6494 - val_accuracy: 0.5592\n",
      "Epoch 1288/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6285 - val_loss: 0.6657 - val_accuracy: 0.5318\n",
      "Epoch 1289/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6322 - accuracy: 0.6308 - val_loss: 0.6423 - val_accuracy: 0.5705\n",
      "Epoch 1290/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6324 - accuracy: 0.6275 - val_loss: 0.6731 - val_accuracy: 0.5227\n",
      "Epoch 1291/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6329 - accuracy: 0.6293 - val_loss: 0.6346 - val_accuracy: 0.5835\n",
      "Epoch 1292/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6335 - accuracy: 0.6256 - val_loss: 0.6885 - val_accuracy: 0.4996\n",
      "Epoch 1293/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6351 - accuracy: 0.6257 - val_loss: 0.6290 - val_accuracy: 0.5908\n",
      "Epoch 1294/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6349 - accuracy: 0.6248 - val_loss: 0.6895 - val_accuracy: 0.4962\n",
      "Epoch 1295/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6354 - accuracy: 0.6260 - val_loss: 0.6341 - val_accuracy: 0.5826\n",
      "Epoch 1296/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6336 - accuracy: 0.6255 - val_loss: 0.6685 - val_accuracy: 0.5272\n",
      "Epoch 1297/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6323 - accuracy: 0.6301 - val_loss: 0.6514 - val_accuracy: 0.5535\n",
      "Epoch 1298/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6319 - accuracy: 0.6304 - val_loss: 0.6487 - val_accuracy: 0.5572\n",
      "Epoch 1299/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6317 - accuracy: 0.6296 - val_loss: 0.6689 - val_accuracy: 0.5274\n",
      "Epoch 1300/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6325 - accuracy: 0.6304 - val_loss: 0.6345 - val_accuracy: 0.5820\n",
      "Epoch 1301/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6332 - accuracy: 0.6272 - val_loss: 0.6880 - val_accuracy: 0.4973\n",
      "Epoch 1302/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6351 - accuracy: 0.6257 - val_loss: 0.6304 - val_accuracy: 0.5877\n",
      "Epoch 1303/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6346 - accuracy: 0.6245 - val_loss: 0.6828 - val_accuracy: 0.5057\n",
      "Epoch 1304/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6341 - accuracy: 0.6281 - val_loss: 0.6413 - val_accuracy: 0.5723\n",
      "Epoch 1305/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6328 - accuracy: 0.6261 - val_loss: 0.6556 - val_accuracy: 0.5486\n",
      "Epoch 1306/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6317 - accuracy: 0.6311 - val_loss: 0.6603 - val_accuracy: 0.5376\n",
      "Epoch 1307/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6321 - accuracy: 0.6300 - val_loss: 0.6399 - val_accuracy: 0.5731\n",
      "Epoch 1308/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6323 - accuracy: 0.6284 - val_loss: 0.6784 - val_accuracy: 0.5104\n",
      "Epoch 1309/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6336 - accuracy: 0.6292 - val_loss: 0.6324 - val_accuracy: 0.5884\n",
      "Epoch 1310/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6339 - accuracy: 0.6264 - val_loss: 0.6851 - val_accuracy: 0.5029\n",
      "Epoch 1311/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6346 - accuracy: 0.6261 - val_loss: 0.6374 - val_accuracy: 0.5773\n",
      "Epoch 1312/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6334 - accuracy: 0.6268 - val_loss: 0.6624 - val_accuracy: 0.5343\n",
      "Epoch 1313/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6319 - accuracy: 0.6311 - val_loss: 0.6563 - val_accuracy: 0.5490\n",
      "Epoch 1314/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6322 - accuracy: 0.6301 - val_loss: 0.6438 - val_accuracy: 0.5680\n",
      "Epoch 1315/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6317 - accuracy: 0.6291 - val_loss: 0.6682 - val_accuracy: 0.5261\n",
      "Epoch 1316/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6326 - accuracy: 0.6288 - val_loss: 0.6433 - val_accuracy: 0.5685\n",
      "Epoch 1317/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6322 - accuracy: 0.6280 - val_loss: 0.6693 - val_accuracy: 0.5261\n",
      "Epoch 1318/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6323 - accuracy: 0.6310 - val_loss: 0.6453 - val_accuracy: 0.5685\n",
      "Epoch 1319/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6322 - accuracy: 0.6290 - val_loss: 0.6654 - val_accuracy: 0.5314\n",
      "Epoch 1320/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6319 - accuracy: 0.6295 - val_loss: 0.6433 - val_accuracy: 0.5669\n",
      "Epoch 1321/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6324 - accuracy: 0.6289 - val_loss: 0.6680 - val_accuracy: 0.5294\n",
      "Epoch 1322/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6319 - accuracy: 0.6316 - val_loss: 0.6431 - val_accuracy: 0.5731\n",
      "Epoch 1323/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6326 - accuracy: 0.6266 - val_loss: 0.6724 - val_accuracy: 0.5223\n",
      "Epoch 1324/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6324 - accuracy: 0.6299 - val_loss: 0.6361 - val_accuracy: 0.5789\n",
      "Epoch 1325/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6333 - accuracy: 0.6267 - val_loss: 0.6794 - val_accuracy: 0.5100\n",
      "Epoch 1326/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6331 - accuracy: 0.6292 - val_loss: 0.6357 - val_accuracy: 0.5828\n",
      "Epoch 1327/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6263 - val_loss: 0.6846 - val_accuracy: 0.5046\n",
      "Epoch 1328/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6339 - accuracy: 0.6277 - val_loss: 0.6318 - val_accuracy: 0.5864\n",
      "Epoch 1329/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6338 - accuracy: 0.6259 - val_loss: 0.6769 - val_accuracy: 0.5126\n",
      "Epoch 1330/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6328 - accuracy: 0.6296 - val_loss: 0.6424 - val_accuracy: 0.5734\n",
      "Epoch 1331/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6321 - accuracy: 0.6286 - val_loss: 0.6614 - val_accuracy: 0.5382\n",
      "Epoch 1332/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6313 - accuracy: 0.6314 - val_loss: 0.6526 - val_accuracy: 0.5502\n",
      "Epoch 1333/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6313 - accuracy: 0.6314 - val_loss: 0.6516 - val_accuracy: 0.5530\n",
      "Epoch 1334/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6311 - accuracy: 0.6313 - val_loss: 0.6622 - val_accuracy: 0.5382\n",
      "Epoch 1335/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6314 - accuracy: 0.6316 - val_loss: 0.6452 - val_accuracy: 0.5685\n",
      "Epoch 1336/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6316 - accuracy: 0.6292 - val_loss: 0.6708 - val_accuracy: 0.5227\n",
      "Epoch 1337/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6319 - accuracy: 0.6303 - val_loss: 0.6375 - val_accuracy: 0.5762\n",
      "Epoch 1338/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6325 - accuracy: 0.6276 - val_loss: 0.6792 - val_accuracy: 0.5102\n",
      "Epoch 1339/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6329 - accuracy: 0.6298 - val_loss: 0.6346 - val_accuracy: 0.5828\n",
      "Epoch 1340/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6330 - accuracy: 0.6267 - val_loss: 0.6805 - val_accuracy: 0.5104\n",
      "Epoch 1341/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6333 - accuracy: 0.6286 - val_loss: 0.6355 - val_accuracy: 0.5786\n",
      "Epoch 1342/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6327 - accuracy: 0.6270 - val_loss: 0.6677 - val_accuracy: 0.5285\n",
      "Epoch 1343/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6315 - accuracy: 0.6311 - val_loss: 0.6502 - val_accuracy: 0.5579\n",
      "Epoch 1344/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6314 - accuracy: 0.6305 - val_loss: 0.6552 - val_accuracy: 0.5482\n",
      "Epoch 1345/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6309 - accuracy: 0.6315 - val_loss: 0.6564 - val_accuracy: 0.5453\n",
      "Epoch 1346/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6311 - accuracy: 0.6316 - val_loss: 0.6493 - val_accuracy: 0.5574\n",
      "Epoch 1347/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6310 - accuracy: 0.6314 - val_loss: 0.6639 - val_accuracy: 0.5364\n",
      "Epoch 1348/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6312 - accuracy: 0.6310 - val_loss: 0.6456 - val_accuracy: 0.5685\n",
      "Epoch 1349/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6313 - accuracy: 0.6298 - val_loss: 0.6697 - val_accuracy: 0.5245\n",
      "Epoch 1350/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6317 - accuracy: 0.6304 - val_loss: 0.6360 - val_accuracy: 0.5786\n",
      "Epoch 1351/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6322 - accuracy: 0.6288 - val_loss: 0.6789 - val_accuracy: 0.5106\n",
      "Epoch 1352/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6327 - accuracy: 0.6293 - val_loss: 0.6361 - val_accuracy: 0.5842\n",
      "Epoch 1353/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6327 - accuracy: 0.6265 - val_loss: 0.6812 - val_accuracy: 0.5088\n",
      "Epoch 1354/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6330 - accuracy: 0.6283 - val_loss: 0.6360 - val_accuracy: 0.5787\n",
      "Epoch 1355/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6325 - accuracy: 0.6276 - val_loss: 0.6696 - val_accuracy: 0.5267\n",
      "Epoch 1356/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6315 - accuracy: 0.6314 - val_loss: 0.6456 - val_accuracy: 0.5681\n",
      "Epoch 1357/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6314 - accuracy: 0.6299 - val_loss: 0.6616 - val_accuracy: 0.5376\n",
      "Epoch 1358/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6308 - accuracy: 0.6320 - val_loss: 0.6483 - val_accuracy: 0.5579\n",
      "Epoch 1359/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6312 - accuracy: 0.6309 - val_loss: 0.6611 - val_accuracy: 0.5404\n",
      "Epoch 1360/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6308 - accuracy: 0.6318 - val_loss: 0.6489 - val_accuracy: 0.5617\n",
      "Epoch 1361/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6310 - accuracy: 0.6306 - val_loss: 0.6633 - val_accuracy: 0.5349\n",
      "Epoch 1362/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6309 - accuracy: 0.6315 - val_loss: 0.6443 - val_accuracy: 0.5661\n",
      "Epoch 1363/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6311 - accuracy: 0.6303 - val_loss: 0.6677 - val_accuracy: 0.5285\n",
      "Epoch 1364/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6312 - accuracy: 0.6310 - val_loss: 0.6417 - val_accuracy: 0.5727\n",
      "Epoch 1365/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6313 - accuracy: 0.6295 - val_loss: 0.6737 - val_accuracy: 0.5210\n",
      "Epoch 1366/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6317 - accuracy: 0.6312 - val_loss: 0.6367 - val_accuracy: 0.5780\n",
      "Epoch 1367/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6319 - accuracy: 0.6283 - val_loss: 0.6804 - val_accuracy: 0.5084\n",
      "Epoch 1368/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6326 - accuracy: 0.6294 - val_loss: 0.6331 - val_accuracy: 0.5839\n",
      "Epoch 1369/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6325 - accuracy: 0.6278 - val_loss: 0.6831 - val_accuracy: 0.5058\n",
      "Epoch 1370/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6330 - accuracy: 0.6290 - val_loss: 0.6351 - val_accuracy: 0.5804\n",
      "Epoch 1371/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6321 - accuracy: 0.6279 - val_loss: 0.6733 - val_accuracy: 0.5201\n",
      "Epoch 1372/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6316 - accuracy: 0.6306 - val_loss: 0.6431 - val_accuracy: 0.5692\n",
      "Epoch 1373/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6309 - accuracy: 0.6297 - val_loss: 0.6582 - val_accuracy: 0.5433\n",
      "Epoch 1374/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6305 - accuracy: 0.6324 - val_loss: 0.6568 - val_accuracy: 0.5451\n",
      "Epoch 1375/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6304 - accuracy: 0.6323 - val_loss: 0.6472 - val_accuracy: 0.5623\n",
      "Epoch 1376/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6306 - accuracy: 0.6312 - val_loss: 0.6691 - val_accuracy: 0.5267\n",
      "Epoch 1377/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6311 - accuracy: 0.6312 - val_loss: 0.6370 - val_accuracy: 0.5796\n",
      "Epoch 1378/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6316 - accuracy: 0.6292 - val_loss: 0.6823 - val_accuracy: 0.5079\n",
      "Epoch 1379/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6327 - accuracy: 0.6290 - val_loss: 0.6312 - val_accuracy: 0.5877\n",
      "Epoch 1380/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6327 - accuracy: 0.6274 - val_loss: 0.6861 - val_accuracy: 0.5009\n",
      "Epoch 1381/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6276 - val_loss: 0.6337 - val_accuracy: 0.5828\n",
      "Epoch 1382/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6319 - accuracy: 0.6282 - val_loss: 0.6673 - val_accuracy: 0.5280\n",
      "Epoch 1383/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6309 - accuracy: 0.6318 - val_loss: 0.6519 - val_accuracy: 0.5550\n",
      "Epoch 1384/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6303 - accuracy: 0.6316 - val_loss: 0.6470 - val_accuracy: 0.5628\n",
      "Epoch 1385/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6304 - accuracy: 0.6315 - val_loss: 0.6718 - val_accuracy: 0.5212\n",
      "Epoch 1386/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6313 - accuracy: 0.6304 - val_loss: 0.6309 - val_accuracy: 0.5884\n",
      "Epoch 1387/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6325 - accuracy: 0.6287 - val_loss: 0.6949 - val_accuracy: 0.4859\n",
      "Epoch 1388/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6350 - accuracy: 0.6255 - val_loss: 0.6282 - val_accuracy: 0.5926\n",
      "Epoch 1389/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6337 - accuracy: 0.6259 - val_loss: 0.6835 - val_accuracy: 0.5049\n",
      "Epoch 1390/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6330 - accuracy: 0.6284 - val_loss: 0.6426 - val_accuracy: 0.5676\n",
      "Epoch 1391/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6308 - accuracy: 0.6310 - val_loss: 0.6463 - val_accuracy: 0.5632\n",
      "Epoch 1392/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6304 - accuracy: 0.6314 - val_loss: 0.6749 - val_accuracy: 0.5137\n",
      "Epoch 1393/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6317 - accuracy: 0.6313 - val_loss: 0.6301 - val_accuracy: 0.5886\n",
      "Epoch 1394/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6327 - accuracy: 0.6280 - val_loss: 0.6911 - val_accuracy: 0.4938\n",
      "Epoch 1395/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6345 - accuracy: 0.6270 - val_loss: 0.6343 - val_accuracy: 0.5802\n",
      "Epoch 1396/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6324 - accuracy: 0.6267 - val_loss: 0.6646 - val_accuracy: 0.5332\n",
      "Epoch 1397/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6305 - accuracy: 0.6319 - val_loss: 0.6591 - val_accuracy: 0.5387\n",
      "Epoch 1398/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6306 - accuracy: 0.6323 - val_loss: 0.6393 - val_accuracy: 0.5734\n",
      "Epoch 1399/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6309 - accuracy: 0.6311 - val_loss: 0.6752 - val_accuracy: 0.5175\n",
      "Epoch 1400/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6322 - accuracy: 0.6280 - val_loss: 0.6332 - val_accuracy: 0.5820\n",
      "Epoch 1401/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6322 - accuracy: 0.6274 - val_loss: 0.6756 - val_accuracy: 0.5170\n",
      "Epoch 1402/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6315 - accuracy: 0.6314 - val_loss: 0.6466 - val_accuracy: 0.5638\n",
      "Epoch 1403/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6313 - accuracy: 0.6294 - val_loss: 0.6608 - val_accuracy: 0.5389\n",
      "Epoch 1404/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6302 - accuracy: 0.6326 - val_loss: 0.6492 - val_accuracy: 0.5546\n",
      "Epoch 1405/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6307 - accuracy: 0.6315 - val_loss: 0.6536 - val_accuracy: 0.5506\n",
      "Epoch 1406/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6301 - accuracy: 0.6334 - val_loss: 0.6567 - val_accuracy: 0.5453\n",
      "Epoch 1407/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6303 - accuracy: 0.6313 - val_loss: 0.6556 - val_accuracy: 0.5477\n",
      "Epoch 1408/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6302 - accuracy: 0.6311 - val_loss: 0.6554 - val_accuracy: 0.5469\n",
      "Epoch 1409/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6301 - accuracy: 0.6320 - val_loss: 0.6507 - val_accuracy: 0.5543\n",
      "Epoch 1410/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6302 - accuracy: 0.6320 - val_loss: 0.6580 - val_accuracy: 0.5462\n",
      "Epoch 1411/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6299 - accuracy: 0.6330 - val_loss: 0.6506 - val_accuracy: 0.5570\n",
      "Epoch 1412/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6302 - accuracy: 0.6324 - val_loss: 0.6645 - val_accuracy: 0.5327\n",
      "Epoch 1413/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6302 - accuracy: 0.6322 - val_loss: 0.6419 - val_accuracy: 0.5691\n",
      "Epoch 1414/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6305 - accuracy: 0.6306 - val_loss: 0.6714 - val_accuracy: 0.5247\n",
      "Epoch 1415/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6309 - accuracy: 0.6316 - val_loss: 0.6386 - val_accuracy: 0.5771\n",
      "Epoch 1416/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6310 - accuracy: 0.6303 - val_loss: 0.6813 - val_accuracy: 0.5088\n",
      "Epoch 1417/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6318 - accuracy: 0.6305 - val_loss: 0.6328 - val_accuracy: 0.5840\n",
      "Epoch 1418/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6319 - accuracy: 0.6289 - val_loss: 0.6856 - val_accuracy: 0.5037\n",
      "Epoch 1419/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6329 - accuracy: 0.6288 - val_loss: 0.6309 - val_accuracy: 0.5910\n",
      "Epoch 1420/15000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6321 - accuracy: 0.6276 - val_loss: 0.6793 - val_accuracy: 0.5104\n",
      "Epoch 1421/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6316 - accuracy: 0.6304 - val_loss: 0.6428 - val_accuracy: 0.5681\n",
      "Epoch 1422/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6307 - accuracy: 0.6305 - val_loss: 0.6606 - val_accuracy: 0.5407\n",
      "Epoch 1423/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6299 - accuracy: 0.6326 - val_loss: 0.6519 - val_accuracy: 0.5555\n",
      "Epoch 1424/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6299 - accuracy: 0.6326 - val_loss: 0.6508 - val_accuracy: 0.5548\n",
      "Epoch 1425/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6297 - accuracy: 0.6333 - val_loss: 0.6645 - val_accuracy: 0.5332\n",
      "Epoch 1426/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6300 - accuracy: 0.6325 - val_loss: 0.6469 - val_accuracy: 0.5647\n",
      "Epoch 1427/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6300 - accuracy: 0.6319 - val_loss: 0.6678 - val_accuracy: 0.5269\n",
      "Epoch 1428/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6303 - accuracy: 0.6321 - val_loss: 0.6382 - val_accuracy: 0.5751\n",
      "Epoch 1429/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6305 - accuracy: 0.6309 - val_loss: 0.6749 - val_accuracy: 0.5181\n",
      "Epoch 1430/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6310 - accuracy: 0.6319 - val_loss: 0.6372 - val_accuracy: 0.5786\n",
      "Epoch 1431/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6312 - accuracy: 0.6301 - val_loss: 0.6797 - val_accuracy: 0.5095\n",
      "Epoch 1432/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6316 - accuracy: 0.6306 - val_loss: 0.6351 - val_accuracy: 0.5822\n",
      "Epoch 1433/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6312 - accuracy: 0.6289 - val_loss: 0.6728 - val_accuracy: 0.5212\n",
      "Epoch 1434/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6307 - accuracy: 0.6316 - val_loss: 0.6426 - val_accuracy: 0.5685\n",
      "Epoch 1435/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6303 - accuracy: 0.6322 - val_loss: 0.6646 - val_accuracy: 0.5340\n",
      "Epoch 1436/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6298 - accuracy: 0.6328 - val_loss: 0.6482 - val_accuracy: 0.5627\n",
      "Epoch 1437/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6298 - accuracy: 0.6320 - val_loss: 0.6581 - val_accuracy: 0.5446\n",
      "Epoch 1438/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6295 - accuracy: 0.6333 - val_loss: 0.6527 - val_accuracy: 0.5517\n",
      "Epoch 1439/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6296 - accuracy: 0.6331 - val_loss: 0.6555 - val_accuracy: 0.5477\n",
      "Epoch 1440/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6294 - accuracy: 0.6327 - val_loss: 0.6550 - val_accuracy: 0.5495\n",
      "Epoch 1441/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6295 - accuracy: 0.6331 - val_loss: 0.6525 - val_accuracy: 0.5530\n",
      "Epoch 1442/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6294 - accuracy: 0.6327 - val_loss: 0.6571 - val_accuracy: 0.5435\n",
      "Epoch 1443/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6294 - accuracy: 0.6334 - val_loss: 0.6522 - val_accuracy: 0.5530\n",
      "Epoch 1444/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6293 - accuracy: 0.6327 - val_loss: 0.6598 - val_accuracy: 0.5422\n",
      "Epoch 1445/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6294 - accuracy: 0.6330 - val_loss: 0.6489 - val_accuracy: 0.5592\n",
      "Epoch 1446/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6294 - accuracy: 0.6328 - val_loss: 0.6639 - val_accuracy: 0.5353\n",
      "Epoch 1447/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6295 - accuracy: 0.6325 - val_loss: 0.6438 - val_accuracy: 0.5683\n",
      "Epoch 1448/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6298 - accuracy: 0.6320 - val_loss: 0.6735 - val_accuracy: 0.5188\n",
      "Epoch 1449/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6304 - accuracy: 0.6325 - val_loss: 0.6326 - val_accuracy: 0.5891\n",
      "Epoch 1450/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6313 - accuracy: 0.6292 - val_loss: 0.6929 - val_accuracy: 0.4936\n",
      "Epoch 1451/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6337 - accuracy: 0.6273 - val_loss: 0.6254 - val_accuracy: 0.5992\n",
      "Epoch 1452/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6335 - accuracy: 0.6251 - val_loss: 0.6948 - val_accuracy: 0.4905\n",
      "Epoch 1453/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6340 - accuracy: 0.6275 - val_loss: 0.6352 - val_accuracy: 0.5849\n",
      "Epoch 1454/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6314 - accuracy: 0.6285 - val_loss: 0.6635 - val_accuracy: 0.5349\n",
      "Epoch 1455/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6297 - accuracy: 0.6328 - val_loss: 0.6555 - val_accuracy: 0.5473\n",
      "Epoch 1456/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6297 - accuracy: 0.6330 - val_loss: 0.6436 - val_accuracy: 0.5681\n",
      "Epoch 1457/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6296 - accuracy: 0.6316 - val_loss: 0.6746 - val_accuracy: 0.5172\n",
      "Epoch 1458/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6308 - accuracy: 0.6319 - val_loss: 0.6339 - val_accuracy: 0.5853\n",
      "Epoch 1459/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6311 - accuracy: 0.6301 - val_loss: 0.6865 - val_accuracy: 0.4998\n",
      "Epoch 1460/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6327 - accuracy: 0.6279 - val_loss: 0.6336 - val_accuracy: 0.5809\n",
      "Epoch 1461/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6318 - accuracy: 0.6283 - val_loss: 0.6713 - val_accuracy: 0.5237\n",
      "Epoch 1462/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6303 - accuracy: 0.6327 - val_loss: 0.6480 - val_accuracy: 0.5597\n",
      "Epoch 1463/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6304 - accuracy: 0.6311 - val_loss: 0.6569 - val_accuracy: 0.5437\n",
      "Epoch 1464/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6293 - accuracy: 0.6337 - val_loss: 0.6516 - val_accuracy: 0.5524\n",
      "Epoch 1465/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6299 - accuracy: 0.6323 - val_loss: 0.6540 - val_accuracy: 0.5519\n",
      "Epoch 1466/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6293 - accuracy: 0.6329 - val_loss: 0.6561 - val_accuracy: 0.5475\n",
      "Epoch 1467/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6296 - accuracy: 0.6327 - val_loss: 0.6584 - val_accuracy: 0.5409\n",
      "Epoch 1468/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6292 - accuracy: 0.6334 - val_loss: 0.6510 - val_accuracy: 0.5526\n",
      "Epoch 1469/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6294 - accuracy: 0.6331 - val_loss: 0.6581 - val_accuracy: 0.5418\n",
      "Epoch 1470/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6293 - accuracy: 0.6331 - val_loss: 0.6467 - val_accuracy: 0.5628\n",
      "Epoch 1471/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6294 - accuracy: 0.6323 - val_loss: 0.6646 - val_accuracy: 0.5342\n",
      "Epoch 1472/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6293 - accuracy: 0.6334 - val_loss: 0.6462 - val_accuracy: 0.5617\n",
      "Epoch 1473/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6296 - accuracy: 0.6321 - val_loss: 0.6686 - val_accuracy: 0.5298\n",
      "Epoch 1474/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6296 - accuracy: 0.6322 - val_loss: 0.6370 - val_accuracy: 0.5782\n",
      "Epoch 1475/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6303 - accuracy: 0.6301 - val_loss: 0.6811 - val_accuracy: 0.5095\n",
      "Epoch 1476/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6310 - accuracy: 0.6311 - val_loss: 0.6309 - val_accuracy: 0.5884\n",
      "Epoch 1477/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6321 - accuracy: 0.6279 - val_loss: 0.6982 - val_accuracy: 0.4863\n",
      "Epoch 1478/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6344 - accuracy: 0.6261 - val_loss: 0.6262 - val_accuracy: 0.5972\n",
      "Epoch 1479/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6326 - accuracy: 0.6264 - val_loss: 0.6791 - val_accuracy: 0.5126\n",
      "Epoch 1480/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6308 - accuracy: 0.6320 - val_loss: 0.6472 - val_accuracy: 0.5634\n",
      "Epoch 1481/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6294 - accuracy: 0.6331 - val_loss: 0.6502 - val_accuracy: 0.5544\n",
      "Epoch 1482/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6289 - accuracy: 0.6346 - val_loss: 0.6669 - val_accuracy: 0.5320\n",
      "Epoch 1483/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6296 - accuracy: 0.6313 - val_loss: 0.6345 - val_accuracy: 0.5842\n",
      "Epoch 1484/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6305 - accuracy: 0.6303 - val_loss: 0.6874 - val_accuracy: 0.4976\n",
      "Epoch 1485/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6320 - accuracy: 0.6302 - val_loss: 0.6313 - val_accuracy: 0.5897\n",
      "Epoch 1486/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6320 - accuracy: 0.6275 - val_loss: 0.6866 - val_accuracy: 0.5004\n",
      "Epoch 1487/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6322 - accuracy: 0.6282 - val_loss: 0.6349 - val_accuracy: 0.5806\n",
      "Epoch 1488/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6308 - accuracy: 0.6294 - val_loss: 0.6618 - val_accuracy: 0.5376\n",
      "Epoch 1489/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6290 - accuracy: 0.6336 - val_loss: 0.6577 - val_accuracy: 0.5446\n",
      "Epoch 1490/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6294 - accuracy: 0.6332 - val_loss: 0.6473 - val_accuracy: 0.5617\n",
      "Epoch 1491/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6290 - accuracy: 0.6338 - val_loss: 0.6641 - val_accuracy: 0.5358\n",
      "Epoch 1492/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6295 - accuracy: 0.6317 - val_loss: 0.6407 - val_accuracy: 0.5701\n",
      "Epoch 1493/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6298 - accuracy: 0.6308 - val_loss: 0.6714 - val_accuracy: 0.5214\n",
      "Epoch 1494/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6295 - accuracy: 0.6318 - val_loss: 0.6416 - val_accuracy: 0.5714\n",
      "Epoch 1495/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6304 - accuracy: 0.6309 - val_loss: 0.6781 - val_accuracy: 0.5115\n",
      "Epoch 1496/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6306 - accuracy: 0.6308 - val_loss: 0.6307 - val_accuracy: 0.5877\n",
      "Epoch 1497/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6314 - accuracy: 0.6286 - val_loss: 0.6794 - val_accuracy: 0.5102\n",
      "Epoch 1498/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6309 - accuracy: 0.6318 - val_loss: 0.6383 - val_accuracy: 0.5798\n",
      "Epoch 1499/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6306 - accuracy: 0.6307 - val_loss: 0.6727 - val_accuracy: 0.5185\n",
      "Epoch 1500/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6297 - accuracy: 0.6328 - val_loss: 0.6420 - val_accuracy: 0.5672\n",
      "Epoch 1501/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6295 - accuracy: 0.6318 - val_loss: 0.6619 - val_accuracy: 0.5395\n",
      "Epoch 1502/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6289 - accuracy: 0.6334 - val_loss: 0.6507 - val_accuracy: 0.5572\n",
      "Epoch 1503/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6289 - accuracy: 0.6341 - val_loss: 0.6588 - val_accuracy: 0.5413\n",
      "Epoch 1504/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6286 - accuracy: 0.6339 - val_loss: 0.6529 - val_accuracy: 0.5512\n",
      "Epoch 1505/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6286 - accuracy: 0.6338 - val_loss: 0.6539 - val_accuracy: 0.5499\n",
      "Epoch 1506/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6285 - accuracy: 0.6335 - val_loss: 0.6545 - val_accuracy: 0.5499\n",
      "Epoch 1507/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6286 - accuracy: 0.6335 - val_loss: 0.6554 - val_accuracy: 0.5466\n",
      "Epoch 1508/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6284 - accuracy: 0.6344 - val_loss: 0.6563 - val_accuracy: 0.5460\n",
      "Epoch 1509/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6285 - accuracy: 0.6351 - val_loss: 0.6546 - val_accuracy: 0.5495\n",
      "Epoch 1510/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6283 - accuracy: 0.6349 - val_loss: 0.6538 - val_accuracy: 0.5528\n",
      "Epoch 1511/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6284 - accuracy: 0.6343 - val_loss: 0.6560 - val_accuracy: 0.5460\n",
      "Epoch 1512/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6283 - accuracy: 0.6345 - val_loss: 0.6543 - val_accuracy: 0.5482\n",
      "Epoch 1513/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6284 - accuracy: 0.6350 - val_loss: 0.6578 - val_accuracy: 0.5446\n",
      "Epoch 1514/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6282 - accuracy: 0.6346 - val_loss: 0.6513 - val_accuracy: 0.5550\n",
      "Epoch 1515/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6283 - accuracy: 0.6342 - val_loss: 0.6611 - val_accuracy: 0.5409\n",
      "Epoch 1516/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6283 - accuracy: 0.6346 - val_loss: 0.6462 - val_accuracy: 0.5638\n",
      "Epoch 1517/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6285 - accuracy: 0.6338 - val_loss: 0.6712 - val_accuracy: 0.5254\n",
      "Epoch 1518/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6291 - accuracy: 0.6329 - val_loss: 0.6339 - val_accuracy: 0.5881\n",
      "Epoch 1519/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6299 - accuracy: 0.6305 - val_loss: 0.6926 - val_accuracy: 0.4932\n",
      "Epoch 1520/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6326 - accuracy: 0.6290 - val_loss: 0.6230 - val_accuracy: 0.6056\n",
      "Epoch 1521/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6329 - accuracy: 0.6263 - val_loss: 0.7041 - val_accuracy: 0.4797\n",
      "Epoch 1522/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6351 - accuracy: 0.6253 - val_loss: 0.6346 - val_accuracy: 0.5839\n",
      "Epoch 1523/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6302 - accuracy: 0.6298 - val_loss: 0.6546 - val_accuracy: 0.5491\n",
      "Epoch 1524/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6283 - accuracy: 0.6345 - val_loss: 0.6721 - val_accuracy: 0.5221\n",
      "Epoch 1525/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6295 - accuracy: 0.6327 - val_loss: 0.6243 - val_accuracy: 0.6038\n",
      "Epoch 1526/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6318 - accuracy: 0.6279 - val_loss: 0.7069 - val_accuracy: 0.4735\n",
      "Epoch 1527/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6363 - accuracy: 0.6234 - val_loss: 0.6319 - val_accuracy: 0.5855\n",
      "Epoch 1528/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6312 - accuracy: 0.6282 - val_loss: 0.6603 - val_accuracy: 0.5404\n",
      "Epoch 1529/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6285 - accuracy: 0.6331 - val_loss: 0.6686 - val_accuracy: 0.5259\n",
      "Epoch 1530/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6292 - accuracy: 0.6337 - val_loss: 0.6264 - val_accuracy: 0.5974\n",
      "Epoch 1531/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6310 - accuracy: 0.6297 - val_loss: 0.6928 - val_accuracy: 0.4883\n",
      "Epoch 1532/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6336 - accuracy: 0.6253 - val_loss: 0.6345 - val_accuracy: 0.5776\n",
      "Epoch 1533/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6304 - accuracy: 0.6285 - val_loss: 0.6574 - val_accuracy: 0.5444\n",
      "Epoch 1534/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6285 - accuracy: 0.6326 - val_loss: 0.6695 - val_accuracy: 0.5216\n",
      "Epoch 1535/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6295 - accuracy: 0.6334 - val_loss: 0.6332 - val_accuracy: 0.5831\n",
      "Epoch 1536/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6299 - accuracy: 0.6311 - val_loss: 0.6785 - val_accuracy: 0.5095\n",
      "Epoch 1537/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6310 - accuracy: 0.6294 - val_loss: 0.6387 - val_accuracy: 0.5723\n",
      "Epoch 1538/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6298 - accuracy: 0.6312 - val_loss: 0.6612 - val_accuracy: 0.5384\n",
      "Epoch 1539/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6284 - accuracy: 0.6335 - val_loss: 0.6581 - val_accuracy: 0.5435\n",
      "Epoch 1540/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6289 - accuracy: 0.6331 - val_loss: 0.6473 - val_accuracy: 0.5594\n",
      "Epoch 1541/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6284 - accuracy: 0.6341 - val_loss: 0.6588 - val_accuracy: 0.5398\n",
      "Epoch 1542/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6287 - accuracy: 0.6330 - val_loss: 0.6472 - val_accuracy: 0.5616\n",
      "Epoch 1543/15000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6285 - accuracy: 0.6335 - val_loss: 0.6596 - val_accuracy: 0.5396\n",
      "Epoch 1544/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6282 - accuracy: 0.6338 - val_loss: 0.6554 - val_accuracy: 0.5468\n",
      "Epoch 1545/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6284 - accuracy: 0.6340 - val_loss: 0.6559 - val_accuracy: 0.5464\n",
      "Epoch 1546/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6281 - accuracy: 0.6353 - val_loss: 0.6493 - val_accuracy: 0.5581\n",
      "Epoch 1547/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6282 - accuracy: 0.6339 - val_loss: 0.6587 - val_accuracy: 0.5420\n",
      "Epoch 1548/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6281 - accuracy: 0.6353 - val_loss: 0.6508 - val_accuracy: 0.5561\n",
      "Epoch 1549/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6281 - accuracy: 0.6343 - val_loss: 0.6680 - val_accuracy: 0.5274\n",
      "Epoch 1550/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6285 - accuracy: 0.6332 - val_loss: 0.6406 - val_accuracy: 0.5733\n",
      "Epoch 1551/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6285 - accuracy: 0.6330 - val_loss: 0.6731 - val_accuracy: 0.5247\n",
      "Epoch 1552/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6293 - accuracy: 0.6331 - val_loss: 0.6346 - val_accuracy: 0.5899\n",
      "Epoch 1553/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6295 - accuracy: 0.6307 - val_loss: 0.6853 - val_accuracy: 0.5029\n",
      "Epoch 1554/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6305 - accuracy: 0.6305 - val_loss: 0.6348 - val_accuracy: 0.5842\n",
      "Epoch 1555/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6303 - accuracy: 0.6298 - val_loss: 0.6806 - val_accuracy: 0.5124\n",
      "Epoch 1556/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6301 - accuracy: 0.6321 - val_loss: 0.6345 - val_accuracy: 0.5901\n",
      "Epoch 1557/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6297 - accuracy: 0.6298 - val_loss: 0.6706 - val_accuracy: 0.5259\n",
      "Epoch 1558/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6285 - accuracy: 0.6341 - val_loss: 0.6470 - val_accuracy: 0.5621\n",
      "Epoch 1559/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6287 - accuracy: 0.6339 - val_loss: 0.6643 - val_accuracy: 0.5362\n",
      "Epoch 1560/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6278 - accuracy: 0.6348 - val_loss: 0.6482 - val_accuracy: 0.5658\n",
      "Epoch 1561/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6281 - accuracy: 0.6341 - val_loss: 0.6598 - val_accuracy: 0.5433\n",
      "Epoch 1562/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6278 - accuracy: 0.6350 - val_loss: 0.6492 - val_accuracy: 0.5570\n",
      "Epoch 1563/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6279 - accuracy: 0.6345 - val_loss: 0.6641 - val_accuracy: 0.5349\n",
      "Epoch 1564/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6278 - accuracy: 0.6343 - val_loss: 0.6472 - val_accuracy: 0.5649\n",
      "Epoch 1565/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6280 - accuracy: 0.6345 - val_loss: 0.6665 - val_accuracy: 0.5305\n",
      "Epoch 1566/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6282 - accuracy: 0.6344 - val_loss: 0.6398 - val_accuracy: 0.5742\n",
      "Epoch 1567/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6284 - accuracy: 0.6334 - val_loss: 0.6753 - val_accuracy: 0.5185\n",
      "Epoch 1568/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6288 - accuracy: 0.6341 - val_loss: 0.6366 - val_accuracy: 0.5842\n",
      "Epoch 1569/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6293 - accuracy: 0.6314 - val_loss: 0.6839 - val_accuracy: 0.5073\n",
      "Epoch 1570/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6302 - accuracy: 0.6313 - val_loss: 0.6300 - val_accuracy: 0.5921\n",
      "Epoch 1571/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6303 - accuracy: 0.6297 - val_loss: 0.6846 - val_accuracy: 0.5046\n",
      "Epoch 1572/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6303 - accuracy: 0.6311 - val_loss: 0.6351 - val_accuracy: 0.5862\n",
      "Epoch 1573/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6297 - accuracy: 0.6311 - val_loss: 0.6741 - val_accuracy: 0.5201\n",
      "Epoch 1574/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6288 - accuracy: 0.6331 - val_loss: 0.6413 - val_accuracy: 0.5711\n",
      "Epoch 1575/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6284 - accuracy: 0.6324 - val_loss: 0.6595 - val_accuracy: 0.5418\n",
      "Epoch 1576/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6274 - accuracy: 0.6359 - val_loss: 0.6555 - val_accuracy: 0.5486\n",
      "Epoch 1577/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6277 - accuracy: 0.6350 - val_loss: 0.6524 - val_accuracy: 0.5533\n",
      "Epoch 1578/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6274 - accuracy: 0.6359 - val_loss: 0.6591 - val_accuracy: 0.5417\n",
      "Epoch 1579/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6276 - accuracy: 0.6351 - val_loss: 0.6472 - val_accuracy: 0.5625\n",
      "Epoch 1580/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6277 - accuracy: 0.6339 - val_loss: 0.6663 - val_accuracy: 0.5322\n",
      "Epoch 1581/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6277 - accuracy: 0.6346 - val_loss: 0.6429 - val_accuracy: 0.5700\n",
      "Epoch 1582/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6283 - accuracy: 0.6341 - val_loss: 0.6749 - val_accuracy: 0.5190\n",
      "Epoch 1583/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6288 - accuracy: 0.6328 - val_loss: 0.6304 - val_accuracy: 0.5904\n",
      "Epoch 1584/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6297 - accuracy: 0.6299 - val_loss: 0.6883 - val_accuracy: 0.4998\n",
      "Epoch 1585/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6308 - accuracy: 0.6305 - val_loss: 0.6319 - val_accuracy: 0.5917\n",
      "Epoch 1586/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6303 - accuracy: 0.6292 - val_loss: 0.6836 - val_accuracy: 0.5040\n",
      "Epoch 1587/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6299 - accuracy: 0.6312 - val_loss: 0.6382 - val_accuracy: 0.5725\n",
      "Epoch 1588/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6286 - accuracy: 0.6324 - val_loss: 0.6581 - val_accuracy: 0.5424\n",
      "Epoch 1589/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6274 - accuracy: 0.6360 - val_loss: 0.6578 - val_accuracy: 0.5453\n",
      "Epoch 1590/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6276 - accuracy: 0.6355 - val_loss: 0.6454 - val_accuracy: 0.5650\n",
      "Epoch 1591/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6277 - accuracy: 0.6352 - val_loss: 0.6725 - val_accuracy: 0.5232\n",
      "Epoch 1592/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6284 - accuracy: 0.6325 - val_loss: 0.6357 - val_accuracy: 0.5813\n",
      "Epoch 1593/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6289 - accuracy: 0.6313 - val_loss: 0.6805 - val_accuracy: 0.5084\n",
      "Epoch 1594/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6293 - accuracy: 0.6329 - val_loss: 0.6344 - val_accuracy: 0.5868\n",
      "Epoch 1595/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6295 - accuracy: 0.6316 - val_loss: 0.6827 - val_accuracy: 0.5075\n",
      "Epoch 1596/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6299 - accuracy: 0.6315 - val_loss: 0.6334 - val_accuracy: 0.5818\n",
      "Epoch 1597/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6294 - accuracy: 0.6307 - val_loss: 0.6713 - val_accuracy: 0.5237\n",
      "Epoch 1598/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6282 - accuracy: 0.6340 - val_loss: 0.6466 - val_accuracy: 0.5619\n",
      "Epoch 1599/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6280 - accuracy: 0.6345 - val_loss: 0.6607 - val_accuracy: 0.5378\n",
      "Epoch 1600/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6273 - accuracy: 0.6354 - val_loss: 0.6511 - val_accuracy: 0.5530\n",
      "Epoch 1601/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6275 - accuracy: 0.6343 - val_loss: 0.6538 - val_accuracy: 0.5502\n",
      "Epoch 1602/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6272 - accuracy: 0.6352 - val_loss: 0.6569 - val_accuracy: 0.5453\n",
      "Epoch 1603/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6273 - accuracy: 0.6358 - val_loss: 0.6536 - val_accuracy: 0.5519\n",
      "Epoch 1604/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6272 - accuracy: 0.6356 - val_loss: 0.6582 - val_accuracy: 0.5440\n",
      "Epoch 1605/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6272 - accuracy: 0.6361 - val_loss: 0.6483 - val_accuracy: 0.5607\n",
      "Epoch 1606/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6271 - accuracy: 0.6352 - val_loss: 0.6596 - val_accuracy: 0.5422\n",
      "Epoch 1607/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6272 - accuracy: 0.6365 - val_loss: 0.6504 - val_accuracy: 0.5550\n",
      "Epoch 1608/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6271 - accuracy: 0.6364 - val_loss: 0.6645 - val_accuracy: 0.5351\n",
      "Epoch 1609/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6273 - accuracy: 0.6353 - val_loss: 0.6448 - val_accuracy: 0.5680\n",
      "Epoch 1610/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6272 - accuracy: 0.6352 - val_loss: 0.6683 - val_accuracy: 0.5294\n",
      "Epoch 1611/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6276 - accuracy: 0.6351 - val_loss: 0.6385 - val_accuracy: 0.5795\n",
      "Epoch 1612/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6280 - accuracy: 0.6330 - val_loss: 0.6831 - val_accuracy: 0.5073\n",
      "Epoch 1613/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6293 - accuracy: 0.6323 - val_loss: 0.6304 - val_accuracy: 0.5928\n",
      "Epoch 1614/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6297 - accuracy: 0.6305 - val_loss: 0.6906 - val_accuracy: 0.5002\n",
      "Epoch 1615/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6311 - accuracy: 0.6300 - val_loss: 0.6286 - val_accuracy: 0.5972\n",
      "Epoch 1616/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6297 - accuracy: 0.6290 - val_loss: 0.6784 - val_accuracy: 0.5157\n",
      "Epoch 1617/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6288 - accuracy: 0.6329 - val_loss: 0.6449 - val_accuracy: 0.5643\n",
      "Epoch 1618/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6278 - accuracy: 0.6343 - val_loss: 0.6563 - val_accuracy: 0.5473\n",
      "Epoch 1619/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6269 - accuracy: 0.6363 - val_loss: 0.6602 - val_accuracy: 0.5433\n",
      "Epoch 1620/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6273 - accuracy: 0.6364 - val_loss: 0.6418 - val_accuracy: 0.5720\n",
      "Epoch 1621/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6273 - accuracy: 0.6351 - val_loss: 0.6771 - val_accuracy: 0.5174\n",
      "Epoch 1622/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6285 - accuracy: 0.6323 - val_loss: 0.6350 - val_accuracy: 0.5835\n",
      "Epoch 1623/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6286 - accuracy: 0.6319 - val_loss: 0.6850 - val_accuracy: 0.5046\n",
      "Epoch 1624/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6298 - accuracy: 0.6323 - val_loss: 0.6309 - val_accuracy: 0.5926\n",
      "Epoch 1625/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6290 - accuracy: 0.6303 - val_loss: 0.6780 - val_accuracy: 0.5150\n",
      "Epoch 1626/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6288 - accuracy: 0.6325 - val_loss: 0.6411 - val_accuracy: 0.5694\n",
      "Epoch 1627/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6278 - accuracy: 0.6337 - val_loss: 0.6593 - val_accuracy: 0.5435\n",
      "Epoch 1628/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6269 - accuracy: 0.6361 - val_loss: 0.6573 - val_accuracy: 0.5468\n",
      "Epoch 1629/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6271 - accuracy: 0.6363 - val_loss: 0.6452 - val_accuracy: 0.5669\n",
      "Epoch 1630/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6269 - accuracy: 0.6351 - val_loss: 0.6702 - val_accuracy: 0.5263\n",
      "Epoch 1631/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6277 - accuracy: 0.6337 - val_loss: 0.6403 - val_accuracy: 0.5740\n",
      "Epoch 1632/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6275 - accuracy: 0.6347 - val_loss: 0.6751 - val_accuracy: 0.5177\n",
      "Epoch 1633/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6281 - accuracy: 0.6349 - val_loss: 0.6364 - val_accuracy: 0.5837\n",
      "Epoch 1634/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6278 - accuracy: 0.6332 - val_loss: 0.6752 - val_accuracy: 0.5201\n",
      "Epoch 1635/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6283 - accuracy: 0.6328 - val_loss: 0.6387 - val_accuracy: 0.5747\n",
      "Epoch 1636/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6277 - accuracy: 0.6341 - val_loss: 0.6677 - val_accuracy: 0.5314\n",
      "Epoch 1637/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6273 - accuracy: 0.6355 - val_loss: 0.6469 - val_accuracy: 0.5676\n",
      "Epoch 1638/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6271 - accuracy: 0.6356 - val_loss: 0.6613 - val_accuracy: 0.5413\n",
      "Epoch 1639/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6267 - accuracy: 0.6363 - val_loss: 0.6506 - val_accuracy: 0.5543\n",
      "Epoch 1640/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6269 - accuracy: 0.6358 - val_loss: 0.6583 - val_accuracy: 0.5451\n",
      "Epoch 1641/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6265 - accuracy: 0.6372 - val_loss: 0.6520 - val_accuracy: 0.5555\n",
      "Epoch 1642/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6268 - accuracy: 0.6365 - val_loss: 0.6609 - val_accuracy: 0.5406\n",
      "Epoch 1643/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6265 - accuracy: 0.6370 - val_loss: 0.6471 - val_accuracy: 0.5601\n",
      "Epoch 1644/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6270 - accuracy: 0.6351 - val_loss: 0.6664 - val_accuracy: 0.5340\n",
      "Epoch 1645/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6269 - accuracy: 0.6359 - val_loss: 0.6399 - val_accuracy: 0.5811\n",
      "Epoch 1646/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6276 - accuracy: 0.6341 - val_loss: 0.6786 - val_accuracy: 0.5183\n",
      "Epoch 1647/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6282 - accuracy: 0.6332 - val_loss: 0.6317 - val_accuracy: 0.5888\n",
      "Epoch 1648/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6294 - accuracy: 0.6309 - val_loss: 0.6932 - val_accuracy: 0.4954\n",
      "Epoch 1649/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6309 - accuracy: 0.6305 - val_loss: 0.6262 - val_accuracy: 0.6018\n",
      "Epoch 1650/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6308 - accuracy: 0.6287 - val_loss: 0.6928 - val_accuracy: 0.4976\n",
      "Epoch 1651/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6311 - accuracy: 0.6288 - val_loss: 0.6374 - val_accuracy: 0.5764\n",
      "Epoch 1652/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6297 - accuracy: 0.6310 - val_loss: 0.6629 - val_accuracy: 0.5378\n",
      "Epoch 1653/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6267 - accuracy: 0.6363 - val_loss: 0.6560 - val_accuracy: 0.5473\n",
      "Epoch 1654/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6281 - accuracy: 0.6351 - val_loss: 0.6499 - val_accuracy: 0.5572\n",
      "Epoch 1655/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6263 - accuracy: 0.6369 - val_loss: 0.6559 - val_accuracy: 0.5482\n",
      "Epoch 1656/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6276 - accuracy: 0.6344 - val_loss: 0.6578 - val_accuracy: 0.5457\n",
      "Epoch 1657/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6266 - accuracy: 0.6360 - val_loss: 0.6502 - val_accuracy: 0.5601\n",
      "Epoch 1658/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6272 - accuracy: 0.6362 - val_loss: 0.6689 - val_accuracy: 0.5283\n",
      "Epoch 1659/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6272 - accuracy: 0.6362 - val_loss: 0.6367 - val_accuracy: 0.5795\n",
      "Epoch 1660/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6276 - accuracy: 0.6338 - val_loss: 0.6771 - val_accuracy: 0.5172\n",
      "Epoch 1661/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6284 - accuracy: 0.6324 - val_loss: 0.6361 - val_accuracy: 0.5818\n",
      "Epoch 1662/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6277 - accuracy: 0.6324 - val_loss: 0.6753 - val_accuracy: 0.5203\n",
      "Epoch 1663/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6277 - accuracy: 0.6358 - val_loss: 0.6427 - val_accuracy: 0.5707\n",
      "Epoch 1664/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6269 - accuracy: 0.6360 - val_loss: 0.6633 - val_accuracy: 0.5364\n",
      "Epoch 1665/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6267 - accuracy: 0.6365 - val_loss: 0.6461 - val_accuracy: 0.5621\n",
      "Epoch 1666/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6264 - accuracy: 0.6359 - val_loss: 0.6582 - val_accuracy: 0.5455\n",
      "Epoch 1667/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6262 - accuracy: 0.6375 - val_loss: 0.6554 - val_accuracy: 0.5491\n",
      "Epoch 1668/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6262 - accuracy: 0.6370 - val_loss: 0.6555 - val_accuracy: 0.5490\n",
      "Epoch 1669/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6261 - accuracy: 0.6368 - val_loss: 0.6540 - val_accuracy: 0.5510\n",
      "Epoch 1670/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6261 - accuracy: 0.6367 - val_loss: 0.6527 - val_accuracy: 0.5543\n",
      "Epoch 1671/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6261 - accuracy: 0.6379 - val_loss: 0.6569 - val_accuracy: 0.5471\n",
      "Epoch 1672/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6260 - accuracy: 0.6372 - val_loss: 0.6552 - val_accuracy: 0.5482\n",
      "Epoch 1673/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6260 - accuracy: 0.6373 - val_loss: 0.6570 - val_accuracy: 0.5480\n",
      "Epoch 1674/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6260 - accuracy: 0.6372 - val_loss: 0.6508 - val_accuracy: 0.5581\n",
      "Epoch 1675/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6260 - accuracy: 0.6369 - val_loss: 0.6595 - val_accuracy: 0.5455\n",
      "Epoch 1676/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6260 - accuracy: 0.6371 - val_loss: 0.6494 - val_accuracy: 0.5590\n",
      "Epoch 1677/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6261 - accuracy: 0.6379 - val_loss: 0.6671 - val_accuracy: 0.5332\n",
      "Epoch 1678/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6264 - accuracy: 0.6362 - val_loss: 0.6405 - val_accuracy: 0.5762\n",
      "Epoch 1679/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6267 - accuracy: 0.6349 - val_loss: 0.6805 - val_accuracy: 0.5141\n",
      "Epoch 1680/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6280 - accuracy: 0.6347 - val_loss: 0.6260 - val_accuracy: 0.6018\n",
      "Epoch 1681/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6295 - accuracy: 0.6309 - val_loss: 0.7071 - val_accuracy: 0.4788\n",
      "Epoch 1682/15000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6338 - accuracy: 0.6262 - val_loss: 0.6273 - val_accuracy: 0.5966\n",
      "Epoch 1683/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6302 - accuracy: 0.6284 - val_loss: 0.6758 - val_accuracy: 0.5194\n",
      "Epoch 1684/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6276 - accuracy: 0.6358 - val_loss: 0.6522 - val_accuracy: 0.5559\n",
      "Epoch 1685/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6267 - accuracy: 0.6369 - val_loss: 0.6427 - val_accuracy: 0.5661\n",
      "Epoch 1686/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6263 - accuracy: 0.6361 - val_loss: 0.6750 - val_accuracy: 0.5216\n",
      "Epoch 1687/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6280 - accuracy: 0.6327 - val_loss: 0.6350 - val_accuracy: 0.5835\n",
      "Epoch 1688/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6279 - accuracy: 0.6327 - val_loss: 0.6860 - val_accuracy: 0.5038\n",
      "Epoch 1689/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6290 - accuracy: 0.6333 - val_loss: 0.6347 - val_accuracy: 0.5881\n",
      "Epoch 1690/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6284 - accuracy: 0.6324 - val_loss: 0.6770 - val_accuracy: 0.5166\n",
      "Epoch 1691/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6282 - accuracy: 0.6323 - val_loss: 0.6401 - val_accuracy: 0.5705\n",
      "Epoch 1692/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6279 - accuracy: 0.6333 - val_loss: 0.6594 - val_accuracy: 0.5431\n",
      "Epoch 1693/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6262 - accuracy: 0.6369 - val_loss: 0.6544 - val_accuracy: 0.5528\n",
      "Epoch 1694/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6273 - accuracy: 0.6360 - val_loss: 0.6570 - val_accuracy: 0.5464\n",
      "Epoch 1695/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6259 - accuracy: 0.6371 - val_loss: 0.6492 - val_accuracy: 0.5559\n",
      "Epoch 1696/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6269 - accuracy: 0.6343 - val_loss: 0.6626 - val_accuracy: 0.5373\n",
      "Epoch 1697/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6263 - accuracy: 0.6366 - val_loss: 0.6430 - val_accuracy: 0.5740\n",
      "Epoch 1698/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6271 - accuracy: 0.6356 - val_loss: 0.6781 - val_accuracy: 0.5148\n",
      "Epoch 1699/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6274 - accuracy: 0.6344 - val_loss: 0.6322 - val_accuracy: 0.5871\n",
      "Epoch 1700/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6285 - accuracy: 0.6318 - val_loss: 0.6845 - val_accuracy: 0.5104\n",
      "Epoch 1701/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6291 - accuracy: 0.6329 - val_loss: 0.6309 - val_accuracy: 0.5952\n",
      "Epoch 1702/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6282 - accuracy: 0.6313 - val_loss: 0.6727 - val_accuracy: 0.5228\n",
      "Epoch 1703/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6267 - accuracy: 0.6360 - val_loss: 0.6490 - val_accuracy: 0.5559\n",
      "Epoch 1704/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6265 - accuracy: 0.6362 - val_loss: 0.6552 - val_accuracy: 0.5493\n",
      "Epoch 1705/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6255 - accuracy: 0.6382 - val_loss: 0.6569 - val_accuracy: 0.5464\n",
      "Epoch 1706/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6261 - accuracy: 0.6370 - val_loss: 0.6453 - val_accuracy: 0.5680\n",
      "Epoch 1707/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6259 - accuracy: 0.6379 - val_loss: 0.6711 - val_accuracy: 0.5245\n",
      "Epoch 1708/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6265 - accuracy: 0.6356 - val_loss: 0.6408 - val_accuracy: 0.5744\n",
      "Epoch 1709/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6268 - accuracy: 0.6360 - val_loss: 0.6775 - val_accuracy: 0.5185\n",
      "Epoch 1710/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6275 - accuracy: 0.6354 - val_loss: 0.6315 - val_accuracy: 0.5937\n",
      "Epoch 1711/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6279 - accuracy: 0.6321 - val_loss: 0.6811 - val_accuracy: 0.5117\n",
      "Epoch 1712/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6278 - accuracy: 0.6348 - val_loss: 0.6376 - val_accuracy: 0.5800\n",
      "Epoch 1713/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6277 - accuracy: 0.6342 - val_loss: 0.6759 - val_accuracy: 0.5205\n",
      "Epoch 1714/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6270 - accuracy: 0.6360 - val_loss: 0.6362 - val_accuracy: 0.5828\n",
      "Epoch 1715/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6271 - accuracy: 0.6344 - val_loss: 0.6739 - val_accuracy: 0.5214\n",
      "Epoch 1716/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6267 - accuracy: 0.6344 - val_loss: 0.6414 - val_accuracy: 0.5723\n",
      "Epoch 1717/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6268 - accuracy: 0.6358 - val_loss: 0.6727 - val_accuracy: 0.5234\n",
      "Epoch 1718/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6263 - accuracy: 0.6362 - val_loss: 0.6392 - val_accuracy: 0.5800\n",
      "Epoch 1719/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6266 - accuracy: 0.6360 - val_loss: 0.6712 - val_accuracy: 0.5237\n",
      "Epoch 1720/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6265 - accuracy: 0.6351 - val_loss: 0.6401 - val_accuracy: 0.5744\n",
      "Epoch 1721/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6265 - accuracy: 0.6357 - val_loss: 0.6700 - val_accuracy: 0.5298\n",
      "Epoch 1722/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6261 - accuracy: 0.6364 - val_loss: 0.6440 - val_accuracy: 0.5716\n",
      "Epoch 1723/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6261 - accuracy: 0.6372 - val_loss: 0.6654 - val_accuracy: 0.5351\n",
      "Epoch 1724/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6257 - accuracy: 0.6371 - val_loss: 0.6457 - val_accuracy: 0.5627\n",
      "Epoch 1725/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6258 - accuracy: 0.6366 - val_loss: 0.6642 - val_accuracy: 0.5385\n",
      "Epoch 1726/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6255 - accuracy: 0.6372 - val_loss: 0.6466 - val_accuracy: 0.5656\n",
      "Epoch 1727/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6259 - accuracy: 0.6386 - val_loss: 0.6681 - val_accuracy: 0.5305\n",
      "Epoch 1728/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6258 - accuracy: 0.6366 - val_loss: 0.6399 - val_accuracy: 0.5734\n",
      "Epoch 1729/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6264 - accuracy: 0.6353 - val_loss: 0.6765 - val_accuracy: 0.5199\n",
      "Epoch 1730/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6267 - accuracy: 0.6360 - val_loss: 0.6331 - val_accuracy: 0.5923\n",
      "Epoch 1731/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6276 - accuracy: 0.6329 - val_loss: 0.6889 - val_accuracy: 0.5040\n",
      "Epoch 1732/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6290 - accuracy: 0.6327 - val_loss: 0.6285 - val_accuracy: 0.5930\n",
      "Epoch 1733/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6288 - accuracy: 0.6306 - val_loss: 0.6850 - val_accuracy: 0.5060\n",
      "Epoch 1734/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6281 - accuracy: 0.6345 - val_loss: 0.6381 - val_accuracy: 0.5824\n",
      "Epoch 1735/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6271 - accuracy: 0.6349 - val_loss: 0.6685 - val_accuracy: 0.5276\n",
      "Epoch 1736/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6259 - accuracy: 0.6363 - val_loss: 0.6462 - val_accuracy: 0.5643\n",
      "Epoch 1737/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6260 - accuracy: 0.6355 - val_loss: 0.6580 - val_accuracy: 0.5466\n",
      "Epoch 1738/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6252 - accuracy: 0.6381 - val_loss: 0.6559 - val_accuracy: 0.5513\n",
      "Epoch 1739/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6257 - accuracy: 0.6381 - val_loss: 0.6550 - val_accuracy: 0.5495\n",
      "Epoch 1740/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6251 - accuracy: 0.6382 - val_loss: 0.6555 - val_accuracy: 0.5493\n",
      "Epoch 1741/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6255 - accuracy: 0.6374 - val_loss: 0.6526 - val_accuracy: 0.5533\n",
      "Epoch 1742/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6252 - accuracy: 0.6373 - val_loss: 0.6564 - val_accuracy: 0.5471\n",
      "Epoch 1743/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6253 - accuracy: 0.6373 - val_loss: 0.6556 - val_accuracy: 0.5464\n",
      "Epoch 1744/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6251 - accuracy: 0.6378 - val_loss: 0.6553 - val_accuracy: 0.5499\n",
      "Epoch 1745/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6252 - accuracy: 0.6381 - val_loss: 0.6537 - val_accuracy: 0.5521\n",
      "Epoch 1746/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6251 - accuracy: 0.6377 - val_loss: 0.6557 - val_accuracy: 0.5506\n",
      "Epoch 1747/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6252 - accuracy: 0.6383 - val_loss: 0.6553 - val_accuracy: 0.5479\n",
      "Epoch 1748/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6250 - accuracy: 0.6381 - val_loss: 0.6577 - val_accuracy: 0.5459\n",
      "Epoch 1749/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6251 - accuracy: 0.6378 - val_loss: 0.6515 - val_accuracy: 0.5566\n",
      "Epoch 1750/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6250 - accuracy: 0.6379 - val_loss: 0.6602 - val_accuracy: 0.5435\n",
      "Epoch 1751/15000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.6252 - accuracy: 0.6378 - val_loss: 0.6477 - val_accuracy: 0.5634\n",
      "Epoch 1752/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6251 - accuracy: 0.6384 - val_loss: 0.6695 - val_accuracy: 0.5312\n",
      "Epoch 1753/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6256 - accuracy: 0.6371 - val_loss: 0.6377 - val_accuracy: 0.5804\n",
      "Epoch 1754/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6262 - accuracy: 0.6352 - val_loss: 0.6851 - val_accuracy: 0.5088\n",
      "Epoch 1755/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6279 - accuracy: 0.6344 - val_loss: 0.6256 - val_accuracy: 0.6036\n",
      "Epoch 1756/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6289 - accuracy: 0.6303 - val_loss: 0.7033 - val_accuracy: 0.4868\n",
      "Epoch 1757/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6317 - accuracy: 0.6288 - val_loss: 0.6299 - val_accuracy: 0.5935\n",
      "Epoch 1758/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6283 - accuracy: 0.6317 - val_loss: 0.6722 - val_accuracy: 0.5267\n",
      "Epoch 1759/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6261 - accuracy: 0.6365 - val_loss: 0.6505 - val_accuracy: 0.5554\n",
      "Epoch 1760/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6252 - accuracy: 0.6384 - val_loss: 0.6434 - val_accuracy: 0.5663\n",
      "Epoch 1761/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6253 - accuracy: 0.6379 - val_loss: 0.6790 - val_accuracy: 0.5161\n",
      "Epoch 1762/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6270 - accuracy: 0.6338 - val_loss: 0.6291 - val_accuracy: 0.5930\n",
      "Epoch 1763/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6281 - accuracy: 0.6324 - val_loss: 0.7002 - val_accuracy: 0.4892\n",
      "Epoch 1764/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6311 - accuracy: 0.6298 - val_loss: 0.6298 - val_accuracy: 0.5948\n",
      "Epoch 1765/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6279 - accuracy: 0.6313 - val_loss: 0.6701 - val_accuracy: 0.5254\n",
      "Epoch 1766/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6259 - accuracy: 0.6367 - val_loss: 0.6528 - val_accuracy: 0.5490\n",
      "Epoch 1767/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6250 - accuracy: 0.6382 - val_loss: 0.6387 - val_accuracy: 0.5802\n",
      "Epoch 1768/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6257 - accuracy: 0.6365 - val_loss: 0.6816 - val_accuracy: 0.5119\n",
      "Epoch 1769/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6276 - accuracy: 0.6348 - val_loss: 0.6284 - val_accuracy: 0.5935\n",
      "Epoch 1770/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6281 - accuracy: 0.6314 - val_loss: 0.6904 - val_accuracy: 0.4987\n",
      "Epoch 1771/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6287 - accuracy: 0.6326 - val_loss: 0.6384 - val_accuracy: 0.5765\n",
      "Epoch 1772/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6261 - accuracy: 0.6361 - val_loss: 0.6564 - val_accuracy: 0.5442\n",
      "Epoch 1773/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6249 - accuracy: 0.6383 - val_loss: 0.6612 - val_accuracy: 0.5400\n",
      "Epoch 1774/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6251 - accuracy: 0.6384 - val_loss: 0.6346 - val_accuracy: 0.5826\n",
      "Epoch 1775/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6263 - accuracy: 0.6364 - val_loss: 0.6864 - val_accuracy: 0.5031\n",
      "Epoch 1776/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6280 - accuracy: 0.6332 - val_loss: 0.6322 - val_accuracy: 0.5873\n",
      "Epoch 1777/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6272 - accuracy: 0.6341 - val_loss: 0.6764 - val_accuracy: 0.5172\n",
      "Epoch 1778/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6265 - accuracy: 0.6353 - val_loss: 0.6440 - val_accuracy: 0.5652\n",
      "Epoch 1779/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6251 - accuracy: 0.6371 - val_loss: 0.6511 - val_accuracy: 0.5535\n",
      "Epoch 1780/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6246 - accuracy: 0.6388 - val_loss: 0.6666 - val_accuracy: 0.5342\n",
      "Epoch 1781/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6252 - accuracy: 0.6383 - val_loss: 0.6364 - val_accuracy: 0.5835\n",
      "Epoch 1782/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6261 - accuracy: 0.6360 - val_loss: 0.6840 - val_accuracy: 0.5106\n",
      "Epoch 1783/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6276 - accuracy: 0.6340 - val_loss: 0.6318 - val_accuracy: 0.5884\n",
      "Epoch 1784/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6272 - accuracy: 0.6326 - val_loss: 0.6796 - val_accuracy: 0.5126\n",
      "Epoch 1785/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6266 - accuracy: 0.6355 - val_loss: 0.6419 - val_accuracy: 0.5703\n",
      "Epoch 1786/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6256 - accuracy: 0.6372 - val_loss: 0.6593 - val_accuracy: 0.5455\n",
      "Epoch 1787/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6247 - accuracy: 0.6382 - val_loss: 0.6538 - val_accuracy: 0.5543\n",
      "Epoch 1788/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6248 - accuracy: 0.6381 - val_loss: 0.6482 - val_accuracy: 0.5614\n",
      "Epoch 1789/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6247 - accuracy: 0.6389 - val_loss: 0.6681 - val_accuracy: 0.5311\n",
      "Epoch 1790/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6251 - accuracy: 0.6372 - val_loss: 0.6415 - val_accuracy: 0.5729\n",
      "Epoch 1791/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6254 - accuracy: 0.6373 - val_loss: 0.6753 - val_accuracy: 0.5210\n",
      "Epoch 1792/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6261 - accuracy: 0.6345 - val_loss: 0.6362 - val_accuracy: 0.5815\n",
      "Epoch 1793/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6261 - accuracy: 0.6346 - val_loss: 0.6780 - val_accuracy: 0.5190\n",
      "Epoch 1794/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6261 - accuracy: 0.6367 - val_loss: 0.6390 - val_accuracy: 0.5796\n",
      "Epoch 1795/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6261 - accuracy: 0.6368 - val_loss: 0.6754 - val_accuracy: 0.5208\n",
      "Epoch 1796/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6260 - accuracy: 0.6355 - val_loss: 0.6364 - val_accuracy: 0.5818\n",
      "Epoch 1797/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6262 - accuracy: 0.6347 - val_loss: 0.6739 - val_accuracy: 0.5245\n",
      "Epoch 1798/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6256 - accuracy: 0.6374 - val_loss: 0.6432 - val_accuracy: 0.5714\n",
      "Epoch 1799/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6258 - accuracy: 0.6373 - val_loss: 0.6729 - val_accuracy: 0.5252\n",
      "Epoch 1800/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6255 - accuracy: 0.6362 - val_loss: 0.6375 - val_accuracy: 0.5782\n",
      "Epoch 1801/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6259 - accuracy: 0.6355 - val_loss: 0.6748 - val_accuracy: 0.5216\n",
      "Epoch 1802/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6257 - accuracy: 0.6367 - val_loss: 0.6381 - val_accuracy: 0.5826\n",
      "Epoch 1803/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - accuracy: 0.6359 - val_loss: 0.6810 - val_accuracy: 0.5132\n",
      "Epoch 1804/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6265 - accuracy: 0.6349 - val_loss: 0.6347 - val_accuracy: 0.5822\n",
      "Epoch 1805/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6265 - accuracy: 0.6341 - val_loss: 0.6731 - val_accuracy: 0.5243\n",
      "Epoch 1806/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6256 - accuracy: 0.6373 - val_loss: 0.6431 - val_accuracy: 0.5705\n",
      "Epoch 1807/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6254 - accuracy: 0.6377 - val_loss: 0.6645 - val_accuracy: 0.5380\n",
      "Epoch 1808/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6247 - accuracy: 0.6380 - val_loss: 0.6495 - val_accuracy: 0.5588\n",
      "Epoch 1809/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6248 - accuracy: 0.6378 - val_loss: 0.6584 - val_accuracy: 0.5479\n",
      "Epoch 1810/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6244 - accuracy: 0.6387 - val_loss: 0.6531 - val_accuracy: 0.5535\n",
      "Epoch 1811/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6246 - accuracy: 0.6390 - val_loss: 0.6568 - val_accuracy: 0.5455\n",
      "Epoch 1812/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6243 - accuracy: 0.6386 - val_loss: 0.6540 - val_accuracy: 0.5530\n",
      "Epoch 1813/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6245 - accuracy: 0.6383 - val_loss: 0.6558 - val_accuracy: 0.5512\n",
      "Epoch 1814/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6242 - accuracy: 0.6386 - val_loss: 0.6528 - val_accuracy: 0.5563\n",
      "Epoch 1815/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6244 - accuracy: 0.6382 - val_loss: 0.6586 - val_accuracy: 0.5448\n",
      "Epoch 1816/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6242 - accuracy: 0.6390 - val_loss: 0.6515 - val_accuracy: 0.5555\n",
      "Epoch 1817/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6244 - accuracy: 0.6387 - val_loss: 0.6608 - val_accuracy: 0.5438\n",
      "Epoch 1818/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6242 - accuracy: 0.6390 - val_loss: 0.6473 - val_accuracy: 0.5658\n",
      "Epoch 1819/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6245 - accuracy: 0.6393 - val_loss: 0.6683 - val_accuracy: 0.5343\n",
      "Epoch 1820/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6246 - accuracy: 0.6390 - val_loss: 0.6409 - val_accuracy: 0.5758\n",
      "Epoch 1821/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6252 - accuracy: 0.6370 - val_loss: 0.6803 - val_accuracy: 0.5159\n",
      "Epoch 1822/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6262 - accuracy: 0.6355 - val_loss: 0.6286 - val_accuracy: 0.6001\n",
      "Epoch 1823/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6272 - accuracy: 0.6323 - val_loss: 0.6975 - val_accuracy: 0.4962\n",
      "Epoch 1824/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6294 - accuracy: 0.6306 - val_loss: 0.6310 - val_accuracy: 0.5930\n",
      "Epoch 1825/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6273 - accuracy: 0.6336 - val_loss: 0.6745 - val_accuracy: 0.5239\n",
      "Epoch 1826/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6255 - accuracy: 0.6373 - val_loss: 0.6469 - val_accuracy: 0.5641\n",
      "Epoch 1827/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6245 - accuracy: 0.6384 - val_loss: 0.6507 - val_accuracy: 0.5563\n",
      "Epoch 1828/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6241 - accuracy: 0.6389 - val_loss: 0.6683 - val_accuracy: 0.5312\n",
      "Epoch 1829/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6248 - accuracy: 0.6369 - val_loss: 0.6393 - val_accuracy: 0.5771\n",
      "Epoch 1830/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6253 - accuracy: 0.6359 - val_loss: 0.6833 - val_accuracy: 0.5115\n",
      "Epoch 1831/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6266 - accuracy: 0.6350 - val_loss: 0.6304 - val_accuracy: 0.5919\n",
      "Epoch 1832/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6265 - accuracy: 0.6339 - val_loss: 0.6863 - val_accuracy: 0.5077\n",
      "Epoch 1833/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6274 - accuracy: 0.6333 - val_loss: 0.6363 - val_accuracy: 0.5796\n",
      "Epoch 1834/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6256 - accuracy: 0.6356 - val_loss: 0.6641 - val_accuracy: 0.5380\n",
      "Epoch 1835/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6244 - accuracy: 0.6391 - val_loss: 0.6549 - val_accuracy: 0.5508\n",
      "Epoch 1836/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6241 - accuracy: 0.6386 - val_loss: 0.6443 - val_accuracy: 0.5667\n",
      "Epoch 1837/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6244 - accuracy: 0.6383 - val_loss: 0.6740 - val_accuracy: 0.5243\n",
      "Epoch 1838/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6253 - accuracy: 0.6363 - val_loss: 0.6344 - val_accuracy: 0.5846\n",
      "Epoch 1839/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6258 - accuracy: 0.6353 - val_loss: 0.6854 - val_accuracy: 0.5055\n",
      "Epoch 1840/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6269 - accuracy: 0.6350 - val_loss: 0.6334 - val_accuracy: 0.5842\n",
      "Epoch 1841/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6260 - accuracy: 0.6353 - val_loss: 0.6760 - val_accuracy: 0.5210\n",
      "Epoch 1842/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6255 - accuracy: 0.6358 - val_loss: 0.6419 - val_accuracy: 0.5705\n",
      "Epoch 1843/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6244 - accuracy: 0.6382 - val_loss: 0.6564 - val_accuracy: 0.5460\n",
      "Epoch 1844/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6239 - accuracy: 0.6387 - val_loss: 0.6603 - val_accuracy: 0.5429\n",
      "Epoch 1845/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6239 - accuracy: 0.6393 - val_loss: 0.6436 - val_accuracy: 0.5691\n",
      "Epoch 1846/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6244 - accuracy: 0.6375 - val_loss: 0.6744 - val_accuracy: 0.5225\n",
      "Epoch 1847/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6251 - accuracy: 0.6362 - val_loss: 0.6340 - val_accuracy: 0.5840\n",
      "Epoch 1848/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6256 - accuracy: 0.6357 - val_loss: 0.6856 - val_accuracy: 0.5079\n",
      "Epoch 1849/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6267 - accuracy: 0.6349 - val_loss: 0.6326 - val_accuracy: 0.5859\n",
      "Epoch 1850/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6261 - accuracy: 0.6349 - val_loss: 0.6794 - val_accuracy: 0.5170\n",
      "Epoch 1851/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6259 - accuracy: 0.6356 - val_loss: 0.6394 - val_accuracy: 0.5762\n",
      "Epoch 1852/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6246 - accuracy: 0.6371 - val_loss: 0.6603 - val_accuracy: 0.5449\n",
      "Epoch 1853/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6238 - accuracy: 0.6395 - val_loss: 0.6574 - val_accuracy: 0.5468\n",
      "Epoch 1854/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6237 - accuracy: 0.6390 - val_loss: 0.6465 - val_accuracy: 0.5634\n",
      "Epoch 1855/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6239 - accuracy: 0.6390 - val_loss: 0.6705 - val_accuracy: 0.5283\n",
      "Epoch 1856/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6246 - accuracy: 0.6376 - val_loss: 0.6365 - val_accuracy: 0.5798\n",
      "Epoch 1857/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6252 - accuracy: 0.6365 - val_loss: 0.6844 - val_accuracy: 0.5091\n",
      "Epoch 1858/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6263 - accuracy: 0.6351 - val_loss: 0.6322 - val_accuracy: 0.5870\n",
      "Epoch 1859/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6262 - accuracy: 0.6354 - val_loss: 0.6840 - val_accuracy: 0.5117\n",
      "Epoch 1860/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6266 - accuracy: 0.6353 - val_loss: 0.6349 - val_accuracy: 0.5868\n",
      "Epoch 1861/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6252 - accuracy: 0.6354 - val_loss: 0.6672 - val_accuracy: 0.5349\n",
      "Epoch 1862/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6241 - accuracy: 0.6388 - val_loss: 0.6521 - val_accuracy: 0.5526\n",
      "Epoch 1863/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6237 - accuracy: 0.6394 - val_loss: 0.6513 - val_accuracy: 0.5552\n",
      "Epoch 1864/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6236 - accuracy: 0.6394 - val_loss: 0.6640 - val_accuracy: 0.5398\n",
      "Epoch 1865/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6240 - accuracy: 0.6388 - val_loss: 0.6412 - val_accuracy: 0.5734\n",
      "Epoch 1866/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6243 - accuracy: 0.6373 - val_loss: 0.6784 - val_accuracy: 0.5164\n",
      "Epoch 1867/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6252 - accuracy: 0.6361 - val_loss: 0.6346 - val_accuracy: 0.5846\n",
      "Epoch 1868/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6255 - accuracy: 0.6365 - val_loss: 0.6834 - val_accuracy: 0.5130\n",
      "Epoch 1869/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6265 - accuracy: 0.6351 - val_loss: 0.6330 - val_accuracy: 0.5884\n",
      "Epoch 1870/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6255 - accuracy: 0.6344 - val_loss: 0.6740 - val_accuracy: 0.5250\n",
      "Epoch 1871/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6247 - accuracy: 0.6381 - val_loss: 0.6459 - val_accuracy: 0.5619\n",
      "Epoch 1872/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6242 - accuracy: 0.6393 - val_loss: 0.6587 - val_accuracy: 0.5473\n",
      "Epoch 1873/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6235 - accuracy: 0.6392 - val_loss: 0.6531 - val_accuracy: 0.5554\n",
      "Epoch 1874/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6237 - accuracy: 0.6383 - val_loss: 0.6529 - val_accuracy: 0.5554\n",
      "Epoch 1875/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6234 - accuracy: 0.6394 - val_loss: 0.6626 - val_accuracy: 0.5424\n",
      "Epoch 1876/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6237 - accuracy: 0.6389 - val_loss: 0.6487 - val_accuracy: 0.5605\n",
      "Epoch 1877/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6236 - accuracy: 0.6396 - val_loss: 0.6629 - val_accuracy: 0.5402\n",
      "Epoch 1878/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6239 - accuracy: 0.6392 - val_loss: 0.6437 - val_accuracy: 0.5685\n",
      "Epoch 1879/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6239 - accuracy: 0.6381 - val_loss: 0.6713 - val_accuracy: 0.5285\n",
      "Epoch 1880/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6242 - accuracy: 0.6387 - val_loss: 0.6406 - val_accuracy: 0.5742\n",
      "Epoch 1881/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6246 - accuracy: 0.6388 - val_loss: 0.6785 - val_accuracy: 0.5199\n",
      "Epoch 1882/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6254 - accuracy: 0.6360 - val_loss: 0.6313 - val_accuracy: 0.5928\n",
      "Epoch 1883/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6261 - accuracy: 0.6346 - val_loss: 0.6891 - val_accuracy: 0.5042\n",
      "Epoch 1884/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6269 - accuracy: 0.6354 - val_loss: 0.6318 - val_accuracy: 0.5908\n",
      "Epoch 1885/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6270 - accuracy: 0.6336 - val_loss: 0.6874 - val_accuracy: 0.5090\n",
      "Epoch 1886/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6271 - accuracy: 0.6341 - val_loss: 0.6339 - val_accuracy: 0.5853\n",
      "Epoch 1887/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6265 - accuracy: 0.6338 - val_loss: 0.6678 - val_accuracy: 0.5353\n",
      "Epoch 1888/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6240 - accuracy: 0.6392 - val_loss: 0.6518 - val_accuracy: 0.5563\n",
      "Epoch 1889/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6249 - accuracy: 0.6381 - val_loss: 0.6597 - val_accuracy: 0.5438\n",
      "Epoch 1890/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6235 - accuracy: 0.6396 - val_loss: 0.6479 - val_accuracy: 0.5610\n",
      "Epoch 1891/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6243 - accuracy: 0.6365 - val_loss: 0.6620 - val_accuracy: 0.5415\n",
      "Epoch 1892/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6239 - accuracy: 0.6383 - val_loss: 0.6465 - val_accuracy: 0.5656\n",
      "Epoch 1893/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6242 - accuracy: 0.6393 - val_loss: 0.6739 - val_accuracy: 0.5228\n",
      "Epoch 1894/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6246 - accuracy: 0.6376 - val_loss: 0.6386 - val_accuracy: 0.5744\n",
      "Epoch 1895/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6245 - accuracy: 0.6369 - val_loss: 0.6730 - val_accuracy: 0.5269\n",
      "Epoch 1896/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6250 - accuracy: 0.6370 - val_loss: 0.6367 - val_accuracy: 0.5840\n",
      "Epoch 1897/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6248 - accuracy: 0.6371 - val_loss: 0.6751 - val_accuracy: 0.5223\n",
      "Epoch 1898/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6246 - accuracy: 0.6372 - val_loss: 0.6439 - val_accuracy: 0.5670\n",
      "Epoch 1899/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6244 - accuracy: 0.6380 - val_loss: 0.6671 - val_accuracy: 0.5349\n",
      "Epoch 1900/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6239 - accuracy: 0.6392 - val_loss: 0.6426 - val_accuracy: 0.5734\n",
      "Epoch 1901/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6242 - accuracy: 0.6382 - val_loss: 0.6662 - val_accuracy: 0.5358\n",
      "Epoch 1902/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6236 - accuracy: 0.6398 - val_loss: 0.6458 - val_accuracy: 0.5661\n",
      "Epoch 1903/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6242 - accuracy: 0.6386 - val_loss: 0.6707 - val_accuracy: 0.5298\n",
      "Epoch 1904/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6239 - accuracy: 0.6393 - val_loss: 0.6378 - val_accuracy: 0.5831\n",
      "Epoch 1905/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6247 - accuracy: 0.6372 - val_loss: 0.6773 - val_accuracy: 0.5205\n",
      "Epoch 1906/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6248 - accuracy: 0.6366 - val_loss: 0.6362 - val_accuracy: 0.5807\n",
      "Epoch 1907/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6253 - accuracy: 0.6367 - val_loss: 0.6805 - val_accuracy: 0.5157\n",
      "Epoch 1908/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6251 - accuracy: 0.6368 - val_loss: 0.6358 - val_accuracy: 0.5835\n",
      "Epoch 1909/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6249 - accuracy: 0.6365 - val_loss: 0.6747 - val_accuracy: 0.5234\n",
      "Epoch 1910/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6245 - accuracy: 0.6372 - val_loss: 0.6420 - val_accuracy: 0.5694\n",
      "Epoch 1911/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6242 - accuracy: 0.6372 - val_loss: 0.6676 - val_accuracy: 0.5369\n",
      "Epoch 1912/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6236 - accuracy: 0.6392 - val_loss: 0.6469 - val_accuracy: 0.5654\n",
      "Epoch 1913/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6236 - accuracy: 0.6396 - val_loss: 0.6613 - val_accuracy: 0.5429\n",
      "Epoch 1914/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6232 - accuracy: 0.6399 - val_loss: 0.6501 - val_accuracy: 0.5574\n",
      "Epoch 1915/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6235 - accuracy: 0.6385 - val_loss: 0.6607 - val_accuracy: 0.5457\n",
      "Epoch 1916/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6231 - accuracy: 0.6393 - val_loss: 0.6509 - val_accuracy: 0.5603\n",
      "Epoch 1917/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6234 - accuracy: 0.6395 - val_loss: 0.6618 - val_accuracy: 0.5435\n",
      "Epoch 1918/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6231 - accuracy: 0.6402 - val_loss: 0.6476 - val_accuracy: 0.5619\n",
      "Epoch 1919/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6234 - accuracy: 0.6382 - val_loss: 0.6660 - val_accuracy: 0.5385\n",
      "Epoch 1920/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6233 - accuracy: 0.6401 - val_loss: 0.6432 - val_accuracy: 0.5723\n",
      "Epoch 1921/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6238 - accuracy: 0.6390 - val_loss: 0.6752 - val_accuracy: 0.5237\n",
      "Epoch 1922/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6243 - accuracy: 0.6370 - val_loss: 0.6351 - val_accuracy: 0.5844\n",
      "Epoch 1923/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6252 - accuracy: 0.6352 - val_loss: 0.6859 - val_accuracy: 0.5082\n",
      "Epoch 1924/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6260 - accuracy: 0.6360 - val_loss: 0.6305 - val_accuracy: 0.5932\n",
      "Epoch 1925/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6265 - accuracy: 0.6335 - val_loss: 0.6911 - val_accuracy: 0.5040\n",
      "Epoch 1926/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6274 - accuracy: 0.6329 - val_loss: 0.6348 - val_accuracy: 0.5855\n",
      "Epoch 1927/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6270 - accuracy: 0.6330 - val_loss: 0.6733 - val_accuracy: 0.5263\n",
      "Epoch 1928/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6244 - accuracy: 0.6387 - val_loss: 0.6447 - val_accuracy: 0.5733\n",
      "Epoch 1929/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6260 - accuracy: 0.6374 - val_loss: 0.6691 - val_accuracy: 0.5309\n",
      "Epoch 1930/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6238 - accuracy: 0.6388 - val_loss: 0.6378 - val_accuracy: 0.5791\n",
      "Epoch 1931/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6266 - accuracy: 0.6343 - val_loss: 0.6826 - val_accuracy: 0.5133\n",
      "Epoch 1932/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6255 - accuracy: 0.6356 - val_loss: 0.6336 - val_accuracy: 0.5893\n",
      "Epoch 1933/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6276 - accuracy: 0.6327 - val_loss: 0.6911 - val_accuracy: 0.5024\n",
      "Epoch 1934/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6270 - accuracy: 0.6333 - val_loss: 0.6323 - val_accuracy: 0.5864\n",
      "Epoch 1935/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6278 - accuracy: 0.6332 - val_loss: 0.6724 - val_accuracy: 0.5276\n",
      "Epoch 1936/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6242 - accuracy: 0.6387 - val_loss: 0.6457 - val_accuracy: 0.5698\n",
      "Epoch 1937/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6253 - accuracy: 0.6379 - val_loss: 0.6590 - val_accuracy: 0.5435\n",
      "Epoch 1938/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6229 - accuracy: 0.6397 - val_loss: 0.6513 - val_accuracy: 0.5535\n",
      "Epoch 1939/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6246 - accuracy: 0.6367 - val_loss: 0.6612 - val_accuracy: 0.5398\n",
      "Epoch 1940/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6231 - accuracy: 0.6398 - val_loss: 0.6471 - val_accuracy: 0.5654\n",
      "Epoch 1941/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6242 - accuracy: 0.6392 - val_loss: 0.6699 - val_accuracy: 0.5283\n",
      "Epoch 1942/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6238 - accuracy: 0.6392 - val_loss: 0.6386 - val_accuracy: 0.5745\n",
      "Epoch 1943/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6242 - accuracy: 0.6376 - val_loss: 0.6724 - val_accuracy: 0.5252\n",
      "Epoch 1944/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6242 - accuracy: 0.6373 - val_loss: 0.6405 - val_accuracy: 0.5744\n",
      "Epoch 1945/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6236 - accuracy: 0.6386 - val_loss: 0.6654 - val_accuracy: 0.5380\n",
      "Epoch 1946/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6232 - accuracy: 0.6405 - val_loss: 0.6508 - val_accuracy: 0.5572\n",
      "Epoch 1947/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6228 - accuracy: 0.6399 - val_loss: 0.6549 - val_accuracy: 0.5510\n",
      "Epoch 1948/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6227 - accuracy: 0.6396 - val_loss: 0.6577 - val_accuracy: 0.5484\n",
      "Epoch 1949/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6227 - accuracy: 0.6402 - val_loss: 0.6485 - val_accuracy: 0.5636\n",
      "Epoch 1950/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6229 - accuracy: 0.6400 - val_loss: 0.6679 - val_accuracy: 0.5343\n",
      "Epoch 1951/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6230 - accuracy: 0.6400 - val_loss: 0.6424 - val_accuracy: 0.5701\n",
      "Epoch 1952/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6235 - accuracy: 0.6385 - val_loss: 0.6755 - val_accuracy: 0.5223\n",
      "Epoch 1953/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6239 - accuracy: 0.6389 - val_loss: 0.6336 - val_accuracy: 0.5904\n",
      "Epoch 1954/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6245 - accuracy: 0.6369 - val_loss: 0.6855 - val_accuracy: 0.5100\n",
      "Epoch 1955/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6255 - accuracy: 0.6355 - val_loss: 0.6333 - val_accuracy: 0.5891\n",
      "Epoch 1956/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6251 - accuracy: 0.6357 - val_loss: 0.6806 - val_accuracy: 0.5153\n",
      "Epoch 1957/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6246 - accuracy: 0.6367 - val_loss: 0.6387 - val_accuracy: 0.5804\n",
      "Epoch 1958/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6239 - accuracy: 0.6384 - val_loss: 0.6683 - val_accuracy: 0.5331\n",
      "Epoch 1959/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6231 - accuracy: 0.6395 - val_loss: 0.6483 - val_accuracy: 0.5608\n",
      "Epoch 1960/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6230 - accuracy: 0.6394 - val_loss: 0.6593 - val_accuracy: 0.5486\n",
      "Epoch 1961/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6225 - accuracy: 0.6399 - val_loss: 0.6556 - val_accuracy: 0.5543\n",
      "Epoch 1962/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6227 - accuracy: 0.6404 - val_loss: 0.6519 - val_accuracy: 0.5559\n",
      "Epoch 1963/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6224 - accuracy: 0.6400 - val_loss: 0.6605 - val_accuracy: 0.5460\n",
      "Epoch 1964/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6227 - accuracy: 0.6402 - val_loss: 0.6494 - val_accuracy: 0.5610\n",
      "Epoch 1965/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6397 - val_loss: 0.6631 - val_accuracy: 0.5442\n",
      "Epoch 1966/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6227 - accuracy: 0.6399 - val_loss: 0.6468 - val_accuracy: 0.5649\n",
      "Epoch 1967/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6225 - accuracy: 0.6402 - val_loss: 0.6657 - val_accuracy: 0.5367\n",
      "Epoch 1968/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6229 - accuracy: 0.6401 - val_loss: 0.6453 - val_accuracy: 0.5674\n",
      "Epoch 1969/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6227 - accuracy: 0.6394 - val_loss: 0.6709 - val_accuracy: 0.5296\n",
      "Epoch 1970/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6232 - accuracy: 0.6403 - val_loss: 0.6392 - val_accuracy: 0.5798\n",
      "Epoch 1971/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6233 - accuracy: 0.6392 - val_loss: 0.6775 - val_accuracy: 0.5221\n",
      "Epoch 1972/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6242 - accuracy: 0.6370 - val_loss: 0.6335 - val_accuracy: 0.5870\n",
      "Epoch 1973/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6243 - accuracy: 0.6369 - val_loss: 0.6836 - val_accuracy: 0.5124\n",
      "Epoch 1974/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6250 - accuracy: 0.6367 - val_loss: 0.6343 - val_accuracy: 0.5873\n",
      "Epoch 1975/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6246 - accuracy: 0.6368 - val_loss: 0.6814 - val_accuracy: 0.5181\n",
      "Epoch 1976/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6248 - accuracy: 0.6358 - val_loss: 0.6374 - val_accuracy: 0.5795\n",
      "Epoch 1977/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6242 - accuracy: 0.6359 - val_loss: 0.6717 - val_accuracy: 0.5296\n",
      "Epoch 1978/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6234 - accuracy: 0.6397 - val_loss: 0.6442 - val_accuracy: 0.5705\n",
      "Epoch 1979/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6235 - accuracy: 0.6392 - val_loss: 0.6660 - val_accuracy: 0.5356\n",
      "Epoch 1980/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6228 - accuracy: 0.6396 - val_loss: 0.6451 - val_accuracy: 0.5647\n",
      "Epoch 1981/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6234 - accuracy: 0.6381 - val_loss: 0.6662 - val_accuracy: 0.5378\n",
      "Epoch 1982/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6227 - accuracy: 0.6406 - val_loss: 0.6437 - val_accuracy: 0.5722\n",
      "Epoch 1983/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6236 - accuracy: 0.6387 - val_loss: 0.6732 - val_accuracy: 0.5265\n",
      "Epoch 1984/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6234 - accuracy: 0.6381 - val_loss: 0.6353 - val_accuracy: 0.5817\n",
      "Epoch 1985/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6248 - accuracy: 0.6352 - val_loss: 0.6835 - val_accuracy: 0.5115\n",
      "Epoch 1986/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6250 - accuracy: 0.6367 - val_loss: 0.6317 - val_accuracy: 0.5924\n",
      "Epoch 1987/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6259 - accuracy: 0.6342 - val_loss: 0.6883 - val_accuracy: 0.5068\n",
      "Epoch 1988/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6260 - accuracy: 0.6339 - val_loss: 0.6358 - val_accuracy: 0.5833\n",
      "Epoch 1989/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6258 - accuracy: 0.6347 - val_loss: 0.6692 - val_accuracy: 0.5334\n",
      "Epoch 1990/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6231 - accuracy: 0.6403 - val_loss: 0.6481 - val_accuracy: 0.5652\n",
      "Epoch 1991/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6242 - accuracy: 0.6389 - val_loss: 0.6598 - val_accuracy: 0.5433\n",
      "Epoch 1992/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6222 - accuracy: 0.6409 - val_loss: 0.6487 - val_accuracy: 0.5574\n",
      "Epoch 1993/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6239 - accuracy: 0.6367 - val_loss: 0.6651 - val_accuracy: 0.5374\n",
      "Epoch 1994/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6225 - accuracy: 0.6397 - val_loss: 0.6436 - val_accuracy: 0.5734\n",
      "Epoch 1995/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6240 - accuracy: 0.6385 - val_loss: 0.6762 - val_accuracy: 0.5206\n",
      "Epoch 1996/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6237 - accuracy: 0.6380 - val_loss: 0.6315 - val_accuracy: 0.5893\n",
      "Epoch 1997/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6252 - accuracy: 0.6364 - val_loss: 0.6854 - val_accuracy: 0.5102\n",
      "Epoch 1998/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6254 - accuracy: 0.6353 - val_loss: 0.6347 - val_accuracy: 0.5853\n",
      "Epoch 1999/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6243 - accuracy: 0.6368 - val_loss: 0.6721 - val_accuracy: 0.5296\n",
      "Epoch 2000/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6230 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.5597\n",
      "Epoch 2001/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6397 - val_loss: 0.6534 - val_accuracy: 0.5535\n",
      "Epoch 2002/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6219 - accuracy: 0.6407 - val_loss: 0.6608 - val_accuracy: 0.5438\n",
      "Epoch 2003/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6223 - accuracy: 0.6403 - val_loss: 0.6442 - val_accuracy: 0.5700\n",
      "Epoch 2004/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6225 - accuracy: 0.6399 - val_loss: 0.6729 - val_accuracy: 0.5263\n",
      "Epoch 2005/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6231 - accuracy: 0.6385 - val_loss: 0.6373 - val_accuracy: 0.5800\n",
      "Epoch 2006/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6234 - accuracy: 0.6377 - val_loss: 0.6785 - val_accuracy: 0.5179\n",
      "Epoch 2007/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6240 - accuracy: 0.6379 - val_loss: 0.6342 - val_accuracy: 0.5877\n",
      "Epoch 2008/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6239 - accuracy: 0.6373 - val_loss: 0.6805 - val_accuracy: 0.5166\n",
      "Epoch 2009/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6242 - accuracy: 0.6367 - val_loss: 0.6390 - val_accuracy: 0.5765\n",
      "Epoch 2010/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6235 - accuracy: 0.6378 - val_loss: 0.6676 - val_accuracy: 0.5364\n",
      "Epoch 2011/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6225 - accuracy: 0.6403 - val_loss: 0.6476 - val_accuracy: 0.5658\n",
      "Epoch 2012/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6224 - accuracy: 0.6409 - val_loss: 0.6584 - val_accuracy: 0.5473\n",
      "Epoch 2013/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6219 - accuracy: 0.6405 - val_loss: 0.6548 - val_accuracy: 0.5517\n",
      "Epoch 2014/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6222 - accuracy: 0.6399 - val_loss: 0.6549 - val_accuracy: 0.5544\n",
      "Epoch 2015/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6218 - accuracy: 0.6412 - val_loss: 0.6565 - val_accuracy: 0.5532\n",
      "Epoch 2016/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6221 - accuracy: 0.6414 - val_loss: 0.6529 - val_accuracy: 0.5564\n",
      "Epoch 2017/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6217 - accuracy: 0.6409 - val_loss: 0.6568 - val_accuracy: 0.5482\n",
      "Epoch 2018/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6220 - accuracy: 0.6404 - val_loss: 0.6557 - val_accuracy: 0.5532\n",
      "Epoch 2019/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6217 - accuracy: 0.6405 - val_loss: 0.6553 - val_accuracy: 0.5555\n",
      "Epoch 2020/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6219 - accuracy: 0.6406 - val_loss: 0.6574 - val_accuracy: 0.5495\n",
      "Epoch 2021/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6217 - accuracy: 0.6407 - val_loss: 0.6498 - val_accuracy: 0.5585\n",
      "Epoch 2022/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6219 - accuracy: 0.6402 - val_loss: 0.6641 - val_accuracy: 0.5413\n",
      "Epoch 2023/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6219 - accuracy: 0.6409 - val_loss: 0.6444 - val_accuracy: 0.5705\n",
      "Epoch 2024/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6224 - accuracy: 0.6397 - val_loss: 0.6752 - val_accuracy: 0.5254\n",
      "Epoch 2025/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6229 - accuracy: 0.6391 - val_loss: 0.6333 - val_accuracy: 0.5881\n",
      "Epoch 2026/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6240 - accuracy: 0.6374 - val_loss: 0.6925 - val_accuracy: 0.5051\n",
      "Epoch 2027/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6260 - accuracy: 0.6345 - val_loss: 0.6260 - val_accuracy: 0.6028\n",
      "Epoch 2028/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6259 - accuracy: 0.6338 - val_loss: 0.6966 - val_accuracy: 0.5009\n",
      "Epoch 2029/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6271 - accuracy: 0.6333 - val_loss: 0.6357 - val_accuracy: 0.5829\n",
      "Epoch 2030/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6241 - accuracy: 0.6361 - val_loss: 0.6610 - val_accuracy: 0.5446\n",
      "Epoch 2031/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6219 - accuracy: 0.6408 - val_loss: 0.6619 - val_accuracy: 0.5442\n",
      "Epoch 2032/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6225 - accuracy: 0.6404 - val_loss: 0.6365 - val_accuracy: 0.5844\n",
      "Epoch 2033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6228 - accuracy: 0.6392 - val_loss: 0.6834 - val_accuracy: 0.5155\n",
      "Epoch 2034/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6249 - accuracy: 0.6358 - val_loss: 0.6352 - val_accuracy: 0.5829\n",
      "Epoch 2035/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6242 - accuracy: 0.6349 - val_loss: 0.6770 - val_accuracy: 0.5195\n",
      "Epoch 2036/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6236 - accuracy: 0.6390 - val_loss: 0.6421 - val_accuracy: 0.5729\n",
      "Epoch 2037/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6231 - accuracy: 0.6400 - val_loss: 0.6605 - val_accuracy: 0.5402\n",
      "Epoch 2038/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6223 - accuracy: 0.6400 - val_loss: 0.6497 - val_accuracy: 0.5586\n",
      "Epoch 2039/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6227 - accuracy: 0.6386 - val_loss: 0.6599 - val_accuracy: 0.5469\n",
      "Epoch 2040/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6218 - accuracy: 0.6407 - val_loss: 0.6521 - val_accuracy: 0.5594\n",
      "Epoch 2041/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6226 - accuracy: 0.6407 - val_loss: 0.6620 - val_accuracy: 0.5424\n",
      "Epoch 2042/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6220 - accuracy: 0.6406 - val_loss: 0.6413 - val_accuracy: 0.5723\n",
      "Epoch 2043/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6228 - accuracy: 0.6384 - val_loss: 0.6721 - val_accuracy: 0.5283\n",
      "Epoch 2044/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6227 - accuracy: 0.6399 - val_loss: 0.6375 - val_accuracy: 0.5817\n",
      "Epoch 2045/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6238 - accuracy: 0.6372 - val_loss: 0.6840 - val_accuracy: 0.5108\n",
      "Epoch 2046/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6244 - accuracy: 0.6361 - val_loss: 0.6324 - val_accuracy: 0.5875\n",
      "Epoch 2047/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6243 - accuracy: 0.6361 - val_loss: 0.6754 - val_accuracy: 0.5241\n",
      "Epoch 2048/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6233 - accuracy: 0.6391 - val_loss: 0.6405 - val_accuracy: 0.5773\n",
      "Epoch 2049/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6232 - accuracy: 0.6393 - val_loss: 0.6685 - val_accuracy: 0.5340\n",
      "Epoch 2050/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6221 - accuracy: 0.6405 - val_loss: 0.6471 - val_accuracy: 0.5616\n",
      "Epoch 2051/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6226 - accuracy: 0.6386 - val_loss: 0.6609 - val_accuracy: 0.5455\n",
      "Epoch 2052/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6216 - accuracy: 0.6408 - val_loss: 0.6491 - val_accuracy: 0.5659\n",
      "Epoch 2053/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6224 - accuracy: 0.6411 - val_loss: 0.6628 - val_accuracy: 0.5407\n",
      "Epoch 2054/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6215 - accuracy: 0.6413 - val_loss: 0.6461 - val_accuracy: 0.5658\n",
      "Epoch 2055/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6225 - accuracy: 0.6394 - val_loss: 0.6685 - val_accuracy: 0.5340\n",
      "Epoch 2056/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6220 - accuracy: 0.6403 - val_loss: 0.6387 - val_accuracy: 0.5811\n",
      "Epoch 2057/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6230 - accuracy: 0.6392 - val_loss: 0.6806 - val_accuracy: 0.5179\n",
      "Epoch 2058/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6235 - accuracy: 0.6379 - val_loss: 0.6314 - val_accuracy: 0.5890\n",
      "Epoch 2059/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6249 - accuracy: 0.6348 - val_loss: 0.6929 - val_accuracy: 0.5037\n",
      "Epoch 2060/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6258 - accuracy: 0.6349 - val_loss: 0.6306 - val_accuracy: 0.5948\n",
      "Epoch 2061/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6245 - accuracy: 0.6358 - val_loss: 0.6784 - val_accuracy: 0.5205\n",
      "Epoch 2062/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6233 - accuracy: 0.6378 - val_loss: 0.6431 - val_accuracy: 0.5678\n",
      "Epoch 2063/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6390 - val_loss: 0.6576 - val_accuracy: 0.5499\n",
      "Epoch 2064/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6213 - accuracy: 0.6409 - val_loss: 0.6593 - val_accuracy: 0.5495\n",
      "Epoch 2065/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6219 - accuracy: 0.6414 - val_loss: 0.6447 - val_accuracy: 0.5689\n",
      "Epoch 2066/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6216 - accuracy: 0.6410 - val_loss: 0.6704 - val_accuracy: 0.5305\n",
      "Epoch 2067/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6226 - accuracy: 0.6388 - val_loss: 0.6419 - val_accuracy: 0.5733\n",
      "Epoch 2068/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6220 - accuracy: 0.6392 - val_loss: 0.6709 - val_accuracy: 0.5298\n",
      "Epoch 2069/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6225 - accuracy: 0.6402 - val_loss: 0.6419 - val_accuracy: 0.5736\n",
      "Epoch 2070/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6220 - accuracy: 0.6398 - val_loss: 0.6675 - val_accuracy: 0.5347\n",
      "Epoch 2071/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6222 - accuracy: 0.6396 - val_loss: 0.6447 - val_accuracy: 0.5669\n",
      "Epoch 2072/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6219 - accuracy: 0.6400 - val_loss: 0.6651 - val_accuracy: 0.5413\n",
      "Epoch 2073/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6218 - accuracy: 0.6406 - val_loss: 0.6484 - val_accuracy: 0.5634\n",
      "Epoch 2074/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6218 - accuracy: 0.6409 - val_loss: 0.6624 - val_accuracy: 0.5409\n",
      "Epoch 2075/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6216 - accuracy: 0.6414 - val_loss: 0.6465 - val_accuracy: 0.5643\n",
      "Epoch 2076/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6217 - accuracy: 0.6397 - val_loss: 0.6644 - val_accuracy: 0.5398\n",
      "Epoch 2077/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6215 - accuracy: 0.6411 - val_loss: 0.6456 - val_accuracy: 0.5707\n",
      "Epoch 2078/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6219 - accuracy: 0.6401 - val_loss: 0.6697 - val_accuracy: 0.5316\n",
      "Epoch 2079/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6219 - accuracy: 0.6403 - val_loss: 0.6383 - val_accuracy: 0.5782\n",
      "Epoch 2080/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6226 - accuracy: 0.6390 - val_loss: 0.6791 - val_accuracy: 0.5195\n",
      "Epoch 2081/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6231 - accuracy: 0.6386 - val_loss: 0.6322 - val_accuracy: 0.5934\n",
      "Epoch 2082/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6241 - accuracy: 0.6362 - val_loss: 0.6929 - val_accuracy: 0.5049\n",
      "Epoch 2083/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6257 - accuracy: 0.6348 - val_loss: 0.6316 - val_accuracy: 0.5908\n",
      "Epoch 2084/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6249 - accuracy: 0.6350 - val_loss: 0.6765 - val_accuracy: 0.5232\n",
      "Epoch 2085/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6229 - accuracy: 0.6391 - val_loss: 0.6423 - val_accuracy: 0.5754\n",
      "Epoch 2086/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6229 - accuracy: 0.6400 - val_loss: 0.6634 - val_accuracy: 0.5406\n",
      "Epoch 2087/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6215 - accuracy: 0.6415 - val_loss: 0.6489 - val_accuracy: 0.5581\n",
      "Epoch 2088/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6223 - accuracy: 0.6390 - val_loss: 0.6617 - val_accuracy: 0.5449\n",
      "Epoch 2089/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6212 - accuracy: 0.6416 - val_loss: 0.6483 - val_accuracy: 0.5663\n",
      "Epoch 2090/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6222 - accuracy: 0.6412 - val_loss: 0.6669 - val_accuracy: 0.5358\n",
      "Epoch 2091/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6215 - accuracy: 0.6408 - val_loss: 0.6388 - val_accuracy: 0.5767\n",
      "Epoch 2092/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6230 - accuracy: 0.6382 - val_loss: 0.6807 - val_accuracy: 0.5170\n",
      "Epoch 2093/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6232 - accuracy: 0.6381 - val_loss: 0.6321 - val_accuracy: 0.5939\n",
      "Epoch 2094/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6242 - accuracy: 0.6365 - val_loss: 0.6883 - val_accuracy: 0.5088\n",
      "Epoch 2095/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6248 - accuracy: 0.6360 - val_loss: 0.6331 - val_accuracy: 0.5864\n",
      "Epoch 2096/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6238 - accuracy: 0.6363 - val_loss: 0.6706 - val_accuracy: 0.5316\n",
      "Epoch 2097/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6219 - accuracy: 0.6406 - val_loss: 0.6473 - val_accuracy: 0.5656\n",
      "Epoch 2098/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6220 - accuracy: 0.6406 - val_loss: 0.6563 - val_accuracy: 0.5491\n",
      "Epoch 2099/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6209 - accuracy: 0.6419 - val_loss: 0.6569 - val_accuracy: 0.5482\n",
      "Epoch 2100/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6216 - accuracy: 0.6402 - val_loss: 0.6517 - val_accuracy: 0.5590\n",
      "Epoch 2101/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6209 - accuracy: 0.6416 - val_loss: 0.6595 - val_accuracy: 0.5486\n",
      "Epoch 2102/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6215 - accuracy: 0.6420 - val_loss: 0.6503 - val_accuracy: 0.5612\n",
      "Epoch 2103/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6420 - val_loss: 0.6585 - val_accuracy: 0.5486\n",
      "Epoch 2104/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6213 - accuracy: 0.6415 - val_loss: 0.6507 - val_accuracy: 0.5563\n",
      "Epoch 2105/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6210 - accuracy: 0.6409 - val_loss: 0.6603 - val_accuracy: 0.5490\n",
      "Epoch 2106/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6211 - accuracy: 0.6418 - val_loss: 0.6511 - val_accuracy: 0.5621\n",
      "Epoch 2107/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6210 - accuracy: 0.6418 - val_loss: 0.6610 - val_accuracy: 0.5475\n",
      "Epoch 2108/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6211 - accuracy: 0.6412 - val_loss: 0.6474 - val_accuracy: 0.5638\n",
      "Epoch 2109/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6211 - accuracy: 0.6408 - val_loss: 0.6659 - val_accuracy: 0.5393\n",
      "Epoch 2110/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6213 - accuracy: 0.6409 - val_loss: 0.6428 - val_accuracy: 0.5744\n",
      "Epoch 2111/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6216 - accuracy: 0.6399 - val_loss: 0.6754 - val_accuracy: 0.5248\n",
      "Epoch 2112/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6223 - accuracy: 0.6385 - val_loss: 0.6340 - val_accuracy: 0.5868\n",
      "Epoch 2113/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6232 - accuracy: 0.6374 - val_loss: 0.6883 - val_accuracy: 0.5075\n",
      "Epoch 2114/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6243 - accuracy: 0.6367 - val_loss: 0.6285 - val_accuracy: 0.5986\n",
      "Epoch 2115/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6248 - accuracy: 0.6350 - val_loss: 0.6953 - val_accuracy: 0.5049\n",
      "Epoch 2116/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6262 - accuracy: 0.6343 - val_loss: 0.6326 - val_accuracy: 0.5893\n",
      "Epoch 2117/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6249 - accuracy: 0.6348 - val_loss: 0.6716 - val_accuracy: 0.5311\n",
      "Epoch 2118/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6219 - accuracy: 0.6399 - val_loss: 0.6488 - val_accuracy: 0.5659\n",
      "Epoch 2119/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6228 - accuracy: 0.6412 - val_loss: 0.6568 - val_accuracy: 0.5499\n",
      "Epoch 2120/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6208 - accuracy: 0.6419 - val_loss: 0.6520 - val_accuracy: 0.5539\n",
      "Epoch 2121/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6222 - accuracy: 0.6386 - val_loss: 0.6604 - val_accuracy: 0.5437\n",
      "Epoch 2122/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6414 - val_loss: 0.6479 - val_accuracy: 0.5667\n",
      "Epoch 2123/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6221 - accuracy: 0.6406 - val_loss: 0.6733 - val_accuracy: 0.5265\n",
      "Epoch 2124/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6220 - accuracy: 0.6402 - val_loss: 0.6310 - val_accuracy: 0.5930\n",
      "Epoch 2125/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6237 - accuracy: 0.6370 - val_loss: 0.6907 - val_accuracy: 0.5077\n",
      "Epoch 2126/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6251 - accuracy: 0.6350 - val_loss: 0.6311 - val_accuracy: 0.5939\n",
      "Epoch 2127/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6238 - accuracy: 0.6361 - val_loss: 0.6777 - val_accuracy: 0.5208\n",
      "Epoch 2128/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6224 - accuracy: 0.6389 - val_loss: 0.6449 - val_accuracy: 0.5658\n",
      "Epoch 2129/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6212 - accuracy: 0.6412 - val_loss: 0.6502 - val_accuracy: 0.5575\n",
      "Epoch 2130/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6207 - accuracy: 0.6416 - val_loss: 0.6665 - val_accuracy: 0.5362\n",
      "Epoch 2131/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6213 - accuracy: 0.6412 - val_loss: 0.6360 - val_accuracy: 0.5873\n",
      "Epoch 2132/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6223 - accuracy: 0.6389 - val_loss: 0.6878 - val_accuracy: 0.5080\n",
      "Epoch 2133/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6242 - accuracy: 0.6361 - val_loss: 0.6303 - val_accuracy: 0.5930\n",
      "Epoch 2134/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6235 - accuracy: 0.6363 - val_loss: 0.6804 - val_accuracy: 0.5174\n",
      "Epoch 2135/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6231 - accuracy: 0.6381 - val_loss: 0.6390 - val_accuracy: 0.5802\n",
      "Epoch 2136/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6218 - accuracy: 0.6395 - val_loss: 0.6611 - val_accuracy: 0.5448\n",
      "Epoch 2137/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6208 - accuracy: 0.6420 - val_loss: 0.6560 - val_accuracy: 0.5517\n",
      "Epoch 2138/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6207 - accuracy: 0.6419 - val_loss: 0.6461 - val_accuracy: 0.5681\n",
      "Epoch 2139/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6208 - accuracy: 0.6417 - val_loss: 0.6704 - val_accuracy: 0.5298\n",
      "Epoch 2140/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6216 - accuracy: 0.6401 - val_loss: 0.6360 - val_accuracy: 0.5833\n",
      "Epoch 2141/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6220 - accuracy: 0.6395 - val_loss: 0.6840 - val_accuracy: 0.5128\n",
      "Epoch 2142/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6234 - accuracy: 0.6366 - val_loss: 0.6345 - val_accuracy: 0.5846\n",
      "Epoch 2143/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6223 - accuracy: 0.6384 - val_loss: 0.6706 - val_accuracy: 0.5303\n",
      "Epoch 2144/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6216 - accuracy: 0.6405 - val_loss: 0.6457 - val_accuracy: 0.5705\n",
      "Epoch 2145/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6207 - accuracy: 0.6417 - val_loss: 0.6555 - val_accuracy: 0.5532\n",
      "Epoch 2146/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6204 - accuracy: 0.6423 - val_loss: 0.6610 - val_accuracy: 0.5448\n",
      "Epoch 2147/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6205 - accuracy: 0.6418 - val_loss: 0.6436 - val_accuracy: 0.5720\n",
      "Epoch 2148/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6210 - accuracy: 0.6407 - val_loss: 0.6758 - val_accuracy: 0.5241\n",
      "Epoch 2149/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6219 - accuracy: 0.6397 - val_loss: 0.6317 - val_accuracy: 0.5913\n",
      "Epoch 2150/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6227 - accuracy: 0.6383 - val_loss: 0.6908 - val_accuracy: 0.5075\n",
      "Epoch 2151/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6246 - accuracy: 0.6358 - val_loss: 0.6327 - val_accuracy: 0.5912\n",
      "Epoch 2152/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6227 - accuracy: 0.6372 - val_loss: 0.6716 - val_accuracy: 0.5311\n",
      "Epoch 2153/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6214 - accuracy: 0.6411 - val_loss: 0.6485 - val_accuracy: 0.5650\n",
      "Epoch 2154/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6204 - accuracy: 0.6421 - val_loss: 0.6485 - val_accuracy: 0.5630\n",
      "Epoch 2155/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6204 - accuracy: 0.6424 - val_loss: 0.6704 - val_accuracy: 0.5292\n",
      "Epoch 2156/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6211 - accuracy: 0.6408 - val_loss: 0.6351 - val_accuracy: 0.5886\n",
      "Epoch 2157/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6223 - accuracy: 0.6382 - val_loss: 0.6914 - val_accuracy: 0.5053\n",
      "Epoch 2158/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6244 - accuracy: 0.6361 - val_loss: 0.6292 - val_accuracy: 0.5948\n",
      "Epoch 2159/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6234 - accuracy: 0.6363 - val_loss: 0.6827 - val_accuracy: 0.5144\n",
      "Epoch 2160/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6231 - accuracy: 0.6371 - val_loss: 0.6394 - val_accuracy: 0.5795\n",
      "Epoch 2161/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6211 - accuracy: 0.6397 - val_loss: 0.6559 - val_accuracy: 0.5517\n",
      "Epoch 2162/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6202 - accuracy: 0.6424 - val_loss: 0.6648 - val_accuracy: 0.5389\n",
      "Epoch 2163/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6205 - accuracy: 0.6410 - val_loss: 0.6371 - val_accuracy: 0.5842\n",
      "Epoch 2164/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6216 - accuracy: 0.6399 - val_loss: 0.6850 - val_accuracy: 0.5130\n",
      "Epoch 2165/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6235 - accuracy: 0.6370 - val_loss: 0.6287 - val_accuracy: 0.5963\n",
      "Epoch 2166/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6234 - accuracy: 0.6363 - val_loss: 0.6879 - val_accuracy: 0.5077\n",
      "Epoch 2167/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6237 - accuracy: 0.6370 - val_loss: 0.6386 - val_accuracy: 0.5780\n",
      "Epoch 2168/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6214 - accuracy: 0.6405 - val_loss: 0.6570 - val_accuracy: 0.5486\n",
      "Epoch 2169/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6203 - accuracy: 0.6419 - val_loss: 0.6615 - val_accuracy: 0.5437\n",
      "Epoch 2170/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6205 - accuracy: 0.6420 - val_loss: 0.6360 - val_accuracy: 0.5846\n",
      "Epoch 2171/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6215 - accuracy: 0.6397 - val_loss: 0.6866 - val_accuracy: 0.5106\n",
      "Epoch 2172/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6234 - accuracy: 0.6369 - val_loss: 0.6314 - val_accuracy: 0.5926\n",
      "Epoch 2173/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6231 - accuracy: 0.6368 - val_loss: 0.6835 - val_accuracy: 0.5132\n",
      "Epoch 2174/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6229 - accuracy: 0.6381 - val_loss: 0.6384 - val_accuracy: 0.5802\n",
      "Epoch 2175/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6210 - accuracy: 0.6407 - val_loss: 0.6587 - val_accuracy: 0.5457\n",
      "Epoch 2176/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6202 - accuracy: 0.6429 - val_loss: 0.6596 - val_accuracy: 0.5460\n",
      "Epoch 2177/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6202 - accuracy: 0.6417 - val_loss: 0.6397 - val_accuracy: 0.5798\n",
      "Epoch 2178/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6209 - accuracy: 0.6410 - val_loss: 0.6788 - val_accuracy: 0.5199\n",
      "Epoch 2179/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6221 - accuracy: 0.6394 - val_loss: 0.6323 - val_accuracy: 0.5897\n",
      "Epoch 2180/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6223 - accuracy: 0.6384 - val_loss: 0.6840 - val_accuracy: 0.5133\n",
      "Epoch 2181/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6229 - accuracy: 0.6377 - val_loss: 0.6363 - val_accuracy: 0.5846\n",
      "Epoch 2182/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6215 - accuracy: 0.6402 - val_loss: 0.6678 - val_accuracy: 0.5351\n",
      "Epoch 2183/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6206 - accuracy: 0.6410 - val_loss: 0.6481 - val_accuracy: 0.5636\n",
      "Epoch 2184/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6200 - accuracy: 0.6430 - val_loss: 0.6517 - val_accuracy: 0.5599\n",
      "Epoch 2185/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6199 - accuracy: 0.6427 - val_loss: 0.6649 - val_accuracy: 0.5396\n",
      "Epoch 2186/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6202 - accuracy: 0.6413 - val_loss: 0.6411 - val_accuracy: 0.5769\n",
      "Epoch 2187/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6207 - accuracy: 0.6403 - val_loss: 0.6764 - val_accuracy: 0.5232\n",
      "Epoch 2188/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6215 - accuracy: 0.6392 - val_loss: 0.6346 - val_accuracy: 0.5853\n",
      "Epoch 2189/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6216 - accuracy: 0.6395 - val_loss: 0.6791 - val_accuracy: 0.5185\n",
      "Epoch 2190/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6219 - accuracy: 0.6392 - val_loss: 0.6378 - val_accuracy: 0.5829\n",
      "Epoch 2191/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6212 - accuracy: 0.6400 - val_loss: 0.6720 - val_accuracy: 0.5294\n",
      "Epoch 2192/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6209 - accuracy: 0.6409 - val_loss: 0.6427 - val_accuracy: 0.5754\n",
      "Epoch 2193/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6204 - accuracy: 0.6415 - val_loss: 0.6624 - val_accuracy: 0.5420\n",
      "Epoch 2194/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6200 - accuracy: 0.6417 - val_loss: 0.6518 - val_accuracy: 0.5588\n",
      "Epoch 2195/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6198 - accuracy: 0.6430 - val_loss: 0.6552 - val_accuracy: 0.5521\n",
      "Epoch 2196/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6197 - accuracy: 0.6430 - val_loss: 0.6582 - val_accuracy: 0.5471\n",
      "Epoch 2197/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6198 - accuracy: 0.6426 - val_loss: 0.6499 - val_accuracy: 0.5614\n",
      "Epoch 2198/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6198 - accuracy: 0.6425 - val_loss: 0.6640 - val_accuracy: 0.5409\n",
      "Epoch 2199/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6200 - accuracy: 0.6419 - val_loss: 0.6437 - val_accuracy: 0.5727\n",
      "Epoch 2200/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6203 - accuracy: 0.6412 - val_loss: 0.6730 - val_accuracy: 0.5287\n",
      "Epoch 2201/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6208 - accuracy: 0.6406 - val_loss: 0.6355 - val_accuracy: 0.5860\n",
      "Epoch 2202/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6214 - accuracy: 0.6392 - val_loss: 0.6860 - val_accuracy: 0.5124\n",
      "Epoch 2203/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6228 - accuracy: 0.6382 - val_loss: 0.6311 - val_accuracy: 0.5928\n",
      "Epoch 2204/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6224 - accuracy: 0.6383 - val_loss: 0.6855 - val_accuracy: 0.5141\n",
      "Epoch 2205/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6228 - accuracy: 0.6381 - val_loss: 0.6353 - val_accuracy: 0.5859\n",
      "Epoch 2206/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6213 - accuracy: 0.6398 - val_loss: 0.6694 - val_accuracy: 0.5347\n",
      "Epoch 2207/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6204 - accuracy: 0.6411 - val_loss: 0.6484 - val_accuracy: 0.5654\n",
      "Epoch 2208/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6198 - accuracy: 0.6433 - val_loss: 0.6553 - val_accuracy: 0.5515\n",
      "Epoch 2209/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6196 - accuracy: 0.6425 - val_loss: 0.6602 - val_accuracy: 0.5462\n",
      "Epoch 2210/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6197 - accuracy: 0.6426 - val_loss: 0.6453 - val_accuracy: 0.5711\n",
      "Epoch 2211/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6200 - accuracy: 0.6422 - val_loss: 0.6717 - val_accuracy: 0.5298\n",
      "Epoch 2212/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6205 - accuracy: 0.6408 - val_loss: 0.6363 - val_accuracy: 0.5839\n",
      "Epoch 2213/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6212 - accuracy: 0.6400 - val_loss: 0.6840 - val_accuracy: 0.5153\n",
      "Epoch 2214/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6383 - val_loss: 0.6319 - val_accuracy: 0.5932\n",
      "Epoch 2215/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6220 - accuracy: 0.6377 - val_loss: 0.6807 - val_accuracy: 0.5192\n",
      "Epoch 2216/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6219 - accuracy: 0.6389 - val_loss: 0.6386 - val_accuracy: 0.5806\n",
      "Epoch 2217/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6207 - accuracy: 0.6408 - val_loss: 0.6653 - val_accuracy: 0.5389\n",
      "Epoch 2218/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6199 - accuracy: 0.6417 - val_loss: 0.6505 - val_accuracy: 0.5608\n",
      "Epoch 2219/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6196 - accuracy: 0.6426 - val_loss: 0.6536 - val_accuracy: 0.5544\n",
      "Epoch 2220/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6195 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.5426\n",
      "Epoch 2221/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6196 - accuracy: 0.6419 - val_loss: 0.6433 - val_accuracy: 0.5738\n",
      "Epoch 2222/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6200 - accuracy: 0.6418 - val_loss: 0.6744 - val_accuracy: 0.5267\n",
      "Epoch 2223/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6209 - accuracy: 0.6406 - val_loss: 0.6342 - val_accuracy: 0.5873\n",
      "Epoch 2224/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6213 - accuracy: 0.6395 - val_loss: 0.6838 - val_accuracy: 0.5142\n",
      "Epoch 2225/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6222 - accuracy: 0.6384 - val_loss: 0.6344 - val_accuracy: 0.5873\n",
      "Epoch 2226/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6215 - accuracy: 0.6398 - val_loss: 0.6790 - val_accuracy: 0.5208\n",
      "Epoch 2227/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6215 - accuracy: 0.6399 - val_loss: 0.6374 - val_accuracy: 0.5828\n",
      "Epoch 2228/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6206 - accuracy: 0.6410 - val_loss: 0.6681 - val_accuracy: 0.5356\n",
      "Epoch 2229/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6201 - accuracy: 0.6413 - val_loss: 0.6480 - val_accuracy: 0.5636\n",
      "Epoch 2230/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6197 - accuracy: 0.6424 - val_loss: 0.6584 - val_accuracy: 0.5486\n",
      "Epoch 2231/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6195 - accuracy: 0.6428 - val_loss: 0.6535 - val_accuracy: 0.5526\n",
      "Epoch 2232/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6525 - val_accuracy: 0.5566\n",
      "Epoch 2233/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6194 - accuracy: 0.6431 - val_loss: 0.6622 - val_accuracy: 0.5424\n",
      "Epoch 2234/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6195 - accuracy: 0.6422 - val_loss: 0.6463 - val_accuracy: 0.5681\n",
      "Epoch 2235/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6197 - accuracy: 0.6425 - val_loss: 0.6702 - val_accuracy: 0.5327\n",
      "Epoch 2236/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6202 - accuracy: 0.6413 - val_loss: 0.6370 - val_accuracy: 0.5842\n",
      "Epoch 2237/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6208 - accuracy: 0.6405 - val_loss: 0.6836 - val_accuracy: 0.5155\n",
      "Epoch 2238/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6221 - accuracy: 0.6392 - val_loss: 0.6297 - val_accuracy: 0.5948\n",
      "Epoch 2239/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6224 - accuracy: 0.6376 - val_loss: 0.6909 - val_accuracy: 0.5086\n",
      "Epoch 2240/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6237 - accuracy: 0.6367 - val_loss: 0.6335 - val_accuracy: 0.5886\n",
      "Epoch 2241/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6216 - accuracy: 0.6383 - val_loss: 0.6689 - val_accuracy: 0.5338\n",
      "Epoch 2242/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6201 - accuracy: 0.6419 - val_loss: 0.6514 - val_accuracy: 0.5616\n",
      "Epoch 2243/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6195 - accuracy: 0.6432 - val_loss: 0.6499 - val_accuracy: 0.5605\n",
      "Epoch 2244/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6195 - accuracy: 0.6420 - val_loss: 0.6674 - val_accuracy: 0.5338\n",
      "Epoch 2245/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6200 - accuracy: 0.6406 - val_loss: 0.6390 - val_accuracy: 0.5813\n",
      "Epoch 2246/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6205 - accuracy: 0.6412 - val_loss: 0.6820 - val_accuracy: 0.5164\n",
      "Epoch 2247/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6216 - accuracy: 0.6395 - val_loss: 0.6320 - val_accuracy: 0.5899\n",
      "Epoch 2248/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6219 - accuracy: 0.6386 - val_loss: 0.6856 - val_accuracy: 0.5128\n",
      "Epoch 2249/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6228 - accuracy: 0.6380 - val_loss: 0.6332 - val_accuracy: 0.5899\n",
      "Epoch 2250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6212 - accuracy: 0.6382 - val_loss: 0.6690 - val_accuracy: 0.5345\n",
      "Epoch 2251/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6199 - accuracy: 0.6419 - val_loss: 0.6534 - val_accuracy: 0.5574\n",
      "Epoch 2252/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6195 - accuracy: 0.6433 - val_loss: 0.6498 - val_accuracy: 0.5634\n",
      "Epoch 2253/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6192 - accuracy: 0.6434 - val_loss: 0.6637 - val_accuracy: 0.5411\n",
      "Epoch 2254/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6198 - accuracy: 0.6421 - val_loss: 0.6402 - val_accuracy: 0.5758\n",
      "Epoch 2255/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6201 - accuracy: 0.6411 - val_loss: 0.6785 - val_accuracy: 0.5199\n",
      "Epoch 2256/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6209 - accuracy: 0.6396 - val_loss: 0.6354 - val_accuracy: 0.5859\n",
      "Epoch 2257/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6212 - accuracy: 0.6400 - val_loss: 0.6819 - val_accuracy: 0.5166\n",
      "Epoch 2258/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6220 - accuracy: 0.6392 - val_loss: 0.6326 - val_accuracy: 0.5908\n",
      "Epoch 2259/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6212 - accuracy: 0.6377 - val_loss: 0.6740 - val_accuracy: 0.5272\n",
      "Epoch 2260/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6203 - accuracy: 0.6407 - val_loss: 0.6476 - val_accuracy: 0.5641\n",
      "Epoch 2261/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6199 - accuracy: 0.6430 - val_loss: 0.6598 - val_accuracy: 0.5431\n",
      "Epoch 2262/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6192 - accuracy: 0.6426 - val_loss: 0.6509 - val_accuracy: 0.5590\n",
      "Epoch 2263/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6194 - accuracy: 0.6424 - val_loss: 0.6538 - val_accuracy: 0.5550\n",
      "Epoch 2264/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6191 - accuracy: 0.6435 - val_loss: 0.6606 - val_accuracy: 0.5459\n",
      "Epoch 2265/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6192 - accuracy: 0.6426 - val_loss: 0.6508 - val_accuracy: 0.5588\n",
      "Epoch 2266/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6192 - accuracy: 0.6427 - val_loss: 0.6607 - val_accuracy: 0.5451\n",
      "Epoch 2267/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6193 - accuracy: 0.6420 - val_loss: 0.6461 - val_accuracy: 0.5678\n",
      "Epoch 2268/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6194 - accuracy: 0.6425 - val_loss: 0.6669 - val_accuracy: 0.5353\n",
      "Epoch 2269/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6194 - accuracy: 0.6420 - val_loss: 0.6447 - val_accuracy: 0.5729\n",
      "Epoch 2270/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6197 - accuracy: 0.6426 - val_loss: 0.6736 - val_accuracy: 0.5300\n",
      "Epoch 2271/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6202 - accuracy: 0.6411 - val_loss: 0.6350 - val_accuracy: 0.5842\n",
      "Epoch 2272/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6208 - accuracy: 0.6396 - val_loss: 0.6838 - val_accuracy: 0.5174\n",
      "Epoch 2273/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6218 - accuracy: 0.6394 - val_loss: 0.6314 - val_accuracy: 0.5913\n",
      "Epoch 2274/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6220 - accuracy: 0.6381 - val_loss: 0.6893 - val_accuracy: 0.5115\n",
      "Epoch 2275/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6229 - accuracy: 0.6372 - val_loss: 0.6345 - val_accuracy: 0.5864\n",
      "Epoch 2276/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6214 - accuracy: 0.6381 - val_loss: 0.6680 - val_accuracy: 0.5369\n",
      "Epoch 2277/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6200 - accuracy: 0.6423 - val_loss: 0.6518 - val_accuracy: 0.5619\n",
      "Epoch 2278/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6196 - accuracy: 0.6434 - val_loss: 0.6516 - val_accuracy: 0.5564\n",
      "Epoch 2279/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6656 - val_accuracy: 0.5389\n",
      "Epoch 2280/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6196 - accuracy: 0.6413 - val_loss: 0.6428 - val_accuracy: 0.5751\n",
      "Epoch 2281/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6199 - accuracy: 0.6419 - val_loss: 0.6750 - val_accuracy: 0.5254\n",
      "Epoch 2282/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6202 - accuracy: 0.6416 - val_loss: 0.6358 - val_accuracy: 0.5828\n",
      "Epoch 2283/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6407 - val_loss: 0.6833 - val_accuracy: 0.5175\n",
      "Epoch 2284/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6221 - accuracy: 0.6390 - val_loss: 0.6299 - val_accuracy: 0.5957\n",
      "Epoch 2285/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6217 - accuracy: 0.6373 - val_loss: 0.6805 - val_accuracy: 0.5199\n",
      "Epoch 2286/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6403 - val_loss: 0.6445 - val_accuracy: 0.5676\n",
      "Epoch 2287/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6200 - accuracy: 0.6428 - val_loss: 0.6607 - val_accuracy: 0.5433\n",
      "Epoch 2288/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6191 - accuracy: 0.6425 - val_loss: 0.6495 - val_accuracy: 0.5607\n",
      "Epoch 2289/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6191 - accuracy: 0.6423 - val_loss: 0.6543 - val_accuracy: 0.5546\n",
      "Epoch 2290/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6188 - accuracy: 0.6436 - val_loss: 0.6619 - val_accuracy: 0.5429\n",
      "Epoch 2291/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6190 - accuracy: 0.6430 - val_loss: 0.6484 - val_accuracy: 0.5645\n",
      "Epoch 2292/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6190 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.5420\n",
      "Epoch 2293/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6192 - accuracy: 0.6419 - val_loss: 0.6435 - val_accuracy: 0.5725\n",
      "Epoch 2294/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6193 - accuracy: 0.6424 - val_loss: 0.6698 - val_accuracy: 0.5323\n",
      "Epoch 2295/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6194 - accuracy: 0.6419 - val_loss: 0.6433 - val_accuracy: 0.5733\n",
      "Epoch 2296/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6196 - accuracy: 0.6418 - val_loss: 0.6732 - val_accuracy: 0.5311\n",
      "Epoch 2297/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6201 - accuracy: 0.6407 - val_loss: 0.6346 - val_accuracy: 0.5873\n",
      "Epoch 2298/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6206 - accuracy: 0.6395 - val_loss: 0.6823 - val_accuracy: 0.5175\n",
      "Epoch 2299/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6211 - accuracy: 0.6401 - val_loss: 0.6355 - val_accuracy: 0.5844\n",
      "Epoch 2300/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6212 - accuracy: 0.6414 - val_loss: 0.6832 - val_accuracy: 0.5174\n",
      "Epoch 2301/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6217 - accuracy: 0.6396 - val_loss: 0.6315 - val_accuracy: 0.5961\n",
      "Epoch 2302/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6212 - accuracy: 0.6385 - val_loss: 0.6763 - val_accuracy: 0.5254\n",
      "Epoch 2303/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6203 - accuracy: 0.6415 - val_loss: 0.6448 - val_accuracy: 0.5678\n",
      "Epoch 2304/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6200 - accuracy: 0.6427 - val_loss: 0.6663 - val_accuracy: 0.5367\n",
      "Epoch 2305/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6193 - accuracy: 0.6416 - val_loss: 0.6440 - val_accuracy: 0.5692\n",
      "Epoch 2306/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6197 - accuracy: 0.6398 - val_loss: 0.6651 - val_accuracy: 0.5402\n",
      "Epoch 2307/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6190 - accuracy: 0.6421 - val_loss: 0.6473 - val_accuracy: 0.5639\n",
      "Epoch 2308/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6198 - accuracy: 0.6429 - val_loss: 0.6708 - val_accuracy: 0.5301\n",
      "Epoch 2309/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6196 - accuracy: 0.6411 - val_loss: 0.6343 - val_accuracy: 0.5875\n",
      "Epoch 2310/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6211 - accuracy: 0.6385 - val_loss: 0.6848 - val_accuracy: 0.5157\n",
      "Epoch 2311/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6216 - accuracy: 0.6398 - val_loss: 0.6320 - val_accuracy: 0.5891\n",
      "Epoch 2312/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6225 - accuracy: 0.6376 - val_loss: 0.6895 - val_accuracy: 0.5119\n",
      "Epoch 2313/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6229 - accuracy: 0.6377 - val_loss: 0.6312 - val_accuracy: 0.5946\n",
      "Epoch 2314/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6228 - accuracy: 0.6358 - val_loss: 0.6758 - val_accuracy: 0.5245\n",
      "Epoch 2315/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6203 - accuracy: 0.6409 - val_loss: 0.6438 - val_accuracy: 0.5696\n",
      "Epoch 2316/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6209 - accuracy: 0.6411 - val_loss: 0.6652 - val_accuracy: 0.5382\n",
      "Epoch 2317/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6192 - accuracy: 0.6417 - val_loss: 0.6462 - val_accuracy: 0.5634\n",
      "Epoch 2318/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6201 - accuracy: 0.6390 - val_loss: 0.6634 - val_accuracy: 0.5402\n",
      "Epoch 2319/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6192 - accuracy: 0.6421 - val_loss: 0.6467 - val_accuracy: 0.5636\n",
      "Epoch 2320/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6198 - accuracy: 0.6422 - val_loss: 0.6698 - val_accuracy: 0.5309\n",
      "Epoch 2321/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6197 - accuracy: 0.6418 - val_loss: 0.6407 - val_accuracy: 0.5740\n",
      "Epoch 2322/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6195 - accuracy: 0.6404 - val_loss: 0.6676 - val_accuracy: 0.5354\n",
      "Epoch 2323/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6198 - accuracy: 0.6421 - val_loss: 0.6445 - val_accuracy: 0.5696\n",
      "Epoch 2324/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6192 - accuracy: 0.6422 - val_loss: 0.6663 - val_accuracy: 0.5376\n",
      "Epoch 2325/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6195 - accuracy: 0.6414 - val_loss: 0.6505 - val_accuracy: 0.5572\n",
      "Epoch 2326/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6185 - accuracy: 0.6428 - val_loss: 0.6535 - val_accuracy: 0.5557\n",
      "Epoch 2327/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6190 - accuracy: 0.6429 - val_loss: 0.6610 - val_accuracy: 0.5462\n",
      "Epoch 2328/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6186 - accuracy: 0.6433 - val_loss: 0.6456 - val_accuracy: 0.5661\n",
      "Epoch 2329/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6195 - accuracy: 0.6427 - val_loss: 0.6749 - val_accuracy: 0.5272\n",
      "Epoch 2330/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6198 - accuracy: 0.6415 - val_loss: 0.6311 - val_accuracy: 0.5952\n",
      "Epoch 2331/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6213 - accuracy: 0.6384 - val_loss: 0.6925 - val_accuracy: 0.5080\n",
      "Epoch 2332/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6229 - accuracy: 0.6378 - val_loss: 0.6303 - val_accuracy: 0.5919\n",
      "Epoch 2333/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6224 - accuracy: 0.6385 - val_loss: 0.6857 - val_accuracy: 0.5146\n",
      "Epoch 2334/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6220 - accuracy: 0.6394 - val_loss: 0.6355 - val_accuracy: 0.5870\n",
      "Epoch 2335/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6205 - accuracy: 0.6401 - val_loss: 0.6639 - val_accuracy: 0.5406\n",
      "Epoch 2336/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6189 - accuracy: 0.6422 - val_loss: 0.6583 - val_accuracy: 0.5468\n",
      "Epoch 2337/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6191 - accuracy: 0.6428 - val_loss: 0.6470 - val_accuracy: 0.5661\n",
      "Epoch 2338/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6190 - accuracy: 0.6430 - val_loss: 0.6704 - val_accuracy: 0.5305\n",
      "Epoch 2339/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6197 - accuracy: 0.6423 - val_loss: 0.6357 - val_accuracy: 0.5839\n",
      "Epoch 2340/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6200 - accuracy: 0.6411 - val_loss: 0.6840 - val_accuracy: 0.5155\n",
      "Epoch 2341/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6212 - accuracy: 0.6393 - val_loss: 0.6357 - val_accuracy: 0.5842\n",
      "Epoch 2342/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6202 - accuracy: 0.6414 - val_loss: 0.6747 - val_accuracy: 0.5285\n",
      "Epoch 2343/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6199 - accuracy: 0.6418 - val_loss: 0.6421 - val_accuracy: 0.5749\n",
      "Epoch 2344/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6188 - accuracy: 0.6427 - val_loss: 0.6588 - val_accuracy: 0.5473\n",
      "Epoch 2345/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6184 - accuracy: 0.6443 - val_loss: 0.6585 - val_accuracy: 0.5499\n",
      "Epoch 2346/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6183 - accuracy: 0.6440 - val_loss: 0.6465 - val_accuracy: 0.5652\n",
      "Epoch 2347/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6185 - accuracy: 0.6433 - val_loss: 0.6698 - val_accuracy: 0.5336\n",
      "Epoch 2348/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6191 - accuracy: 0.6416 - val_loss: 0.6387 - val_accuracy: 0.5793\n",
      "Epoch 2349/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6194 - accuracy: 0.6417 - val_loss: 0.6790 - val_accuracy: 0.5228\n",
      "Epoch 2350/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6203 - accuracy: 0.6415 - val_loss: 0.6337 - val_accuracy: 0.5886\n",
      "Epoch 2351/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6203 - accuracy: 0.6404 - val_loss: 0.6813 - val_accuracy: 0.5192\n",
      "Epoch 2352/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6209 - accuracy: 0.6394 - val_loss: 0.6369 - val_accuracy: 0.5822\n",
      "Epoch 2353/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6202 - accuracy: 0.6402 - val_loss: 0.6707 - val_accuracy: 0.5320\n",
      "Epoch 2354/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6477 - val_accuracy: 0.5639\n",
      "Epoch 2355/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6192 - accuracy: 0.6431 - val_loss: 0.6604 - val_accuracy: 0.5411\n",
      "Epoch 2356/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6188 - accuracy: 0.6413 - val_loss: 0.6536 - val_accuracy: 0.5526\n",
      "Epoch 2357/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6186 - accuracy: 0.6412 - val_loss: 0.6532 - val_accuracy: 0.5574\n",
      "Epoch 2358/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6185 - accuracy: 0.6432 - val_loss: 0.6604 - val_accuracy: 0.5493\n",
      "Epoch 2359/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6186 - accuracy: 0.6434 - val_loss: 0.6511 - val_accuracy: 0.5579\n",
      "Epoch 2360/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6186 - accuracy: 0.6436 - val_loss: 0.6611 - val_accuracy: 0.5429\n",
      "Epoch 2361/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6185 - accuracy: 0.6416 - val_loss: 0.6459 - val_accuracy: 0.5680\n",
      "Epoch 2362/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6187 - accuracy: 0.6425 - val_loss: 0.6692 - val_accuracy: 0.5360\n",
      "Epoch 2363/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6186 - accuracy: 0.6431 - val_loss: 0.6430 - val_accuracy: 0.5698\n",
      "Epoch 2364/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6772 - val_accuracy: 0.5250\n",
      "Epoch 2365/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6201 - accuracy: 0.6414 - val_loss: 0.6296 - val_accuracy: 0.5990\n",
      "Epoch 2366/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6213 - accuracy: 0.6384 - val_loss: 0.6912 - val_accuracy: 0.5064\n",
      "Epoch 2367/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6219 - accuracy: 0.6392 - val_loss: 0.6367 - val_accuracy: 0.5789\n",
      "Epoch 2368/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6216 - accuracy: 0.6395 - val_loss: 0.6771 - val_accuracy: 0.5241\n",
      "Epoch 2369/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6205 - accuracy: 0.6410 - val_loss: 0.6352 - val_accuracy: 0.5882\n",
      "Epoch 2370/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6207 - accuracy: 0.6397 - val_loss: 0.6678 - val_accuracy: 0.5356\n",
      "Epoch 2371/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6186 - accuracy: 0.6424 - val_loss: 0.6525 - val_accuracy: 0.5537\n",
      "Epoch 2372/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6199 - accuracy: 0.6424 - val_loss: 0.6649 - val_accuracy: 0.5409\n",
      "Epoch 2373/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6186 - accuracy: 0.6430 - val_loss: 0.6424 - val_accuracy: 0.5744\n",
      "Epoch 2374/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6198 - accuracy: 0.6404 - val_loss: 0.6678 - val_accuracy: 0.5345\n",
      "Epoch 2375/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6188 - accuracy: 0.6420 - val_loss: 0.6442 - val_accuracy: 0.5680\n",
      "Epoch 2376/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6202 - accuracy: 0.6423 - val_loss: 0.6793 - val_accuracy: 0.5210\n",
      "Epoch 2377/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6203 - accuracy: 0.6414 - val_loss: 0.6324 - val_accuracy: 0.5939\n",
      "Epoch 2378/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6211 - accuracy: 0.6390 - val_loss: 0.6795 - val_accuracy: 0.5217\n",
      "Epoch 2379/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6207 - accuracy: 0.6393 - val_loss: 0.6409 - val_accuracy: 0.5727\n",
      "Epoch 2380/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6210 - accuracy: 0.6407 - val_loss: 0.6703 - val_accuracy: 0.5345\n",
      "Epoch 2381/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6197 - accuracy: 0.6419 - val_loss: 0.6488 - val_accuracy: 0.5665\n",
      "Epoch 2382/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6200 - accuracy: 0.6429 - val_loss: 0.6571 - val_accuracy: 0.5475\n",
      "Epoch 2383/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6185 - accuracy: 0.6417 - val_loss: 0.6560 - val_accuracy: 0.5490\n",
      "Epoch 2384/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6199 - accuracy: 0.6411 - val_loss: 0.6584 - val_accuracy: 0.5513\n",
      "Epoch 2385/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6185 - accuracy: 0.6439 - val_loss: 0.6519 - val_accuracy: 0.5614\n",
      "Epoch 2386/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6198 - accuracy: 0.6425 - val_loss: 0.6653 - val_accuracy: 0.5371\n",
      "Epoch 2387/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6186 - accuracy: 0.6416 - val_loss: 0.6398 - val_accuracy: 0.5751\n",
      "Epoch 2388/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6212 - accuracy: 0.6387 - val_loss: 0.6847 - val_accuracy: 0.5124\n",
      "Epoch 2389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6212 - accuracy: 0.6405 - val_loss: 0.6299 - val_accuracy: 0.5954\n",
      "Epoch 2390/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6243 - accuracy: 0.6348 - val_loss: 0.6983 - val_accuracy: 0.5020\n",
      "Epoch 2391/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6247 - accuracy: 0.6359 - val_loss: 0.6345 - val_accuracy: 0.5864\n",
      "Epoch 2392/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6271 - accuracy: 0.6329 - val_loss: 0.6805 - val_accuracy: 0.5201\n",
      "Epoch 2393/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6211 - accuracy: 0.6404 - val_loss: 0.6396 - val_accuracy: 0.5826\n",
      "Epoch 2394/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6268 - accuracy: 0.6346 - val_loss: 0.6866 - val_accuracy: 0.5132\n",
      "Epoch 2395/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6226 - accuracy: 0.6378 - val_loss: 0.6258 - val_accuracy: 0.5983\n",
      "Epoch 2396/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6282 - accuracy: 0.6311 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
      "Epoch 2397/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6243 - accuracy: 0.6363 - val_loss: 0.6404 - val_accuracy: 0.5791\n",
      "Epoch 2398/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6220 - accuracy: 0.6398 - val_loss: 0.6563 - val_accuracy: 0.5495\n",
      "Epoch 2399/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6189 - accuracy: 0.6436 - val_loss: 0.6677 - val_accuracy: 0.5329\n",
      "Epoch 2400/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6201 - accuracy: 0.6404 - val_loss: 0.6335 - val_accuracy: 0.5829\n",
      "Epoch 2401/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6210 - accuracy: 0.6384 - val_loss: 0.6803 - val_accuracy: 0.5181\n",
      "Epoch 2402/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6212 - accuracy: 0.6407 - val_loss: 0.6398 - val_accuracy: 0.5773\n",
      "Epoch 2403/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6221 - accuracy: 0.6395 - val_loss: 0.6712 - val_accuracy: 0.5307\n",
      "Epoch 2404/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6194 - accuracy: 0.6416 - val_loss: 0.6457 - val_accuracy: 0.5599\n",
      "Epoch 2405/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6215 - accuracy: 0.6376 - val_loss: 0.6605 - val_accuracy: 0.5440\n",
      "Epoch 2406/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6186 - accuracy: 0.6427 - val_loss: 0.6508 - val_accuracy: 0.5656\n",
      "Epoch 2407/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6206 - accuracy: 0.6413 - val_loss: 0.6646 - val_accuracy: 0.5409\n",
      "Epoch 2408/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6183 - accuracy: 0.6434 - val_loss: 0.6437 - val_accuracy: 0.5636\n",
      "Epoch 2409/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6207 - accuracy: 0.6410 - val_loss: 0.6706 - val_accuracy: 0.5309\n",
      "Epoch 2410/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6191 - accuracy: 0.6418 - val_loss: 0.6394 - val_accuracy: 0.5806\n",
      "Epoch 2411/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6205 - accuracy: 0.6407 - val_loss: 0.6762 - val_accuracy: 0.5245\n",
      "Epoch 2412/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6194 - accuracy: 0.6420 - val_loss: 0.6411 - val_accuracy: 0.5709\n",
      "Epoch 2413/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6201 - accuracy: 0.6422 - val_loss: 0.6665 - val_accuracy: 0.5380\n",
      "Epoch 2414/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6183 - accuracy: 0.6422 - val_loss: 0.6466 - val_accuracy: 0.5683\n",
      "Epoch 2415/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6189 - accuracy: 0.6435 - val_loss: 0.6604 - val_accuracy: 0.5471\n",
      "Epoch 2416/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6178 - accuracy: 0.6438 - val_loss: 0.6555 - val_accuracy: 0.5550\n",
      "Epoch 2417/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6183 - accuracy: 0.6434 - val_loss: 0.6554 - val_accuracy: 0.5499\n",
      "Epoch 2418/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6176 - accuracy: 0.6440 - val_loss: 0.6558 - val_accuracy: 0.5524\n",
      "Epoch 2419/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6180 - accuracy: 0.6440 - val_loss: 0.6547 - val_accuracy: 0.5552\n",
      "Epoch 2420/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6177 - accuracy: 0.6438 - val_loss: 0.6570 - val_accuracy: 0.5522\n",
      "Epoch 2421/15000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6178 - accuracy: 0.6439 - val_loss: 0.6567 - val_accuracy: 0.5552\n",
      "Epoch 2422/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6176 - accuracy: 0.6438 - val_loss: 0.6554 - val_accuracy: 0.5550\n",
      "Epoch 2423/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6176 - accuracy: 0.6435 - val_loss: 0.6575 - val_accuracy: 0.5508\n",
      "Epoch 2424/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6176 - accuracy: 0.6439 - val_loss: 0.6539 - val_accuracy: 0.5564\n",
      "Epoch 2425/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6176 - accuracy: 0.6439 - val_loss: 0.6585 - val_accuracy: 0.5521\n",
      "Epoch 2426/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6175 - accuracy: 0.6444 - val_loss: 0.6543 - val_accuracy: 0.5566\n",
      "Epoch 2427/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6175 - accuracy: 0.6440 - val_loss: 0.6601 - val_accuracy: 0.5484\n",
      "Epoch 2428/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6176 - accuracy: 0.6437 - val_loss: 0.6525 - val_accuracy: 0.5574\n",
      "Epoch 2429/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6175 - accuracy: 0.6432 - val_loss: 0.6598 - val_accuracy: 0.5501\n",
      "Epoch 2430/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6175 - accuracy: 0.6441 - val_loss: 0.6519 - val_accuracy: 0.5623\n",
      "Epoch 2431/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6174 - accuracy: 0.6451 - val_loss: 0.6623 - val_accuracy: 0.5449\n",
      "Epoch 2432/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6175 - accuracy: 0.6441 - val_loss: 0.6490 - val_accuracy: 0.5634\n",
      "Epoch 2433/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6435 - val_loss: 0.6652 - val_accuracy: 0.5422\n",
      "Epoch 2434/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6176 - accuracy: 0.6436 - val_loss: 0.6457 - val_accuracy: 0.5687\n",
      "Epoch 2435/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6178 - accuracy: 0.6429 - val_loss: 0.6728 - val_accuracy: 0.5318\n",
      "Epoch 2436/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6183 - accuracy: 0.6433 - val_loss: 0.6378 - val_accuracy: 0.5822\n",
      "Epoch 2437/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6188 - accuracy: 0.6416 - val_loss: 0.6816 - val_accuracy: 0.5210\n",
      "Epoch 2438/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6197 - accuracy: 0.6413 - val_loss: 0.6336 - val_accuracy: 0.5866\n",
      "Epoch 2439/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6196 - accuracy: 0.6405 - val_loss: 0.6833 - val_accuracy: 0.5188\n",
      "Epoch 2440/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6199 - accuracy: 0.6410 - val_loss: 0.6364 - val_accuracy: 0.5835\n",
      "Epoch 2441/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6191 - accuracy: 0.6417 - val_loss: 0.6747 - val_accuracy: 0.5272\n",
      "Epoch 2442/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6186 - accuracy: 0.6424 - val_loss: 0.6427 - val_accuracy: 0.5720\n",
      "Epoch 2443/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6180 - accuracy: 0.6435 - val_loss: 0.6624 - val_accuracy: 0.5448\n",
      "Epoch 2444/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6174 - accuracy: 0.6442 - val_loss: 0.6549 - val_accuracy: 0.5539\n",
      "Epoch 2445/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6173 - accuracy: 0.6435 - val_loss: 0.6518 - val_accuracy: 0.5568\n",
      "Epoch 2446/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6172 - accuracy: 0.6442 - val_loss: 0.6633 - val_accuracy: 0.5437\n",
      "Epoch 2447/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6175 - accuracy: 0.6440 - val_loss: 0.6442 - val_accuracy: 0.5720\n",
      "Epoch 2448/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6177 - accuracy: 0.6436 - val_loss: 0.6714 - val_accuracy: 0.5322\n",
      "Epoch 2449/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6181 - accuracy: 0.6426 - val_loss: 0.6397 - val_accuracy: 0.5802\n",
      "Epoch 2450/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6184 - accuracy: 0.6426 - val_loss: 0.6784 - val_accuracy: 0.5237\n",
      "Epoch 2451/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6190 - accuracy: 0.6417 - val_loss: 0.6352 - val_accuracy: 0.5851\n",
      "Epoch 2452/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6189 - accuracy: 0.6415 - val_loss: 0.6776 - val_accuracy: 0.5243\n",
      "Epoch 2453/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6189 - accuracy: 0.6421 - val_loss: 0.6399 - val_accuracy: 0.5782\n",
      "Epoch 2454/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6183 - accuracy: 0.6427 - val_loss: 0.6707 - val_accuracy: 0.5345\n",
      "Epoch 2455/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6179 - accuracy: 0.6435 - val_loss: 0.6449 - val_accuracy: 0.5696\n",
      "Epoch 2456/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6176 - accuracy: 0.6435 - val_loss: 0.6617 - val_accuracy: 0.5451\n",
      "Epoch 2457/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6172 - accuracy: 0.6445 - val_loss: 0.6521 - val_accuracy: 0.5572\n",
      "Epoch 2458/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6570 - val_accuracy: 0.5501\n",
      "Epoch 2459/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6170 - accuracy: 0.6445 - val_loss: 0.6577 - val_accuracy: 0.5510\n",
      "Epoch 2460/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6171 - accuracy: 0.6444 - val_loss: 0.6511 - val_accuracy: 0.5603\n",
      "Epoch 2461/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6171 - accuracy: 0.6442 - val_loss: 0.6626 - val_accuracy: 0.5442\n",
      "Epoch 2462/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6464 - val_accuracy: 0.5692\n",
      "Epoch 2463/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6174 - accuracy: 0.6434 - val_loss: 0.6704 - val_accuracy: 0.5354\n",
      "Epoch 2464/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6178 - accuracy: 0.6433 - val_loss: 0.6393 - val_accuracy: 0.5793\n",
      "Epoch 2465/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6181 - accuracy: 0.6431 - val_loss: 0.6790 - val_accuracy: 0.5230\n",
      "Epoch 2466/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6189 - accuracy: 0.6423 - val_loss: 0.6346 - val_accuracy: 0.5848\n",
      "Epoch 2467/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6191 - accuracy: 0.6407 - val_loss: 0.6851 - val_accuracy: 0.5183\n",
      "Epoch 2468/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6199 - accuracy: 0.6409 - val_loss: 0.6333 - val_accuracy: 0.5882\n",
      "Epoch 2469/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6191 - accuracy: 0.6412 - val_loss: 0.6785 - val_accuracy: 0.5237\n",
      "Epoch 2470/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6189 - accuracy: 0.6421 - val_loss: 0.6406 - val_accuracy: 0.5784\n",
      "Epoch 2471/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6180 - accuracy: 0.6429 - val_loss: 0.6683 - val_accuracy: 0.5382\n",
      "Epoch 2472/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6175 - accuracy: 0.6436 - val_loss: 0.6478 - val_accuracy: 0.5652\n",
      "Epoch 2473/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6172 - accuracy: 0.6440 - val_loss: 0.6595 - val_accuracy: 0.5466\n",
      "Epoch 2474/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6442 - val_loss: 0.6545 - val_accuracy: 0.5532\n",
      "Epoch 2475/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6169 - accuracy: 0.6435 - val_loss: 0.6548 - val_accuracy: 0.5533\n",
      "Epoch 2476/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6168 - accuracy: 0.6447 - val_loss: 0.6590 - val_accuracy: 0.5501\n",
      "Epoch 2477/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6508 - val_accuracy: 0.5605\n",
      "Epoch 2478/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6628 - val_accuracy: 0.5433\n",
      "Epoch 2479/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6170 - accuracy: 0.6442 - val_loss: 0.6462 - val_accuracy: 0.5674\n",
      "Epoch 2480/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6172 - accuracy: 0.6434 - val_loss: 0.6702 - val_accuracy: 0.5367\n",
      "Epoch 2481/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6176 - accuracy: 0.6438 - val_loss: 0.6397 - val_accuracy: 0.5804\n",
      "Epoch 2482/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6179 - accuracy: 0.6426 - val_loss: 0.6807 - val_accuracy: 0.5223\n",
      "Epoch 2483/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6191 - accuracy: 0.6425 - val_loss: 0.6314 - val_accuracy: 0.5891\n",
      "Epoch 2484/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6196 - accuracy: 0.6398 - val_loss: 0.6917 - val_accuracy: 0.5079\n",
      "Epoch 2485/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6211 - accuracy: 0.6392 - val_loss: 0.6311 - val_accuracy: 0.5913\n",
      "Epoch 2486/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6197 - accuracy: 0.6397 - val_loss: 0.6807 - val_accuracy: 0.5228\n",
      "Epoch 2487/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6192 - accuracy: 0.6421 - val_loss: 0.6404 - val_accuracy: 0.5764\n",
      "Epoch 2488/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6178 - accuracy: 0.6433 - val_loss: 0.6624 - val_accuracy: 0.5442\n",
      "Epoch 2489/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6170 - accuracy: 0.6444 - val_loss: 0.6569 - val_accuracy: 0.5528\n",
      "Epoch 2490/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6168 - accuracy: 0.6446 - val_loss: 0.6472 - val_accuracy: 0.5652\n",
      "Epoch 2491/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6170 - accuracy: 0.6442 - val_loss: 0.6710 - val_accuracy: 0.5311\n",
      "Epoch 2492/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6177 - accuracy: 0.6429 - val_loss: 0.6365 - val_accuracy: 0.5813\n",
      "Epoch 2493/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6185 - accuracy: 0.6427 - val_loss: 0.6880 - val_accuracy: 0.5119\n",
      "Epoch 2494/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6203 - accuracy: 0.6400 - val_loss: 0.6285 - val_accuracy: 0.5957\n",
      "Epoch 2495/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6200 - accuracy: 0.6391 - val_loss: 0.6873 - val_accuracy: 0.5141\n",
      "Epoch 2496/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6204 - accuracy: 0.6399 - val_loss: 0.6368 - val_accuracy: 0.5804\n",
      "Epoch 2497/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6183 - accuracy: 0.6422 - val_loss: 0.6645 - val_accuracy: 0.5415\n",
      "Epoch 2498/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6171 - accuracy: 0.6448 - val_loss: 0.6554 - val_accuracy: 0.5526\n",
      "Epoch 2499/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6168 - accuracy: 0.6449 - val_loss: 0.6453 - val_accuracy: 0.5678\n",
      "Epoch 2500/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6171 - accuracy: 0.6437 - val_loss: 0.6751 - val_accuracy: 0.5281\n",
      "Epoch 2501/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6182 - accuracy: 0.6427 - val_loss: 0.6333 - val_accuracy: 0.5875\n",
      "Epoch 2502/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6191 - accuracy: 0.6415 - val_loss: 0.6902 - val_accuracy: 0.5091\n",
      "Epoch 2503/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6208 - accuracy: 0.6397 - val_loss: 0.6301 - val_accuracy: 0.5915\n",
      "Epoch 2504/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6195 - accuracy: 0.6397 - val_loss: 0.6776 - val_accuracy: 0.5259\n",
      "Epoch 2505/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6187 - accuracy: 0.6428 - val_loss: 0.6439 - val_accuracy: 0.5683\n",
      "Epoch 2506/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6563 - val_accuracy: 0.5499\n",
      "Epoch 2507/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6166 - accuracy: 0.6446 - val_loss: 0.6644 - val_accuracy: 0.5402\n",
      "Epoch 2508/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6393 - val_accuracy: 0.5796\n",
      "Epoch 2509/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6177 - accuracy: 0.6434 - val_loss: 0.6833 - val_accuracy: 0.5194\n",
      "Epoch 2510/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6194 - accuracy: 0.6409 - val_loss: 0.6304 - val_accuracy: 0.5912\n",
      "Epoch 2511/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6196 - accuracy: 0.6404 - val_loss: 0.6885 - val_accuracy: 0.5111\n",
      "Epoch 2512/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6204 - accuracy: 0.6399 - val_loss: 0.6346 - val_accuracy: 0.5837\n",
      "Epoch 2513/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6184 - accuracy: 0.6422 - val_loss: 0.6655 - val_accuracy: 0.5389\n",
      "Epoch 2514/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6171 - accuracy: 0.6437 - val_loss: 0.6555 - val_accuracy: 0.5493\n",
      "Epoch 2515/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6166 - accuracy: 0.6445 - val_loss: 0.6452 - val_accuracy: 0.5689\n",
      "Epoch 2516/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6170 - accuracy: 0.6442 - val_loss: 0.6775 - val_accuracy: 0.5252\n",
      "Epoch 2517/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6183 - accuracy: 0.6424 - val_loss: 0.6309 - val_accuracy: 0.5902\n",
      "Epoch 2518/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6195 - accuracy: 0.6404 - val_loss: 0.6949 - val_accuracy: 0.5037\n",
      "Epoch 2519/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6217 - accuracy: 0.6387 - val_loss: 0.6305 - val_accuracy: 0.5923\n",
      "Epoch 2520/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6196 - accuracy: 0.6395 - val_loss: 0.6755 - val_accuracy: 0.5285\n",
      "Epoch 2521/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6182 - accuracy: 0.6436 - val_loss: 0.6479 - val_accuracy: 0.5632\n",
      "Epoch 2522/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6168 - accuracy: 0.6440 - val_loss: 0.6455 - val_accuracy: 0.5672\n",
      "Epoch 2523/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6168 - accuracy: 0.6443 - val_loss: 0.6773 - val_accuracy: 0.5256\n",
      "Epoch 2524/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6182 - accuracy: 0.6426 - val_loss: 0.6332 - val_accuracy: 0.5881\n",
      "Epoch 2525/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6194 - accuracy: 0.6410 - val_loss: 0.6928 - val_accuracy: 0.5040\n",
      "Epoch 2526/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6211 - accuracy: 0.6400 - val_loss: 0.6302 - val_accuracy: 0.5930\n",
      "Epoch 2527/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6192 - accuracy: 0.6400 - val_loss: 0.6755 - val_accuracy: 0.5272\n",
      "Epoch 2528/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6181 - accuracy: 0.6432 - val_loss: 0.6472 - val_accuracy: 0.5623\n",
      "Epoch 2529/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6168 - accuracy: 0.6438 - val_loss: 0.6515 - val_accuracy: 0.5585\n",
      "Epoch 2530/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6166 - accuracy: 0.6452 - val_loss: 0.6700 - val_accuracy: 0.5342\n",
      "Epoch 2531/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6173 - accuracy: 0.6439 - val_loss: 0.6343 - val_accuracy: 0.5860\n",
      "Epoch 2532/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6181 - accuracy: 0.6422 - val_loss: 0.6847 - val_accuracy: 0.5181\n",
      "Epoch 2533/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6195 - accuracy: 0.6410 - val_loss: 0.6347 - val_accuracy: 0.5853\n",
      "Epoch 2534/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6189 - accuracy: 0.6417 - val_loss: 0.6797 - val_accuracy: 0.5206\n",
      "Epoch 2535/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6184 - accuracy: 0.6427 - val_loss: 0.6411 - val_accuracy: 0.5751\n",
      "Epoch 2536/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6171 - accuracy: 0.6436 - val_loss: 0.6585 - val_accuracy: 0.5462\n",
      "Epoch 2537/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6165 - accuracy: 0.6440 - val_loss: 0.6579 - val_accuracy: 0.5473\n",
      "Epoch 2538/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6164 - accuracy: 0.6445 - val_loss: 0.6466 - val_accuracy: 0.5672\n",
      "Epoch 2539/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6167 - accuracy: 0.6446 - val_loss: 0.6739 - val_accuracy: 0.5290\n",
      "Epoch 2540/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6174 - accuracy: 0.6438 - val_loss: 0.6356 - val_accuracy: 0.5842\n",
      "Epoch 2541/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6180 - accuracy: 0.6423 - val_loss: 0.6833 - val_accuracy: 0.5206\n",
      "Epoch 2542/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6191 - accuracy: 0.6416 - val_loss: 0.6340 - val_accuracy: 0.5862\n",
      "Epoch 2543/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6185 - accuracy: 0.6415 - val_loss: 0.6787 - val_accuracy: 0.5237\n",
      "Epoch 2544/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6181 - accuracy: 0.6427 - val_loss: 0.6427 - val_accuracy: 0.5720\n",
      "Epoch 2545/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6593 - val_accuracy: 0.5460\n",
      "Epoch 2546/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6163 - accuracy: 0.6448 - val_loss: 0.6574 - val_accuracy: 0.5484\n",
      "Epoch 2547/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6477 - val_accuracy: 0.5643\n",
      "Epoch 2548/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6165 - accuracy: 0.6449 - val_loss: 0.6731 - val_accuracy: 0.5309\n",
      "Epoch 2549/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6172 - accuracy: 0.6439 - val_loss: 0.6365 - val_accuracy: 0.5837\n",
      "Epoch 2550/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6178 - accuracy: 0.6427 - val_loss: 0.6848 - val_accuracy: 0.5194\n",
      "Epoch 2551/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6192 - accuracy: 0.6412 - val_loss: 0.6315 - val_accuracy: 0.5912\n",
      "Epoch 2552/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6188 - accuracy: 0.6399 - val_loss: 0.6834 - val_accuracy: 0.5194\n",
      "Epoch 2553/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6188 - accuracy: 0.6417 - val_loss: 0.6405 - val_accuracy: 0.5760\n",
      "Epoch 2554/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6617 - val_accuracy: 0.5433\n",
      "Epoch 2555/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6163 - accuracy: 0.6448 - val_loss: 0.6561 - val_accuracy: 0.5493\n",
      "Epoch 2556/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6161 - accuracy: 0.6453 - val_loss: 0.6482 - val_accuracy: 0.5654\n",
      "Epoch 2557/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6164 - accuracy: 0.6450 - val_loss: 0.6743 - val_accuracy: 0.5280\n",
      "Epoch 2558/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6172 - accuracy: 0.6442 - val_loss: 0.6348 - val_accuracy: 0.5862\n",
      "Epoch 2559/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6180 - accuracy: 0.6421 - val_loss: 0.6874 - val_accuracy: 0.5161\n",
      "Epoch 2560/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6197 - accuracy: 0.6406 - val_loss: 0.6307 - val_accuracy: 0.5915\n",
      "Epoch 2561/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6189 - accuracy: 0.6401 - val_loss: 0.6815 - val_accuracy: 0.5216\n",
      "Epoch 2562/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6184 - accuracy: 0.6427 - val_loss: 0.6434 - val_accuracy: 0.5725\n",
      "Epoch 2563/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6167 - accuracy: 0.6441 - val_loss: 0.6565 - val_accuracy: 0.5499\n",
      "Epoch 2564/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6161 - accuracy: 0.6452 - val_loss: 0.6615 - val_accuracy: 0.5429\n",
      "Epoch 2565/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6162 - accuracy: 0.6445 - val_loss: 0.6426 - val_accuracy: 0.5727\n",
      "Epoch 2566/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6169 - accuracy: 0.6436 - val_loss: 0.6820 - val_accuracy: 0.5197\n",
      "Epoch 2567/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6183 - accuracy: 0.6420 - val_loss: 0.6317 - val_accuracy: 0.5906\n",
      "Epoch 2568/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6188 - accuracy: 0.6408 - val_loss: 0.6876 - val_accuracy: 0.5159\n",
      "Epoch 2569/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6199 - accuracy: 0.6404 - val_loss: 0.6331 - val_accuracy: 0.5893\n",
      "Epoch 2570/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6181 - accuracy: 0.6413 - val_loss: 0.6692 - val_accuracy: 0.5353\n",
      "Epoch 2571/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6167 - accuracy: 0.6445 - val_loss: 0.6563 - val_accuracy: 0.5506\n",
      "Epoch 2572/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6160 - accuracy: 0.6455 - val_loss: 0.6436 - val_accuracy: 0.5720\n",
      "Epoch 2573/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6165 - accuracy: 0.6443 - val_loss: 0.6772 - val_accuracy: 0.5256\n",
      "Epoch 2574/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6179 - accuracy: 0.6428 - val_loss: 0.6323 - val_accuracy: 0.5888\n",
      "Epoch 2575/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6188 - accuracy: 0.6412 - val_loss: 0.6919 - val_accuracy: 0.5066\n",
      "Epoch 2576/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6203 - accuracy: 0.6402 - val_loss: 0.6321 - val_accuracy: 0.5897\n",
      "Epoch 2577/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6186 - accuracy: 0.6407 - val_loss: 0.6743 - val_accuracy: 0.5298\n",
      "Epoch 2578/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6175 - accuracy: 0.6432 - val_loss: 0.6485 - val_accuracy: 0.5594\n",
      "Epoch 2579/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6465 - val_accuracy: 0.5667\n",
      "Epoch 2580/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6163 - accuracy: 0.6449 - val_loss: 0.6773 - val_accuracy: 0.5216\n",
      "Epoch 2581/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6176 - accuracy: 0.6433 - val_loss: 0.6319 - val_accuracy: 0.5895\n",
      "Epoch 2582/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6189 - accuracy: 0.6411 - val_loss: 0.6930 - val_accuracy: 0.5058\n",
      "Epoch 2583/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6209 - accuracy: 0.6393 - val_loss: 0.6302 - val_accuracy: 0.5930\n",
      "Epoch 2584/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6188 - accuracy: 0.6400 - val_loss: 0.6747 - val_accuracy: 0.5259\n",
      "Epoch 2585/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6172 - accuracy: 0.6438 - val_loss: 0.6515 - val_accuracy: 0.5550\n",
      "Epoch 2586/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6161 - accuracy: 0.6446 - val_loss: 0.6469 - val_accuracy: 0.5661\n",
      "Epoch 2587/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6161 - accuracy: 0.6454 - val_loss: 0.6715 - val_accuracy: 0.5331\n",
      "Epoch 2588/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6171 - accuracy: 0.6435 - val_loss: 0.6362 - val_accuracy: 0.5822\n",
      "Epoch 2589/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6429 - val_loss: 0.6825 - val_accuracy: 0.5195\n",
      "Epoch 2590/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6182 - accuracy: 0.6419 - val_loss: 0.6378 - val_accuracy: 0.5802\n",
      "Epoch 2591/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6176 - accuracy: 0.6430 - val_loss: 0.6728 - val_accuracy: 0.5322\n",
      "Epoch 2592/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6171 - accuracy: 0.6435 - val_loss: 0.6441 - val_accuracy: 0.5709\n",
      "Epoch 2593/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6163 - accuracy: 0.6445 - val_loss: 0.6563 - val_accuracy: 0.5491\n",
      "Epoch 2594/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6456 - val_loss: 0.6627 - val_accuracy: 0.5426\n",
      "Epoch 2595/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6160 - accuracy: 0.6457 - val_loss: 0.6459 - val_accuracy: 0.5680\n",
      "Epoch 2596/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6161 - accuracy: 0.6447 - val_loss: 0.6695 - val_accuracy: 0.5356\n",
      "Epoch 2597/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6166 - accuracy: 0.6441 - val_loss: 0.6405 - val_accuracy: 0.5767\n",
      "Epoch 2598/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6166 - accuracy: 0.6436 - val_loss: 0.6738 - val_accuracy: 0.5280\n",
      "Epoch 2599/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6168 - accuracy: 0.6441 - val_loss: 0.6426 - val_accuracy: 0.5740\n",
      "Epoch 2600/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6168 - accuracy: 0.6442 - val_loss: 0.6729 - val_accuracy: 0.5318\n",
      "Epoch 2601/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6436 - val_loss: 0.6402 - val_accuracy: 0.5775\n",
      "Epoch 2602/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6166 - accuracy: 0.6439 - val_loss: 0.6678 - val_accuracy: 0.5360\n",
      "Epoch 2603/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6455 - val_loss: 0.6497 - val_accuracy: 0.5623\n",
      "Epoch 2604/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6161 - accuracy: 0.6450 - val_loss: 0.6635 - val_accuracy: 0.5453\n",
      "Epoch 2605/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6158 - accuracy: 0.6453 - val_loss: 0.6507 - val_accuracy: 0.5617\n",
      "Epoch 2606/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6158 - accuracy: 0.6450 - val_loss: 0.6578 - val_accuracy: 0.5493\n",
      "Epoch 2607/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6156 - accuracy: 0.6457 - val_loss: 0.6561 - val_accuracy: 0.5524\n",
      "Epoch 2608/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6157 - accuracy: 0.6450 - val_loss: 0.6582 - val_accuracy: 0.5502\n",
      "Epoch 2609/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6546 - val_accuracy: 0.5546\n",
      "Epoch 2610/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6156 - accuracy: 0.6453 - val_loss: 0.6561 - val_accuracy: 0.5532\n",
      "Epoch 2611/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6455 - val_loss: 0.6547 - val_accuracy: 0.5550\n",
      "Epoch 2612/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6604 - val_accuracy: 0.5479\n",
      "Epoch 2613/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6155 - accuracy: 0.6456 - val_loss: 0.6525 - val_accuracy: 0.5577\n",
      "Epoch 2614/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6156 - accuracy: 0.6453 - val_loss: 0.6616 - val_accuracy: 0.5448\n",
      "Epoch 2615/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6459 - val_loss: 0.6486 - val_accuracy: 0.5672\n",
      "Epoch 2616/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6158 - accuracy: 0.6449 - val_loss: 0.6687 - val_accuracy: 0.5369\n",
      "Epoch 2617/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6159 - accuracy: 0.6451 - val_loss: 0.6421 - val_accuracy: 0.5760\n",
      "Epoch 2618/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6164 - accuracy: 0.6440 - val_loss: 0.6784 - val_accuracy: 0.5256\n",
      "Epoch 2619/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6172 - accuracy: 0.6439 - val_loss: 0.6339 - val_accuracy: 0.5873\n",
      "Epoch 2620/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6176 - accuracy: 0.6418 - val_loss: 0.6876 - val_accuracy: 0.5172\n",
      "Epoch 2621/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6189 - accuracy: 0.6417 - val_loss: 0.6313 - val_accuracy: 0.5941\n",
      "Epoch 2622/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6185 - accuracy: 0.6411 - val_loss: 0.6863 - val_accuracy: 0.5172\n",
      "Epoch 2623/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6185 - accuracy: 0.6420 - val_loss: 0.6376 - val_accuracy: 0.5807\n",
      "Epoch 2624/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6434 - val_loss: 0.6682 - val_accuracy: 0.5371\n",
      "Epoch 2625/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6161 - accuracy: 0.6449 - val_loss: 0.6498 - val_accuracy: 0.5607\n",
      "Epoch 2626/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6155 - accuracy: 0.6454 - val_loss: 0.6550 - val_accuracy: 0.5541\n",
      "Epoch 2627/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6154 - accuracy: 0.6458 - val_loss: 0.6649 - val_accuracy: 0.5407\n",
      "Epoch 2628/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6429 - val_accuracy: 0.5745\n",
      "Epoch 2629/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6160 - accuracy: 0.6443 - val_loss: 0.6766 - val_accuracy: 0.5265\n",
      "Epoch 2630/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6171 - accuracy: 0.6435 - val_loss: 0.6335 - val_accuracy: 0.5884\n",
      "Epoch 2631/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6177 - accuracy: 0.6421 - val_loss: 0.6882 - val_accuracy: 0.5135\n",
      "Epoch 2632/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6190 - accuracy: 0.6413 - val_loss: 0.6323 - val_accuracy: 0.5893\n",
      "Epoch 2633/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6180 - accuracy: 0.6415 - val_loss: 0.6789 - val_accuracy: 0.5263\n",
      "Epoch 2634/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6175 - accuracy: 0.6432 - val_loss: 0.6422 - val_accuracy: 0.5740\n",
      "Epoch 2635/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6160 - accuracy: 0.6447 - val_loss: 0.6579 - val_accuracy: 0.5506\n",
      "Epoch 2636/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6154 - accuracy: 0.6462 - val_loss: 0.6634 - val_accuracy: 0.5417\n",
      "Epoch 2637/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6462 - val_loss: 0.6421 - val_accuracy: 0.5753\n",
      "Epoch 2638/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6162 - accuracy: 0.6442 - val_loss: 0.6793 - val_accuracy: 0.5234\n",
      "Epoch 2639/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6175 - accuracy: 0.6431 - val_loss: 0.6318 - val_accuracy: 0.5915\n",
      "Epoch 2640/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6179 - accuracy: 0.6419 - val_loss: 0.6880 - val_accuracy: 0.5122\n",
      "Epoch 2641/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6188 - accuracy: 0.6413 - val_loss: 0.6360 - val_accuracy: 0.5815\n",
      "Epoch 2642/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6173 - accuracy: 0.6426 - val_loss: 0.6706 - val_accuracy: 0.5365\n",
      "Epoch 2643/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6166 - accuracy: 0.6445 - val_loss: 0.6471 - val_accuracy: 0.5665\n",
      "Epoch 2644/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6458 - val_loss: 0.6537 - val_accuracy: 0.5541\n",
      "Epoch 2645/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6156 - accuracy: 0.6460 - val_loss: 0.6704 - val_accuracy: 0.5309\n",
      "Epoch 2646/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6159 - accuracy: 0.6445 - val_loss: 0.6359 - val_accuracy: 0.5868\n",
      "Epoch 2647/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6173 - accuracy: 0.6431 - val_loss: 0.6879 - val_accuracy: 0.5164\n",
      "Epoch 2648/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6190 - accuracy: 0.6411 - val_loss: 0.6300 - val_accuracy: 0.5932\n",
      "Epoch 2649/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6188 - accuracy: 0.6403 - val_loss: 0.6843 - val_accuracy: 0.5150\n",
      "Epoch 2650/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6187 - accuracy: 0.6421 - val_loss: 0.6399 - val_accuracy: 0.5822\n",
      "Epoch 2651/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6170 - accuracy: 0.6438 - val_loss: 0.6609 - val_accuracy: 0.5437\n",
      "Epoch 2652/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6160 - accuracy: 0.6446 - val_loss: 0.6621 - val_accuracy: 0.5415\n",
      "Epoch 2653/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6442 - val_loss: 0.6429 - val_accuracy: 0.5764\n",
      "Epoch 2654/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6166 - accuracy: 0.6450 - val_loss: 0.6803 - val_accuracy: 0.5195\n",
      "Epoch 2655/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6174 - accuracy: 0.6439 - val_loss: 0.6317 - val_accuracy: 0.5899\n",
      "Epoch 2656/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6187 - accuracy: 0.6416 - val_loss: 0.6907 - val_accuracy: 0.5104\n",
      "Epoch 2657/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6199 - accuracy: 0.6403 - val_loss: 0.6314 - val_accuracy: 0.5943\n",
      "Epoch 2658/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6181 - accuracy: 0.6408 - val_loss: 0.6717 - val_accuracy: 0.5336\n",
      "Epoch 2659/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6452 - val_loss: 0.6565 - val_accuracy: 0.5502\n",
      "Epoch 2660/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6159 - accuracy: 0.6459 - val_loss: 0.6453 - val_accuracy: 0.5701\n",
      "Epoch 2661/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6159 - accuracy: 0.6448 - val_loss: 0.6708 - val_accuracy: 0.5338\n",
      "Epoch 2662/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6167 - accuracy: 0.6439 - val_loss: 0.6391 - val_accuracy: 0.5793\n",
      "Epoch 2663/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6170 - accuracy: 0.6434 - val_loss: 0.6838 - val_accuracy: 0.5152\n",
      "Epoch 2664/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6177 - accuracy: 0.6423 - val_loss: 0.6353 - val_accuracy: 0.5862\n",
      "Epoch 2665/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6171 - accuracy: 0.6437 - val_loss: 0.6735 - val_accuracy: 0.5309\n",
      "Epoch 2666/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6168 - accuracy: 0.6440 - val_loss: 0.6445 - val_accuracy: 0.5681\n",
      "Epoch 2667/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6158 - accuracy: 0.6451 - val_loss: 0.6581 - val_accuracy: 0.5490\n",
      "Epoch 2668/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6152 - accuracy: 0.6475 - val_loss: 0.6630 - val_accuracy: 0.5437\n",
      "Epoch 2669/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6154 - accuracy: 0.6463 - val_loss: 0.6432 - val_accuracy: 0.5729\n",
      "Epoch 2670/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6157 - accuracy: 0.6445 - val_loss: 0.6735 - val_accuracy: 0.5309\n",
      "Epoch 2671/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6164 - accuracy: 0.6437 - val_loss: 0.6397 - val_accuracy: 0.5798\n",
      "Epoch 2672/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6165 - accuracy: 0.6433 - val_loss: 0.6775 - val_accuracy: 0.5243\n",
      "Epoch 2673/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6166 - accuracy: 0.6448 - val_loss: 0.6389 - val_accuracy: 0.5791\n",
      "Epoch 2674/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6163 - accuracy: 0.6449 - val_loss: 0.6723 - val_accuracy: 0.5314\n",
      "Epoch 2675/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6163 - accuracy: 0.6445 - val_loss: 0.6430 - val_accuracy: 0.5740\n",
      "Epoch 2676/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6157 - accuracy: 0.6448 - val_loss: 0.6637 - val_accuracy: 0.5442\n",
      "Epoch 2677/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6152 - accuracy: 0.6471 - val_loss: 0.6563 - val_accuracy: 0.5552\n",
      "Epoch 2678/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6151 - accuracy: 0.6459 - val_loss: 0.6523 - val_accuracy: 0.5579\n",
      "Epoch 2679/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6150 - accuracy: 0.6459 - val_loss: 0.6611 - val_accuracy: 0.5490\n",
      "Epoch 2680/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6152 - accuracy: 0.6458 - val_loss: 0.6492 - val_accuracy: 0.5649\n",
      "Epoch 2681/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6151 - accuracy: 0.6460 - val_loss: 0.6682 - val_accuracy: 0.5353\n",
      "Epoch 2682/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6154 - accuracy: 0.6460 - val_loss: 0.6439 - val_accuracy: 0.5745\n",
      "Epoch 2683/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6454 - val_loss: 0.6721 - val_accuracy: 0.5331\n",
      "Epoch 2684/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6160 - accuracy: 0.6445 - val_loss: 0.6393 - val_accuracy: 0.5807\n",
      "Epoch 2685/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6160 - accuracy: 0.6444 - val_loss: 0.6787 - val_accuracy: 0.5261\n",
      "Epoch 2686/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6166 - accuracy: 0.6441 - val_loss: 0.6378 - val_accuracy: 0.5817\n",
      "Epoch 2687/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6165 - accuracy: 0.6435 - val_loss: 0.6793 - val_accuracy: 0.5256\n",
      "Epoch 2688/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6169 - accuracy: 0.6437 - val_loss: 0.6373 - val_accuracy: 0.5833\n",
      "Epoch 2689/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6164 - accuracy: 0.6441 - val_loss: 0.6738 - val_accuracy: 0.5283\n",
      "Epoch 2690/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6160 - accuracy: 0.6447 - val_loss: 0.6447 - val_accuracy: 0.5716\n",
      "Epoch 2691/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6156 - accuracy: 0.6447 - val_loss: 0.6686 - val_accuracy: 0.5384\n",
      "Epoch 2692/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6154 - accuracy: 0.6459 - val_loss: 0.6453 - val_accuracy: 0.5701\n",
      "Epoch 2693/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6153 - accuracy: 0.6453 - val_loss: 0.6640 - val_accuracy: 0.5426\n",
      "Epoch 2694/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6150 - accuracy: 0.6461 - val_loss: 0.6518 - val_accuracy: 0.5603\n",
      "Epoch 2695/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6150 - accuracy: 0.6458 - val_loss: 0.6615 - val_accuracy: 0.5466\n",
      "Epoch 2696/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6149 - accuracy: 0.6467 - val_loss: 0.6500 - val_accuracy: 0.5636\n",
      "Epoch 2697/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6149 - accuracy: 0.6459 - val_loss: 0.6611 - val_accuracy: 0.5440\n",
      "Epoch 2698/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6148 - accuracy: 0.6459 - val_loss: 0.6513 - val_accuracy: 0.5634\n",
      "Epoch 2699/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6149 - accuracy: 0.6459 - val_loss: 0.6653 - val_accuracy: 0.5437\n",
      "Epoch 2700/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6150 - accuracy: 0.6469 - val_loss: 0.6454 - val_accuracy: 0.5705\n",
      "Epoch 2701/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6152 - accuracy: 0.6451 - val_loss: 0.6690 - val_accuracy: 0.5336\n",
      "Epoch 2702/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6154 - accuracy: 0.6458 - val_loss: 0.6417 - val_accuracy: 0.5769\n",
      "Epoch 2703/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6158 - accuracy: 0.6442 - val_loss: 0.6807 - val_accuracy: 0.5247\n",
      "Epoch 2704/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6168 - accuracy: 0.6437 - val_loss: 0.6328 - val_accuracy: 0.5893\n",
      "Epoch 2705/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6173 - accuracy: 0.6422 - val_loss: 0.6883 - val_accuracy: 0.5126\n",
      "Epoch 2706/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6184 - accuracy: 0.6423 - val_loss: 0.6307 - val_accuracy: 0.5932\n",
      "Epoch 2707/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6178 - accuracy: 0.6427 - val_loss: 0.6844 - val_accuracy: 0.5210\n",
      "Epoch 2708/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6178 - accuracy: 0.6420 - val_loss: 0.6398 - val_accuracy: 0.5775\n",
      "Epoch 2709/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6162 - accuracy: 0.6439 - val_loss: 0.6640 - val_accuracy: 0.5435\n",
      "Epoch 2710/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6155 - accuracy: 0.6464 - val_loss: 0.6571 - val_accuracy: 0.5548\n",
      "Epoch 2711/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6150 - accuracy: 0.6460 - val_loss: 0.6473 - val_accuracy: 0.5661\n",
      "Epoch 2712/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6158 - accuracy: 0.6449 - val_loss: 0.6750 - val_accuracy: 0.5281\n",
      "Epoch 2713/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6164 - accuracy: 0.6443 - val_loss: 0.6329 - val_accuracy: 0.5913\n",
      "Epoch 2714/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6178 - accuracy: 0.6432 - val_loss: 0.6922 - val_accuracy: 0.5073\n",
      "Epoch 2715/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6189 - accuracy: 0.6404 - val_loss: 0.6343 - val_accuracy: 0.5846\n",
      "Epoch 2716/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6186 - accuracy: 0.6416 - val_loss: 0.6781 - val_accuracy: 0.5278\n",
      "Epoch 2717/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6183 - accuracy: 0.6441 - val_loss: 0.6400 - val_accuracy: 0.5793\n",
      "Epoch 2718/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6176 - accuracy: 0.6437 - val_loss: 0.6603 - val_accuracy: 0.5457\n",
      "Epoch 2719/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6153 - accuracy: 0.6452 - val_loss: 0.6639 - val_accuracy: 0.5382\n",
      "Epoch 2720/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6169 - accuracy: 0.6441 - val_loss: 0.6530 - val_accuracy: 0.5610\n",
      "Epoch 2721/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6161 - accuracy: 0.6448 - val_loss: 0.6585 - val_accuracy: 0.5532\n",
      "Epoch 2722/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6166 - accuracy: 0.6449 - val_loss: 0.6501 - val_accuracy: 0.5616\n",
      "Epoch 2723/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6153 - accuracy: 0.6452 - val_loss: 0.6612 - val_accuracy: 0.5427\n",
      "Epoch 2724/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6160 - accuracy: 0.6449 - val_loss: 0.6603 - val_accuracy: 0.5495\n",
      "Epoch 2725/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6158 - accuracy: 0.6457 - val_loss: 0.6508 - val_accuracy: 0.5639\n",
      "Epoch 2726/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6156 - accuracy: 0.6449 - val_loss: 0.6601 - val_accuracy: 0.5460\n",
      "Epoch 2727/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6155 - accuracy: 0.6452 - val_loss: 0.6501 - val_accuracy: 0.5610\n",
      "Epoch 2728/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6456 - val_loss: 0.6679 - val_accuracy: 0.5413\n",
      "Epoch 2729/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6161 - accuracy: 0.6457 - val_loss: 0.6479 - val_accuracy: 0.5691\n",
      "Epoch 2730/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6449 - val_loss: 0.6657 - val_accuracy: 0.5380\n",
      "Epoch 2731/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6162 - accuracy: 0.6441 - val_loss: 0.6500 - val_accuracy: 0.5592\n",
      "Epoch 2732/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6152 - accuracy: 0.6455 - val_loss: 0.6590 - val_accuracy: 0.5522\n",
      "Epoch 2733/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6159 - accuracy: 0.6451 - val_loss: 0.6625 - val_accuracy: 0.5459\n",
      "Epoch 2734/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6149 - accuracy: 0.6466 - val_loss: 0.6450 - val_accuracy: 0.5685\n",
      "Epoch 2735/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6163 - accuracy: 0.6439 - val_loss: 0.6761 - val_accuracy: 0.5281\n",
      "Epoch 2736/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6164 - accuracy: 0.6440 - val_loss: 0.6321 - val_accuracy: 0.5932\n",
      "Epoch 2737/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6181 - accuracy: 0.6427 - val_loss: 0.6981 - val_accuracy: 0.5015\n",
      "Epoch 2738/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6197 - accuracy: 0.6399 - val_loss: 0.6298 - val_accuracy: 0.5946\n",
      "Epoch 2739/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6204 - accuracy: 0.6401 - val_loss: 0.6918 - val_accuracy: 0.5068\n",
      "Epoch 2740/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6203 - accuracy: 0.6412 - val_loss: 0.6326 - val_accuracy: 0.5934\n",
      "Epoch 2741/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6190 - accuracy: 0.6407 - val_loss: 0.6669 - val_accuracy: 0.5374\n",
      "Epoch 2742/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6600 - val_accuracy: 0.5471\n",
      "Epoch 2743/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6179 - accuracy: 0.6427 - val_loss: 0.6605 - val_accuracy: 0.5495\n",
      "Epoch 2744/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6159 - accuracy: 0.6458 - val_loss: 0.6492 - val_accuracy: 0.5694\n",
      "Epoch 2745/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6175 - accuracy: 0.6444 - val_loss: 0.6648 - val_accuracy: 0.5407\n",
      "Epoch 2746/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6155 - accuracy: 0.6454 - val_loss: 0.6411 - val_accuracy: 0.5754\n",
      "Epoch 2747/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6198 - accuracy: 0.6420 - val_loss: 0.6957 - val_accuracy: 0.4995\n",
      "Epoch 2748/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6204 - accuracy: 0.6399 - val_loss: 0.6262 - val_accuracy: 0.6074\n",
      "Epoch 2749/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6238 - accuracy: 0.6337 - val_loss: 0.6982 - val_accuracy: 0.5053\n",
      "Epoch 2750/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6225 - accuracy: 0.6370 - val_loss: 0.6422 - val_accuracy: 0.5765\n",
      "Epoch 2751/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6237 - accuracy: 0.6361 - val_loss: 0.6678 - val_accuracy: 0.5345\n",
      "Epoch 2752/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6512 - val_accuracy: 0.5658\n",
      "Epoch 2753/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6210 - accuracy: 0.6420 - val_loss: 0.6757 - val_accuracy: 0.5250\n",
      "Epoch 2754/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6173 - accuracy: 0.6456 - val_loss: 0.6284 - val_accuracy: 0.5977\n",
      "Epoch 2755/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6230 - accuracy: 0.6372 - val_loss: 0.6983 - val_accuracy: 0.4989\n",
      "Epoch 2756/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6221 - accuracy: 0.6376 - val_loss: 0.6380 - val_accuracy: 0.5849\n",
      "Epoch 2757/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6203 - accuracy: 0.6393 - val_loss: 0.6668 - val_accuracy: 0.5393\n",
      "Epoch 2758/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6461 - val_loss: 0.6624 - val_accuracy: 0.5398\n",
      "Epoch 2759/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6170 - accuracy: 0.6438 - val_loss: 0.6394 - val_accuracy: 0.5793\n",
      "Epoch 2760/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6161 - accuracy: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.5287\n",
      "Epoch 2761/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6176 - accuracy: 0.6429 - val_loss: 0.6417 - val_accuracy: 0.5771\n",
      "Epoch 2762/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6167 - accuracy: 0.6439 - val_loss: 0.6665 - val_accuracy: 0.5382\n",
      "Epoch 2763/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6161 - accuracy: 0.6442 - val_loss: 0.6529 - val_accuracy: 0.5543\n",
      "Epoch 2764/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6154 - accuracy: 0.6457 - val_loss: 0.6490 - val_accuracy: 0.5650\n",
      "Epoch 2765/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6153 - accuracy: 0.6460 - val_loss: 0.6696 - val_accuracy: 0.5369\n",
      "Epoch 2766/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6157 - accuracy: 0.6461 - val_loss: 0.6427 - val_accuracy: 0.5745\n",
      "Epoch 2767/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6163 - accuracy: 0.6448 - val_loss: 0.6772 - val_accuracy: 0.5281\n",
      "Epoch 2768/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6165 - accuracy: 0.6442 - val_loss: 0.6380 - val_accuracy: 0.5807\n",
      "Epoch 2769/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6162 - accuracy: 0.6440 - val_loss: 0.6755 - val_accuracy: 0.5278\n",
      "Epoch 2770/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6159 - accuracy: 0.6454 - val_loss: 0.6488 - val_accuracy: 0.5639\n",
      "Epoch 2771/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6152 - accuracy: 0.6455 - val_loss: 0.6588 - val_accuracy: 0.5501\n",
      "Epoch 2772/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6146 - accuracy: 0.6460 - val_loss: 0.6573 - val_accuracy: 0.5541\n",
      "Epoch 2773/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6147 - accuracy: 0.6458 - val_loss: 0.6478 - val_accuracy: 0.5674\n",
      "Epoch 2774/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6148 - accuracy: 0.6465 - val_loss: 0.6713 - val_accuracy: 0.5329\n",
      "Epoch 2775/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6149 - accuracy: 0.6457 - val_loss: 0.6441 - val_accuracy: 0.5740\n",
      "Epoch 2776/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6153 - accuracy: 0.6453 - val_loss: 0.6747 - val_accuracy: 0.5322\n",
      "Epoch 2777/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6157 - accuracy: 0.6456 - val_loss: 0.6380 - val_accuracy: 0.5811\n",
      "Epoch 2778/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6154 - accuracy: 0.6450 - val_loss: 0.6711 - val_accuracy: 0.5349\n",
      "Epoch 2779/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6151 - accuracy: 0.6458 - val_loss: 0.6479 - val_accuracy: 0.5676\n",
      "Epoch 2780/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6148 - accuracy: 0.6460 - val_loss: 0.6649 - val_accuracy: 0.5446\n",
      "Epoch 2781/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6145 - accuracy: 0.6475 - val_loss: 0.6504 - val_accuracy: 0.5645\n",
      "Epoch 2782/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6143 - accuracy: 0.6464 - val_loss: 0.6593 - val_accuracy: 0.5490\n",
      "Epoch 2783/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6143 - accuracy: 0.6466 - val_loss: 0.6567 - val_accuracy: 0.5535\n",
      "Epoch 2784/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6141 - accuracy: 0.6471 - val_loss: 0.6553 - val_accuracy: 0.5577\n",
      "Epoch 2785/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6142 - accuracy: 0.6463 - val_loss: 0.6608 - val_accuracy: 0.5468\n",
      "Epoch 2786/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6142 - accuracy: 0.6466 - val_loss: 0.6484 - val_accuracy: 0.5683\n",
      "Epoch 2787/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6143 - accuracy: 0.6469 - val_loss: 0.6656 - val_accuracy: 0.5395\n",
      "Epoch 2788/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6144 - accuracy: 0.6468 - val_loss: 0.6463 - val_accuracy: 0.5705\n",
      "Epoch 2789/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6146 - accuracy: 0.6457 - val_loss: 0.6712 - val_accuracy: 0.5345\n",
      "Epoch 2790/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6148 - accuracy: 0.6461 - val_loss: 0.6421 - val_accuracy: 0.5771\n",
      "Epoch 2791/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6149 - accuracy: 0.6446 - val_loss: 0.6747 - val_accuracy: 0.5323\n",
      "Epoch 2792/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6152 - accuracy: 0.6468 - val_loss: 0.6399 - val_accuracy: 0.5817\n",
      "Epoch 2793/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6153 - accuracy: 0.6460 - val_loss: 0.6792 - val_accuracy: 0.5256\n",
      "Epoch 2794/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6159 - accuracy: 0.6446 - val_loss: 0.6383 - val_accuracy: 0.5804\n",
      "Epoch 2795/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6157 - accuracy: 0.6441 - val_loss: 0.6761 - val_accuracy: 0.5290\n",
      "Epoch 2796/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6156 - accuracy: 0.6463 - val_loss: 0.6410 - val_accuracy: 0.5809\n",
      "Epoch 2797/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6154 - accuracy: 0.6455 - val_loss: 0.6713 - val_accuracy: 0.5322\n",
      "Epoch 2798/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6152 - accuracy: 0.6457 - val_loss: 0.6459 - val_accuracy: 0.5685\n",
      "Epoch 2799/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6149 - accuracy: 0.6446 - val_loss: 0.6637 - val_accuracy: 0.5444\n",
      "Epoch 2800/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6145 - accuracy: 0.6477 - val_loss: 0.6527 - val_accuracy: 0.5596\n",
      "Epoch 2801/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6145 - accuracy: 0.6469 - val_loss: 0.6584 - val_accuracy: 0.5479\n",
      "Epoch 2802/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6143 - accuracy: 0.6465 - val_loss: 0.6539 - val_accuracy: 0.5574\n",
      "Epoch 2803/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6141 - accuracy: 0.6468 - val_loss: 0.6576 - val_accuracy: 0.5532\n",
      "Epoch 2804/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6142 - accuracy: 0.6467 - val_loss: 0.6563 - val_accuracy: 0.5548\n",
      "Epoch 2805/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6140 - accuracy: 0.6479 - val_loss: 0.6556 - val_accuracy: 0.5512\n",
      "Epoch 2806/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6143 - accuracy: 0.6467 - val_loss: 0.6564 - val_accuracy: 0.5528\n",
      "Epoch 2807/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6139 - accuracy: 0.6477 - val_loss: 0.6537 - val_accuracy: 0.5594\n",
      "Epoch 2808/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6140 - accuracy: 0.6466 - val_loss: 0.6631 - val_accuracy: 0.5457\n",
      "Epoch 2809/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6139 - accuracy: 0.6479 - val_loss: 0.6498 - val_accuracy: 0.5643\n",
      "Epoch 2810/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6141 - accuracy: 0.6465 - val_loss: 0.6638 - val_accuracy: 0.5440\n",
      "Epoch 2811/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6143 - accuracy: 0.6474 - val_loss: 0.6436 - val_accuracy: 0.5751\n",
      "Epoch 2812/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6146 - accuracy: 0.6459 - val_loss: 0.6768 - val_accuracy: 0.5280\n",
      "Epoch 2813/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6151 - accuracy: 0.6466 - val_loss: 0.6397 - val_accuracy: 0.5773\n",
      "Epoch 2814/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6443 - val_loss: 0.6797 - val_accuracy: 0.5248\n",
      "Epoch 2815/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6165 - accuracy: 0.6449 - val_loss: 0.6301 - val_accuracy: 0.5979\n",
      "Epoch 2816/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6168 - accuracy: 0.6438 - val_loss: 0.6897 - val_accuracy: 0.5108\n",
      "Epoch 2817/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6420 - val_loss: 0.6409 - val_accuracy: 0.5764\n",
      "Epoch 2818/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6167 - accuracy: 0.6439 - val_loss: 0.6718 - val_accuracy: 0.5345\n",
      "Epoch 2819/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6160 - accuracy: 0.6467 - val_loss: 0.6426 - val_accuracy: 0.5771\n",
      "Epoch 2820/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6160 - accuracy: 0.6451 - val_loss: 0.6617 - val_accuracy: 0.5438\n",
      "Epoch 2821/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6146 - accuracy: 0.6456 - val_loss: 0.6577 - val_accuracy: 0.5486\n",
      "Epoch 2822/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6153 - accuracy: 0.6439 - val_loss: 0.6644 - val_accuracy: 0.5431\n",
      "Epoch 2823/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6149 - accuracy: 0.6465 - val_loss: 0.6446 - val_accuracy: 0.5738\n",
      "Epoch 2824/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6156 - accuracy: 0.6450 - val_loss: 0.6681 - val_accuracy: 0.5338\n",
      "Epoch 2825/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6153 - accuracy: 0.6458 - val_loss: 0.6412 - val_accuracy: 0.5742\n",
      "Epoch 2826/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6166 - accuracy: 0.6428 - val_loss: 0.6868 - val_accuracy: 0.5121\n",
      "Epoch 2827/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6177 - accuracy: 0.6437 - val_loss: 0.6333 - val_accuracy: 0.5926\n",
      "Epoch 2828/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6188 - accuracy: 0.6411 - val_loss: 0.6859 - val_accuracy: 0.5183\n",
      "Epoch 2829/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6181 - accuracy: 0.6416 - val_loss: 0.6384 - val_accuracy: 0.5800\n",
      "Epoch 2830/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6205 - accuracy: 0.6392 - val_loss: 0.6781 - val_accuracy: 0.5256\n",
      "Epoch 2831/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6172 - accuracy: 0.6447 - val_loss: 0.6427 - val_accuracy: 0.5822\n",
      "Epoch 2832/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6218 - accuracy: 0.6395 - val_loss: 0.6852 - val_accuracy: 0.5185\n",
      "Epoch 2833/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6185 - accuracy: 0.6420 - val_loss: 0.6269 - val_accuracy: 0.6021\n",
      "Epoch 2834/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6258 - accuracy: 0.6342 - val_loss: 0.7128 - val_accuracy: 0.4826\n",
      "Epoch 2835/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6238 - accuracy: 0.6354 - val_loss: 0.6314 - val_accuracy: 0.5974\n",
      "Epoch 2836/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6237 - accuracy: 0.6360 - val_loss: 0.6822 - val_accuracy: 0.5197\n",
      "Epoch 2837/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6173 - accuracy: 0.6437 - val_loss: 0.6431 - val_accuracy: 0.5727\n",
      "Epoch 2838/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6197 - accuracy: 0.6384 - val_loss: 0.6578 - val_accuracy: 0.5479\n",
      "Epoch 2839/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6149 - accuracy: 0.6443 - val_loss: 0.6562 - val_accuracy: 0.5552\n",
      "Epoch 2840/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6165 - accuracy: 0.6452 - val_loss: 0.6595 - val_accuracy: 0.5502\n",
      "Epoch 2841/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6155 - accuracy: 0.6462 - val_loss: 0.6552 - val_accuracy: 0.5510\n",
      "Epoch 2842/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6150 - accuracy: 0.6449 - val_loss: 0.6517 - val_accuracy: 0.5564\n",
      "Epoch 2843/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6156 - accuracy: 0.6427 - val_loss: 0.6629 - val_accuracy: 0.5462\n",
      "Epoch 2844/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6147 - accuracy: 0.6466 - val_loss: 0.6454 - val_accuracy: 0.5722\n",
      "Epoch 2845/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6163 - accuracy: 0.6452 - val_loss: 0.6777 - val_accuracy: 0.5228\n",
      "Epoch 2846/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6161 - accuracy: 0.6448 - val_loss: 0.6327 - val_accuracy: 0.5904\n",
      "Epoch 2847/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6172 - accuracy: 0.6422 - val_loss: 0.6771 - val_accuracy: 0.5248\n",
      "Epoch 2848/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6164 - accuracy: 0.6448 - val_loss: 0.6442 - val_accuracy: 0.5751\n",
      "Epoch 2849/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6161 - accuracy: 0.6442 - val_loss: 0.6651 - val_accuracy: 0.5409\n",
      "Epoch 2850/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6142 - accuracy: 0.6471 - val_loss: 0.6537 - val_accuracy: 0.5564\n",
      "Epoch 2851/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6153 - accuracy: 0.6455 - val_loss: 0.6528 - val_accuracy: 0.5605\n",
      "Epoch 2852/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6142 - accuracy: 0.6466 - val_loss: 0.6611 - val_accuracy: 0.5493\n",
      "Epoch 2853/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6151 - accuracy: 0.6460 - val_loss: 0.6549 - val_accuracy: 0.5566\n",
      "Epoch 2854/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6138 - accuracy: 0.6475 - val_loss: 0.6597 - val_accuracy: 0.5466\n",
      "Epoch 2855/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6151 - accuracy: 0.6455 - val_loss: 0.6561 - val_accuracy: 0.5533\n",
      "Epoch 2856/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6138 - accuracy: 0.6478 - val_loss: 0.6475 - val_accuracy: 0.5701\n",
      "Epoch 2857/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6148 - accuracy: 0.6458 - val_loss: 0.6729 - val_accuracy: 0.5314\n",
      "Epoch 2858/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6144 - accuracy: 0.6469 - val_loss: 0.6425 - val_accuracy: 0.5749\n",
      "Epoch 2859/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6158 - accuracy: 0.6449 - val_loss: 0.6782 - val_accuracy: 0.5248\n",
      "Epoch 2860/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6156 - accuracy: 0.6455 - val_loss: 0.6327 - val_accuracy: 0.5948\n",
      "Epoch 2861/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6166 - accuracy: 0.6440 - val_loss: 0.6857 - val_accuracy: 0.5201\n",
      "Epoch 2862/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6163 - accuracy: 0.6437 - val_loss: 0.6400 - val_accuracy: 0.5780\n",
      "Epoch 2863/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6791 - val_accuracy: 0.5248\n",
      "Epoch 2864/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6463 - val_loss: 0.6376 - val_accuracy: 0.5868\n",
      "Epoch 2865/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6163 - accuracy: 0.6450 - val_loss: 0.6700 - val_accuracy: 0.5353\n",
      "Epoch 2866/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6145 - accuracy: 0.6468 - val_loss: 0.6496 - val_accuracy: 0.5641\n",
      "Epoch 2867/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6161 - accuracy: 0.6436 - val_loss: 0.6686 - val_accuracy: 0.5398\n",
      "Epoch 2868/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6143 - accuracy: 0.6467 - val_loss: 0.6447 - val_accuracy: 0.5778\n",
      "Epoch 2869/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6158 - accuracy: 0.6455 - val_loss: 0.6694 - val_accuracy: 0.5358\n",
      "Epoch 2870/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6143 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.5751\n",
      "Epoch 2871/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6170 - accuracy: 0.6438 - val_loss: 0.6843 - val_accuracy: 0.5183\n",
      "Epoch 2872/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6163 - accuracy: 0.6453 - val_loss: 0.6323 - val_accuracy: 0.5948\n",
      "Epoch 2873/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6181 - accuracy: 0.6418 - val_loss: 0.6842 - val_accuracy: 0.5194\n",
      "Epoch 2874/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6168 - accuracy: 0.6430 - val_loss: 0.6391 - val_accuracy: 0.5782\n",
      "Epoch 2875/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6180 - accuracy: 0.6426 - val_loss: 0.6739 - val_accuracy: 0.5301\n",
      "Epoch 2876/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6148 - accuracy: 0.6471 - val_loss: 0.6474 - val_accuracy: 0.5718\n",
      "Epoch 2877/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6165 - accuracy: 0.6451 - val_loss: 0.6656 - val_accuracy: 0.5406\n",
      "Epoch 2878/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6139 - accuracy: 0.6480 - val_loss: 0.6459 - val_accuracy: 0.5689\n",
      "Epoch 2879/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6168 - accuracy: 0.6439 - val_loss: 0.6739 - val_accuracy: 0.5276\n",
      "Epoch 2880/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6146 - accuracy: 0.6478 - val_loss: 0.6406 - val_accuracy: 0.5826\n",
      "Epoch 2881/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6169 - accuracy: 0.6445 - val_loss: 0.6824 - val_accuracy: 0.5197\n",
      "Epoch 2882/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6160 - accuracy: 0.6444 - val_loss: 0.6334 - val_accuracy: 0.5893\n",
      "Epoch 2883/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6180 - accuracy: 0.6418 - val_loss: 0.6831 - val_accuracy: 0.5183\n",
      "Epoch 2884/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6160 - accuracy: 0.6452 - val_loss: 0.6398 - val_accuracy: 0.5824\n",
      "Epoch 2885/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6167 - accuracy: 0.6447 - val_loss: 0.6719 - val_accuracy: 0.5334\n",
      "Epoch 2886/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6143 - accuracy: 0.6473 - val_loss: 0.6469 - val_accuracy: 0.5667\n",
      "Epoch 2887/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6157 - accuracy: 0.6437 - val_loss: 0.6610 - val_accuracy: 0.5469\n",
      "Epoch 2888/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6134 - accuracy: 0.6480 - val_loss: 0.6536 - val_accuracy: 0.5627\n",
      "Epoch 2889/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6148 - accuracy: 0.6463 - val_loss: 0.6625 - val_accuracy: 0.5471\n",
      "Epoch 2890/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6134 - accuracy: 0.6486 - val_loss: 0.6484 - val_accuracy: 0.5669\n",
      "Epoch 2891/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6148 - accuracy: 0.6456 - val_loss: 0.6678 - val_accuracy: 0.5376\n",
      "Epoch 2892/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6139 - accuracy: 0.6474 - val_loss: 0.6417 - val_accuracy: 0.5807\n",
      "Epoch 2893/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6150 - accuracy: 0.6460 - val_loss: 0.6772 - val_accuracy: 0.5254\n",
      "Epoch 2894/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6147 - accuracy: 0.6473 - val_loss: 0.6396 - val_accuracy: 0.5778\n",
      "Epoch 2895/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6155 - accuracy: 0.6445 - val_loss: 0.6740 - val_accuracy: 0.5290\n",
      "Epoch 2896/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6145 - accuracy: 0.6470 - val_loss: 0.6427 - val_accuracy: 0.5795\n",
      "Epoch 2897/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6146 - accuracy: 0.6463 - val_loss: 0.6683 - val_accuracy: 0.5398\n",
      "Epoch 2898/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6136 - accuracy: 0.6479 - val_loss: 0.6502 - val_accuracy: 0.5652\n",
      "Epoch 2899/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6141 - accuracy: 0.6464 - val_loss: 0.6606 - val_accuracy: 0.5493\n",
      "Epoch 2900/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6132 - accuracy: 0.6475 - val_loss: 0.6530 - val_accuracy: 0.5625\n",
      "Epoch 2901/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6137 - accuracy: 0.6471 - val_loss: 0.6579 - val_accuracy: 0.5544\n",
      "Epoch 2902/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6481 - val_loss: 0.6562 - val_accuracy: 0.5532\n",
      "Epoch 2903/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6136 - accuracy: 0.6472 - val_loss: 0.6579 - val_accuracy: 0.5535\n",
      "Epoch 2904/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6131 - accuracy: 0.6482 - val_loss: 0.6540 - val_accuracy: 0.5617\n",
      "Epoch 2905/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6135 - accuracy: 0.6477 - val_loss: 0.6600 - val_accuracy: 0.5512\n",
      "Epoch 2906/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6130 - accuracy: 0.6481 - val_loss: 0.6517 - val_accuracy: 0.5623\n",
      "Epoch 2907/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6136 - accuracy: 0.6472 - val_loss: 0.6653 - val_accuracy: 0.5431\n",
      "Epoch 2908/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6133 - accuracy: 0.6479 - val_loss: 0.6444 - val_accuracy: 0.5747\n",
      "Epoch 2909/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6139 - accuracy: 0.6474 - val_loss: 0.6736 - val_accuracy: 0.5322\n",
      "Epoch 2910/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6141 - accuracy: 0.6480 - val_loss: 0.6396 - val_accuracy: 0.5802\n",
      "Epoch 2911/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6149 - accuracy: 0.6447 - val_loss: 0.6825 - val_accuracy: 0.5199\n",
      "Epoch 2912/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6154 - accuracy: 0.6463 - val_loss: 0.6347 - val_accuracy: 0.5912\n",
      "Epoch 2913/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6157 - accuracy: 0.6449 - val_loss: 0.6832 - val_accuracy: 0.5210\n",
      "Epoch 2914/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6157 - accuracy: 0.6445 - val_loss: 0.6384 - val_accuracy: 0.5806\n",
      "Epoch 2915/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6154 - accuracy: 0.6449 - val_loss: 0.6740 - val_accuracy: 0.5298\n",
      "Epoch 2916/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6144 - accuracy: 0.6480 - val_loss: 0.6463 - val_accuracy: 0.5736\n",
      "Epoch 2917/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6144 - accuracy: 0.6469 - val_loss: 0.6608 - val_accuracy: 0.5482\n",
      "Epoch 2918/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6133 - accuracy: 0.6474 - val_loss: 0.6546 - val_accuracy: 0.5563\n",
      "Epoch 2919/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6139 - accuracy: 0.6461 - val_loss: 0.6582 - val_accuracy: 0.5557\n",
      "Epoch 2920/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6132 - accuracy: 0.6484 - val_loss: 0.6575 - val_accuracy: 0.5575\n",
      "Epoch 2921/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6137 - accuracy: 0.6468 - val_loss: 0.6565 - val_accuracy: 0.5544\n",
      "Epoch 2922/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6130 - accuracy: 0.6482 - val_loss: 0.6537 - val_accuracy: 0.5581\n",
      "Epoch 2923/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6136 - accuracy: 0.6473 - val_loss: 0.6620 - val_accuracy: 0.5495\n",
      "Epoch 2924/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6131 - accuracy: 0.6486 - val_loss: 0.6494 - val_accuracy: 0.5689\n",
      "Epoch 2925/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6138 - accuracy: 0.6470 - val_loss: 0.6679 - val_accuracy: 0.5382\n",
      "Epoch 2926/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6480 - val_loss: 0.6420 - val_accuracy: 0.5760\n",
      "Epoch 2927/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6144 - accuracy: 0.6455 - val_loss: 0.6777 - val_accuracy: 0.5261\n",
      "Epoch 2928/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6147 - accuracy: 0.6475 - val_loss: 0.6364 - val_accuracy: 0.5881\n",
      "Epoch 2929/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6156 - accuracy: 0.6449 - val_loss: 0.6856 - val_accuracy: 0.5186\n",
      "Epoch 2930/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6160 - accuracy: 0.6445 - val_loss: 0.6357 - val_accuracy: 0.5851\n",
      "Epoch 2931/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6162 - accuracy: 0.6440 - val_loss: 0.6794 - val_accuracy: 0.5227\n",
      "Epoch 2932/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6153 - accuracy: 0.6469 - val_loss: 0.6408 - val_accuracy: 0.5824\n",
      "Epoch 2933/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6156 - accuracy: 0.6463 - val_loss: 0.6699 - val_accuracy: 0.5365\n",
      "Epoch 2934/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6139 - accuracy: 0.6474 - val_loss: 0.6474 - val_accuracy: 0.5672\n",
      "Epoch 2935/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6153 - accuracy: 0.6440 - val_loss: 0.6671 - val_accuracy: 0.5415\n",
      "Epoch 2936/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6137 - accuracy: 0.6477 - val_loss: 0.6477 - val_accuracy: 0.5742\n",
      "Epoch 2937/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6153 - accuracy: 0.6465 - val_loss: 0.6718 - val_accuracy: 0.5327\n",
      "Epoch 2938/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6139 - accuracy: 0.6480 - val_loss: 0.6382 - val_accuracy: 0.5800\n",
      "Epoch 2939/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6169 - accuracy: 0.6441 - val_loss: 0.6874 - val_accuracy: 0.5150\n",
      "Epoch 2940/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6166 - accuracy: 0.6446 - val_loss: 0.6297 - val_accuracy: 0.6021\n",
      "Epoch 2941/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6192 - accuracy: 0.6394 - val_loss: 0.6953 - val_accuracy: 0.5073\n",
      "Epoch 2942/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6182 - accuracy: 0.6419 - val_loss: 0.6363 - val_accuracy: 0.5857\n",
      "Epoch 2943/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6195 - accuracy: 0.6412 - val_loss: 0.6719 - val_accuracy: 0.5298\n",
      "Epoch 2944/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6147 - accuracy: 0.6469 - val_loss: 0.6495 - val_accuracy: 0.5701\n",
      "Epoch 2945/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6175 - accuracy: 0.6453 - val_loss: 0.6654 - val_accuracy: 0.5431\n",
      "Epoch 2946/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6136 - accuracy: 0.6487 - val_loss: 0.6435 - val_accuracy: 0.5731\n",
      "Epoch 2947/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6176 - accuracy: 0.6436 - val_loss: 0.6829 - val_accuracy: 0.5183\n",
      "Epoch 2948/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6154 - accuracy: 0.6451 - val_loss: 0.6333 - val_accuracy: 0.5944\n",
      "Epoch 2949/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6182 - accuracy: 0.6412 - val_loss: 0.6922 - val_accuracy: 0.5062\n",
      "Epoch 2950/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6175 - accuracy: 0.6426 - val_loss: 0.6324 - val_accuracy: 0.5937\n",
      "Epoch 2951/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6170 - accuracy: 0.6429 - val_loss: 0.6714 - val_accuracy: 0.5327\n",
      "Epoch 2952/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6140 - accuracy: 0.6477 - val_loss: 0.6516 - val_accuracy: 0.5643\n",
      "Epoch 2953/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6142 - accuracy: 0.6463 - val_loss: 0.6525 - val_accuracy: 0.5607\n",
      "Epoch 2954/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6129 - accuracy: 0.6477 - val_loss: 0.6672 - val_accuracy: 0.5385\n",
      "Epoch 2955/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6141 - accuracy: 0.6462 - val_loss: 0.6437 - val_accuracy: 0.5742\n",
      "Epoch 2956/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6134 - accuracy: 0.6470 - val_loss: 0.6686 - val_accuracy: 0.5362\n",
      "Epoch 2957/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6140 - accuracy: 0.6474 - val_loss: 0.6490 - val_accuracy: 0.5685\n",
      "Epoch 2958/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6134 - accuracy: 0.6472 - val_loss: 0.6614 - val_accuracy: 0.5479\n",
      "Epoch 2959/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6133 - accuracy: 0.6479 - val_loss: 0.6535 - val_accuracy: 0.5592\n",
      "Epoch 2960/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6132 - accuracy: 0.6479 - val_loss: 0.6546 - val_accuracy: 0.5594\n",
      "Epoch 2961/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6130 - accuracy: 0.6484 - val_loss: 0.6616 - val_accuracy: 0.5506\n",
      "Epoch 2962/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6132 - accuracy: 0.6482 - val_loss: 0.6528 - val_accuracy: 0.5625\n",
      "Epoch 2963/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6128 - accuracy: 0.6482 - val_loss: 0.6597 - val_accuracy: 0.5491\n",
      "Epoch 2964/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6131 - accuracy: 0.6479 - val_loss: 0.6529 - val_accuracy: 0.5617\n",
      "Epoch 2965/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6127 - accuracy: 0.6486 - val_loss: 0.6592 - val_accuracy: 0.5554\n",
      "Epoch 2966/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6129 - accuracy: 0.6479 - val_loss: 0.6595 - val_accuracy: 0.5513\n",
      "Epoch 2967/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6487 - val_loss: 0.6521 - val_accuracy: 0.5627\n",
      "Epoch 2968/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6128 - accuracy: 0.6482 - val_loss: 0.6612 - val_accuracy: 0.5486\n",
      "Epoch 2969/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6128 - accuracy: 0.6481 - val_loss: 0.6489 - val_accuracy: 0.5683\n",
      "Epoch 2970/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6130 - accuracy: 0.6472 - val_loss: 0.6697 - val_accuracy: 0.5365\n",
      "Epoch 2971/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6485 - val_loss: 0.6443 - val_accuracy: 0.5734\n",
      "Epoch 2972/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6134 - accuracy: 0.6470 - val_loss: 0.6739 - val_accuracy: 0.5322\n",
      "Epoch 2973/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6139 - accuracy: 0.6471 - val_loss: 0.6374 - val_accuracy: 0.5886\n",
      "Epoch 2974/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6144 - accuracy: 0.6458 - val_loss: 0.6850 - val_accuracy: 0.5205\n",
      "Epoch 2975/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6151 - accuracy: 0.6464 - val_loss: 0.6360 - val_accuracy: 0.5862\n",
      "Epoch 2976/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6151 - accuracy: 0.6446 - val_loss: 0.6817 - val_accuracy: 0.5237\n",
      "Epoch 2977/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6153 - accuracy: 0.6461 - val_loss: 0.6353 - val_accuracy: 0.5915\n",
      "Epoch 2978/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6147 - accuracy: 0.6452 - val_loss: 0.6753 - val_accuracy: 0.5285\n",
      "Epoch 2979/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6136 - accuracy: 0.6477 - val_loss: 0.6512 - val_accuracy: 0.5658\n",
      "Epoch 2980/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6135 - accuracy: 0.6468 - val_loss: 0.6593 - val_accuracy: 0.5522\n",
      "Epoch 2981/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6491 - val_loss: 0.6532 - val_accuracy: 0.5623\n",
      "Epoch 2982/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6131 - accuracy: 0.6487 - val_loss: 0.6553 - val_accuracy: 0.5583\n",
      "Epoch 2983/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6125 - accuracy: 0.6485 - val_loss: 0.6646 - val_accuracy: 0.5417\n",
      "Epoch 2984/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6131 - accuracy: 0.6481 - val_loss: 0.6525 - val_accuracy: 0.5641\n",
      "Epoch 2985/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6125 - accuracy: 0.6484 - val_loss: 0.6577 - val_accuracy: 0.5566\n",
      "Epoch 2986/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6129 - accuracy: 0.6486 - val_loss: 0.6519 - val_accuracy: 0.5638\n",
      "Epoch 2987/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6124 - accuracy: 0.6484 - val_loss: 0.6619 - val_accuracy: 0.5484\n",
      "Epoch 2988/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6128 - accuracy: 0.6484 - val_loss: 0.6570 - val_accuracy: 0.5566\n",
      "Epoch 2989/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6489 - val_loss: 0.6535 - val_accuracy: 0.5619\n",
      "Epoch 2990/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6126 - accuracy: 0.6483 - val_loss: 0.6588 - val_accuracy: 0.5532\n",
      "Epoch 2991/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6124 - accuracy: 0.6492 - val_loss: 0.6528 - val_accuracy: 0.5621\n",
      "Epoch 2992/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6126 - accuracy: 0.6479 - val_loss: 0.6675 - val_accuracy: 0.5387\n",
      "Epoch 2993/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6127 - accuracy: 0.6486 - val_loss: 0.6428 - val_accuracy: 0.5784\n",
      "Epoch 2994/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6131 - accuracy: 0.6473 - val_loss: 0.6745 - val_accuracy: 0.5292\n",
      "Epoch 2995/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6137 - accuracy: 0.6480 - val_loss: 0.6379 - val_accuracy: 0.5828\n",
      "Epoch 2996/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6142 - accuracy: 0.6455 - val_loss: 0.6874 - val_accuracy: 0.5142\n",
      "Epoch 2997/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6459 - val_loss: 0.6300 - val_accuracy: 0.6012\n",
      "Epoch 2998/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6158 - accuracy: 0.6443 - val_loss: 0.6916 - val_accuracy: 0.5119\n",
      "Epoch 2999/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6168 - accuracy: 0.6443 - val_loss: 0.6356 - val_accuracy: 0.5857\n",
      "Epoch 3000/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6151 - accuracy: 0.6447 - val_loss: 0.6723 - val_accuracy: 0.5322\n",
      "Epoch 3001/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6136 - accuracy: 0.6490 - val_loss: 0.6518 - val_accuracy: 0.5674\n",
      "Epoch 3002/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6133 - accuracy: 0.6470 - val_loss: 0.6536 - val_accuracy: 0.5585\n",
      "Epoch 3003/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6125 - accuracy: 0.6494 - val_loss: 0.6624 - val_accuracy: 0.5460\n",
      "Epoch 3004/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6470 - val_loss: 0.6501 - val_accuracy: 0.5661\n",
      "Epoch 3005/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6127 - accuracy: 0.6481 - val_loss: 0.6678 - val_accuracy: 0.5418\n",
      "Epoch 3006/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6132 - accuracy: 0.6491 - val_loss: 0.6459 - val_accuracy: 0.5705\n",
      "Epoch 3007/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6483 - val_loss: 0.6666 - val_accuracy: 0.5395\n",
      "Epoch 3008/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6132 - accuracy: 0.6468 - val_loss: 0.6468 - val_accuracy: 0.5698\n",
      "Epoch 3009/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6128 - accuracy: 0.6484 - val_loss: 0.6678 - val_accuracy: 0.5427\n",
      "Epoch 3010/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6129 - accuracy: 0.6490 - val_loss: 0.6483 - val_accuracy: 0.5691\n",
      "Epoch 3011/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6126 - accuracy: 0.6482 - val_loss: 0.6637 - val_accuracy: 0.5435\n",
      "Epoch 3012/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6128 - accuracy: 0.6476 - val_loss: 0.6471 - val_accuracy: 0.5700\n",
      "Epoch 3013/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6127 - accuracy: 0.6481 - val_loss: 0.6698 - val_accuracy: 0.5396\n",
      "Epoch 3014/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6129 - accuracy: 0.6492 - val_loss: 0.6464 - val_accuracy: 0.5733\n",
      "Epoch 3015/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6128 - accuracy: 0.6473 - val_loss: 0.6693 - val_accuracy: 0.5376\n",
      "Epoch 3016/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6133 - accuracy: 0.6472 - val_loss: 0.6399 - val_accuracy: 0.5813\n",
      "Epoch 3017/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6133 - accuracy: 0.6467 - val_loss: 0.6794 - val_accuracy: 0.5248\n",
      "Epoch 3018/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6140 - accuracy: 0.6478 - val_loss: 0.6389 - val_accuracy: 0.5842\n",
      "Epoch 3019/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6143 - accuracy: 0.6462 - val_loss: 0.6839 - val_accuracy: 0.5194\n",
      "Epoch 3020/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6154 - accuracy: 0.6449 - val_loss: 0.6318 - val_accuracy: 0.5963\n",
      "Epoch 3021/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6152 - accuracy: 0.6428 - val_loss: 0.6852 - val_accuracy: 0.5152\n",
      "Epoch 3022/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6152 - accuracy: 0.6464 - val_loss: 0.6400 - val_accuracy: 0.5842\n",
      "Epoch 3023/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6152 - accuracy: 0.6457 - val_loss: 0.6773 - val_accuracy: 0.5274\n",
      "Epoch 3024/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6146 - accuracy: 0.6456 - val_loss: 0.6393 - val_accuracy: 0.5811\n",
      "Epoch 3025/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6154 - accuracy: 0.6426 - val_loss: 0.6746 - val_accuracy: 0.5316\n",
      "Epoch 3026/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6138 - accuracy: 0.6478 - val_loss: 0.6437 - val_accuracy: 0.5776\n",
      "Epoch 3027/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6162 - accuracy: 0.6452 - val_loss: 0.6828 - val_accuracy: 0.5208\n",
      "Epoch 3028/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6152 - accuracy: 0.6447 - val_loss: 0.6296 - val_accuracy: 0.5976\n",
      "Epoch 3029/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6195 - accuracy: 0.6388 - val_loss: 0.7009 - val_accuracy: 0.4962\n",
      "Epoch 3030/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6192 - accuracy: 0.6405 - val_loss: 0.6272 - val_accuracy: 0.6140\n",
      "Epoch 3031/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6231 - accuracy: 0.6365 - val_loss: 0.7028 - val_accuracy: 0.4987\n",
      "Epoch 3032/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6199 - accuracy: 0.6401 - val_loss: 0.6364 - val_accuracy: 0.5842\n",
      "Epoch 3033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6245 - accuracy: 0.6341 - val_loss: 0.6824 - val_accuracy: 0.5201\n",
      "Epoch 3034/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6381 - val_accuracy: 0.5912\n",
      "Epoch 3035/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6207 - accuracy: 0.6408 - val_loss: 0.6803 - val_accuracy: 0.5185\n",
      "Epoch 3036/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6159 - accuracy: 0.6461 - val_loss: 0.6379 - val_accuracy: 0.5765\n",
      "Epoch 3037/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6163 - accuracy: 0.6422 - val_loss: 0.6704 - val_accuracy: 0.5325\n",
      "Epoch 3038/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6146 - accuracy: 0.6452 - val_loss: 0.6527 - val_accuracy: 0.5608\n",
      "Epoch 3039/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6131 - accuracy: 0.6478 - val_loss: 0.6473 - val_accuracy: 0.5707\n",
      "Epoch 3040/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6143 - accuracy: 0.6470 - val_loss: 0.6820 - val_accuracy: 0.5164\n",
      "Epoch 3041/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6150 - accuracy: 0.6465 - val_loss: 0.6290 - val_accuracy: 0.5990\n",
      "Epoch 3042/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6175 - accuracy: 0.6414 - val_loss: 0.6898 - val_accuracy: 0.5115\n",
      "Epoch 3043/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6173 - accuracy: 0.6429 - val_loss: 0.6367 - val_accuracy: 0.5873\n",
      "Epoch 3044/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6165 - accuracy: 0.6436 - val_loss: 0.6611 - val_accuracy: 0.5460\n",
      "Epoch 3045/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6126 - accuracy: 0.6484 - val_loss: 0.6656 - val_accuracy: 0.5365\n",
      "Epoch 3046/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6149 - accuracy: 0.6444 - val_loss: 0.6441 - val_accuracy: 0.5736\n",
      "Epoch 3047/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6129 - accuracy: 0.6484 - val_loss: 0.6678 - val_accuracy: 0.5393\n",
      "Epoch 3048/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6143 - accuracy: 0.6470 - val_loss: 0.6480 - val_accuracy: 0.5705\n",
      "Epoch 3049/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6138 - accuracy: 0.6478 - val_loss: 0.6590 - val_accuracy: 0.5475\n",
      "Epoch 3050/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6128 - accuracy: 0.6473 - val_loss: 0.6585 - val_accuracy: 0.5469\n",
      "Epoch 3051/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6138 - accuracy: 0.6453 - val_loss: 0.6575 - val_accuracy: 0.5561\n",
      "Epoch 3052/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6123 - accuracy: 0.6488 - val_loss: 0.6561 - val_accuracy: 0.5590\n",
      "Epoch 3053/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6132 - accuracy: 0.6478 - val_loss: 0.6568 - val_accuracy: 0.5583\n",
      "Epoch 3054/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6123 - accuracy: 0.6488 - val_loss: 0.6512 - val_accuracy: 0.5625\n",
      "Epoch 3055/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6132 - accuracy: 0.6475 - val_loss: 0.6668 - val_accuracy: 0.5404\n",
      "Epoch 3056/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6125 - accuracy: 0.6486 - val_loss: 0.6453 - val_accuracy: 0.5764\n",
      "Epoch 3057/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6133 - accuracy: 0.6477 - val_loss: 0.6724 - val_accuracy: 0.5316\n",
      "Epoch 3058/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6132 - accuracy: 0.6479 - val_loss: 0.6422 - val_accuracy: 0.5773\n",
      "Epoch 3059/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6135 - accuracy: 0.6455 - val_loss: 0.6728 - val_accuracy: 0.5298\n",
      "Epoch 3060/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6129 - accuracy: 0.6488 - val_loss: 0.6454 - val_accuracy: 0.5765\n",
      "Epoch 3061/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6130 - accuracy: 0.6466 - val_loss: 0.6702 - val_accuracy: 0.5376\n",
      "Epoch 3062/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6128 - accuracy: 0.6482 - val_loss: 0.6434 - val_accuracy: 0.5740\n",
      "Epoch 3063/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6131 - accuracy: 0.6468 - val_loss: 0.6709 - val_accuracy: 0.5347\n",
      "Epoch 3064/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6125 - accuracy: 0.6489 - val_loss: 0.6486 - val_accuracy: 0.5725\n",
      "Epoch 3065/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6128 - accuracy: 0.6474 - val_loss: 0.6683 - val_accuracy: 0.5389\n",
      "Epoch 3066/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6493 - val_loss: 0.6437 - val_accuracy: 0.5756\n",
      "Epoch 3067/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6128 - accuracy: 0.6468 - val_loss: 0.6683 - val_accuracy: 0.5385\n",
      "Epoch 3068/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6487 - val_loss: 0.6481 - val_accuracy: 0.5738\n",
      "Epoch 3069/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6127 - accuracy: 0.6473 - val_loss: 0.6715 - val_accuracy: 0.5358\n",
      "Epoch 3070/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6126 - accuracy: 0.6490 - val_loss: 0.6406 - val_accuracy: 0.5778\n",
      "Epoch 3071/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6129 - accuracy: 0.6463 - val_loss: 0.6736 - val_accuracy: 0.5305\n",
      "Epoch 3072/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6129 - accuracy: 0.6486 - val_loss: 0.6422 - val_accuracy: 0.5791\n",
      "Epoch 3073/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6132 - accuracy: 0.6470 - val_loss: 0.6776 - val_accuracy: 0.5269\n",
      "Epoch 3074/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6133 - accuracy: 0.6482 - val_loss: 0.6384 - val_accuracy: 0.5822\n",
      "Epoch 3075/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6133 - accuracy: 0.6459 - val_loss: 0.6765 - val_accuracy: 0.5259\n",
      "Epoch 3076/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6133 - accuracy: 0.6486 - val_loss: 0.6425 - val_accuracy: 0.5782\n",
      "Epoch 3077/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6131 - accuracy: 0.6474 - val_loss: 0.6738 - val_accuracy: 0.5312\n",
      "Epoch 3078/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6129 - accuracy: 0.6488 - val_loss: 0.6424 - val_accuracy: 0.5758\n",
      "Epoch 3079/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6128 - accuracy: 0.6466 - val_loss: 0.6694 - val_accuracy: 0.5376\n",
      "Epoch 3080/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6126 - accuracy: 0.6495 - val_loss: 0.6465 - val_accuracy: 0.5742\n",
      "Epoch 3081/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6480 - val_loss: 0.6690 - val_accuracy: 0.5395\n",
      "Epoch 3082/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6123 - accuracy: 0.6491 - val_loss: 0.6478 - val_accuracy: 0.5678\n",
      "Epoch 3083/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6123 - accuracy: 0.6481 - val_loss: 0.6636 - val_accuracy: 0.5471\n",
      "Epoch 3084/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6122 - accuracy: 0.6490 - val_loss: 0.6493 - val_accuracy: 0.5689\n",
      "Epoch 3085/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6123 - accuracy: 0.6480 - val_loss: 0.6660 - val_accuracy: 0.5442\n",
      "Epoch 3086/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6120 - accuracy: 0.6496 - val_loss: 0.6503 - val_accuracy: 0.5654\n",
      "Epoch 3087/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6122 - accuracy: 0.6485 - val_loss: 0.6649 - val_accuracy: 0.5451\n",
      "Epoch 3088/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6122 - accuracy: 0.6493 - val_loss: 0.6468 - val_accuracy: 0.5727\n",
      "Epoch 3089/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6479 - val_loss: 0.6700 - val_accuracy: 0.5385\n",
      "Epoch 3090/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6123 - accuracy: 0.6491 - val_loss: 0.6455 - val_accuracy: 0.5731\n",
      "Epoch 3091/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6127 - accuracy: 0.6472 - val_loss: 0.6723 - val_accuracy: 0.5327\n",
      "Epoch 3092/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6129 - accuracy: 0.6490 - val_loss: 0.6388 - val_accuracy: 0.5888\n",
      "Epoch 3093/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6483 - val_loss: 0.6830 - val_accuracy: 0.5216\n",
      "Epoch 3094/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6141 - accuracy: 0.6466 - val_loss: 0.6369 - val_accuracy: 0.5853\n",
      "Epoch 3095/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6148 - accuracy: 0.6449 - val_loss: 0.6856 - val_accuracy: 0.5185\n",
      "Epoch 3096/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6154 - accuracy: 0.6459 - val_loss: 0.6307 - val_accuracy: 0.6012\n",
      "Epoch 3097/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6159 - accuracy: 0.6440 - val_loss: 0.6854 - val_accuracy: 0.5159\n",
      "Epoch 3098/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6146 - accuracy: 0.6458 - val_loss: 0.6435 - val_accuracy: 0.5734\n",
      "Epoch 3099/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6157 - accuracy: 0.6443 - val_loss: 0.6729 - val_accuracy: 0.5334\n",
      "Epoch 3100/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6135 - accuracy: 0.6492 - val_loss: 0.6419 - val_accuracy: 0.5820\n",
      "Epoch 3101/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6154 - accuracy: 0.6469 - val_loss: 0.6722 - val_accuracy: 0.5343\n",
      "Epoch 3102/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6127 - accuracy: 0.6488 - val_loss: 0.6423 - val_accuracy: 0.5753\n",
      "Epoch 3103/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6167 - accuracy: 0.6438 - val_loss: 0.6902 - val_accuracy: 0.5121\n",
      "Epoch 3104/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6157 - accuracy: 0.6447 - val_loss: 0.6256 - val_accuracy: 0.6105\n",
      "Epoch 3105/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6190 - accuracy: 0.6403 - val_loss: 0.6985 - val_accuracy: 0.5031\n",
      "Epoch 3106/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6179 - accuracy: 0.6421 - val_loss: 0.6374 - val_accuracy: 0.5831\n",
      "Epoch 3107/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6183 - accuracy: 0.6419 - val_loss: 0.6707 - val_accuracy: 0.5323\n",
      "Epoch 3108/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6128 - accuracy: 0.6492 - val_loss: 0.6511 - val_accuracy: 0.5670\n",
      "Epoch 3109/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6151 - accuracy: 0.6474 - val_loss: 0.6572 - val_accuracy: 0.5570\n",
      "Epoch 3110/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6120 - accuracy: 0.6494 - val_loss: 0.6544 - val_accuracy: 0.5588\n",
      "Epoch 3111/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6141 - accuracy: 0.6462 - val_loss: 0.6687 - val_accuracy: 0.5373\n",
      "Epoch 3112/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6481 - val_loss: 0.6442 - val_accuracy: 0.5764\n",
      "Epoch 3113/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6134 - accuracy: 0.6477 - val_loss: 0.6738 - val_accuracy: 0.5300\n",
      "Epoch 3114/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6134 - accuracy: 0.6487 - val_loss: 0.6383 - val_accuracy: 0.5826\n",
      "Epoch 3115/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6132 - accuracy: 0.6464 - val_loss: 0.6735 - val_accuracy: 0.5296\n",
      "Epoch 3116/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6129 - accuracy: 0.6479 - val_loss: 0.6474 - val_accuracy: 0.5683\n",
      "Epoch 3117/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6480 - val_loss: 0.6603 - val_accuracy: 0.5533\n",
      "Epoch 3118/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6118 - accuracy: 0.6497 - val_loss: 0.6579 - val_accuracy: 0.5552\n",
      "Epoch 3119/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6117 - accuracy: 0.6495 - val_loss: 0.6469 - val_accuracy: 0.5714\n",
      "Epoch 3120/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6121 - accuracy: 0.6490 - val_loss: 0.6740 - val_accuracy: 0.5289\n",
      "Epoch 3121/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6125 - accuracy: 0.6487 - val_loss: 0.6404 - val_accuracy: 0.5822\n",
      "Epoch 3122/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6131 - accuracy: 0.6477 - val_loss: 0.6787 - val_accuracy: 0.5254\n",
      "Epoch 3123/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6133 - accuracy: 0.6482 - val_loss: 0.6379 - val_accuracy: 0.5855\n",
      "Epoch 3124/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6131 - accuracy: 0.6461 - val_loss: 0.6742 - val_accuracy: 0.5285\n",
      "Epoch 3125/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6127 - accuracy: 0.6490 - val_loss: 0.6458 - val_accuracy: 0.5725\n",
      "Epoch 3126/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6122 - accuracy: 0.6483 - val_loss: 0.6646 - val_accuracy: 0.5480\n",
      "Epoch 3127/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6117 - accuracy: 0.6507 - val_loss: 0.6546 - val_accuracy: 0.5601\n",
      "Epoch 3128/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6115 - accuracy: 0.6503 - val_loss: 0.6522 - val_accuracy: 0.5652\n",
      "Epoch 3129/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6493 - val_loss: 0.6662 - val_accuracy: 0.5435\n",
      "Epoch 3130/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6117 - accuracy: 0.6501 - val_loss: 0.6469 - val_accuracy: 0.5696\n",
      "Epoch 3131/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6120 - accuracy: 0.6486 - val_loss: 0.6726 - val_accuracy: 0.5320\n",
      "Epoch 3132/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6123 - accuracy: 0.6491 - val_loss: 0.6398 - val_accuracy: 0.5846\n",
      "Epoch 3133/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6125 - accuracy: 0.6471 - val_loss: 0.6776 - val_accuracy: 0.5263\n",
      "Epoch 3134/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6129 - accuracy: 0.6486 - val_loss: 0.6389 - val_accuracy: 0.5839\n",
      "Epoch 3135/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6130 - accuracy: 0.6470 - val_loss: 0.6792 - val_accuracy: 0.5261\n",
      "Epoch 3136/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6131 - accuracy: 0.6480 - val_loss: 0.6393 - val_accuracy: 0.5811\n",
      "Epoch 3137/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6126 - accuracy: 0.6476 - val_loss: 0.6730 - val_accuracy: 0.5322\n",
      "Epoch 3138/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6123 - accuracy: 0.6500 - val_loss: 0.6443 - val_accuracy: 0.5749\n",
      "Epoch 3139/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6120 - accuracy: 0.6479 - val_loss: 0.6683 - val_accuracy: 0.5395\n",
      "Epoch 3140/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6117 - accuracy: 0.6492 - val_loss: 0.6506 - val_accuracy: 0.5667\n",
      "Epoch 3141/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6115 - accuracy: 0.6494 - val_loss: 0.6597 - val_accuracy: 0.5561\n",
      "Epoch 3142/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6113 - accuracy: 0.6503 - val_loss: 0.6550 - val_accuracy: 0.5621\n",
      "Epoch 3143/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6113 - accuracy: 0.6497 - val_loss: 0.6556 - val_accuracy: 0.5590\n",
      "Epoch 3144/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6113 - accuracy: 0.6496 - val_loss: 0.6617 - val_accuracy: 0.5482\n",
      "Epoch 3145/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6113 - accuracy: 0.6501 - val_loss: 0.6508 - val_accuracy: 0.5698\n",
      "Epoch 3146/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6114 - accuracy: 0.6494 - val_loss: 0.6660 - val_accuracy: 0.5438\n",
      "Epoch 3147/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6505 - val_loss: 0.6448 - val_accuracy: 0.5740\n",
      "Epoch 3148/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6118 - accuracy: 0.6486 - val_loss: 0.6739 - val_accuracy: 0.5320\n",
      "Epoch 3149/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6498 - val_loss: 0.6384 - val_accuracy: 0.5853\n",
      "Epoch 3150/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6127 - accuracy: 0.6473 - val_loss: 0.6850 - val_accuracy: 0.5199\n",
      "Epoch 3151/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6139 - accuracy: 0.6469 - val_loss: 0.6322 - val_accuracy: 0.5965\n",
      "Epoch 3152/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6141 - accuracy: 0.6447 - val_loss: 0.6894 - val_accuracy: 0.5135\n",
      "Epoch 3153/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6149 - accuracy: 0.6454 - val_loss: 0.6330 - val_accuracy: 0.5944\n",
      "Epoch 3154/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6137 - accuracy: 0.6466 - val_loss: 0.6806 - val_accuracy: 0.5248\n",
      "Epoch 3155/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6131 - accuracy: 0.6484 - val_loss: 0.6428 - val_accuracy: 0.5760\n",
      "Epoch 3156/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6121 - accuracy: 0.6486 - val_loss: 0.6674 - val_accuracy: 0.5420\n",
      "Epoch 3157/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6115 - accuracy: 0.6507 - val_loss: 0.6506 - val_accuracy: 0.5685\n",
      "Epoch 3158/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6112 - accuracy: 0.6497 - val_loss: 0.6578 - val_accuracy: 0.5557\n",
      "Epoch 3159/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6111 - accuracy: 0.6500 - val_loss: 0.6598 - val_accuracy: 0.5537\n",
      "Epoch 3160/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6111 - accuracy: 0.6504 - val_loss: 0.6512 - val_accuracy: 0.5683\n",
      "Epoch 3161/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6112 - accuracy: 0.6496 - val_loss: 0.6664 - val_accuracy: 0.5429\n",
      "Epoch 3162/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6114 - accuracy: 0.6505 - val_loss: 0.6436 - val_accuracy: 0.5764\n",
      "Epoch 3163/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6118 - accuracy: 0.6489 - val_loss: 0.6757 - val_accuracy: 0.5283\n",
      "Epoch 3164/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6491 - val_loss: 0.6368 - val_accuracy: 0.5877\n",
      "Epoch 3165/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6129 - accuracy: 0.6473 - val_loss: 0.6854 - val_accuracy: 0.5181\n",
      "Epoch 3166/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6139 - accuracy: 0.6470 - val_loss: 0.6320 - val_accuracy: 0.5972\n",
      "Epoch 3167/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6140 - accuracy: 0.6451 - val_loss: 0.6881 - val_accuracy: 0.5157\n",
      "Epoch 3168/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6145 - accuracy: 0.6458 - val_loss: 0.6343 - val_accuracy: 0.5937\n",
      "Epoch 3169/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6133 - accuracy: 0.6466 - val_loss: 0.6769 - val_accuracy: 0.5263\n",
      "Epoch 3170/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6125 - accuracy: 0.6492 - val_loss: 0.6461 - val_accuracy: 0.5707\n",
      "Epoch 3171/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6115 - accuracy: 0.6490 - val_loss: 0.6612 - val_accuracy: 0.5522\n",
      "Epoch 3172/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6111 - accuracy: 0.6505 - val_loss: 0.6560 - val_accuracy: 0.5596\n",
      "Epoch 3173/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6109 - accuracy: 0.6502 - val_loss: 0.6523 - val_accuracy: 0.5665\n",
      "Epoch 3174/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6501 - val_loss: 0.6676 - val_accuracy: 0.5398\n",
      "Epoch 3175/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6113 - accuracy: 0.6507 - val_loss: 0.6429 - val_accuracy: 0.5760\n",
      "Epoch 3176/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6118 - accuracy: 0.6486 - val_loss: 0.6765 - val_accuracy: 0.5289\n",
      "Epoch 3177/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6125 - accuracy: 0.6495 - val_loss: 0.6355 - val_accuracy: 0.5888\n",
      "Epoch 3178/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6129 - accuracy: 0.6460 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
      "Epoch 3179/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6138 - accuracy: 0.6469 - val_loss: 0.6337 - val_accuracy: 0.5935\n",
      "Epoch 3180/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6136 - accuracy: 0.6462 - val_loss: 0.6844 - val_accuracy: 0.5203\n",
      "Epoch 3181/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6137 - accuracy: 0.6476 - val_loss: 0.6366 - val_accuracy: 0.5870\n",
      "Epoch 3182/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6127 - accuracy: 0.6470 - val_loss: 0.6747 - val_accuracy: 0.5285\n",
      "Epoch 3183/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6121 - accuracy: 0.6498 - val_loss: 0.6459 - val_accuracy: 0.5718\n",
      "Epoch 3184/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6114 - accuracy: 0.6492 - val_loss: 0.6631 - val_accuracy: 0.5488\n",
      "Epoch 3185/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6110 - accuracy: 0.6505 - val_loss: 0.6547 - val_accuracy: 0.5638\n",
      "Epoch 3186/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6108 - accuracy: 0.6505 - val_loss: 0.6542 - val_accuracy: 0.5623\n",
      "Epoch 3187/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6108 - accuracy: 0.6502 - val_loss: 0.6648 - val_accuracy: 0.5459\n",
      "Epoch 3188/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6507 - val_loss: 0.6457 - val_accuracy: 0.5734\n",
      "Epoch 3189/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6113 - accuracy: 0.6496 - val_loss: 0.6737 - val_accuracy: 0.5316\n",
      "Epoch 3190/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6119 - accuracy: 0.6499 - val_loss: 0.6377 - val_accuracy: 0.5870\n",
      "Epoch 3191/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6124 - accuracy: 0.6475 - val_loss: 0.6846 - val_accuracy: 0.5206\n",
      "Epoch 3192/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6136 - accuracy: 0.6477 - val_loss: 0.6324 - val_accuracy: 0.5972\n",
      "Epoch 3193/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6138 - accuracy: 0.6457 - val_loss: 0.6895 - val_accuracy: 0.5135\n",
      "Epoch 3194/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6147 - accuracy: 0.6456 - val_loss: 0.6320 - val_accuracy: 0.5957\n",
      "Epoch 3195/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6135 - accuracy: 0.6465 - val_loss: 0.6803 - val_accuracy: 0.5245\n",
      "Epoch 3196/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6129 - accuracy: 0.6482 - val_loss: 0.6430 - val_accuracy: 0.5753\n",
      "Epoch 3197/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6118 - accuracy: 0.6487 - val_loss: 0.6666 - val_accuracy: 0.5429\n",
      "Epoch 3198/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6111 - accuracy: 0.6505 - val_loss: 0.6518 - val_accuracy: 0.5674\n",
      "Epoch 3199/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6501 - val_loss: 0.6554 - val_accuracy: 0.5627\n",
      "Epoch 3200/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6107 - accuracy: 0.6504 - val_loss: 0.6630 - val_accuracy: 0.5475\n",
      "Epoch 3201/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6108 - accuracy: 0.6507 - val_loss: 0.6484 - val_accuracy: 0.5711\n",
      "Epoch 3202/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6111 - accuracy: 0.6492 - val_loss: 0.6707 - val_accuracy: 0.5345\n",
      "Epoch 3203/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6115 - accuracy: 0.6497 - val_loss: 0.6390 - val_accuracy: 0.5839\n",
      "Epoch 3204/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6121 - accuracy: 0.6476 - val_loss: 0.6826 - val_accuracy: 0.5221\n",
      "Epoch 3205/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6131 - accuracy: 0.6483 - val_loss: 0.6338 - val_accuracy: 0.5939\n",
      "Epoch 3206/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6133 - accuracy: 0.6461 - val_loss: 0.6872 - val_accuracy: 0.5161\n",
      "Epoch 3207/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6142 - accuracy: 0.6464 - val_loss: 0.6324 - val_accuracy: 0.5954\n",
      "Epoch 3208/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6134 - accuracy: 0.6458 - val_loss: 0.6825 - val_accuracy: 0.5217\n",
      "Epoch 3209/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6130 - accuracy: 0.6484 - val_loss: 0.6415 - val_accuracy: 0.5778\n",
      "Epoch 3210/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6118 - accuracy: 0.6486 - val_loss: 0.6671 - val_accuracy: 0.5400\n",
      "Epoch 3211/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6113 - accuracy: 0.6494 - val_loss: 0.6498 - val_accuracy: 0.5696\n",
      "Epoch 3212/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6502 - val_loss: 0.6596 - val_accuracy: 0.5533\n",
      "Epoch 3213/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6107 - accuracy: 0.6505 - val_loss: 0.6608 - val_accuracy: 0.5530\n",
      "Epoch 3214/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6106 - accuracy: 0.6507 - val_loss: 0.6475 - val_accuracy: 0.5725\n",
      "Epoch 3215/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6109 - accuracy: 0.6501 - val_loss: 0.6702 - val_accuracy: 0.5365\n",
      "Epoch 3216/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6114 - accuracy: 0.6498 - val_loss: 0.6401 - val_accuracy: 0.5800\n",
      "Epoch 3217/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6121 - accuracy: 0.6479 - val_loss: 0.6842 - val_accuracy: 0.5214\n",
      "Epoch 3218/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6135 - accuracy: 0.6478 - val_loss: 0.6300 - val_accuracy: 0.6012\n",
      "Epoch 3219/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6140 - accuracy: 0.6447 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 3220/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6150 - accuracy: 0.6458 - val_loss: 0.6341 - val_accuracy: 0.5926\n",
      "Epoch 3221/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6133 - accuracy: 0.6461 - val_loss: 0.6763 - val_accuracy: 0.5281\n",
      "Epoch 3222/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6125 - accuracy: 0.6495 - val_loss: 0.6447 - val_accuracy: 0.5747\n",
      "Epoch 3223/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6112 - accuracy: 0.6491 - val_loss: 0.6605 - val_accuracy: 0.5532\n",
      "Epoch 3224/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6109 - accuracy: 0.6506 - val_loss: 0.6628 - val_accuracy: 0.5480\n",
      "Epoch 3225/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6107 - accuracy: 0.6509 - val_loss: 0.6434 - val_accuracy: 0.5776\n",
      "Epoch 3226/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6491 - val_loss: 0.6793 - val_accuracy: 0.5237\n",
      "Epoch 3227/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6125 - accuracy: 0.6486 - val_loss: 0.6335 - val_accuracy: 0.5930\n",
      "Epoch 3228/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6140 - accuracy: 0.6457 - val_loss: 0.6956 - val_accuracy: 0.5077\n",
      "Epoch 3229/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6160 - accuracy: 0.6440 - val_loss: 0.6263 - val_accuracy: 0.6083\n",
      "Epoch 3230/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6148 - accuracy: 0.6445 - val_loss: 0.6845 - val_accuracy: 0.5183\n",
      "Epoch 3231/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6134 - accuracy: 0.6466 - val_loss: 0.6474 - val_accuracy: 0.5680\n",
      "Epoch 3232/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6114 - accuracy: 0.6489 - val_loss: 0.6529 - val_accuracy: 0.5652\n",
      "Epoch 3233/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6109 - accuracy: 0.6498 - val_loss: 0.6692 - val_accuracy: 0.5360\n",
      "Epoch 3234/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6116 - accuracy: 0.6500 - val_loss: 0.6357 - val_accuracy: 0.5891\n",
      "Epoch 3235/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6132 - accuracy: 0.6458 - val_loss: 0.6961 - val_accuracy: 0.5038\n",
      "Epoch 3236/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6157 - accuracy: 0.6440 - val_loss: 0.6269 - val_accuracy: 0.6067\n",
      "Epoch 3237/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6152 - accuracy: 0.6433 - val_loss: 0.6904 - val_accuracy: 0.5124\n",
      "Epoch 3238/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6147 - accuracy: 0.6459 - val_loss: 0.6384 - val_accuracy: 0.5813\n",
      "Epoch 3239/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6121 - accuracy: 0.6477 - val_loss: 0.6584 - val_accuracy: 0.5561\n",
      "Epoch 3240/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6107 - accuracy: 0.6503 - val_loss: 0.6658 - val_accuracy: 0.5427\n",
      "Epoch 3241/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6109 - accuracy: 0.6510 - val_loss: 0.6383 - val_accuracy: 0.5828\n",
      "Epoch 3242/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6477 - val_loss: 0.6900 - val_accuracy: 0.5122\n",
      "Epoch 3243/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6146 - accuracy: 0.6451 - val_loss: 0.6287 - val_accuracy: 0.6018\n",
      "Epoch 3244/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6142 - accuracy: 0.6451 - val_loss: 0.6871 - val_accuracy: 0.5137\n",
      "Epoch 3245/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6139 - accuracy: 0.6464 - val_loss: 0.6396 - val_accuracy: 0.5804\n",
      "Epoch 3246/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6119 - accuracy: 0.6483 - val_loss: 0.6619 - val_accuracy: 0.5502\n",
      "Epoch 3247/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6108 - accuracy: 0.6502 - val_loss: 0.6603 - val_accuracy: 0.5543\n",
      "Epoch 3248/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6106 - accuracy: 0.6508 - val_loss: 0.6420 - val_accuracy: 0.5771\n",
      "Epoch 3249/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6494 - val_loss: 0.6840 - val_accuracy: 0.5186\n",
      "Epoch 3250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6477 - val_loss: 0.6310 - val_accuracy: 0.5974\n",
      "Epoch 3251/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6138 - accuracy: 0.6449 - val_loss: 0.6893 - val_accuracy: 0.5111\n",
      "Epoch 3252/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6144 - accuracy: 0.6455 - val_loss: 0.6351 - val_accuracy: 0.5901\n",
      "Epoch 3253/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6471 - val_loss: 0.6699 - val_accuracy: 0.5349\n",
      "Epoch 3254/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6113 - accuracy: 0.6503 - val_loss: 0.6548 - val_accuracy: 0.5623\n",
      "Epoch 3255/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6502 - val_loss: 0.6458 - val_accuracy: 0.5727\n",
      "Epoch 3256/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6109 - accuracy: 0.6501 - val_loss: 0.6773 - val_accuracy: 0.5267\n",
      "Epoch 3257/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6121 - accuracy: 0.6490 - val_loss: 0.6329 - val_accuracy: 0.5955\n",
      "Epoch 3258/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6133 - accuracy: 0.6454 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
      "Epoch 3259/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6150 - accuracy: 0.6450 - val_loss: 0.6320 - val_accuracy: 0.5948\n",
      "Epoch 3260/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6134 - accuracy: 0.6455 - val_loss: 0.6770 - val_accuracy: 0.5283\n",
      "Epoch 3261/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6120 - accuracy: 0.6493 - val_loss: 0.6486 - val_accuracy: 0.5707\n",
      "Epoch 3262/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6106 - accuracy: 0.6496 - val_loss: 0.6498 - val_accuracy: 0.5674\n",
      "Epoch 3263/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6105 - accuracy: 0.6501 - val_loss: 0.6734 - val_accuracy: 0.5320\n",
      "Epoch 3264/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6114 - accuracy: 0.6505 - val_loss: 0.6360 - val_accuracy: 0.5895\n",
      "Epoch 3265/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6126 - accuracy: 0.6475 - val_loss: 0.6891 - val_accuracy: 0.5119\n",
      "Epoch 3266/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6142 - accuracy: 0.6462 - val_loss: 0.6314 - val_accuracy: 0.5963\n",
      "Epoch 3267/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6134 - accuracy: 0.6449 - val_loss: 0.6812 - val_accuracy: 0.5221\n",
      "Epoch 3268/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6125 - accuracy: 0.6482 - val_loss: 0.6457 - val_accuracy: 0.5723\n",
      "Epoch 3269/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6109 - accuracy: 0.6490 - val_loss: 0.6557 - val_accuracy: 0.5601\n",
      "Epoch 3270/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6103 - accuracy: 0.6506 - val_loss: 0.6654 - val_accuracy: 0.5433\n",
      "Epoch 3271/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6107 - accuracy: 0.6508 - val_loss: 0.6401 - val_accuracy: 0.5809\n",
      "Epoch 3272/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6117 - accuracy: 0.6487 - val_loss: 0.6852 - val_accuracy: 0.5172\n",
      "Epoch 3273/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6131 - accuracy: 0.6474 - val_loss: 0.6332 - val_accuracy: 0.5928\n",
      "Epoch 3274/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6455 - val_loss: 0.6831 - val_accuracy: 0.5195\n",
      "Epoch 3275/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6129 - accuracy: 0.6481 - val_loss: 0.6404 - val_accuracy: 0.5789\n",
      "Epoch 3276/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6114 - accuracy: 0.6486 - val_loss: 0.6623 - val_accuracy: 0.5502\n",
      "Epoch 3277/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6104 - accuracy: 0.6509 - val_loss: 0.6594 - val_accuracy: 0.5559\n",
      "Epoch 3278/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6102 - accuracy: 0.6507 - val_loss: 0.6464 - val_accuracy: 0.5723\n",
      "Epoch 3279/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6108 - accuracy: 0.6501 - val_loss: 0.6766 - val_accuracy: 0.5283\n",
      "Epoch 3280/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6118 - accuracy: 0.6497 - val_loss: 0.6337 - val_accuracy: 0.5934\n",
      "Epoch 3281/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6126 - accuracy: 0.6463 - val_loss: 0.6880 - val_accuracy: 0.5141\n",
      "Epoch 3282/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6136 - accuracy: 0.6464 - val_loss: 0.6366 - val_accuracy: 0.5866\n",
      "Epoch 3283/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6124 - accuracy: 0.6470 - val_loss: 0.6714 - val_accuracy: 0.5331\n",
      "Epoch 3284/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6111 - accuracy: 0.6510 - val_loss: 0.6495 - val_accuracy: 0.5692\n",
      "Epoch 3285/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6103 - accuracy: 0.6502 - val_loss: 0.6520 - val_accuracy: 0.5661\n",
      "Epoch 3286/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6102 - accuracy: 0.6504 - val_loss: 0.6710 - val_accuracy: 0.5376\n",
      "Epoch 3287/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6109 - accuracy: 0.6507 - val_loss: 0.6395 - val_accuracy: 0.5824\n",
      "Epoch 3288/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6116 - accuracy: 0.6483 - val_loss: 0.6819 - val_accuracy: 0.5232\n",
      "Epoch 3289/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6485 - val_loss: 0.6346 - val_accuracy: 0.5924\n",
      "Epoch 3290/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6460 - val_loss: 0.6806 - val_accuracy: 0.5236\n",
      "Epoch 3291/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6488 - val_loss: 0.6433 - val_accuracy: 0.5769\n",
      "Epoch 3292/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6494 - val_loss: 0.6628 - val_accuracy: 0.5497\n",
      "Epoch 3293/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6103 - accuracy: 0.6507 - val_loss: 0.6570 - val_accuracy: 0.5577\n",
      "Epoch 3294/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6101 - accuracy: 0.6509 - val_loss: 0.6485 - val_accuracy: 0.5703\n",
      "Epoch 3295/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6104 - accuracy: 0.6503 - val_loss: 0.6739 - val_accuracy: 0.5322\n",
      "Epoch 3296/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6111 - accuracy: 0.6506 - val_loss: 0.6389 - val_accuracy: 0.5839\n",
      "Epoch 3297/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6116 - accuracy: 0.6482 - val_loss: 0.6804 - val_accuracy: 0.5243\n",
      "Epoch 3298/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6492 - val_loss: 0.6358 - val_accuracy: 0.5890\n",
      "Epoch 3299/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6121 - accuracy: 0.6470 - val_loss: 0.6799 - val_accuracy: 0.5248\n",
      "Epoch 3300/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6120 - accuracy: 0.6501 - val_loss: 0.6423 - val_accuracy: 0.5778\n",
      "Epoch 3301/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6110 - accuracy: 0.6489 - val_loss: 0.6652 - val_accuracy: 0.5442\n",
      "Epoch 3302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6103 - accuracy: 0.6515 - val_loss: 0.6546 - val_accuracy: 0.5627\n",
      "Epoch 3303/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6517 - val_loss: 0.6530 - val_accuracy: 0.5638\n",
      "Epoch 3304/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6100 - accuracy: 0.6511 - val_loss: 0.6678 - val_accuracy: 0.5426\n",
      "Epoch 3305/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6104 - accuracy: 0.6516 - val_loss: 0.6433 - val_accuracy: 0.5769\n",
      "Epoch 3306/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6108 - accuracy: 0.6496 - val_loss: 0.6758 - val_accuracy: 0.5290\n",
      "Epoch 3307/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6504 - val_loss: 0.6366 - val_accuracy: 0.5882\n",
      "Epoch 3308/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6118 - accuracy: 0.6477 - val_loss: 0.6825 - val_accuracy: 0.5208\n",
      "Epoch 3309/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6485 - val_loss: 0.6392 - val_accuracy: 0.5813\n",
      "Epoch 3310/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6115 - accuracy: 0.6482 - val_loss: 0.6724 - val_accuracy: 0.5338\n",
      "Epoch 3311/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6109 - accuracy: 0.6509 - val_loss: 0.6460 - val_accuracy: 0.5736\n",
      "Epoch 3312/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6104 - accuracy: 0.6501 - val_loss: 0.6630 - val_accuracy: 0.5499\n",
      "Epoch 3313/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6100 - accuracy: 0.6521 - val_loss: 0.6566 - val_accuracy: 0.5614\n",
      "Epoch 3314/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6099 - accuracy: 0.6508 - val_loss: 0.6537 - val_accuracy: 0.5627\n",
      "Epoch 3315/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6099 - accuracy: 0.6512 - val_loss: 0.6626 - val_accuracy: 0.5522\n",
      "Epoch 3316/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6510 - val_loss: 0.6480 - val_accuracy: 0.5711\n",
      "Epoch 3317/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6102 - accuracy: 0.6507 - val_loss: 0.6704 - val_accuracy: 0.5378\n",
      "Epoch 3318/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.5778\n",
      "Epoch 3319/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - accuracy: 0.6500 - val_loss: 0.6766 - val_accuracy: 0.5289\n",
      "Epoch 3320/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6113 - accuracy: 0.6508 - val_loss: 0.6367 - val_accuracy: 0.5879\n",
      "Epoch 3321/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6117 - accuracy: 0.6474 - val_loss: 0.6844 - val_accuracy: 0.5206\n",
      "Epoch 3322/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6126 - accuracy: 0.6483 - val_loss: 0.6353 - val_accuracy: 0.5890\n",
      "Epoch 3323/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6122 - accuracy: 0.6477 - val_loss: 0.6804 - val_accuracy: 0.5254\n",
      "Epoch 3324/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6119 - accuracy: 0.6493 - val_loss: 0.6404 - val_accuracy: 0.5807\n",
      "Epoch 3325/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6110 - accuracy: 0.6490 - val_loss: 0.6697 - val_accuracy: 0.5402\n",
      "Epoch 3326/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6511 - val_loss: 0.6501 - val_accuracy: 0.5691\n",
      "Epoch 3327/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6100 - accuracy: 0.6507 - val_loss: 0.6591 - val_accuracy: 0.5566\n",
      "Epoch 3328/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6098 - accuracy: 0.6515 - val_loss: 0.6592 - val_accuracy: 0.5568\n",
      "Epoch 3329/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6515 - val_loss: 0.6513 - val_accuracy: 0.5674\n",
      "Epoch 3330/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6099 - accuracy: 0.6511 - val_loss: 0.6669 - val_accuracy: 0.5435\n",
      "Epoch 3331/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6102 - accuracy: 0.6517 - val_loss: 0.6441 - val_accuracy: 0.5764\n",
      "Epoch 3332/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6499 - val_loss: 0.6745 - val_accuracy: 0.5323\n",
      "Epoch 3333/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6110 - accuracy: 0.6515 - val_loss: 0.6385 - val_accuracy: 0.5835\n",
      "Epoch 3334/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6113 - accuracy: 0.6482 - val_loss: 0.6825 - val_accuracy: 0.5223\n",
      "Epoch 3335/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6121 - accuracy: 0.6491 - val_loss: 0.6356 - val_accuracy: 0.5895\n",
      "Epoch 3336/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6120 - accuracy: 0.6474 - val_loss: 0.6831 - val_accuracy: 0.5221\n",
      "Epoch 3337/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6489 - val_loss: 0.6357 - val_accuracy: 0.5899\n",
      "Epoch 3338/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6117 - accuracy: 0.6478 - val_loss: 0.6794 - val_accuracy: 0.5265\n",
      "Epoch 3339/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6116 - accuracy: 0.6499 - val_loss: 0.6421 - val_accuracy: 0.5782\n",
      "Epoch 3340/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6108 - accuracy: 0.6490 - val_loss: 0.6683 - val_accuracy: 0.5409\n",
      "Epoch 3341/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6103 - accuracy: 0.6518 - val_loss: 0.6494 - val_accuracy: 0.5694\n",
      "Epoch 3342/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6099 - accuracy: 0.6509 - val_loss: 0.6591 - val_accuracy: 0.5570\n",
      "Epoch 3343/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6513 - val_loss: 0.6600 - val_accuracy: 0.5544\n",
      "Epoch 3344/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6097 - accuracy: 0.6519 - val_loss: 0.6510 - val_accuracy: 0.5663\n",
      "Epoch 3345/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6513 - val_loss: 0.6651 - val_accuracy: 0.5457\n",
      "Epoch 3346/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6517 - val_loss: 0.6455 - val_accuracy: 0.5740\n",
      "Epoch 3347/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6102 - accuracy: 0.6503 - val_loss: 0.6736 - val_accuracy: 0.5347\n",
      "Epoch 3348/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6107 - accuracy: 0.6514 - val_loss: 0.6393 - val_accuracy: 0.5828\n",
      "Epoch 3349/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6482 - val_loss: 0.6804 - val_accuracy: 0.5258\n",
      "Epoch 3350/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6117 - accuracy: 0.6493 - val_loss: 0.6356 - val_accuracy: 0.5902\n",
      "Epoch 3351/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6120 - accuracy: 0.6473 - val_loss: 0.6871 - val_accuracy: 0.5170\n",
      "Epoch 3352/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6130 - accuracy: 0.6474 - val_loss: 0.6326 - val_accuracy: 0.5963\n",
      "Epoch 3353/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6124 - accuracy: 0.6463 - val_loss: 0.6836 - val_accuracy: 0.5199\n",
      "Epoch 3354/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6487 - val_loss: 0.6396 - val_accuracy: 0.5815\n",
      "Epoch 3355/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6112 - accuracy: 0.6486 - val_loss: 0.6709 - val_accuracy: 0.5360\n",
      "Epoch 3356/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6106 - accuracy: 0.6506 - val_loss: 0.6479 - val_accuracy: 0.5705\n",
      "Epoch 3357/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6100 - accuracy: 0.6503 - val_loss: 0.6614 - val_accuracy: 0.5543\n",
      "Epoch 3358/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6518 - val_loss: 0.6596 - val_accuracy: 0.5543\n",
      "Epoch 3359/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6518 - val_loss: 0.6486 - val_accuracy: 0.5700\n",
      "Epoch 3360/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6098 - accuracy: 0.6508 - val_loss: 0.6687 - val_accuracy: 0.5413\n",
      "Epoch 3361/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6517 - val_loss: 0.6436 - val_accuracy: 0.5754\n",
      "Epoch 3362/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6106 - accuracy: 0.6502 - val_loss: 0.6773 - val_accuracy: 0.5285\n",
      "Epoch 3363/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6112 - accuracy: 0.6507 - val_loss: 0.6351 - val_accuracy: 0.5915\n",
      "Epoch 3364/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6116 - accuracy: 0.6481 - val_loss: 0.6858 - val_accuracy: 0.5175\n",
      "Epoch 3365/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6126 - accuracy: 0.6483 - val_loss: 0.6352 - val_accuracy: 0.5899\n",
      "Epoch 3366/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6121 - accuracy: 0.6475 - val_loss: 0.6815 - val_accuracy: 0.5234\n",
      "Epoch 3367/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6120 - accuracy: 0.6497 - val_loss: 0.6379 - val_accuracy: 0.5871\n",
      "Epoch 3368/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6110 - accuracy: 0.6483 - val_loss: 0.6729 - val_accuracy: 0.5349\n",
      "Epoch 3369/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6104 - accuracy: 0.6519 - val_loss: 0.6487 - val_accuracy: 0.5711\n",
      "Epoch 3370/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6099 - accuracy: 0.6504 - val_loss: 0.6599 - val_accuracy: 0.5555\n",
      "Epoch 3371/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6096 - accuracy: 0.6519 - val_loss: 0.6562 - val_accuracy: 0.5596\n",
      "Epoch 3372/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6095 - accuracy: 0.6519 - val_loss: 0.6532 - val_accuracy: 0.5649\n",
      "Epoch 3373/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6096 - accuracy: 0.6510 - val_loss: 0.6672 - val_accuracy: 0.5433\n",
      "Epoch 3374/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6098 - accuracy: 0.6519 - val_loss: 0.6433 - val_accuracy: 0.5778\n",
      "Epoch 3375/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6501 - val_loss: 0.6764 - val_accuracy: 0.5312\n",
      "Epoch 3376/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6510 - val_loss: 0.6359 - val_accuracy: 0.5897\n",
      "Epoch 3377/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6481 - val_loss: 0.6886 - val_accuracy: 0.5155\n",
      "Epoch 3378/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6131 - accuracy: 0.6472 - val_loss: 0.6325 - val_accuracy: 0.5970\n",
      "Epoch 3379/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6124 - accuracy: 0.6466 - val_loss: 0.6835 - val_accuracy: 0.5208\n",
      "Epoch 3380/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6121 - accuracy: 0.6493 - val_loss: 0.6398 - val_accuracy: 0.5840\n",
      "Epoch 3381/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6108 - accuracy: 0.6491 - val_loss: 0.6672 - val_accuracy: 0.5426\n",
      "Epoch 3382/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6101 - accuracy: 0.6502 - val_loss: 0.6539 - val_accuracy: 0.5628\n",
      "Epoch 3383/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6096 - accuracy: 0.6506 - val_loss: 0.6547 - val_accuracy: 0.5619\n",
      "Epoch 3384/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6097 - accuracy: 0.6515 - val_loss: 0.6673 - val_accuracy: 0.5413\n",
      "Epoch 3385/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6099 - accuracy: 0.6514 - val_loss: 0.6396 - val_accuracy: 0.5837\n",
      "Epoch 3386/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6108 - accuracy: 0.6486 - val_loss: 0.6828 - val_accuracy: 0.5225\n",
      "Epoch 3387/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6119 - accuracy: 0.6491 - val_loss: 0.6338 - val_accuracy: 0.5968\n",
      "Epoch 3388/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6466 - val_loss: 0.6894 - val_accuracy: 0.5157\n",
      "Epoch 3389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6135 - accuracy: 0.6467 - val_loss: 0.6332 - val_accuracy: 0.5939\n",
      "Epoch 3390/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6123 - accuracy: 0.6465 - val_loss: 0.6776 - val_accuracy: 0.5305\n",
      "Epoch 3391/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6506 - val_loss: 0.6473 - val_accuracy: 0.5733\n",
      "Epoch 3392/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6102 - accuracy: 0.6503 - val_loss: 0.6559 - val_accuracy: 0.5541\n",
      "Epoch 3393/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6103 - accuracy: 0.6489 - val_loss: 0.6681 - val_accuracy: 0.5415\n",
      "Epoch 3394/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6101 - accuracy: 0.6508 - val_loss: 0.6400 - val_accuracy: 0.5881\n",
      "Epoch 3395/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6118 - accuracy: 0.6490 - val_loss: 0.6899 - val_accuracy: 0.5095\n",
      "Epoch 3396/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6133 - accuracy: 0.6470 - val_loss: 0.6264 - val_accuracy: 0.6028\n",
      "Epoch 3397/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6147 - accuracy: 0.6435 - val_loss: 0.6973 - val_accuracy: 0.5066\n",
      "Epoch 3398/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6157 - accuracy: 0.6445 - val_loss: 0.6320 - val_accuracy: 0.5968\n",
      "Epoch 3399/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6134 - accuracy: 0.6472 - val_loss: 0.6718 - val_accuracy: 0.5342\n",
      "Epoch 3400/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6111 - accuracy: 0.6491 - val_loss: 0.6613 - val_accuracy: 0.5464\n",
      "Epoch 3401/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6109 - accuracy: 0.6489 - val_loss: 0.6430 - val_accuracy: 0.5815\n",
      "Epoch 3402/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6109 - accuracy: 0.6498 - val_loss: 0.6790 - val_accuracy: 0.5280\n",
      "Epoch 3403/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6122 - accuracy: 0.6489 - val_loss: 0.6331 - val_accuracy: 0.5930\n",
      "Epoch 3404/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6122 - accuracy: 0.6463 - val_loss: 0.6863 - val_accuracy: 0.5157\n",
      "Epoch 3405/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6127 - accuracy: 0.6472 - val_loss: 0.6388 - val_accuracy: 0.5831\n",
      "Epoch 3406/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6112 - accuracy: 0.6486 - val_loss: 0.6696 - val_accuracy: 0.5391\n",
      "Epoch 3407/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6101 - accuracy: 0.6521 - val_loss: 0.6525 - val_accuracy: 0.5639\n",
      "Epoch 3408/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6095 - accuracy: 0.6520 - val_loss: 0.6486 - val_accuracy: 0.5703\n",
      "Epoch 3409/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6096 - accuracy: 0.6509 - val_loss: 0.6706 - val_accuracy: 0.5371\n",
      "Epoch 3410/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6102 - accuracy: 0.6524 - val_loss: 0.6410 - val_accuracy: 0.5806\n",
      "Epoch 3411/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6108 - accuracy: 0.6488 - val_loss: 0.6814 - val_accuracy: 0.5227\n",
      "Epoch 3412/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6117 - accuracy: 0.6499 - val_loss: 0.6344 - val_accuracy: 0.5932\n",
      "Epoch 3413/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6466 - val_loss: 0.6808 - val_accuracy: 0.5241\n",
      "Epoch 3414/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6115 - accuracy: 0.6492 - val_loss: 0.6413 - val_accuracy: 0.5776\n",
      "Epoch 3415/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6104 - accuracy: 0.6493 - val_loss: 0.6652 - val_accuracy: 0.5453\n",
      "Epoch 3416/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6510 - val_loss: 0.6561 - val_accuracy: 0.5588\n",
      "Epoch 3417/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6093 - accuracy: 0.6523 - val_loss: 0.6502 - val_accuracy: 0.5674\n",
      "Epoch 3418/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6097 - accuracy: 0.6511 - val_loss: 0.6732 - val_accuracy: 0.5338\n",
      "Epoch 3419/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6513 - val_loss: 0.6367 - val_accuracy: 0.5901\n",
      "Epoch 3420/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6114 - accuracy: 0.6474 - val_loss: 0.6876 - val_accuracy: 0.5144\n",
      "Epoch 3421/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6479 - val_loss: 0.6311 - val_accuracy: 0.6016\n",
      "Epoch 3422/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6466 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
      "Epoch 3423/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6131 - accuracy: 0.6472 - val_loss: 0.6393 - val_accuracy: 0.5851\n",
      "Epoch 3424/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6114 - accuracy: 0.6466 - val_loss: 0.6662 - val_accuracy: 0.5460\n",
      "Epoch 3425/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6100 - accuracy: 0.6525 - val_loss: 0.6600 - val_accuracy: 0.5544\n",
      "Epoch 3426/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6526 - val_loss: 0.6429 - val_accuracy: 0.5804\n",
      "Epoch 3427/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6105 - accuracy: 0.6497 - val_loss: 0.6783 - val_accuracy: 0.5274\n",
      "Epoch 3428/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6111 - accuracy: 0.6505 - val_loss: 0.6386 - val_accuracy: 0.5851\n",
      "Epoch 3429/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6119 - accuracy: 0.6471 - val_loss: 0.6864 - val_accuracy: 0.5133\n",
      "Epoch 3430/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6123 - accuracy: 0.6482 - val_loss: 0.6317 - val_accuracy: 0.5999\n",
      "Epoch 3431/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6119 - accuracy: 0.6464 - val_loss: 0.6769 - val_accuracy: 0.5294\n",
      "Epoch 3432/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6109 - accuracy: 0.6510 - val_loss: 0.6465 - val_accuracy: 0.5734\n",
      "Epoch 3433/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6100 - accuracy: 0.6504 - val_loss: 0.6593 - val_accuracy: 0.5566\n",
      "Epoch 3434/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6092 - accuracy: 0.6521 - val_loss: 0.6627 - val_accuracy: 0.5497\n",
      "Epoch 3435/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6095 - accuracy: 0.6521 - val_loss: 0.6443 - val_accuracy: 0.5762\n",
      "Epoch 3436/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6100 - accuracy: 0.6504 - val_loss: 0.6802 - val_accuracy: 0.5270\n",
      "Epoch 3437/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6111 - accuracy: 0.6500 - val_loss: 0.6349 - val_accuracy: 0.5923\n",
      "Epoch 3438/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6116 - accuracy: 0.6469 - val_loss: 0.6857 - val_accuracy: 0.5174\n",
      "Epoch 3439/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6124 - accuracy: 0.6486 - val_loss: 0.6336 - val_accuracy: 0.5961\n",
      "Epoch 3440/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6115 - accuracy: 0.6475 - val_loss: 0.6777 - val_accuracy: 0.5278\n",
      "Epoch 3441/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6510 - val_loss: 0.6471 - val_accuracy: 0.5705\n",
      "Epoch 3442/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6098 - accuracy: 0.6497 - val_loss: 0.6589 - val_accuracy: 0.5583\n",
      "Epoch 3443/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6091 - accuracy: 0.6524 - val_loss: 0.6625 - val_accuracy: 0.5504\n",
      "Epoch 3444/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6094 - accuracy: 0.6528 - val_loss: 0.6429 - val_accuracy: 0.5786\n",
      "Epoch 3445/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6099 - accuracy: 0.6501 - val_loss: 0.6791 - val_accuracy: 0.5263\n",
      "Epoch 3446/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6108 - accuracy: 0.6501 - val_loss: 0.6373 - val_accuracy: 0.5890\n",
      "Epoch 3447/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6112 - accuracy: 0.6477 - val_loss: 0.6828 - val_accuracy: 0.5212\n",
      "Epoch 3448/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6117 - accuracy: 0.6492 - val_loss: 0.6350 - val_accuracy: 0.5913\n",
      "Epoch 3449/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6109 - accuracy: 0.6480 - val_loss: 0.6742 - val_accuracy: 0.5343\n",
      "Epoch 3450/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6102 - accuracy: 0.6525 - val_loss: 0.6490 - val_accuracy: 0.5711\n",
      "Epoch 3451/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6094 - accuracy: 0.6510 - val_loss: 0.6577 - val_accuracy: 0.5577\n",
      "Epoch 3452/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6090 - accuracy: 0.6524 - val_loss: 0.6623 - val_accuracy: 0.5515\n",
      "Epoch 3453/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6092 - accuracy: 0.6525 - val_loss: 0.6456 - val_accuracy: 0.5740\n",
      "Epoch 3454/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6509 - val_loss: 0.6778 - val_accuracy: 0.5287\n",
      "Epoch 3455/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6106 - accuracy: 0.6511 - val_loss: 0.6345 - val_accuracy: 0.5913\n",
      "Epoch 3456/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6112 - accuracy: 0.6466 - val_loss: 0.6854 - val_accuracy: 0.5190\n",
      "Epoch 3457/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6120 - accuracy: 0.6491 - val_loss: 0.6349 - val_accuracy: 0.5934\n",
      "Epoch 3458/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6113 - accuracy: 0.6482 - val_loss: 0.6786 - val_accuracy: 0.5263\n",
      "Epoch 3459/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6107 - accuracy: 0.6511 - val_loss: 0.6451 - val_accuracy: 0.5758\n",
      "Epoch 3460/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6499 - val_loss: 0.6618 - val_accuracy: 0.5533\n",
      "Epoch 3461/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6091 - accuracy: 0.6532 - val_loss: 0.6573 - val_accuracy: 0.5594\n",
      "Epoch 3462/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6528 - val_loss: 0.6489 - val_accuracy: 0.5698\n",
      "Epoch 3463/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6092 - accuracy: 0.6506 - val_loss: 0.6726 - val_accuracy: 0.5371\n",
      "Epoch 3464/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6523 - val_loss: 0.6409 - val_accuracy: 0.5813\n",
      "Epoch 3465/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6102 - accuracy: 0.6495 - val_loss: 0.6796 - val_accuracy: 0.5267\n",
      "Epoch 3466/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6110 - accuracy: 0.6507 - val_loss: 0.6337 - val_accuracy: 0.5941\n",
      "Epoch 3467/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6112 - accuracy: 0.6478 - val_loss: 0.6853 - val_accuracy: 0.5190\n",
      "Epoch 3468/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6118 - accuracy: 0.6489 - val_loss: 0.6384 - val_accuracy: 0.5875\n",
      "Epoch 3469/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6107 - accuracy: 0.6483 - val_loss: 0.6729 - val_accuracy: 0.5354\n",
      "Epoch 3470/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6518 - val_loss: 0.6480 - val_accuracy: 0.5709\n",
      "Epoch 3471/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6092 - accuracy: 0.6506 - val_loss: 0.6578 - val_accuracy: 0.5583\n",
      "Epoch 3472/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6089 - accuracy: 0.6523 - val_loss: 0.6621 - val_accuracy: 0.5522\n",
      "Epoch 3473/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6089 - accuracy: 0.6526 - val_loss: 0.6487 - val_accuracy: 0.5709\n",
      "Epoch 3474/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6092 - accuracy: 0.6513 - val_loss: 0.6715 - val_accuracy: 0.5374\n",
      "Epoch 3475/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6098 - accuracy: 0.6514 - val_loss: 0.6386 - val_accuracy: 0.5864\n",
      "Epoch 3476/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6102 - accuracy: 0.6490 - val_loss: 0.6832 - val_accuracy: 0.5227\n",
      "Epoch 3477/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6112 - accuracy: 0.6495 - val_loss: 0.6362 - val_accuracy: 0.5906\n",
      "Epoch 3478/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6113 - accuracy: 0.6473 - val_loss: 0.6824 - val_accuracy: 0.5217\n",
      "Epoch 3479/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6115 - accuracy: 0.6500 - val_loss: 0.6361 - val_accuracy: 0.5926\n",
      "Epoch 3480/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6106 - accuracy: 0.6487 - val_loss: 0.6740 - val_accuracy: 0.5347\n",
      "Epoch 3481/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6101 - accuracy: 0.6509 - val_loss: 0.6510 - val_accuracy: 0.5650\n",
      "Epoch 3482/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6093 - accuracy: 0.6509 - val_loss: 0.6568 - val_accuracy: 0.5616\n",
      "Epoch 3483/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6515 - val_loss: 0.6635 - val_accuracy: 0.5497\n",
      "Epoch 3484/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6091 - accuracy: 0.6526 - val_loss: 0.6427 - val_accuracy: 0.5793\n",
      "Epoch 3485/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6101 - accuracy: 0.6491 - val_loss: 0.6825 - val_accuracy: 0.5232\n",
      "Epoch 3486/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6113 - accuracy: 0.6498 - val_loss: 0.6331 - val_accuracy: 0.5992\n",
      "Epoch 3487/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6120 - accuracy: 0.6471 - val_loss: 0.6910 - val_accuracy: 0.5128\n",
      "Epoch 3488/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6132 - accuracy: 0.6468 - val_loss: 0.6331 - val_accuracy: 0.5959\n",
      "Epoch 3489/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6116 - accuracy: 0.6470 - val_loss: 0.6743 - val_accuracy: 0.5358\n",
      "Epoch 3490/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6109 - accuracy: 0.6519 - val_loss: 0.6513 - val_accuracy: 0.5676\n",
      "Epoch 3491/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6096 - accuracy: 0.6507 - val_loss: 0.6535 - val_accuracy: 0.5625\n",
      "Epoch 3492/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6099 - accuracy: 0.6491 - val_loss: 0.6740 - val_accuracy: 0.5331\n",
      "Epoch 3493/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6102 - accuracy: 0.6506 - val_loss: 0.6316 - val_accuracy: 0.6030\n",
      "Epoch 3494/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6125 - accuracy: 0.6469 - val_loss: 0.7009 - val_accuracy: 0.4998\n",
      "Epoch 3495/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6149 - accuracy: 0.6452 - val_loss: 0.6300 - val_accuracy: 0.6014\n",
      "Epoch 3496/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6140 - accuracy: 0.6444 - val_loss: 0.6814 - val_accuracy: 0.5239\n",
      "Epoch 3497/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6500 - val_loss: 0.6426 - val_accuracy: 0.5813\n",
      "Epoch 3498/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6110 - accuracy: 0.6493 - val_loss: 0.6592 - val_accuracy: 0.5566\n",
      "Epoch 3499/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6508 - val_loss: 0.6701 - val_accuracy: 0.5411\n",
      "Epoch 3500/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6100 - accuracy: 0.6505 - val_loss: 0.6405 - val_accuracy: 0.5842\n",
      "Epoch 3501/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6104 - accuracy: 0.6491 - val_loss: 0.6757 - val_accuracy: 0.5316\n",
      "Epoch 3502/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - accuracy: 0.6515 - val_loss: 0.6406 - val_accuracy: 0.5824\n",
      "Epoch 3503/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6107 - accuracy: 0.6485 - val_loss: 0.6737 - val_accuracy: 0.5338\n",
      "Epoch 3504/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6104 - accuracy: 0.6500 - val_loss: 0.6452 - val_accuracy: 0.5765\n",
      "Epoch 3505/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6098 - accuracy: 0.6493 - val_loss: 0.6647 - val_accuracy: 0.5482\n",
      "Epoch 3506/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6093 - accuracy: 0.6525 - val_loss: 0.6580 - val_accuracy: 0.5552\n",
      "Epoch 3507/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6091 - accuracy: 0.6527 - val_loss: 0.6456 - val_accuracy: 0.5769\n",
      "Epoch 3508/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6094 - accuracy: 0.6509 - val_loss: 0.6711 - val_accuracy: 0.5382\n",
      "Epoch 3509/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6528 - val_loss: 0.6463 - val_accuracy: 0.5742\n",
      "Epoch 3510/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6502 - val_loss: 0.6756 - val_accuracy: 0.5283\n",
      "Epoch 3511/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6103 - accuracy: 0.6514 - val_loss: 0.6363 - val_accuracy: 0.5928\n",
      "Epoch 3512/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6104 - accuracy: 0.6482 - val_loss: 0.6768 - val_accuracy: 0.5334\n",
      "Epoch 3513/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6103 - accuracy: 0.6506 - val_loss: 0.6468 - val_accuracy: 0.5734\n",
      "Epoch 3514/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6097 - accuracy: 0.6504 - val_loss: 0.6661 - val_accuracy: 0.5444\n",
      "Epoch 3515/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6096 - accuracy: 0.6521 - val_loss: 0.6499 - val_accuracy: 0.5691\n",
      "Epoch 3516/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6089 - accuracy: 0.6510 - val_loss: 0.6586 - val_accuracy: 0.5579\n",
      "Epoch 3517/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6093 - accuracy: 0.6517 - val_loss: 0.6656 - val_accuracy: 0.5493\n",
      "Epoch 3518/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6088 - accuracy: 0.6527 - val_loss: 0.6436 - val_accuracy: 0.5813\n",
      "Epoch 3519/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6098 - accuracy: 0.6495 - val_loss: 0.6755 - val_accuracy: 0.5338\n",
      "Epoch 3520/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6101 - accuracy: 0.6510 - val_loss: 0.6374 - val_accuracy: 0.5902\n",
      "Epoch 3521/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6112 - accuracy: 0.6478 - val_loss: 0.6886 - val_accuracy: 0.5168\n",
      "Epoch 3522/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6128 - accuracy: 0.6480 - val_loss: 0.6323 - val_accuracy: 0.5972\n",
      "Epoch 3523/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6460 - val_loss: 0.6837 - val_accuracy: 0.5227\n",
      "Epoch 3524/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6117 - accuracy: 0.6489 - val_loss: 0.6461 - val_accuracy: 0.5749\n",
      "Epoch 3525/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6098 - accuracy: 0.6509 - val_loss: 0.6547 - val_accuracy: 0.5597\n",
      "Epoch 3526/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6101 - accuracy: 0.6488 - val_loss: 0.6679 - val_accuracy: 0.5444\n",
      "Epoch 3527/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6095 - accuracy: 0.6510 - val_loss: 0.6467 - val_accuracy: 0.5740\n",
      "Epoch 3528/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6111 - accuracy: 0.6491 - val_loss: 0.6832 - val_accuracy: 0.5206\n",
      "Epoch 3529/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6117 - accuracy: 0.6499 - val_loss: 0.6249 - val_accuracy: 0.6074\n",
      "Epoch 3530/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6132 - accuracy: 0.6463 - val_loss: 0.6954 - val_accuracy: 0.5097\n",
      "Epoch 3531/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6463 - val_loss: 0.6423 - val_accuracy: 0.5822\n",
      "Epoch 3532/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6117 - accuracy: 0.6480 - val_loss: 0.6662 - val_accuracy: 0.5475\n",
      "Epoch 3533/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6106 - accuracy: 0.6510 - val_loss: 0.6542 - val_accuracy: 0.5617\n",
      "Epoch 3534/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6102 - accuracy: 0.6500 - val_loss: 0.6460 - val_accuracy: 0.5745\n",
      "Epoch 3535/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6104 - accuracy: 0.6505 - val_loss: 0.6827 - val_accuracy: 0.5241\n",
      "Epoch 3536/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6108 - accuracy: 0.6496 - val_loss: 0.6361 - val_accuracy: 0.5915\n",
      "Epoch 3537/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6113 - accuracy: 0.6483 - val_loss: 0.6817 - val_accuracy: 0.5236\n",
      "Epoch 3538/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6112 - accuracy: 0.6513 - val_loss: 0.6372 - val_accuracy: 0.5881\n",
      "Epoch 3539/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6110 - accuracy: 0.6477 - val_loss: 0.6759 - val_accuracy: 0.5320\n",
      "Epoch 3540/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6102 - accuracy: 0.6522 - val_loss: 0.6464 - val_accuracy: 0.5745\n",
      "Epoch 3541/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6096 - accuracy: 0.6496 - val_loss: 0.6610 - val_accuracy: 0.5526\n",
      "Epoch 3542/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6087 - accuracy: 0.6526 - val_loss: 0.6608 - val_accuracy: 0.5512\n",
      "Epoch 3543/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6088 - accuracy: 0.6533 - val_loss: 0.6452 - val_accuracy: 0.5780\n",
      "Epoch 3544/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6092 - accuracy: 0.6511 - val_loss: 0.6746 - val_accuracy: 0.5345\n",
      "Epoch 3545/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6514 - val_loss: 0.6418 - val_accuracy: 0.5798\n",
      "Epoch 3546/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6102 - accuracy: 0.6476 - val_loss: 0.6768 - val_accuracy: 0.5323\n",
      "Epoch 3547/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6101 - accuracy: 0.6522 - val_loss: 0.6382 - val_accuracy: 0.5906\n",
      "Epoch 3548/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6102 - accuracy: 0.6493 - val_loss: 0.6735 - val_accuracy: 0.5358\n",
      "Epoch 3549/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6097 - accuracy: 0.6512 - val_loss: 0.6501 - val_accuracy: 0.5687\n",
      "Epoch 3550/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6093 - accuracy: 0.6501 - val_loss: 0.6608 - val_accuracy: 0.5541\n",
      "Epoch 3551/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6088 - accuracy: 0.6529 - val_loss: 0.6567 - val_accuracy: 0.5592\n",
      "Epoch 3552/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6088 - accuracy: 0.6531 - val_loss: 0.6503 - val_accuracy: 0.5670\n",
      "Epoch 3553/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6090 - accuracy: 0.6504 - val_loss: 0.6695 - val_accuracy: 0.5433\n",
      "Epoch 3554/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6090 - accuracy: 0.6531 - val_loss: 0.6464 - val_accuracy: 0.5751\n",
      "Epoch 3555/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6095 - accuracy: 0.6502 - val_loss: 0.6747 - val_accuracy: 0.5338\n",
      "Epoch 3556/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6097 - accuracy: 0.6517 - val_loss: 0.6370 - val_accuracy: 0.5901\n",
      "Epoch 3557/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6102 - accuracy: 0.6491 - val_loss: 0.6802 - val_accuracy: 0.5274\n",
      "Epoch 3558/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6106 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.5842\n",
      "Epoch 3559/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6103 - accuracy: 0.6492 - val_loss: 0.6757 - val_accuracy: 0.5342\n",
      "Epoch 3560/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6518 - val_loss: 0.6460 - val_accuracy: 0.5751\n",
      "Epoch 3561/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6090 - accuracy: 0.6501 - val_loss: 0.6586 - val_accuracy: 0.5581\n",
      "Epoch 3562/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6087 - accuracy: 0.6528 - val_loss: 0.6608 - val_accuracy: 0.5548\n",
      "Epoch 3563/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6084 - accuracy: 0.6524 - val_loss: 0.6515 - val_accuracy: 0.5674\n",
      "Epoch 3564/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6091 - accuracy: 0.6510 - val_loss: 0.6727 - val_accuracy: 0.5374\n",
      "Epoch 3565/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6095 - accuracy: 0.6518 - val_loss: 0.6347 - val_accuracy: 0.5977\n",
      "Epoch 3566/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6106 - accuracy: 0.6485 - val_loss: 0.6902 - val_accuracy: 0.5153\n",
      "Epoch 3567/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6120 - accuracy: 0.6483 - val_loss: 0.6356 - val_accuracy: 0.5928\n",
      "Epoch 3568/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6119 - accuracy: 0.6467 - val_loss: 0.6813 - val_accuracy: 0.5269\n",
      "Epoch 3569/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6115 - accuracy: 0.6509 - val_loss: 0.6379 - val_accuracy: 0.5935\n",
      "Epoch 3570/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6106 - accuracy: 0.6504 - val_loss: 0.6673 - val_accuracy: 0.5455\n",
      "Epoch 3571/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6102 - accuracy: 0.6505 - val_loss: 0.6621 - val_accuracy: 0.5519\n",
      "Epoch 3572/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6091 - accuracy: 0.6505 - val_loss: 0.6487 - val_accuracy: 0.5705\n",
      "Epoch 3573/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6098 - accuracy: 0.6506 - val_loss: 0.6733 - val_accuracy: 0.5354\n",
      "Epoch 3574/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6099 - accuracy: 0.6521 - val_loss: 0.6355 - val_accuracy: 0.5899\n",
      "Epoch 3575/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6115 - accuracy: 0.6484 - val_loss: 0.6899 - val_accuracy: 0.5150\n",
      "Epoch 3576/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6123 - accuracy: 0.6482 - val_loss: 0.6329 - val_accuracy: 0.5999\n",
      "Epoch 3577/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6128 - accuracy: 0.6452 - val_loss: 0.6864 - val_accuracy: 0.5194\n",
      "Epoch 3578/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6484 - val_loss: 0.6419 - val_accuracy: 0.5798\n",
      "Epoch 3579/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6105 - accuracy: 0.6488 - val_loss: 0.6582 - val_accuracy: 0.5583\n",
      "Epoch 3580/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6095 - accuracy: 0.6523 - val_loss: 0.6637 - val_accuracy: 0.5515\n",
      "Epoch 3581/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6095 - accuracy: 0.6518 - val_loss: 0.6446 - val_accuracy: 0.5778\n",
      "Epoch 3582/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6102 - accuracy: 0.6490 - val_loss: 0.6813 - val_accuracy: 0.5248\n",
      "Epoch 3583/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6109 - accuracy: 0.6505 - val_loss: 0.6299 - val_accuracy: 0.6034\n",
      "Epoch 3584/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6116 - accuracy: 0.6486 - val_loss: 0.6911 - val_accuracy: 0.5133\n",
      "Epoch 3585/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6121 - accuracy: 0.6483 - val_loss: 0.6399 - val_accuracy: 0.5833\n",
      "Epoch 3586/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6108 - accuracy: 0.6474 - val_loss: 0.6690 - val_accuracy: 0.5415\n",
      "Epoch 3587/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6091 - accuracy: 0.6522 - val_loss: 0.6500 - val_accuracy: 0.5692\n",
      "Epoch 3588/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6087 - accuracy: 0.6523 - val_loss: 0.6503 - val_accuracy: 0.5681\n",
      "Epoch 3589/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6086 - accuracy: 0.6527 - val_loss: 0.6734 - val_accuracy: 0.5376\n",
      "Epoch 3590/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6091 - accuracy: 0.6523 - val_loss: 0.6412 - val_accuracy: 0.5820\n",
      "Epoch 3591/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6097 - accuracy: 0.6486 - val_loss: 0.6782 - val_accuracy: 0.5292\n",
      "Epoch 3592/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6101 - accuracy: 0.6517 - val_loss: 0.6371 - val_accuracy: 0.5917\n",
      "Epoch 3593/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6100 - accuracy: 0.6486 - val_loss: 0.6767 - val_accuracy: 0.5329\n",
      "Epoch 3594/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6100 - accuracy: 0.6513 - val_loss: 0.6439 - val_accuracy: 0.5782\n",
      "Epoch 3595/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6095 - accuracy: 0.6483 - val_loss: 0.6692 - val_accuracy: 0.5426\n",
      "Epoch 3596/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6089 - accuracy: 0.6532 - val_loss: 0.6515 - val_accuracy: 0.5650\n",
      "Epoch 3597/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6085 - accuracy: 0.6531 - val_loss: 0.6530 - val_accuracy: 0.5625\n",
      "Epoch 3598/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6085 - accuracy: 0.6513 - val_loss: 0.6635 - val_accuracy: 0.5517\n",
      "Epoch 3599/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6084 - accuracy: 0.6530 - val_loss: 0.6511 - val_accuracy: 0.5678\n",
      "Epoch 3600/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6089 - accuracy: 0.6513 - val_loss: 0.6710 - val_accuracy: 0.5400\n",
      "Epoch 3601/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6089 - accuracy: 0.6522 - val_loss: 0.6380 - val_accuracy: 0.5873\n",
      "Epoch 3602/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6096 - accuracy: 0.6501 - val_loss: 0.6791 - val_accuracy: 0.5307\n",
      "Epoch 3603/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6519 - val_loss: 0.6415 - val_accuracy: 0.5820\n",
      "Epoch 3604/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6099 - accuracy: 0.6498 - val_loss: 0.6755 - val_accuracy: 0.5327\n",
      "Epoch 3605/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6524 - val_loss: 0.6412 - val_accuracy: 0.5829\n",
      "Epoch 3606/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6091 - accuracy: 0.6493 - val_loss: 0.6676 - val_accuracy: 0.5469\n",
      "Epoch 3607/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6086 - accuracy: 0.6537 - val_loss: 0.6547 - val_accuracy: 0.5639\n",
      "Epoch 3608/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6082 - accuracy: 0.6530 - val_loss: 0.6575 - val_accuracy: 0.5581\n",
      "Epoch 3609/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6082 - accuracy: 0.6523 - val_loss: 0.6615 - val_accuracy: 0.5532\n",
      "Epoch 3610/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6081 - accuracy: 0.6531 - val_loss: 0.6461 - val_accuracy: 0.5754\n",
      "Epoch 3611/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6087 - accuracy: 0.6510 - val_loss: 0.6763 - val_accuracy: 0.5325\n",
      "Epoch 3612/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6094 - accuracy: 0.6525 - val_loss: 0.6360 - val_accuracy: 0.5932\n",
      "Epoch 3613/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6104 - accuracy: 0.6483 - val_loss: 0.6885 - val_accuracy: 0.5172\n",
      "Epoch 3614/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6491 - val_loss: 0.6315 - val_accuracy: 0.6030\n",
      "Epoch 3615/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6113 - accuracy: 0.6484 - val_loss: 0.6859 - val_accuracy: 0.5206\n",
      "Epoch 3616/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6116 - accuracy: 0.6494 - val_loss: 0.6394 - val_accuracy: 0.5868\n",
      "Epoch 3617/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6486 - val_loss: 0.6692 - val_accuracy: 0.5438\n",
      "Epoch 3618/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6522 - val_loss: 0.6574 - val_accuracy: 0.5594\n",
      "Epoch 3619/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6082 - accuracy: 0.6539 - val_loss: 0.6428 - val_accuracy: 0.5826\n",
      "Epoch 3620/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6092 - accuracy: 0.6499 - val_loss: 0.6790 - val_accuracy: 0.5287\n",
      "Epoch 3621/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6096 - accuracy: 0.6517 - val_loss: 0.6389 - val_accuracy: 0.5884\n",
      "Epoch 3622/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6112 - accuracy: 0.6490 - val_loss: 0.6900 - val_accuracy: 0.5153\n",
      "Epoch 3623/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6483 - val_loss: 0.6248 - val_accuracy: 0.6067\n",
      "Epoch 3624/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6467 - val_loss: 0.6885 - val_accuracy: 0.5174\n",
      "Epoch 3625/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6114 - accuracy: 0.6488 - val_loss: 0.6456 - val_accuracy: 0.5767\n",
      "Epoch 3626/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6097 - accuracy: 0.6505 - val_loss: 0.6585 - val_accuracy: 0.5544\n",
      "Epoch 3627/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6089 - accuracy: 0.6517 - val_loss: 0.6611 - val_accuracy: 0.5522\n",
      "Epoch 3628/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6087 - accuracy: 0.6519 - val_loss: 0.6425 - val_accuracy: 0.5806\n",
      "Epoch 3629/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6498 - val_loss: 0.6902 - val_accuracy: 0.5139\n",
      "Epoch 3630/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6119 - accuracy: 0.6489 - val_loss: 0.6284 - val_accuracy: 0.6039\n",
      "Epoch 3631/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6467 - val_loss: 0.6884 - val_accuracy: 0.5170\n",
      "Epoch 3632/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6117 - accuracy: 0.6487 - val_loss: 0.6406 - val_accuracy: 0.5829\n",
      "Epoch 3633/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6102 - accuracy: 0.6495 - val_loss: 0.6641 - val_accuracy: 0.5499\n",
      "Epoch 3634/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6093 - accuracy: 0.6519 - val_loss: 0.6575 - val_accuracy: 0.5568\n",
      "Epoch 3635/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6089 - accuracy: 0.6509 - val_loss: 0.6475 - val_accuracy: 0.5733\n",
      "Epoch 3636/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6091 - accuracy: 0.6514 - val_loss: 0.6771 - val_accuracy: 0.5305\n",
      "Epoch 3637/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6097 - accuracy: 0.6520 - val_loss: 0.6324 - val_accuracy: 0.5996\n",
      "Epoch 3638/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6490 - val_loss: 0.6887 - val_accuracy: 0.5166\n",
      "Epoch 3639/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6486 - val_loss: 0.6390 - val_accuracy: 0.5851\n",
      "Epoch 3640/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6108 - accuracy: 0.6475 - val_loss: 0.6727 - val_accuracy: 0.5367\n",
      "Epoch 3641/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6093 - accuracy: 0.6527 - val_loss: 0.6467 - val_accuracy: 0.5742\n",
      "Epoch 3642/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6089 - accuracy: 0.6521 - val_loss: 0.6536 - val_accuracy: 0.5628\n",
      "Epoch 3643/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6085 - accuracy: 0.6510 - val_loss: 0.6681 - val_accuracy: 0.5451\n",
      "Epoch 3644/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6085 - accuracy: 0.6531 - val_loss: 0.6484 - val_accuracy: 0.5720\n",
      "Epoch 3645/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6089 - accuracy: 0.6508 - val_loss: 0.6716 - val_accuracy: 0.5371\n",
      "Epoch 3646/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6089 - accuracy: 0.6530 - val_loss: 0.6382 - val_accuracy: 0.5899\n",
      "Epoch 3647/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6095 - accuracy: 0.6498 - val_loss: 0.6772 - val_accuracy: 0.5311\n",
      "Epoch 3648/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6095 - accuracy: 0.6531 - val_loss: 0.6427 - val_accuracy: 0.5807\n",
      "Epoch 3649/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6096 - accuracy: 0.6495 - val_loss: 0.6737 - val_accuracy: 0.5384\n",
      "Epoch 3650/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6088 - accuracy: 0.6532 - val_loss: 0.6461 - val_accuracy: 0.5749\n",
      "Epoch 3651/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6085 - accuracy: 0.6512 - val_loss: 0.6593 - val_accuracy: 0.5564\n",
      "Epoch 3652/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6080 - accuracy: 0.6537 - val_loss: 0.6600 - val_accuracy: 0.5575\n",
      "Epoch 3653/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6080 - accuracy: 0.6524 - val_loss: 0.6529 - val_accuracy: 0.5656\n",
      "Epoch 3654/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6082 - accuracy: 0.6520 - val_loss: 0.6672 - val_accuracy: 0.5453\n",
      "Epoch 3655/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6084 - accuracy: 0.6528 - val_loss: 0.6385 - val_accuracy: 0.5901\n",
      "Epoch 3656/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6093 - accuracy: 0.6492 - val_loss: 0.6832 - val_accuracy: 0.5252\n",
      "Epoch 3657/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6099 - accuracy: 0.6511 - val_loss: 0.6389 - val_accuracy: 0.5855\n",
      "Epoch 3658/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6474 - val_loss: 0.6820 - val_accuracy: 0.5254\n",
      "Epoch 3659/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6107 - accuracy: 0.6517 - val_loss: 0.6341 - val_accuracy: 0.5977\n",
      "Epoch 3660/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6101 - accuracy: 0.6495 - val_loss: 0.6755 - val_accuracy: 0.5329\n",
      "Epoch 3661/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6098 - accuracy: 0.6518 - val_loss: 0.6538 - val_accuracy: 0.5649\n",
      "Epoch 3662/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6518 - val_loss: 0.6554 - val_accuracy: 0.5647\n",
      "Epoch 3663/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6087 - accuracy: 0.6520 - val_loss: 0.6644 - val_accuracy: 0.5499\n",
      "Epoch 3664/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6084 - accuracy: 0.6536 - val_loss: 0.6414 - val_accuracy: 0.5813\n",
      "Epoch 3665/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6100 - accuracy: 0.6487 - val_loss: 0.6846 - val_accuracy: 0.5212\n",
      "Epoch 3666/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6105 - accuracy: 0.6507 - val_loss: 0.6338 - val_accuracy: 0.5968\n",
      "Epoch 3667/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6115 - accuracy: 0.6468 - val_loss: 0.6884 - val_accuracy: 0.5188\n",
      "Epoch 3668/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6112 - accuracy: 0.6491 - val_loss: 0.6375 - val_accuracy: 0.5908\n",
      "Epoch 3669/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - accuracy: 0.6485 - val_loss: 0.6704 - val_accuracy: 0.5424\n",
      "Epoch 3670/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6525 - val_loss: 0.6513 - val_accuracy: 0.5665\n",
      "Epoch 3671/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6511 - val_loss: 0.6543 - val_accuracy: 0.5616\n",
      "Epoch 3672/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6086 - accuracy: 0.6525 - val_loss: 0.6720 - val_accuracy: 0.5387\n",
      "Epoch 3673/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6092 - accuracy: 0.6523 - val_loss: 0.6367 - val_accuracy: 0.5934\n",
      "Epoch 3674/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6099 - accuracy: 0.6496 - val_loss: 0.6834 - val_accuracy: 0.5225\n",
      "Epoch 3675/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6104 - accuracy: 0.6508 - val_loss: 0.6385 - val_accuracy: 0.5868\n",
      "Epoch 3676/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6107 - accuracy: 0.6470 - val_loss: 0.6817 - val_accuracy: 0.5261\n",
      "Epoch 3677/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6102 - accuracy: 0.6519 - val_loss: 0.6347 - val_accuracy: 0.5966\n",
      "Epoch 3678/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6499 - val_loss: 0.6755 - val_accuracy: 0.5334\n",
      "Epoch 3679/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6092 - accuracy: 0.6519 - val_loss: 0.6505 - val_accuracy: 0.5670\n",
      "Epoch 3680/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6087 - accuracy: 0.6505 - val_loss: 0.6608 - val_accuracy: 0.5575\n",
      "Epoch 3681/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6083 - accuracy: 0.6526 - val_loss: 0.6573 - val_accuracy: 0.5585\n",
      "Epoch 3682/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6081 - accuracy: 0.6542 - val_loss: 0.6473 - val_accuracy: 0.5733\n",
      "Epoch 3683/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6089 - accuracy: 0.6498 - val_loss: 0.6746 - val_accuracy: 0.5380\n",
      "Epoch 3684/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6088 - accuracy: 0.6531 - val_loss: 0.6404 - val_accuracy: 0.5875\n",
      "Epoch 3685/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6098 - accuracy: 0.6487 - val_loss: 0.6825 - val_accuracy: 0.5263\n",
      "Epoch 3686/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6098 - accuracy: 0.6514 - val_loss: 0.6363 - val_accuracy: 0.5901\n",
      "Epoch 3687/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6102 - accuracy: 0.6489 - val_loss: 0.6777 - val_accuracy: 0.5314\n",
      "Epoch 3688/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6103 - accuracy: 0.6523 - val_loss: 0.6411 - val_accuracy: 0.5849\n",
      "Epoch 3689/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6097 - accuracy: 0.6485 - val_loss: 0.6701 - val_accuracy: 0.5422\n",
      "Epoch 3690/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6086 - accuracy: 0.6522 - val_loss: 0.6568 - val_accuracy: 0.5586\n",
      "Epoch 3691/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6083 - accuracy: 0.6517 - val_loss: 0.6493 - val_accuracy: 0.5722\n",
      "Epoch 3692/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6088 - accuracy: 0.6512 - val_loss: 0.6676 - val_accuracy: 0.5480\n",
      "Epoch 3693/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6086 - accuracy: 0.6533 - val_loss: 0.6455 - val_accuracy: 0.5787\n",
      "Epoch 3694/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6093 - accuracy: 0.6497 - val_loss: 0.6786 - val_accuracy: 0.5296\n",
      "Epoch 3695/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6094 - accuracy: 0.6524 - val_loss: 0.6327 - val_accuracy: 0.6014\n",
      "Epoch 3696/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6102 - accuracy: 0.6495 - val_loss: 0.6864 - val_accuracy: 0.5208\n",
      "Epoch 3697/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6104 - accuracy: 0.6505 - val_loss: 0.6389 - val_accuracy: 0.5851\n",
      "Epoch 3698/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6101 - accuracy: 0.6481 - val_loss: 0.6770 - val_accuracy: 0.5311\n",
      "Epoch 3699/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6096 - accuracy: 0.6530 - val_loss: 0.6405 - val_accuracy: 0.5859\n",
      "Epoch 3700/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6088 - accuracy: 0.6500 - val_loss: 0.6657 - val_accuracy: 0.5490\n",
      "Epoch 3701/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6082 - accuracy: 0.6528 - val_loss: 0.6601 - val_accuracy: 0.5561\n",
      "Epoch 3702/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6536 - val_loss: 0.6485 - val_accuracy: 0.5736\n",
      "Epoch 3703/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6083 - accuracy: 0.6517 - val_loss: 0.6712 - val_accuracy: 0.5429\n",
      "Epoch 3704/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6083 - accuracy: 0.6537 - val_loss: 0.6398 - val_accuracy: 0.5855\n",
      "Epoch 3705/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6095 - accuracy: 0.6493 - val_loss: 0.6834 - val_accuracy: 0.5241\n",
      "Epoch 3706/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6514 - val_loss: 0.6331 - val_accuracy: 0.6007\n",
      "Epoch 3707/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6104 - accuracy: 0.6486 - val_loss: 0.6859 - val_accuracy: 0.5214\n",
      "Epoch 3708/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6103 - accuracy: 0.6500 - val_loss: 0.6411 - val_accuracy: 0.5828\n",
      "Epoch 3709/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6091 - accuracy: 0.6493 - val_loss: 0.6659 - val_accuracy: 0.5484\n",
      "Epoch 3710/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6087 - accuracy: 0.6533 - val_loss: 0.6539 - val_accuracy: 0.5636\n",
      "Epoch 3711/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6079 - accuracy: 0.6529 - val_loss: 0.6528 - val_accuracy: 0.5650\n",
      "Epoch 3712/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6086 - accuracy: 0.6521 - val_loss: 0.6758 - val_accuracy: 0.5353\n",
      "Epoch 3713/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6536 - val_loss: 0.6326 - val_accuracy: 0.5992\n",
      "Epoch 3714/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6105 - accuracy: 0.6488 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 3715/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6116 - accuracy: 0.6483 - val_loss: 0.6329 - val_accuracy: 0.5981\n",
      "Epoch 3716/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6115 - accuracy: 0.6485 - val_loss: 0.6841 - val_accuracy: 0.5230\n",
      "Epoch 3717/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6112 - accuracy: 0.6508 - val_loss: 0.6381 - val_accuracy: 0.5923\n",
      "Epoch 3718/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6097 - accuracy: 0.6494 - val_loss: 0.6658 - val_accuracy: 0.5479\n",
      "Epoch 3719/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6085 - accuracy: 0.6528 - val_loss: 0.6655 - val_accuracy: 0.5502\n",
      "Epoch 3720/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6079 - accuracy: 0.6531 - val_loss: 0.6391 - val_accuracy: 0.5890\n",
      "Epoch 3721/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6094 - accuracy: 0.6494 - val_loss: 0.6829 - val_accuracy: 0.5228\n",
      "Epoch 3722/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6102 - accuracy: 0.6509 - val_loss: 0.6341 - val_accuracy: 0.5966\n",
      "Epoch 3723/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6113 - accuracy: 0.6481 - val_loss: 0.6910 - val_accuracy: 0.5128\n",
      "Epoch 3724/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6117 - accuracy: 0.6481 - val_loss: 0.6328 - val_accuracy: 0.5974\n",
      "Epoch 3725/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6104 - accuracy: 0.6478 - val_loss: 0.6742 - val_accuracy: 0.5373\n",
      "Epoch 3726/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6086 - accuracy: 0.6531 - val_loss: 0.6548 - val_accuracy: 0.5639\n",
      "Epoch 3727/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6078 - accuracy: 0.6537 - val_loss: 0.6465 - val_accuracy: 0.5747\n",
      "Epoch 3728/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6510 - val_loss: 0.6719 - val_accuracy: 0.5398\n",
      "Epoch 3729/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6533 - val_loss: 0.6405 - val_accuracy: 0.5837\n",
      "Epoch 3730/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6096 - accuracy: 0.6501 - val_loss: 0.6843 - val_accuracy: 0.5206\n",
      "Epoch 3731/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6101 - accuracy: 0.6512 - val_loss: 0.6324 - val_accuracy: 0.5972\n",
      "Epoch 3732/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6100 - accuracy: 0.6486 - val_loss: 0.6782 - val_accuracy: 0.5336\n",
      "Epoch 3733/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6090 - accuracy: 0.6526 - val_loss: 0.6467 - val_accuracy: 0.5745\n",
      "Epoch 3734/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6084 - accuracy: 0.6521 - val_loss: 0.6623 - val_accuracy: 0.5519\n",
      "Epoch 3735/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6077 - accuracy: 0.6545 - val_loss: 0.6567 - val_accuracy: 0.5607\n",
      "Epoch 3736/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6075 - accuracy: 0.6540 - val_loss: 0.6501 - val_accuracy: 0.5683\n",
      "Epoch 3737/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6530 - val_loss: 0.6718 - val_accuracy: 0.5420\n",
      "Epoch 3738/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6080 - accuracy: 0.6542 - val_loss: 0.6403 - val_accuracy: 0.5853\n",
      "Epoch 3739/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6086 - accuracy: 0.6501 - val_loss: 0.6753 - val_accuracy: 0.5367\n",
      "Epoch 3740/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6086 - accuracy: 0.6533 - val_loss: 0.6412 - val_accuracy: 0.5839\n",
      "Epoch 3741/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6507 - val_loss: 0.6737 - val_accuracy: 0.5376\n",
      "Epoch 3742/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6083 - accuracy: 0.6533 - val_loss: 0.6453 - val_accuracy: 0.5769\n",
      "Epoch 3743/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6080 - accuracy: 0.6502 - val_loss: 0.6660 - val_accuracy: 0.5508\n",
      "Epoch 3744/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6076 - accuracy: 0.6546 - val_loss: 0.6538 - val_accuracy: 0.5652\n",
      "Epoch 3745/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6073 - accuracy: 0.6538 - val_loss: 0.6549 - val_accuracy: 0.5641\n",
      "Epoch 3746/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6074 - accuracy: 0.6527 - val_loss: 0.6630 - val_accuracy: 0.5519\n",
      "Epoch 3747/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6541 - val_loss: 0.6499 - val_accuracy: 0.5718\n",
      "Epoch 3748/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6077 - accuracy: 0.6527 - val_loss: 0.6698 - val_accuracy: 0.5451\n",
      "Epoch 3749/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6078 - accuracy: 0.6534 - val_loss: 0.6405 - val_accuracy: 0.5849\n",
      "Epoch 3750/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6084 - accuracy: 0.6502 - val_loss: 0.6781 - val_accuracy: 0.5347\n",
      "Epoch 3751/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6532 - val_loss: 0.6414 - val_accuracy: 0.5844\n",
      "Epoch 3752/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6086 - accuracy: 0.6508 - val_loss: 0.6755 - val_accuracy: 0.5364\n",
      "Epoch 3753/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6087 - accuracy: 0.6522 - val_loss: 0.6420 - val_accuracy: 0.5833\n",
      "Epoch 3754/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6081 - accuracy: 0.6501 - val_loss: 0.6689 - val_accuracy: 0.5471\n",
      "Epoch 3755/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6080 - accuracy: 0.6539 - val_loss: 0.6525 - val_accuracy: 0.5658\n",
      "Epoch 3756/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6073 - accuracy: 0.6534 - val_loss: 0.6573 - val_accuracy: 0.5605\n",
      "Epoch 3757/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6524 - val_loss: 0.6630 - val_accuracy: 0.5537\n",
      "Epoch 3758/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6072 - accuracy: 0.6542 - val_loss: 0.6464 - val_accuracy: 0.5782\n",
      "Epoch 3759/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6083 - accuracy: 0.6527 - val_loss: 0.6785 - val_accuracy: 0.5311\n",
      "Epoch 3760/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6088 - accuracy: 0.6530 - val_loss: 0.6325 - val_accuracy: 0.5955\n",
      "Epoch 3761/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6104 - accuracy: 0.6476 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 3762/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6116 - accuracy: 0.6485 - val_loss: 0.6322 - val_accuracy: 0.6034\n",
      "Epoch 3763/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6112 - accuracy: 0.6487 - val_loss: 0.6832 - val_accuracy: 0.5296\n",
      "Epoch 3764/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6111 - accuracy: 0.6499 - val_loss: 0.6485 - val_accuracy: 0.5694\n",
      "Epoch 3765/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6100 - accuracy: 0.6473 - val_loss: 0.6590 - val_accuracy: 0.5561\n",
      "Epoch 3766/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6085 - accuracy: 0.6529 - val_loss: 0.6658 - val_accuracy: 0.5497\n",
      "Epoch 3767/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6089 - accuracy: 0.6526 - val_loss: 0.6425 - val_accuracy: 0.5767\n",
      "Epoch 3768/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6495 - val_loss: 0.6720 - val_accuracy: 0.5382\n",
      "Epoch 3769/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6088 - accuracy: 0.6520 - val_loss: 0.6483 - val_accuracy: 0.5723\n",
      "Epoch 3770/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6087 - accuracy: 0.6516 - val_loss: 0.6705 - val_accuracy: 0.5431\n",
      "Epoch 3771/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6078 - accuracy: 0.6541 - val_loss: 0.6455 - val_accuracy: 0.5734\n",
      "Epoch 3772/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6083 - accuracy: 0.6509 - val_loss: 0.6610 - val_accuracy: 0.5522\n",
      "Epoch 3773/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6074 - accuracy: 0.6531 - val_loss: 0.6536 - val_accuracy: 0.5649\n",
      "Epoch 3774/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6078 - accuracy: 0.6529 - val_loss: 0.6626 - val_accuracy: 0.5533\n",
      "Epoch 3775/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6072 - accuracy: 0.6541 - val_loss: 0.6539 - val_accuracy: 0.5627\n",
      "Epoch 3776/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6074 - accuracy: 0.6526 - val_loss: 0.6555 - val_accuracy: 0.5621\n",
      "Epoch 3777/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6073 - accuracy: 0.6552 - val_loss: 0.6591 - val_accuracy: 0.5594\n",
      "Epoch 3778/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6072 - accuracy: 0.6537 - val_loss: 0.6574 - val_accuracy: 0.5588\n",
      "Epoch 3779/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6072 - accuracy: 0.6529 - val_loss: 0.6600 - val_accuracy: 0.5564\n",
      "Epoch 3780/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6542 - val_loss: 0.6481 - val_accuracy: 0.5753\n",
      "Epoch 3781/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6073 - accuracy: 0.6534 - val_loss: 0.6677 - val_accuracy: 0.5480\n",
      "Epoch 3782/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6073 - accuracy: 0.6545 - val_loss: 0.6473 - val_accuracy: 0.5738\n",
      "Epoch 3783/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6508 - val_loss: 0.6738 - val_accuracy: 0.5406\n",
      "Epoch 3784/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6081 - accuracy: 0.6541 - val_loss: 0.6374 - val_accuracy: 0.5904\n",
      "Epoch 3785/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6084 - accuracy: 0.6509 - val_loss: 0.6809 - val_accuracy: 0.5285\n",
      "Epoch 3786/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6090 - accuracy: 0.6524 - val_loss: 0.6380 - val_accuracy: 0.5886\n",
      "Epoch 3787/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6089 - accuracy: 0.6493 - val_loss: 0.6814 - val_accuracy: 0.5274\n",
      "Epoch 3788/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6095 - accuracy: 0.6521 - val_loss: 0.6360 - val_accuracy: 0.5954\n",
      "Epoch 3789/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6087 - accuracy: 0.6509 - val_loss: 0.6779 - val_accuracy: 0.5336\n",
      "Epoch 3790/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6087 - accuracy: 0.6527 - val_loss: 0.6454 - val_accuracy: 0.5756\n",
      "Epoch 3791/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6076 - accuracy: 0.6509 - val_loss: 0.6645 - val_accuracy: 0.5522\n",
      "Epoch 3792/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6078 - accuracy: 0.6543 - val_loss: 0.6546 - val_accuracy: 0.5639\n",
      "Epoch 3793/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6069 - accuracy: 0.6541 - val_loss: 0.6545 - val_accuracy: 0.5605\n",
      "Epoch 3794/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6077 - accuracy: 0.6530 - val_loss: 0.6703 - val_accuracy: 0.5448\n",
      "Epoch 3795/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6076 - accuracy: 0.6542 - val_loss: 0.6365 - val_accuracy: 0.5950\n",
      "Epoch 3796/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6091 - accuracy: 0.6503 - val_loss: 0.6901 - val_accuracy: 0.5188\n",
      "Epoch 3797/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6108 - accuracy: 0.6493 - val_loss: 0.6310 - val_accuracy: 0.6007\n",
      "Epoch 3798/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6116 - accuracy: 0.6475 - val_loss: 0.6944 - val_accuracy: 0.5135\n",
      "Epoch 3799/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6476 - val_loss: 0.6308 - val_accuracy: 0.6038\n",
      "Epoch 3800/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6122 - accuracy: 0.6479 - val_loss: 0.6774 - val_accuracy: 0.5351\n",
      "Epoch 3801/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6099 - accuracy: 0.6513 - val_loss: 0.6591 - val_accuracy: 0.5535\n",
      "Epoch 3802/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6109 - accuracy: 0.6492 - val_loss: 0.6562 - val_accuracy: 0.5650\n",
      "Epoch 3803/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6094 - accuracy: 0.6516 - val_loss: 0.6594 - val_accuracy: 0.5597\n",
      "Epoch 3804/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6111 - accuracy: 0.6513 - val_loss: 0.6573 - val_accuracy: 0.5575\n",
      "Epoch 3805/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6530 - val_loss: 0.6506 - val_accuracy: 0.5665\n",
      "Epoch 3806/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6122 - accuracy: 0.6475 - val_loss: 0.6877 - val_accuracy: 0.5221\n",
      "Epoch 3807/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6120 - accuracy: 0.6492 - val_loss: 0.6249 - val_accuracy: 0.6145\n",
      "Epoch 3808/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6188 - accuracy: 0.6407 - val_loss: 0.7128 - val_accuracy: 0.4974\n",
      "Epoch 3809/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6181 - accuracy: 0.6423 - val_loss: 0.6411 - val_accuracy: 0.5884\n",
      "Epoch 3810/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6230 - accuracy: 0.6394 - val_loss: 0.6870 - val_accuracy: 0.5205\n",
      "Epoch 3811/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6487 - val_loss: 0.6387 - val_accuracy: 0.6008\n",
      "Epoch 3812/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6237 - accuracy: 0.6375 - val_loss: 0.6980 - val_accuracy: 0.5077\n",
      "Epoch 3813/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6447 - val_loss: 0.6292 - val_accuracy: 0.6007\n",
      "Epoch 3814/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6177 - accuracy: 0.6411 - val_loss: 0.6910 - val_accuracy: 0.5115\n",
      "Epoch 3815/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6152 - accuracy: 0.6455 - val_loss: 0.6627 - val_accuracy: 0.5508\n",
      "Epoch 3816/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6093 - accuracy: 0.6522 - val_loss: 0.6271 - val_accuracy: 0.6080\n",
      "Epoch 3817/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6167 - accuracy: 0.6424 - val_loss: 0.7198 - val_accuracy: 0.4814\n",
      "Epoch 3818/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6215 - accuracy: 0.6380 - val_loss: 0.6383 - val_accuracy: 0.5923\n",
      "Epoch 3819/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6214 - accuracy: 0.6414 - val_loss: 0.6649 - val_accuracy: 0.5440\n",
      "Epoch 3820/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6104 - accuracy: 0.6508 - val_loss: 0.6591 - val_accuracy: 0.5563\n",
      "Epoch 3821/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6165 - accuracy: 0.6470 - val_loss: 0.6558 - val_accuracy: 0.5607\n",
      "Epoch 3822/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6116 - accuracy: 0.6496 - val_loss: 0.6426 - val_accuracy: 0.5727\n",
      "Epoch 3823/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6123 - accuracy: 0.6461 - val_loss: 0.6850 - val_accuracy: 0.5206\n",
      "Epoch 3824/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6138 - accuracy: 0.6460 - val_loss: 0.6620 - val_accuracy: 0.5512\n",
      "Epoch 3825/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6094 - accuracy: 0.6508 - val_loss: 0.6373 - val_accuracy: 0.5890\n",
      "Epoch 3826/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6122 - accuracy: 0.6485 - val_loss: 0.6871 - val_accuracy: 0.5163\n",
      "Epoch 3827/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6142 - accuracy: 0.6480 - val_loss: 0.6285 - val_accuracy: 0.6036\n",
      "Epoch 3828/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6135 - accuracy: 0.6466 - val_loss: 0.6793 - val_accuracy: 0.5259\n",
      "Epoch 3829/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6096 - accuracy: 0.6516 - val_loss: 0.6617 - val_accuracy: 0.5554\n",
      "Epoch 3830/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6092 - accuracy: 0.6523 - val_loss: 0.6384 - val_accuracy: 0.5862\n",
      "Epoch 3831/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6089 - accuracy: 0.6502 - val_loss: 0.6758 - val_accuracy: 0.5334\n",
      "Epoch 3832/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6106 - accuracy: 0.6515 - val_loss: 0.6408 - val_accuracy: 0.5807\n",
      "Epoch 3833/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6096 - accuracy: 0.6504 - val_loss: 0.6653 - val_accuracy: 0.5482\n",
      "Epoch 3834/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6084 - accuracy: 0.6529 - val_loss: 0.6626 - val_accuracy: 0.5524\n",
      "Epoch 3835/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6081 - accuracy: 0.6528 - val_loss: 0.6403 - val_accuracy: 0.5835\n",
      "Epoch 3836/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6090 - accuracy: 0.6501 - val_loss: 0.6775 - val_accuracy: 0.5300\n",
      "Epoch 3837/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6092 - accuracy: 0.6517 - val_loss: 0.6384 - val_accuracy: 0.5897\n",
      "Epoch 3838/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6513 - val_loss: 0.6716 - val_accuracy: 0.5391\n",
      "Epoch 3839/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6082 - accuracy: 0.6525 - val_loss: 0.6503 - val_accuracy: 0.5680\n",
      "Epoch 3840/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6509 - val_loss: 0.6562 - val_accuracy: 0.5608\n",
      "Epoch 3841/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6071 - accuracy: 0.6537 - val_loss: 0.6671 - val_accuracy: 0.5469\n",
      "Epoch 3842/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6077 - accuracy: 0.6544 - val_loss: 0.6440 - val_accuracy: 0.5787\n",
      "Epoch 3843/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6074 - accuracy: 0.6508 - val_loss: 0.6663 - val_accuracy: 0.5451\n",
      "Epoch 3844/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6537 - val_loss: 0.6534 - val_accuracy: 0.5641\n",
      "Epoch 3845/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6072 - accuracy: 0.6521 - val_loss: 0.6571 - val_accuracy: 0.5632\n",
      "Epoch 3846/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6607 - val_accuracy: 0.5586\n",
      "Epoch 3847/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6070 - accuracy: 0.6553 - val_loss: 0.6472 - val_accuracy: 0.5731\n",
      "Epoch 3848/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6074 - accuracy: 0.6517 - val_loss: 0.6715 - val_accuracy: 0.5448\n",
      "Epoch 3849/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6075 - accuracy: 0.6543 - val_loss: 0.6460 - val_accuracy: 0.5753\n",
      "Epoch 3850/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6076 - accuracy: 0.6517 - val_loss: 0.6687 - val_accuracy: 0.5448\n",
      "Epoch 3851/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6540 - val_loss: 0.6474 - val_accuracy: 0.5727\n",
      "Epoch 3852/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6513 - val_loss: 0.6647 - val_accuracy: 0.5528\n",
      "Epoch 3853/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6541 - val_loss: 0.6559 - val_accuracy: 0.5647\n",
      "Epoch 3854/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6068 - accuracy: 0.6535 - val_loss: 0.6545 - val_accuracy: 0.5634\n",
      "Epoch 3855/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6066 - accuracy: 0.6535 - val_loss: 0.6587 - val_accuracy: 0.5561\n",
      "Epoch 3856/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6067 - accuracy: 0.6543 - val_loss: 0.6525 - val_accuracy: 0.5670\n",
      "Epoch 3857/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6539 - val_loss: 0.6658 - val_accuracy: 0.5515\n",
      "Epoch 3858/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6550 - val_loss: 0.6506 - val_accuracy: 0.5722\n",
      "Epoch 3859/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6067 - accuracy: 0.6526 - val_loss: 0.6624 - val_accuracy: 0.5552\n",
      "Epoch 3860/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6547 - val_loss: 0.6511 - val_accuracy: 0.5685\n",
      "Epoch 3861/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6067 - accuracy: 0.6546 - val_loss: 0.6626 - val_accuracy: 0.5548\n",
      "Epoch 3862/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6549 - val_loss: 0.6542 - val_accuracy: 0.5643\n",
      "Epoch 3863/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6066 - accuracy: 0.6537 - val_loss: 0.6601 - val_accuracy: 0.5568\n",
      "Epoch 3864/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6065 - accuracy: 0.6547 - val_loss: 0.6553 - val_accuracy: 0.5638\n",
      "Epoch 3865/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6065 - accuracy: 0.6551 - val_loss: 0.6558 - val_accuracy: 0.5625\n",
      "Epoch 3866/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6064 - accuracy: 0.6549 - val_loss: 0.6592 - val_accuracy: 0.5575\n",
      "Epoch 3867/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6064 - accuracy: 0.6545 - val_loss: 0.6564 - val_accuracy: 0.5612\n",
      "Epoch 3868/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6064 - accuracy: 0.6543 - val_loss: 0.6605 - val_accuracy: 0.5568\n",
      "Epoch 3869/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6065 - accuracy: 0.6553 - val_loss: 0.6511 - val_accuracy: 0.5685\n",
      "Epoch 3870/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6065 - accuracy: 0.6531 - val_loss: 0.6629 - val_accuracy: 0.5548\n",
      "Epoch 3871/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6065 - accuracy: 0.6547 - val_loss: 0.6519 - val_accuracy: 0.5689\n",
      "Epoch 3872/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6535 - val_loss: 0.6638 - val_accuracy: 0.5535\n",
      "Epoch 3873/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6552 - val_loss: 0.6496 - val_accuracy: 0.5711\n",
      "Epoch 3874/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6533 - val_loss: 0.6658 - val_accuracy: 0.5502\n",
      "Epoch 3875/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6549 - val_loss: 0.6472 - val_accuracy: 0.5749\n",
      "Epoch 3876/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6525 - val_loss: 0.6688 - val_accuracy: 0.5480\n",
      "Epoch 3877/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6069 - accuracy: 0.6546 - val_loss: 0.6447 - val_accuracy: 0.5809\n",
      "Epoch 3878/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6070 - accuracy: 0.6520 - val_loss: 0.6725 - val_accuracy: 0.5422\n",
      "Epoch 3879/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6545 - val_loss: 0.6423 - val_accuracy: 0.5820\n",
      "Epoch 3880/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6511 - val_loss: 0.6746 - val_accuracy: 0.5391\n",
      "Epoch 3881/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6076 - accuracy: 0.6542 - val_loss: 0.6402 - val_accuracy: 0.5859\n",
      "Epoch 3882/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6507 - val_loss: 0.6749 - val_accuracy: 0.5389\n",
      "Epoch 3883/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6075 - accuracy: 0.6539 - val_loss: 0.6430 - val_accuracy: 0.5815\n",
      "Epoch 3884/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6511 - val_loss: 0.6734 - val_accuracy: 0.5406\n",
      "Epoch 3885/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6075 - accuracy: 0.6545 - val_loss: 0.6412 - val_accuracy: 0.5837\n",
      "Epoch 3886/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6507 - val_loss: 0.6723 - val_accuracy: 0.5424\n",
      "Epoch 3887/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6072 - accuracy: 0.6541 - val_loss: 0.6463 - val_accuracy: 0.5780\n",
      "Epoch 3888/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6069 - accuracy: 0.6522 - val_loss: 0.6679 - val_accuracy: 0.5473\n",
      "Epoch 3889/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6069 - accuracy: 0.6548 - val_loss: 0.6472 - val_accuracy: 0.5769\n",
      "Epoch 3890/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6528 - val_loss: 0.6645 - val_accuracy: 0.5515\n",
      "Epoch 3891/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6066 - accuracy: 0.6544 - val_loss: 0.6533 - val_accuracy: 0.5663\n",
      "Epoch 3892/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6063 - accuracy: 0.6545 - val_loss: 0.6566 - val_accuracy: 0.5623\n",
      "Epoch 3893/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6063 - accuracy: 0.6548 - val_loss: 0.6606 - val_accuracy: 0.5550\n",
      "Epoch 3894/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6557 - val_loss: 0.6506 - val_accuracy: 0.5698\n",
      "Epoch 3895/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6065 - accuracy: 0.6534 - val_loss: 0.6681 - val_accuracy: 0.5482\n",
      "Epoch 3896/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6068 - accuracy: 0.6549 - val_loss: 0.6422 - val_accuracy: 0.5818\n",
      "Epoch 3897/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6072 - accuracy: 0.6511 - val_loss: 0.6798 - val_accuracy: 0.5332\n",
      "Epoch 3898/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6080 - accuracy: 0.6533 - val_loss: 0.6367 - val_accuracy: 0.5921\n",
      "Epoch 3899/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6084 - accuracy: 0.6496 - val_loss: 0.6864 - val_accuracy: 0.5230\n",
      "Epoch 3900/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6099 - accuracy: 0.6511 - val_loss: 0.6308 - val_accuracy: 0.6023\n",
      "Epoch 3901/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6492 - val_loss: 0.6858 - val_accuracy: 0.5241\n",
      "Epoch 3902/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6094 - accuracy: 0.6508 - val_loss: 0.6441 - val_accuracy: 0.5771\n",
      "Epoch 3903/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6499 - val_loss: 0.6627 - val_accuracy: 0.5552\n",
      "Epoch 3904/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6074 - accuracy: 0.6553 - val_loss: 0.6574 - val_accuracy: 0.5597\n",
      "Epoch 3905/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6067 - accuracy: 0.6548 - val_loss: 0.6460 - val_accuracy: 0.5745\n",
      "Epoch 3906/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6080 - accuracy: 0.6508 - val_loss: 0.6835 - val_accuracy: 0.5250\n",
      "Epoch 3907/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6088 - accuracy: 0.6518 - val_loss: 0.6279 - val_accuracy: 0.6072\n",
      "Epoch 3908/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6111 - accuracy: 0.6486 - val_loss: 0.7022 - val_accuracy: 0.5057\n",
      "Epoch 3909/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6129 - accuracy: 0.6474 - val_loss: 0.6299 - val_accuracy: 0.6008\n",
      "Epoch 3910/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6113 - accuracy: 0.6477 - val_loss: 0.6798 - val_accuracy: 0.5312\n",
      "Epoch 3911/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6097 - accuracy: 0.6523 - val_loss: 0.6454 - val_accuracy: 0.5773\n",
      "Epoch 3912/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6087 - accuracy: 0.6504 - val_loss: 0.6567 - val_accuracy: 0.5588\n",
      "Epoch 3913/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6067 - accuracy: 0.6542 - val_loss: 0.6706 - val_accuracy: 0.5415\n",
      "Epoch 3914/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6085 - accuracy: 0.6521 - val_loss: 0.6424 - val_accuracy: 0.5818\n",
      "Epoch 3915/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6076 - accuracy: 0.6519 - val_loss: 0.6704 - val_accuracy: 0.5451\n",
      "Epoch 3916/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6081 - accuracy: 0.6541 - val_loss: 0.6470 - val_accuracy: 0.5769\n",
      "Epoch 3917/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6069 - accuracy: 0.6522 - val_loss: 0.6669 - val_accuracy: 0.5440\n",
      "Epoch 3918/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6072 - accuracy: 0.6534 - val_loss: 0.6506 - val_accuracy: 0.5698\n",
      "Epoch 3919/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6064 - accuracy: 0.6536 - val_loss: 0.6555 - val_accuracy: 0.5632\n",
      "Epoch 3920/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6541 - val_loss: 0.6635 - val_accuracy: 0.5532\n",
      "Epoch 3921/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6064 - accuracy: 0.6544 - val_loss: 0.6471 - val_accuracy: 0.5734\n",
      "Epoch 3922/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6069 - accuracy: 0.6515 - val_loss: 0.6713 - val_accuracy: 0.5438\n",
      "Epoch 3923/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6548 - val_loss: 0.6384 - val_accuracy: 0.5902\n",
      "Epoch 3924/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6079 - accuracy: 0.6516 - val_loss: 0.6816 - val_accuracy: 0.5320\n",
      "Epoch 3925/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6085 - accuracy: 0.6525 - val_loss: 0.6414 - val_accuracy: 0.5824\n",
      "Epoch 3926/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6081 - accuracy: 0.6501 - val_loss: 0.6748 - val_accuracy: 0.5409\n",
      "Epoch 3927/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6087 - accuracy: 0.6539 - val_loss: 0.6407 - val_accuracy: 0.5868\n",
      "Epoch 3928/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6081 - accuracy: 0.6515 - val_loss: 0.6685 - val_accuracy: 0.5453\n",
      "Epoch 3929/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6525 - val_loss: 0.6567 - val_accuracy: 0.5605\n",
      "Epoch 3930/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6522 - val_loss: 0.6581 - val_accuracy: 0.5612\n",
      "Epoch 3931/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6534 - val_loss: 0.6580 - val_accuracy: 0.5608\n",
      "Epoch 3932/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6075 - accuracy: 0.6541 - val_loss: 0.6501 - val_accuracy: 0.5685\n",
      "Epoch 3933/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6071 - accuracy: 0.6514 - val_loss: 0.6697 - val_accuracy: 0.5455\n",
      "Epoch 3934/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6545 - val_loss: 0.6467 - val_accuracy: 0.5753\n",
      "Epoch 3935/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6074 - accuracy: 0.6526 - val_loss: 0.6694 - val_accuracy: 0.5460\n",
      "Epoch 3936/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6544 - val_loss: 0.6424 - val_accuracy: 0.5800\n",
      "Epoch 3937/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6074 - accuracy: 0.6508 - val_loss: 0.6752 - val_accuracy: 0.5389\n",
      "Epoch 3938/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6073 - accuracy: 0.6542 - val_loss: 0.6400 - val_accuracy: 0.5862\n",
      "Epoch 3939/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6077 - accuracy: 0.6512 - val_loss: 0.6798 - val_accuracy: 0.5338\n",
      "Epoch 3940/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6080 - accuracy: 0.6530 - val_loss: 0.6376 - val_accuracy: 0.5893\n",
      "Epoch 3941/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6082 - accuracy: 0.6500 - val_loss: 0.6818 - val_accuracy: 0.5294\n",
      "Epoch 3942/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6083 - accuracy: 0.6532 - val_loss: 0.6362 - val_accuracy: 0.5941\n",
      "Epoch 3943/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6081 - accuracy: 0.6519 - val_loss: 0.6798 - val_accuracy: 0.5331\n",
      "Epoch 3944/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6083 - accuracy: 0.6524 - val_loss: 0.6432 - val_accuracy: 0.5800\n",
      "Epoch 3945/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6501 - val_loss: 0.6697 - val_accuracy: 0.5477\n",
      "Epoch 3946/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6545 - val_loss: 0.6499 - val_accuracy: 0.5720\n",
      "Epoch 3947/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6066 - accuracy: 0.6539 - val_loss: 0.6558 - val_accuracy: 0.5634\n",
      "Epoch 3948/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6069 - accuracy: 0.6524 - val_loss: 0.6649 - val_accuracy: 0.5521\n",
      "Epoch 3949/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6552 - val_loss: 0.6462 - val_accuracy: 0.5787\n",
      "Epoch 3950/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6538 - val_loss: 0.6762 - val_accuracy: 0.5356\n",
      "Epoch 3951/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6077 - accuracy: 0.6538 - val_loss: 0.6332 - val_accuracy: 0.5943\n",
      "Epoch 3952/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6089 - accuracy: 0.6491 - val_loss: 0.6916 - val_accuracy: 0.5172\n",
      "Epoch 3953/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6100 - accuracy: 0.6510 - val_loss: 0.6312 - val_accuracy: 0.6041\n",
      "Epoch 3954/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6102 - accuracy: 0.6497 - val_loss: 0.6873 - val_accuracy: 0.5216\n",
      "Epoch 3955/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6100 - accuracy: 0.6509 - val_loss: 0.6386 - val_accuracy: 0.5870\n",
      "Epoch 3956/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6087 - accuracy: 0.6490 - val_loss: 0.6700 - val_accuracy: 0.5468\n",
      "Epoch 3957/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6077 - accuracy: 0.6538 - val_loss: 0.6570 - val_accuracy: 0.5596\n",
      "Epoch 3958/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6070 - accuracy: 0.6545 - val_loss: 0.6463 - val_accuracy: 0.5745\n",
      "Epoch 3959/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6076 - accuracy: 0.6498 - val_loss: 0.6755 - val_accuracy: 0.5374\n",
      "Epoch 3960/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6079 - accuracy: 0.6527 - val_loss: 0.6386 - val_accuracy: 0.5915\n",
      "Epoch 3961/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6088 - accuracy: 0.6519 - val_loss: 0.6883 - val_accuracy: 0.5206\n",
      "Epoch 3962/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6097 - accuracy: 0.6506 - val_loss: 0.6281 - val_accuracy: 0.6036\n",
      "Epoch 3963/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6487 - val_loss: 0.6862 - val_accuracy: 0.5230\n",
      "Epoch 3964/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6511 - val_loss: 0.6406 - val_accuracy: 0.5855\n",
      "Epoch 3965/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6537 - val_loss: 0.6662 - val_accuracy: 0.5499\n",
      "Epoch 3966/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6550 - val_loss: 0.6546 - val_accuracy: 0.5634\n",
      "Epoch 3967/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6063 - accuracy: 0.6537 - val_loss: 0.6504 - val_accuracy: 0.5683\n",
      "Epoch 3968/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6065 - accuracy: 0.6542 - val_loss: 0.6726 - val_accuracy: 0.5404\n",
      "Epoch 3969/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6070 - accuracy: 0.6560 - val_loss: 0.6345 - val_accuracy: 0.5944\n",
      "Epoch 3970/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6080 - accuracy: 0.6497 - val_loss: 0.6855 - val_accuracy: 0.5248\n",
      "Epoch 3971/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6087 - accuracy: 0.6516 - val_loss: 0.6352 - val_accuracy: 0.5961\n",
      "Epoch 3972/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6088 - accuracy: 0.6509 - val_loss: 0.6848 - val_accuracy: 0.5252\n",
      "Epoch 3973/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6093 - accuracy: 0.6514 - val_loss: 0.6341 - val_accuracy: 0.5944\n",
      "Epoch 3974/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6081 - accuracy: 0.6498 - val_loss: 0.6739 - val_accuracy: 0.5376\n",
      "Epoch 3975/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6072 - accuracy: 0.6535 - val_loss: 0.6536 - val_accuracy: 0.5654\n",
      "Epoch 3976/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6494 - val_accuracy: 0.5722\n",
      "Epoch 3977/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6527 - val_loss: 0.6697 - val_accuracy: 0.5438\n",
      "Epoch 3978/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6542 - val_loss: 0.6400 - val_accuracy: 0.5875\n",
      "Epoch 3979/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6520 - val_loss: 0.6887 - val_accuracy: 0.5185\n",
      "Epoch 3980/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6506 - val_loss: 0.6256 - val_accuracy: 0.6100\n",
      "Epoch 3981/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6101 - accuracy: 0.6492 - val_loss: 0.6929 - val_accuracy: 0.5164\n",
      "Epoch 3982/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6102 - accuracy: 0.6508 - val_loss: 0.6399 - val_accuracy: 0.5881\n",
      "Epoch 3983/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6082 - accuracy: 0.6522 - val_loss: 0.6666 - val_accuracy: 0.5471\n",
      "Epoch 3984/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6074 - accuracy: 0.6539 - val_loss: 0.6534 - val_accuracy: 0.5647\n",
      "Epoch 3985/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6064 - accuracy: 0.6535 - val_loss: 0.6487 - val_accuracy: 0.5731\n",
      "Epoch 3986/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6536 - val_loss: 0.6822 - val_accuracy: 0.5298\n",
      "Epoch 3987/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6080 - accuracy: 0.6524 - val_loss: 0.6275 - val_accuracy: 0.6049\n",
      "Epoch 3988/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6102 - accuracy: 0.6487 - val_loss: 0.6978 - val_accuracy: 0.5090\n",
      "Epoch 3989/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6114 - accuracy: 0.6494 - val_loss: 0.6325 - val_accuracy: 0.5985\n",
      "Epoch 3990/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6100 - accuracy: 0.6499 - val_loss: 0.6782 - val_accuracy: 0.5354\n",
      "Epoch 3991/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6526 - val_loss: 0.6448 - val_accuracy: 0.5778\n",
      "Epoch 3992/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6506 - val_loss: 0.6565 - val_accuracy: 0.5605\n",
      "Epoch 3993/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6066 - accuracy: 0.6546 - val_loss: 0.6733 - val_accuracy: 0.5400\n",
      "Epoch 3994/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6070 - accuracy: 0.6535 - val_loss: 0.6340 - val_accuracy: 0.5954\n",
      "Epoch 3995/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6498 - val_loss: 0.6876 - val_accuracy: 0.5194\n",
      "Epoch 3996/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6096 - accuracy: 0.6509 - val_loss: 0.6324 - val_accuracy: 0.5988\n",
      "Epoch 3997/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6096 - accuracy: 0.6498 - val_loss: 0.6852 - val_accuracy: 0.5248\n",
      "Epoch 3998/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6090 - accuracy: 0.6517 - val_loss: 0.6372 - val_accuracy: 0.5884\n",
      "Epoch 3999/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6077 - accuracy: 0.6501 - val_loss: 0.6649 - val_accuracy: 0.5512\n",
      "Epoch 4000/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6061 - accuracy: 0.6558 - val_loss: 0.6611 - val_accuracy: 0.5555\n",
      "Epoch 4001/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6063 - accuracy: 0.6554 - val_loss: 0.6444 - val_accuracy: 0.5778\n",
      "Epoch 4002/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6066 - accuracy: 0.6528 - val_loss: 0.6740 - val_accuracy: 0.5378\n",
      "Epoch 4003/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6073 - accuracy: 0.6545 - val_loss: 0.6377 - val_accuracy: 0.5917\n",
      "Epoch 4004/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6078 - accuracy: 0.6515 - val_loss: 0.6843 - val_accuracy: 0.5259\n",
      "Epoch 4005/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6084 - accuracy: 0.6520 - val_loss: 0.6353 - val_accuracy: 0.5913\n",
      "Epoch 4006/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6492 - val_loss: 0.6730 - val_accuracy: 0.5395\n",
      "Epoch 4007/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6068 - accuracy: 0.6548 - val_loss: 0.6476 - val_accuracy: 0.5756\n",
      "Epoch 4008/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6542 - val_loss: 0.6598 - val_accuracy: 0.5581\n",
      "Epoch 4009/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6059 - accuracy: 0.6551 - val_loss: 0.6588 - val_accuracy: 0.5581\n",
      "Epoch 4010/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6058 - accuracy: 0.6555 - val_loss: 0.6491 - val_accuracy: 0.5729\n",
      "Epoch 4011/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6541 - val_loss: 0.6691 - val_accuracy: 0.5444\n",
      "Epoch 4012/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6552 - val_loss: 0.6412 - val_accuracy: 0.5833\n",
      "Epoch 4013/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6067 - accuracy: 0.6511 - val_loss: 0.6758 - val_accuracy: 0.5385\n",
      "Epoch 4014/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6069 - accuracy: 0.6542 - val_loss: 0.6408 - val_accuracy: 0.5855\n",
      "Epoch 4015/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6070 - accuracy: 0.6531 - val_loss: 0.6765 - val_accuracy: 0.5371\n",
      "Epoch 4016/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6539 - val_loss: 0.6393 - val_accuracy: 0.5840\n",
      "Epoch 4017/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6069 - accuracy: 0.6511 - val_loss: 0.6726 - val_accuracy: 0.5449\n",
      "Epoch 4018/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6067 - accuracy: 0.6558 - val_loss: 0.6480 - val_accuracy: 0.5760\n",
      "Epoch 4019/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6061 - accuracy: 0.6543 - val_loss: 0.6618 - val_accuracy: 0.5574\n",
      "Epoch 4020/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6060 - accuracy: 0.6545 - val_loss: 0.6567 - val_accuracy: 0.5627\n",
      "Epoch 4021/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6056 - accuracy: 0.6559 - val_loss: 0.6507 - val_accuracy: 0.5698\n",
      "Epoch 4022/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6061 - accuracy: 0.6540 - val_loss: 0.6703 - val_accuracy: 0.5442\n",
      "Epoch 4023/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6062 - accuracy: 0.6554 - val_loss: 0.6388 - val_accuracy: 0.5860\n",
      "Epoch 4024/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6506 - val_loss: 0.6860 - val_accuracy: 0.5263\n",
      "Epoch 4025/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6085 - accuracy: 0.6517 - val_loss: 0.6310 - val_accuracy: 0.6041\n",
      "Epoch 4026/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6090 - accuracy: 0.6505 - val_loss: 0.6903 - val_accuracy: 0.5210\n",
      "Epoch 4027/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6099 - accuracy: 0.6505 - val_loss: 0.6356 - val_accuracy: 0.5937\n",
      "Epoch 4028/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6085 - accuracy: 0.6493 - val_loss: 0.6740 - val_accuracy: 0.5415\n",
      "Epoch 4029/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6543 - val_loss: 0.6513 - val_accuracy: 0.5689\n",
      "Epoch 4030/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6548 - val_loss: 0.6509 - val_accuracy: 0.5680\n",
      "Epoch 4031/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6071 - accuracy: 0.6505 - val_loss: 0.6737 - val_accuracy: 0.5393\n",
      "Epoch 4032/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6069 - accuracy: 0.6539 - val_loss: 0.6371 - val_accuracy: 0.5963\n",
      "Epoch 4033/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6089 - accuracy: 0.6516 - val_loss: 0.6909 - val_accuracy: 0.5168\n",
      "Epoch 4034/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6501 - val_loss: 0.6267 - val_accuracy: 0.6074\n",
      "Epoch 4035/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6106 - accuracy: 0.6478 - val_loss: 0.6918 - val_accuracy: 0.5168\n",
      "Epoch 4036/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6100 - accuracy: 0.6505 - val_loss: 0.6370 - val_accuracy: 0.5939\n",
      "Epoch 4037/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6087 - accuracy: 0.6525 - val_loss: 0.6698 - val_accuracy: 0.5444\n",
      "Epoch 4038/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6071 - accuracy: 0.6535 - val_loss: 0.6556 - val_accuracy: 0.5607\n",
      "Epoch 4039/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6067 - accuracy: 0.6522 - val_loss: 0.6480 - val_accuracy: 0.5733\n",
      "Epoch 4040/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6543 - val_loss: 0.6744 - val_accuracy: 0.5389\n",
      "Epoch 4041/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6071 - accuracy: 0.6548 - val_loss: 0.6362 - val_accuracy: 0.5906\n",
      "Epoch 4042/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6078 - accuracy: 0.6503 - val_loss: 0.6823 - val_accuracy: 0.5269\n",
      "Epoch 4043/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6081 - accuracy: 0.6532 - val_loss: 0.6351 - val_accuracy: 0.5976\n",
      "Epoch 4044/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6519 - val_loss: 0.6819 - val_accuracy: 0.5290\n",
      "Epoch 4045/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6078 - accuracy: 0.6531 - val_loss: 0.6391 - val_accuracy: 0.5857\n",
      "Epoch 4046/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6071 - accuracy: 0.6498 - val_loss: 0.6695 - val_accuracy: 0.5457\n",
      "Epoch 4047/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6062 - accuracy: 0.6562 - val_loss: 0.6489 - val_accuracy: 0.5723\n",
      "Epoch 4048/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6059 - accuracy: 0.6542 - val_loss: 0.6568 - val_accuracy: 0.5625\n",
      "Epoch 4049/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6056 - accuracy: 0.6550 - val_loss: 0.6597 - val_accuracy: 0.5585\n",
      "Epoch 4050/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6056 - accuracy: 0.6551 - val_loss: 0.6508 - val_accuracy: 0.5692\n",
      "Epoch 4051/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6057 - accuracy: 0.6553 - val_loss: 0.6678 - val_accuracy: 0.5482\n",
      "Epoch 4052/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6567 - val_loss: 0.6419 - val_accuracy: 0.5824\n",
      "Epoch 4053/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6512 - val_loss: 0.6743 - val_accuracy: 0.5404\n",
      "Epoch 4054/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6065 - accuracy: 0.6549 - val_loss: 0.6405 - val_accuracy: 0.5877\n",
      "Epoch 4055/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6067 - accuracy: 0.6524 - val_loss: 0.6775 - val_accuracy: 0.5367\n",
      "Epoch 4056/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6377 - val_accuracy: 0.5873\n",
      "Epoch 4057/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6069 - accuracy: 0.6505 - val_loss: 0.6771 - val_accuracy: 0.5364\n",
      "Epoch 4058/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6068 - accuracy: 0.6543 - val_loss: 0.6427 - val_accuracy: 0.5833\n",
      "Epoch 4059/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6529 - val_loss: 0.6689 - val_accuracy: 0.5442\n",
      "Epoch 4060/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6544 - val_loss: 0.6481 - val_accuracy: 0.5769\n",
      "Epoch 4061/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6056 - accuracy: 0.6536 - val_loss: 0.6620 - val_accuracy: 0.5563\n",
      "Epoch 4062/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6056 - accuracy: 0.6557 - val_loss: 0.6571 - val_accuracy: 0.5627\n",
      "Epoch 4063/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6561 - val_loss: 0.6508 - val_accuracy: 0.5714\n",
      "Epoch 4064/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6056 - accuracy: 0.6533 - val_loss: 0.6666 - val_accuracy: 0.5506\n",
      "Epoch 4065/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6555 - val_loss: 0.6451 - val_accuracy: 0.5804\n",
      "Epoch 4066/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6541 - val_loss: 0.6758 - val_accuracy: 0.5376\n",
      "Epoch 4067/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6068 - accuracy: 0.6544 - val_loss: 0.6355 - val_accuracy: 0.5917\n",
      "Epoch 4068/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6072 - accuracy: 0.6506 - val_loss: 0.6836 - val_accuracy: 0.5281\n",
      "Epoch 4069/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6079 - accuracy: 0.6524 - val_loss: 0.6368 - val_accuracy: 0.5944\n",
      "Epoch 4070/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6524 - val_loss: 0.6793 - val_accuracy: 0.5332\n",
      "Epoch 4071/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6531 - val_loss: 0.6407 - val_accuracy: 0.5839\n",
      "Epoch 4072/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6066 - accuracy: 0.6507 - val_loss: 0.6691 - val_accuracy: 0.5479\n",
      "Epoch 4073/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6066 - accuracy: 0.6550 - val_loss: 0.6547 - val_accuracy: 0.5650\n",
      "Epoch 4074/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6055 - accuracy: 0.6555 - val_loss: 0.6488 - val_accuracy: 0.5698\n",
      "Epoch 4075/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6510 - val_loss: 0.6713 - val_accuracy: 0.5440\n",
      "Epoch 4076/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6061 - accuracy: 0.6544 - val_loss: 0.6405 - val_accuracy: 0.5908\n",
      "Epoch 4077/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6079 - accuracy: 0.6529 - val_loss: 0.6900 - val_accuracy: 0.5199\n",
      "Epoch 4078/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6093 - accuracy: 0.6513 - val_loss: 0.6238 - val_accuracy: 0.6160\n",
      "Epoch 4079/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6105 - accuracy: 0.6489 - val_loss: 0.6971 - val_accuracy: 0.5126\n",
      "Epoch 4080/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6109 - accuracy: 0.6488 - val_loss: 0.6364 - val_accuracy: 0.5966\n",
      "Epoch 4081/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6091 - accuracy: 0.6529 - val_loss: 0.6707 - val_accuracy: 0.5427\n",
      "Epoch 4082/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6076 - accuracy: 0.6520 - val_loss: 0.6546 - val_accuracy: 0.5638\n",
      "Epoch 4083/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6070 - accuracy: 0.6505 - val_loss: 0.6496 - val_accuracy: 0.5714\n",
      "Epoch 4084/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6552 - val_loss: 0.6778 - val_accuracy: 0.5338\n",
      "Epoch 4085/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6077 - accuracy: 0.6542 - val_loss: 0.6328 - val_accuracy: 0.5959\n",
      "Epoch 4086/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6507 - val_loss: 0.6819 - val_accuracy: 0.5307\n",
      "Epoch 4087/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6081 - accuracy: 0.6530 - val_loss: 0.6399 - val_accuracy: 0.5890\n",
      "Epoch 4088/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6071 - accuracy: 0.6533 - val_loss: 0.6732 - val_accuracy: 0.5395\n",
      "Epoch 4089/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6064 - accuracy: 0.6557 - val_loss: 0.6438 - val_accuracy: 0.5786\n",
      "Epoch 4090/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6059 - accuracy: 0.6526 - val_loss: 0.6608 - val_accuracy: 0.5555\n",
      "Epoch 4091/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6053 - accuracy: 0.6556 - val_loss: 0.6573 - val_accuracy: 0.5614\n",
      "Epoch 4092/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6561 - val_loss: 0.6518 - val_accuracy: 0.5703\n",
      "Epoch 4093/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6555 - val_loss: 0.6649 - val_accuracy: 0.5490\n",
      "Epoch 4094/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6056 - accuracy: 0.6551 - val_loss: 0.6442 - val_accuracy: 0.5804\n",
      "Epoch 4095/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6059 - accuracy: 0.6536 - val_loss: 0.6737 - val_accuracy: 0.5407\n",
      "Epoch 4096/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6064 - accuracy: 0.6556 - val_loss: 0.6386 - val_accuracy: 0.5882\n",
      "Epoch 4097/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6065 - accuracy: 0.6518 - val_loss: 0.6779 - val_accuracy: 0.5358\n",
      "Epoch 4098/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6069 - accuracy: 0.6538 - val_loss: 0.6402 - val_accuracy: 0.5868\n",
      "Epoch 4099/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6066 - accuracy: 0.6521 - val_loss: 0.6768 - val_accuracy: 0.5367\n",
      "Epoch 4100/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6069 - accuracy: 0.6549 - val_loss: 0.6402 - val_accuracy: 0.5857\n",
      "Epoch 4101/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6063 - accuracy: 0.6521 - val_loss: 0.6719 - val_accuracy: 0.5440\n",
      "Epoch 4102/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6545 - val_loss: 0.6466 - val_accuracy: 0.5771\n",
      "Epoch 4103/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6054 - accuracy: 0.6543 - val_loss: 0.6619 - val_accuracy: 0.5564\n",
      "Epoch 4104/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6056 - accuracy: 0.6558 - val_loss: 0.6563 - val_accuracy: 0.5634\n",
      "Epoch 4105/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6050 - accuracy: 0.6558 - val_loss: 0.6531 - val_accuracy: 0.5670\n",
      "Epoch 4106/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6054 - accuracy: 0.6555 - val_loss: 0.6662 - val_accuracy: 0.5486\n",
      "Epoch 4107/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6055 - accuracy: 0.6556 - val_loss: 0.6407 - val_accuracy: 0.5859\n",
      "Epoch 4108/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6521 - val_loss: 0.6815 - val_accuracy: 0.5311\n",
      "Epoch 4109/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6071 - accuracy: 0.6538 - val_loss: 0.6348 - val_accuracy: 0.5963\n",
      "Epoch 4110/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6079 - accuracy: 0.6506 - val_loss: 0.6903 - val_accuracy: 0.5190\n",
      "Epoch 4111/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6099 - accuracy: 0.6502 - val_loss: 0.6268 - val_accuracy: 0.6096\n",
      "Epoch 4112/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6094 - accuracy: 0.6498 - val_loss: 0.6896 - val_accuracy: 0.5214\n",
      "Epoch 4113/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6514 - val_loss: 0.6445 - val_accuracy: 0.5809\n",
      "Epoch 4114/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6512 - val_loss: 0.6595 - val_accuracy: 0.5599\n",
      "Epoch 4115/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6634 - val_accuracy: 0.5554\n",
      "Epoch 4116/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6065 - accuracy: 0.6562 - val_loss: 0.6399 - val_accuracy: 0.5846\n",
      "Epoch 4117/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6511 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 4118/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6094 - accuracy: 0.6511 - val_loss: 0.6263 - val_accuracy: 0.6111\n",
      "Epoch 4119/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6103 - accuracy: 0.6489 - val_loss: 0.6981 - val_accuracy: 0.5097\n",
      "Epoch 4120/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6107 - accuracy: 0.6495 - val_loss: 0.6333 - val_accuracy: 0.5972\n",
      "Epoch 4121/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6083 - accuracy: 0.6494 - val_loss: 0.6696 - val_accuracy: 0.5437\n",
      "Epoch 4122/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6067 - accuracy: 0.6550 - val_loss: 0.6502 - val_accuracy: 0.5705\n",
      "Epoch 4123/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6058 - accuracy: 0.6550 - val_loss: 0.6509 - val_accuracy: 0.5700\n",
      "Epoch 4124/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6556 - val_loss: 0.6765 - val_accuracy: 0.5364\n",
      "Epoch 4125/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6066 - accuracy: 0.6545 - val_loss: 0.6330 - val_accuracy: 0.5965\n",
      "Epoch 4126/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6075 - accuracy: 0.6513 - val_loss: 0.6872 - val_accuracy: 0.5241\n",
      "Epoch 4127/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6511 - val_loss: 0.6338 - val_accuracy: 0.5983\n",
      "Epoch 4128/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6079 - accuracy: 0.6506 - val_loss: 0.6794 - val_accuracy: 0.5323\n",
      "Epoch 4129/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6074 - accuracy: 0.6539 - val_loss: 0.6392 - val_accuracy: 0.5864\n",
      "Epoch 4130/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6062 - accuracy: 0.6519 - val_loss: 0.6675 - val_accuracy: 0.5502\n",
      "Epoch 4131/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6055 - accuracy: 0.6562 - val_loss: 0.6558 - val_accuracy: 0.5634\n",
      "Epoch 4132/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6050 - accuracy: 0.6556 - val_loss: 0.6491 - val_accuracy: 0.5734\n",
      "Epoch 4133/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6053 - accuracy: 0.6545 - val_loss: 0.6659 - val_accuracy: 0.5491\n",
      "Epoch 4134/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6054 - accuracy: 0.6564 - val_loss: 0.6436 - val_accuracy: 0.5835\n",
      "Epoch 4135/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6540 - val_loss: 0.6789 - val_accuracy: 0.5345\n",
      "Epoch 4136/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6068 - accuracy: 0.6546 - val_loss: 0.6340 - val_accuracy: 0.5961\n",
      "Epoch 4137/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6071 - accuracy: 0.6507 - val_loss: 0.6823 - val_accuracy: 0.5280\n",
      "Epoch 4138/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6076 - accuracy: 0.6529 - val_loss: 0.6374 - val_accuracy: 0.5915\n",
      "Epoch 4139/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6069 - accuracy: 0.6526 - val_loss: 0.6761 - val_accuracy: 0.5393\n",
      "Epoch 4140/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6070 - accuracy: 0.6538 - val_loss: 0.6451 - val_accuracy: 0.5789\n",
      "Epoch 4141/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6526 - val_loss: 0.6642 - val_accuracy: 0.5546\n",
      "Epoch 4142/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6058 - accuracy: 0.6566 - val_loss: 0.6589 - val_accuracy: 0.5601\n",
      "Epoch 4143/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6569 - val_loss: 0.6426 - val_accuracy: 0.5809\n",
      "Epoch 4144/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6516 - val_loss: 0.6792 - val_accuracy: 0.5340\n",
      "Epoch 4145/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6065 - accuracy: 0.6544 - val_loss: 0.6370 - val_accuracy: 0.5946\n",
      "Epoch 4146/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6528 - val_loss: 0.6904 - val_accuracy: 0.5194\n",
      "Epoch 4147/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6097 - accuracy: 0.6507 - val_loss: 0.6255 - val_accuracy: 0.6118\n",
      "Epoch 4148/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6095 - accuracy: 0.6492 - val_loss: 0.6894 - val_accuracy: 0.5192\n",
      "Epoch 4149/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6089 - accuracy: 0.6517 - val_loss: 0.6454 - val_accuracy: 0.5817\n",
      "Epoch 4150/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6069 - accuracy: 0.6546 - val_loss: 0.6577 - val_accuracy: 0.5592\n",
      "Epoch 4151/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6068 - accuracy: 0.6527 - val_loss: 0.6633 - val_accuracy: 0.5521\n",
      "Epoch 4152/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6543 - val_loss: 0.6423 - val_accuracy: 0.5875\n",
      "Epoch 4153/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6078 - accuracy: 0.6538 - val_loss: 0.6906 - val_accuracy: 0.5172\n",
      "Epoch 4154/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6092 - accuracy: 0.6509 - val_loss: 0.6232 - val_accuracy: 0.6175\n",
      "Epoch 4155/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6100 - accuracy: 0.6509 - val_loss: 0.6938 - val_accuracy: 0.5161\n",
      "Epoch 4156/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6095 - accuracy: 0.6506 - val_loss: 0.6393 - val_accuracy: 0.5917\n",
      "Epoch 4157/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6077 - accuracy: 0.6537 - val_loss: 0.6660 - val_accuracy: 0.5504\n",
      "Epoch 4158/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6066 - accuracy: 0.6536 - val_loss: 0.6522 - val_accuracy: 0.5685\n",
      "Epoch 4159/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6058 - accuracy: 0.6537 - val_loss: 0.6506 - val_accuracy: 0.5725\n",
      "Epoch 4160/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6553 - val_loss: 0.6761 - val_accuracy: 0.5362\n",
      "Epoch 4161/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6541 - val_loss: 0.6319 - val_accuracy: 0.5985\n",
      "Epoch 4162/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6507 - val_loss: 0.6867 - val_accuracy: 0.5234\n",
      "Epoch 4163/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6081 - accuracy: 0.6516 - val_loss: 0.6372 - val_accuracy: 0.5924\n",
      "Epoch 4164/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6076 - accuracy: 0.6516 - val_loss: 0.6756 - val_accuracy: 0.5371\n",
      "Epoch 4165/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6069 - accuracy: 0.6547 - val_loss: 0.6394 - val_accuracy: 0.5839\n",
      "Epoch 4166/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6060 - accuracy: 0.6519 - val_loss: 0.6643 - val_accuracy: 0.5510\n",
      "Epoch 4167/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6053 - accuracy: 0.6553 - val_loss: 0.6631 - val_accuracy: 0.5555\n",
      "Epoch 4168/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6051 - accuracy: 0.6557 - val_loss: 0.6450 - val_accuracy: 0.5798\n",
      "Epoch 4169/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6055 - accuracy: 0.6539 - val_loss: 0.6700 - val_accuracy: 0.5424\n",
      "Epoch 4170/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6551 - val_loss: 0.6387 - val_accuracy: 0.5899\n",
      "Epoch 4171/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6070 - accuracy: 0.6520 - val_loss: 0.6847 - val_accuracy: 0.5269\n",
      "Epoch 4172/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6077 - accuracy: 0.6528 - val_loss: 0.6325 - val_accuracy: 0.6005\n",
      "Epoch 4173/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6075 - accuracy: 0.6512 - val_loss: 0.6811 - val_accuracy: 0.5318\n",
      "Epoch 4174/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6070 - accuracy: 0.6534 - val_loss: 0.6428 - val_accuracy: 0.5840\n",
      "Epoch 4175/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6540 - val_loss: 0.6646 - val_accuracy: 0.5532\n",
      "Epoch 4176/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6057 - accuracy: 0.6559 - val_loss: 0.6526 - val_accuracy: 0.5700\n",
      "Epoch 4177/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6052 - accuracy: 0.6553 - val_loss: 0.6550 - val_accuracy: 0.5649\n",
      "Epoch 4178/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6558 - val_loss: 0.6677 - val_accuracy: 0.5473\n",
      "Epoch 4179/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6052 - accuracy: 0.6559 - val_loss: 0.6395 - val_accuracy: 0.5859\n",
      "Epoch 4180/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6526 - val_loss: 0.6779 - val_accuracy: 0.5351\n",
      "Epoch 4181/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6064 - accuracy: 0.6545 - val_loss: 0.6385 - val_accuracy: 0.5923\n",
      "Epoch 4182/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6070 - accuracy: 0.6523 - val_loss: 0.6823 - val_accuracy: 0.5285\n",
      "Epoch 4183/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6075 - accuracy: 0.6533 - val_loss: 0.6331 - val_accuracy: 0.6003\n",
      "Epoch 4184/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6071 - accuracy: 0.6508 - val_loss: 0.6786 - val_accuracy: 0.5353\n",
      "Epoch 4185/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6066 - accuracy: 0.6538 - val_loss: 0.6484 - val_accuracy: 0.5760\n",
      "Epoch 4186/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6054 - accuracy: 0.6549 - val_loss: 0.6580 - val_accuracy: 0.5627\n",
      "Epoch 4187/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6054 - accuracy: 0.6555 - val_loss: 0.6594 - val_accuracy: 0.5594\n",
      "Epoch 4188/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6050 - accuracy: 0.6563 - val_loss: 0.6464 - val_accuracy: 0.5793\n",
      "Epoch 4189/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6061 - accuracy: 0.6549 - val_loss: 0.6810 - val_accuracy: 0.5301\n",
      "Epoch 4190/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6544 - val_loss: 0.6299 - val_accuracy: 0.6054\n",
      "Epoch 4191/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6082 - accuracy: 0.6506 - val_loss: 0.6926 - val_accuracy: 0.5175\n",
      "Epoch 4192/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6093 - accuracy: 0.6507 - val_loss: 0.6324 - val_accuracy: 0.6008\n",
      "Epoch 4193/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6083 - accuracy: 0.6507 - val_loss: 0.6810 - val_accuracy: 0.5311\n",
      "Epoch 4194/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6081 - accuracy: 0.6530 - val_loss: 0.6432 - val_accuracy: 0.5820\n",
      "Epoch 4195/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6066 - accuracy: 0.6512 - val_loss: 0.6598 - val_accuracy: 0.5590\n",
      "Epoch 4196/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6058 - accuracy: 0.6557 - val_loss: 0.6675 - val_accuracy: 0.5484\n",
      "Epoch 4197/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6055 - accuracy: 0.6551 - val_loss: 0.6362 - val_accuracy: 0.5915\n",
      "Epoch 4198/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6513 - val_loss: 0.6885 - val_accuracy: 0.5241\n",
      "Epoch 4199/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6083 - accuracy: 0.6513 - val_loss: 0.6318 - val_accuracy: 0.6019\n",
      "Epoch 4200/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6092 - accuracy: 0.6505 - val_loss: 0.6887 - val_accuracy: 0.5208\n",
      "Epoch 4201/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6088 - accuracy: 0.6519 - val_loss: 0.6321 - val_accuracy: 0.5994\n",
      "Epoch 4202/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6076 - accuracy: 0.6508 - val_loss: 0.6725 - val_accuracy: 0.5431\n",
      "Epoch 4203/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6058 - accuracy: 0.6549 - val_loss: 0.6563 - val_accuracy: 0.5652\n",
      "Epoch 4204/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6053 - accuracy: 0.6550 - val_loss: 0.6472 - val_accuracy: 0.5749\n",
      "Epoch 4205/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6054 - accuracy: 0.6541 - val_loss: 0.6707 - val_accuracy: 0.5429\n",
      "Epoch 4206/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6555 - val_loss: 0.6379 - val_accuracy: 0.5928\n",
      "Epoch 4207/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6534 - val_loss: 0.6852 - val_accuracy: 0.5272\n",
      "Epoch 4208/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6075 - accuracy: 0.6528 - val_loss: 0.6339 - val_accuracy: 0.5976\n",
      "Epoch 4209/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6070 - accuracy: 0.6511 - val_loss: 0.6760 - val_accuracy: 0.5356\n",
      "Epoch 4210/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6060 - accuracy: 0.6558 - val_loss: 0.6453 - val_accuracy: 0.5833\n",
      "Epoch 4211/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6054 - accuracy: 0.6557 - val_loss: 0.6620 - val_accuracy: 0.5535\n",
      "Epoch 4212/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6048 - accuracy: 0.6557 - val_loss: 0.6552 - val_accuracy: 0.5645\n",
      "Epoch 4213/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6046 - accuracy: 0.6560 - val_loss: 0.6531 - val_accuracy: 0.5689\n",
      "Epoch 4214/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6047 - accuracy: 0.6562 - val_loss: 0.6657 - val_accuracy: 0.5504\n",
      "Epoch 4215/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6049 - accuracy: 0.6561 - val_loss: 0.6425 - val_accuracy: 0.5833\n",
      "Epoch 4216/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6053 - accuracy: 0.6533 - val_loss: 0.6744 - val_accuracy: 0.5407\n",
      "Epoch 4217/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6560 - val_loss: 0.6394 - val_accuracy: 0.5913\n",
      "Epoch 4218/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6060 - accuracy: 0.6539 - val_loss: 0.6785 - val_accuracy: 0.5365\n",
      "Epoch 4219/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6064 - accuracy: 0.6548 - val_loss: 0.6366 - val_accuracy: 0.5906\n",
      "Epoch 4220/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6512 - val_loss: 0.6771 - val_accuracy: 0.5351\n",
      "Epoch 4221/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6552 - val_loss: 0.6441 - val_accuracy: 0.5824\n",
      "Epoch 4222/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6543 - val_loss: 0.6653 - val_accuracy: 0.5521\n",
      "Epoch 4223/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6049 - accuracy: 0.6556 - val_loss: 0.6509 - val_accuracy: 0.5722\n",
      "Epoch 4224/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6560 - val_loss: 0.6565 - val_accuracy: 0.5650\n",
      "Epoch 4225/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6045 - accuracy: 0.6567 - val_loss: 0.6630 - val_accuracy: 0.5548\n",
      "Epoch 4226/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6045 - accuracy: 0.6563 - val_loss: 0.6462 - val_accuracy: 0.5787\n",
      "Epoch 4227/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6049 - accuracy: 0.6542 - val_loss: 0.6700 - val_accuracy: 0.5451\n",
      "Epoch 4228/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6052 - accuracy: 0.6567 - val_loss: 0.6418 - val_accuracy: 0.5868\n",
      "Epoch 4229/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6055 - accuracy: 0.6545 - val_loss: 0.6764 - val_accuracy: 0.5371\n",
      "Epoch 4230/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6058 - accuracy: 0.6557 - val_loss: 0.6393 - val_accuracy: 0.5871\n",
      "Epoch 4231/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6524 - val_loss: 0.6751 - val_accuracy: 0.5373\n",
      "Epoch 4232/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6058 - accuracy: 0.6563 - val_loss: 0.6414 - val_accuracy: 0.5866\n",
      "Epoch 4233/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6053 - accuracy: 0.6541 - val_loss: 0.6703 - val_accuracy: 0.5446\n",
      "Epoch 4234/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6054 - accuracy: 0.6548 - val_loss: 0.6476 - val_accuracy: 0.5784\n",
      "Epoch 4235/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6047 - accuracy: 0.6551 - val_loss: 0.6632 - val_accuracy: 0.5570\n",
      "Epoch 4236/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6048 - accuracy: 0.6571 - val_loss: 0.6545 - val_accuracy: 0.5676\n",
      "Epoch 4237/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6043 - accuracy: 0.6571 - val_loss: 0.6521 - val_accuracy: 0.5692\n",
      "Epoch 4238/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6046 - accuracy: 0.6550 - val_loss: 0.6657 - val_accuracy: 0.5526\n",
      "Epoch 4239/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6045 - accuracy: 0.6568 - val_loss: 0.6467 - val_accuracy: 0.5800\n",
      "Epoch 4240/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6561 - val_loss: 0.6727 - val_accuracy: 0.5406\n",
      "Epoch 4241/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6056 - accuracy: 0.6551 - val_loss: 0.6359 - val_accuracy: 0.5934\n",
      "Epoch 4242/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6520 - val_loss: 0.6829 - val_accuracy: 0.5270\n",
      "Epoch 4243/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6069 - accuracy: 0.6539 - val_loss: 0.6364 - val_accuracy: 0.5959\n",
      "Epoch 4244/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6066 - accuracy: 0.6530 - val_loss: 0.6807 - val_accuracy: 0.5325\n",
      "Epoch 4245/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6070 - accuracy: 0.6539 - val_loss: 0.6386 - val_accuracy: 0.5886\n",
      "Epoch 4246/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6057 - accuracy: 0.6512 - val_loss: 0.6699 - val_accuracy: 0.5466\n",
      "Epoch 4247/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6057 - accuracy: 0.6558 - val_loss: 0.6535 - val_accuracy: 0.5678\n",
      "Epoch 4248/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6044 - accuracy: 0.6566 - val_loss: 0.6511 - val_accuracy: 0.5689\n",
      "Epoch 4249/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6052 - accuracy: 0.6528 - val_loss: 0.6693 - val_accuracy: 0.5451\n",
      "Epoch 4250/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6049 - accuracy: 0.6562 - val_loss: 0.6387 - val_accuracy: 0.5955\n",
      "Epoch 4251/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6069 - accuracy: 0.6548 - val_loss: 0.6902 - val_accuracy: 0.5217\n",
      "Epoch 4252/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6084 - accuracy: 0.6525 - val_loss: 0.6248 - val_accuracy: 0.6162\n",
      "Epoch 4253/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6494 - val_loss: 0.6983 - val_accuracy: 0.5082\n",
      "Epoch 4254/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6105 - accuracy: 0.6490 - val_loss: 0.6349 - val_accuracy: 0.6016\n",
      "Epoch 4255/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6085 - accuracy: 0.6535 - val_loss: 0.6707 - val_accuracy: 0.5457\n",
      "Epoch 4256/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6073 - accuracy: 0.6521 - val_loss: 0.6589 - val_accuracy: 0.5603\n",
      "Epoch 4257/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6069 - accuracy: 0.6508 - val_loss: 0.6498 - val_accuracy: 0.5751\n",
      "Epoch 4258/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6560 - val_loss: 0.6731 - val_accuracy: 0.5376\n",
      "Epoch 4259/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6547 - val_loss: 0.6368 - val_accuracy: 0.5901\n",
      "Epoch 4260/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6526 - val_loss: 0.6725 - val_accuracy: 0.5407\n",
      "Epoch 4261/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6543 - val_loss: 0.6478 - val_accuracy: 0.5765\n",
      "Epoch 4262/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6054 - accuracy: 0.6557 - val_loss: 0.6661 - val_accuracy: 0.5515\n",
      "Epoch 4263/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6048 - accuracy: 0.6566 - val_loss: 0.6486 - val_accuracy: 0.5744\n",
      "Epoch 4264/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6047 - accuracy: 0.6549 - val_loss: 0.6554 - val_accuracy: 0.5656\n",
      "Epoch 4265/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6043 - accuracy: 0.6558 - val_loss: 0.6601 - val_accuracy: 0.5603\n",
      "Epoch 4266/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6046 - accuracy: 0.6562 - val_loss: 0.6529 - val_accuracy: 0.5701\n",
      "Epoch 4267/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6043 - accuracy: 0.6565 - val_loss: 0.6610 - val_accuracy: 0.5563\n",
      "Epoch 4268/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6047 - accuracy: 0.6559 - val_loss: 0.6477 - val_accuracy: 0.5758\n",
      "Epoch 4269/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6044 - accuracy: 0.6557 - val_loss: 0.6679 - val_accuracy: 0.5502\n",
      "Epoch 4270/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6048 - accuracy: 0.6570 - val_loss: 0.6468 - val_accuracy: 0.5778\n",
      "Epoch 4271/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6047 - accuracy: 0.6552 - val_loss: 0.6672 - val_accuracy: 0.5486\n",
      "Epoch 4272/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6049 - accuracy: 0.6555 - val_loss: 0.6437 - val_accuracy: 0.5837\n",
      "Epoch 4273/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6049 - accuracy: 0.6543 - val_loss: 0.6728 - val_accuracy: 0.5409\n",
      "Epoch 4274/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6051 - accuracy: 0.6557 - val_loss: 0.6429 - val_accuracy: 0.5835\n",
      "Epoch 4275/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6052 - accuracy: 0.6538 - val_loss: 0.6735 - val_accuracy: 0.5402\n",
      "Epoch 4276/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6054 - accuracy: 0.6559 - val_loss: 0.6386 - val_accuracy: 0.5888\n",
      "Epoch 4277/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6054 - accuracy: 0.6537 - val_loss: 0.6769 - val_accuracy: 0.5378\n",
      "Epoch 4278/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6056 - accuracy: 0.6554 - val_loss: 0.6402 - val_accuracy: 0.5873\n",
      "Epoch 4279/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6055 - accuracy: 0.6530 - val_loss: 0.6775 - val_accuracy: 0.5376\n",
      "Epoch 4280/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6057 - accuracy: 0.6558 - val_loss: 0.6363 - val_accuracy: 0.5944\n",
      "Epoch 4281/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6534 - val_loss: 0.6792 - val_accuracy: 0.5347\n",
      "Epoch 4282/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6061 - accuracy: 0.6545 - val_loss: 0.6372 - val_accuracy: 0.5926\n",
      "Epoch 4283/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6059 - accuracy: 0.6523 - val_loss: 0.6820 - val_accuracy: 0.5289\n",
      "Epoch 4284/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6550 - val_loss: 0.6349 - val_accuracy: 0.5965\n",
      "Epoch 4285/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6060 - accuracy: 0.6526 - val_loss: 0.6806 - val_accuracy: 0.5329\n",
      "Epoch 4286/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6547 - val_loss: 0.6356 - val_accuracy: 0.5963\n",
      "Epoch 4287/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6524 - val_loss: 0.6809 - val_accuracy: 0.5307\n",
      "Epoch 4288/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6060 - accuracy: 0.6556 - val_loss: 0.6380 - val_accuracy: 0.5915\n",
      "Epoch 4289/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6055 - accuracy: 0.6532 - val_loss: 0.6751 - val_accuracy: 0.5400\n",
      "Epoch 4290/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6055 - accuracy: 0.6550 - val_loss: 0.6406 - val_accuracy: 0.5875\n",
      "Epoch 4291/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6537 - val_loss: 0.6732 - val_accuracy: 0.5400\n",
      "Epoch 4292/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6564 - val_loss: 0.6428 - val_accuracy: 0.5839\n",
      "Epoch 4293/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6047 - accuracy: 0.6547 - val_loss: 0.6680 - val_accuracy: 0.5473\n",
      "Epoch 4294/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6045 - accuracy: 0.6561 - val_loss: 0.6477 - val_accuracy: 0.5776\n",
      "Epoch 4295/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6558 - val_loss: 0.6651 - val_accuracy: 0.5517\n",
      "Epoch 4296/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6042 - accuracy: 0.6571 - val_loss: 0.6499 - val_accuracy: 0.5749\n",
      "Epoch 4297/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6041 - accuracy: 0.6564 - val_loss: 0.6608 - val_accuracy: 0.5594\n",
      "Epoch 4298/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6040 - accuracy: 0.6573 - val_loss: 0.6544 - val_accuracy: 0.5694\n",
      "Epoch 4299/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6568 - val_loss: 0.6589 - val_accuracy: 0.5599\n",
      "Epoch 4300/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6571 - val_loss: 0.6547 - val_accuracy: 0.5687\n",
      "Epoch 4301/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6039 - accuracy: 0.6564 - val_loss: 0.6577 - val_accuracy: 0.5641\n",
      "Epoch 4302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6039 - accuracy: 0.6577 - val_loss: 0.6566 - val_accuracy: 0.5658\n",
      "Epoch 4303/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6575 - val_loss: 0.6565 - val_accuracy: 0.5639\n",
      "Epoch 4304/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6567 - val_loss: 0.6577 - val_accuracy: 0.5638\n",
      "Epoch 4305/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6575 - val_loss: 0.6547 - val_accuracy: 0.5676\n",
      "Epoch 4306/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6038 - accuracy: 0.6572 - val_loss: 0.6593 - val_accuracy: 0.5610\n",
      "Epoch 4307/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6038 - accuracy: 0.6574 - val_loss: 0.6534 - val_accuracy: 0.5705\n",
      "Epoch 4308/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6565 - val_loss: 0.6621 - val_accuracy: 0.5570\n",
      "Epoch 4309/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6039 - accuracy: 0.6574 - val_loss: 0.6497 - val_accuracy: 0.5753\n",
      "Epoch 4310/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6040 - accuracy: 0.6566 - val_loss: 0.6663 - val_accuracy: 0.5502\n",
      "Epoch 4311/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6042 - accuracy: 0.6565 - val_loss: 0.6445 - val_accuracy: 0.5817\n",
      "Epoch 4312/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6550 - val_loss: 0.6769 - val_accuracy: 0.5382\n",
      "Epoch 4313/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6053 - accuracy: 0.6564 - val_loss: 0.6328 - val_accuracy: 0.6012\n",
      "Epoch 4314/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6063 - accuracy: 0.6522 - val_loss: 0.6934 - val_accuracy: 0.5168\n",
      "Epoch 4315/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6086 - accuracy: 0.6511 - val_loss: 0.6245 - val_accuracy: 0.6182\n",
      "Epoch 4316/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6090 - accuracy: 0.6514 - val_loss: 0.7048 - val_accuracy: 0.5055\n",
      "Epoch 4317/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6112 - accuracy: 0.6482 - val_loss: 0.6271 - val_accuracy: 0.6140\n",
      "Epoch 4318/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6080 - accuracy: 0.6514 - val_loss: 0.6813 - val_accuracy: 0.5307\n",
      "Epoch 4319/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6063 - accuracy: 0.6545 - val_loss: 0.6439 - val_accuracy: 0.5833\n",
      "Epoch 4320/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6560 - val_loss: 0.6572 - val_accuracy: 0.5623\n",
      "Epoch 4321/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6571 - val_loss: 0.6656 - val_accuracy: 0.5513\n",
      "Epoch 4322/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6041 - accuracy: 0.6566 - val_loss: 0.6398 - val_accuracy: 0.5906\n",
      "Epoch 4323/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6052 - accuracy: 0.6542 - val_loss: 0.6859 - val_accuracy: 0.5239\n",
      "Epoch 4324/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6533 - val_loss: 0.6243 - val_accuracy: 0.6178\n",
      "Epoch 4325/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6085 - accuracy: 0.6516 - val_loss: 0.7038 - val_accuracy: 0.5038\n",
      "Epoch 4326/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6111 - accuracy: 0.6483 - val_loss: 0.6287 - val_accuracy: 0.6094\n",
      "Epoch 4327/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6079 - accuracy: 0.6507 - val_loss: 0.6780 - val_accuracy: 0.5347\n",
      "Epoch 4328/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6060 - accuracy: 0.6549 - val_loss: 0.6488 - val_accuracy: 0.5745\n",
      "Epoch 4329/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6042 - accuracy: 0.6554 - val_loss: 0.6493 - val_accuracy: 0.5742\n",
      "Epoch 4330/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6561 - val_loss: 0.6762 - val_accuracy: 0.5376\n",
      "Epoch 4331/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6557 - val_loss: 0.6292 - val_accuracy: 0.6091\n",
      "Epoch 4332/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6079 - accuracy: 0.6508 - val_loss: 0.7035 - val_accuracy: 0.5042\n",
      "Epoch 4333/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6486 - val_loss: 0.6233 - val_accuracy: 0.6206\n",
      "Epoch 4334/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6497 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 4335/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6091 - accuracy: 0.6513 - val_loss: 0.6405 - val_accuracy: 0.5857\n",
      "Epoch 4336/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6061 - accuracy: 0.6517 - val_loss: 0.6571 - val_accuracy: 0.5649\n",
      "Epoch 4337/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6568 - val_loss: 0.6763 - val_accuracy: 0.5342\n",
      "Epoch 4338/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6557 - val_loss: 0.6241 - val_accuracy: 0.6184\n",
      "Epoch 4339/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6088 - accuracy: 0.6506 - val_loss: 0.7046 - val_accuracy: 0.5013\n",
      "Epoch 4340/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6110 - accuracy: 0.6483 - val_loss: 0.6309 - val_accuracy: 0.6074\n",
      "Epoch 4341/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6512 - val_loss: 0.6776 - val_accuracy: 0.5347\n",
      "Epoch 4342/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6070 - accuracy: 0.6541 - val_loss: 0.6436 - val_accuracy: 0.5800\n",
      "Epoch 4343/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6532 - val_loss: 0.6534 - val_accuracy: 0.5689\n",
      "Epoch 4344/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6050 - accuracy: 0.6560 - val_loss: 0.6823 - val_accuracy: 0.5270\n",
      "Epoch 4345/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6063 - accuracy: 0.6541 - val_loss: 0.6233 - val_accuracy: 0.6204\n",
      "Epoch 4346/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6086 - accuracy: 0.6519 - val_loss: 0.7002 - val_accuracy: 0.5097\n",
      "Epoch 4347/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6101 - accuracy: 0.6496 - val_loss: 0.6350 - val_accuracy: 0.5976\n",
      "Epoch 4348/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6077 - accuracy: 0.6517 - val_loss: 0.6700 - val_accuracy: 0.5429\n",
      "Epoch 4349/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6060 - accuracy: 0.6554 - val_loss: 0.6499 - val_accuracy: 0.5711\n",
      "Epoch 4350/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6047 - accuracy: 0.6550 - val_loss: 0.6460 - val_accuracy: 0.5787\n",
      "Epoch 4351/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6055 - accuracy: 0.6560 - val_loss: 0.6880 - val_accuracy: 0.5214\n",
      "Epoch 4352/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6070 - accuracy: 0.6531 - val_loss: 0.6249 - val_accuracy: 0.6153\n",
      "Epoch 4353/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6088 - accuracy: 0.6506 - val_loss: 0.6971 - val_accuracy: 0.5126\n",
      "Epoch 4354/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6094 - accuracy: 0.6502 - val_loss: 0.6367 - val_accuracy: 0.5943\n",
      "Epoch 4355/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6520 - val_loss: 0.6641 - val_accuracy: 0.5539\n",
      "Epoch 4356/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6052 - accuracy: 0.6568 - val_loss: 0.6569 - val_accuracy: 0.5649\n",
      "Epoch 4357/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6047 - accuracy: 0.6567 - val_loss: 0.6428 - val_accuracy: 0.5844\n",
      "Epoch 4358/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6056 - accuracy: 0.6546 - val_loss: 0.6885 - val_accuracy: 0.5225\n",
      "Epoch 4359/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6071 - accuracy: 0.6526 - val_loss: 0.6278 - val_accuracy: 0.6103\n",
      "Epoch 4360/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6079 - accuracy: 0.6509 - val_loss: 0.6880 - val_accuracy: 0.5214\n",
      "Epoch 4361/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6532 - val_loss: 0.6397 - val_accuracy: 0.5901\n",
      "Epoch 4362/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6529 - val_loss: 0.6634 - val_accuracy: 0.5563\n",
      "Epoch 4363/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6571 - val_loss: 0.6590 - val_accuracy: 0.5623\n",
      "Epoch 4364/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6041 - accuracy: 0.6572 - val_loss: 0.6415 - val_accuracy: 0.5848\n",
      "Epoch 4365/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6052 - accuracy: 0.6547 - val_loss: 0.6819 - val_accuracy: 0.5290\n",
      "Epoch 4366/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6545 - val_loss: 0.6321 - val_accuracy: 0.6023\n",
      "Epoch 4367/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6525 - val_loss: 0.6871 - val_accuracy: 0.5230\n",
      "Epoch 4368/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6070 - accuracy: 0.6533 - val_loss: 0.6393 - val_accuracy: 0.5884\n",
      "Epoch 4369/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6056 - accuracy: 0.6527 - val_loss: 0.6655 - val_accuracy: 0.5543\n",
      "Epoch 4370/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6049 - accuracy: 0.6572 - val_loss: 0.6558 - val_accuracy: 0.5669\n",
      "Epoch 4371/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6041 - accuracy: 0.6571 - val_loss: 0.6458 - val_accuracy: 0.5798\n",
      "Epoch 4372/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6052 - accuracy: 0.6539 - val_loss: 0.6810 - val_accuracy: 0.5311\n",
      "Epoch 4373/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6555 - val_loss: 0.6309 - val_accuracy: 0.6071\n",
      "Epoch 4374/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6075 - accuracy: 0.6517 - val_loss: 0.6895 - val_accuracy: 0.5217\n",
      "Epoch 4375/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6526 - val_loss: 0.6360 - val_accuracy: 0.5930\n",
      "Epoch 4376/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6519 - val_loss: 0.6712 - val_accuracy: 0.5466\n",
      "Epoch 4377/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6055 - accuracy: 0.6558 - val_loss: 0.6525 - val_accuracy: 0.5729\n",
      "Epoch 4378/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6569 - val_loss: 0.6503 - val_accuracy: 0.5734\n",
      "Epoch 4379/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6052 - accuracy: 0.6533 - val_loss: 0.6751 - val_accuracy: 0.5411\n",
      "Epoch 4380/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6050 - accuracy: 0.6556 - val_loss: 0.6327 - val_accuracy: 0.6045\n",
      "Epoch 4381/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6525 - val_loss: 0.6932 - val_accuracy: 0.5181\n",
      "Epoch 4382/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6080 - accuracy: 0.6519 - val_loss: 0.6339 - val_accuracy: 0.5983\n",
      "Epoch 4383/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6074 - accuracy: 0.6524 - val_loss: 0.6755 - val_accuracy: 0.5369\n",
      "Epoch 4384/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6063 - accuracy: 0.6554 - val_loss: 0.6456 - val_accuracy: 0.5817\n",
      "Epoch 4385/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6055 - accuracy: 0.6563 - val_loss: 0.6588 - val_accuracy: 0.5614\n",
      "Epoch 4386/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6050 - accuracy: 0.6543 - val_loss: 0.6669 - val_accuracy: 0.5508\n",
      "Epoch 4387/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6045 - accuracy: 0.6558 - val_loss: 0.6425 - val_accuracy: 0.5875\n",
      "Epoch 4388/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6056 - accuracy: 0.6553 - val_loss: 0.6783 - val_accuracy: 0.5323\n",
      "Epoch 4389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6055 - accuracy: 0.6562 - val_loss: 0.6349 - val_accuracy: 0.5957\n",
      "Epoch 4390/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6524 - val_loss: 0.6834 - val_accuracy: 0.5283\n",
      "Epoch 4391/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6543 - val_loss: 0.6359 - val_accuracy: 0.6001\n",
      "Epoch 4392/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6064 - accuracy: 0.6538 - val_loss: 0.6755 - val_accuracy: 0.5407\n",
      "Epoch 4393/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6052 - accuracy: 0.6555 - val_loss: 0.6487 - val_accuracy: 0.5749\n",
      "Epoch 4394/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6045 - accuracy: 0.6547 - val_loss: 0.6552 - val_accuracy: 0.5667\n",
      "Epoch 4395/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6046 - accuracy: 0.6569 - val_loss: 0.6645 - val_accuracy: 0.5537\n",
      "Epoch 4396/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6043 - accuracy: 0.6578 - val_loss: 0.6437 - val_accuracy: 0.5840\n",
      "Epoch 4397/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6052 - accuracy: 0.6538 - val_loss: 0.6792 - val_accuracy: 0.5336\n",
      "Epoch 4398/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6054 - accuracy: 0.6557 - val_loss: 0.6335 - val_accuracy: 0.6018\n",
      "Epoch 4399/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6064 - accuracy: 0.6533 - val_loss: 0.6849 - val_accuracy: 0.5285\n",
      "Epoch 4400/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6063 - accuracy: 0.6548 - val_loss: 0.6390 - val_accuracy: 0.5910\n",
      "Epoch 4401/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6527 - val_loss: 0.6704 - val_accuracy: 0.5469\n",
      "Epoch 4402/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6050 - accuracy: 0.6571 - val_loss: 0.6477 - val_accuracy: 0.5804\n",
      "Epoch 4403/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6043 - accuracy: 0.6571 - val_loss: 0.6587 - val_accuracy: 0.5632\n",
      "Epoch 4404/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6044 - accuracy: 0.6556 - val_loss: 0.6655 - val_accuracy: 0.5530\n",
      "Epoch 4405/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6569 - val_loss: 0.6425 - val_accuracy: 0.5877\n",
      "Epoch 4406/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6050 - accuracy: 0.6560 - val_loss: 0.6763 - val_accuracy: 0.5389\n",
      "Epoch 4407/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6051 - accuracy: 0.6565 - val_loss: 0.6355 - val_accuracy: 0.5959\n",
      "Epoch 4408/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6521 - val_loss: 0.6859 - val_accuracy: 0.5252\n",
      "Epoch 4409/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6069 - accuracy: 0.6536 - val_loss: 0.6340 - val_accuracy: 0.6032\n",
      "Epoch 4410/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6066 - accuracy: 0.6537 - val_loss: 0.6784 - val_accuracy: 0.5374\n",
      "Epoch 4411/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6058 - accuracy: 0.6545 - val_loss: 0.6494 - val_accuracy: 0.5740\n",
      "Epoch 4412/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6551 - val_loss: 0.6519 - val_accuracy: 0.5734\n",
      "Epoch 4413/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6049 - accuracy: 0.6573 - val_loss: 0.6710 - val_accuracy: 0.5446\n",
      "Epoch 4414/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6048 - accuracy: 0.6580 - val_loss: 0.6370 - val_accuracy: 0.5932\n",
      "Epoch 4415/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6067 - accuracy: 0.6528 - val_loss: 0.6908 - val_accuracy: 0.5208\n",
      "Epoch 4416/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6524 - val_loss: 0.6268 - val_accuracy: 0.6138\n",
      "Epoch 4417/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6083 - accuracy: 0.6510 - val_loss: 0.6896 - val_accuracy: 0.5254\n",
      "Epoch 4418/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6074 - accuracy: 0.6531 - val_loss: 0.6435 - val_accuracy: 0.5844\n",
      "Epoch 4419/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6058 - accuracy: 0.6523 - val_loss: 0.6602 - val_accuracy: 0.5619\n",
      "Epoch 4420/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6048 - accuracy: 0.6568 - val_loss: 0.6609 - val_accuracy: 0.5605\n",
      "Epoch 4421/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6049 - accuracy: 0.6573 - val_loss: 0.6408 - val_accuracy: 0.5851\n",
      "Epoch 4422/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6530 - val_loss: 0.6846 - val_accuracy: 0.5278\n",
      "Epoch 4423/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6360 - val_accuracy: 0.5988\n",
      "Epoch 4424/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6529 - val_loss: 0.6763 - val_accuracy: 0.5374\n",
      "Epoch 4425/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6570 - val_loss: 0.6428 - val_accuracy: 0.5844\n",
      "Epoch 4426/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6550 - val_loss: 0.6628 - val_accuracy: 0.5555\n",
      "Epoch 4427/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6035 - accuracy: 0.6582 - val_loss: 0.6557 - val_accuracy: 0.5667\n",
      "Epoch 4428/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6036 - accuracy: 0.6577 - val_loss: 0.6519 - val_accuracy: 0.5723\n",
      "Epoch 4429/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6561 - val_loss: 0.6664 - val_accuracy: 0.5491\n",
      "Epoch 4430/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6038 - accuracy: 0.6570 - val_loss: 0.6434 - val_accuracy: 0.5859\n",
      "Epoch 4431/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6040 - accuracy: 0.6559 - val_loss: 0.6724 - val_accuracy: 0.5427\n",
      "Epoch 4432/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6573 - val_loss: 0.6419 - val_accuracy: 0.5884\n",
      "Epoch 4433/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6043 - accuracy: 0.6550 - val_loss: 0.6711 - val_accuracy: 0.5457\n",
      "Epoch 4434/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6041 - accuracy: 0.6577 - val_loss: 0.6445 - val_accuracy: 0.5855\n",
      "Epoch 4435/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6561 - val_loss: 0.6674 - val_accuracy: 0.5501\n",
      "Epoch 4436/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6036 - accuracy: 0.6577 - val_loss: 0.6510 - val_accuracy: 0.5754\n",
      "Epoch 4437/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6034 - accuracy: 0.6560 - val_loss: 0.6587 - val_accuracy: 0.5643\n",
      "Epoch 4438/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6032 - accuracy: 0.6581 - val_loss: 0.6557 - val_accuracy: 0.5681\n",
      "Epoch 4439/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6032 - accuracy: 0.6578 - val_loss: 0.6538 - val_accuracy: 0.5701\n",
      "Epoch 4440/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6033 - accuracy: 0.6572 - val_loss: 0.6633 - val_accuracy: 0.5561\n",
      "Epoch 4441/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6033 - accuracy: 0.6581 - val_loss: 0.6477 - val_accuracy: 0.5811\n",
      "Epoch 4442/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6035 - accuracy: 0.6568 - val_loss: 0.6669 - val_accuracy: 0.5510\n",
      "Epoch 4443/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6036 - accuracy: 0.6580 - val_loss: 0.6457 - val_accuracy: 0.5835\n",
      "Epoch 4444/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6037 - accuracy: 0.6565 - val_loss: 0.6705 - val_accuracy: 0.5459\n",
      "Epoch 4445/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6039 - accuracy: 0.6577 - val_loss: 0.6435 - val_accuracy: 0.5870\n",
      "Epoch 4446/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6039 - accuracy: 0.6557 - val_loss: 0.6715 - val_accuracy: 0.5457\n",
      "Epoch 4447/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6040 - accuracy: 0.6576 - val_loss: 0.6428 - val_accuracy: 0.5870\n",
      "Epoch 4448/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6548 - val_loss: 0.6711 - val_accuracy: 0.5457\n",
      "Epoch 4449/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6039 - accuracy: 0.6578 - val_loss: 0.6453 - val_accuracy: 0.5855\n",
      "Epoch 4450/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6037 - accuracy: 0.6560 - val_loss: 0.6689 - val_accuracy: 0.5493\n",
      "Epoch 4451/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6037 - accuracy: 0.6579 - val_loss: 0.6444 - val_accuracy: 0.5855\n",
      "Epoch 4452/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6036 - accuracy: 0.6559 - val_loss: 0.6679 - val_accuracy: 0.5502\n",
      "Epoch 4453/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6580 - val_loss: 0.6479 - val_accuracy: 0.5817\n",
      "Epoch 4454/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6035 - accuracy: 0.6565 - val_loss: 0.6664 - val_accuracy: 0.5508\n",
      "Epoch 4455/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6579 - val_loss: 0.6465 - val_accuracy: 0.5837\n",
      "Epoch 4456/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6568 - val_loss: 0.6662 - val_accuracy: 0.5522\n",
      "Epoch 4457/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6584 - val_loss: 0.6488 - val_accuracy: 0.5804\n",
      "Epoch 4458/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6033 - accuracy: 0.6566 - val_loss: 0.6662 - val_accuracy: 0.5504\n",
      "Epoch 4459/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6034 - accuracy: 0.6578 - val_loss: 0.6461 - val_accuracy: 0.5839\n",
      "Epoch 4460/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6034 - accuracy: 0.6568 - val_loss: 0.6687 - val_accuracy: 0.5490\n",
      "Epoch 4461/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6035 - accuracy: 0.6579 - val_loss: 0.6453 - val_accuracy: 0.5846\n",
      "Epoch 4462/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6036 - accuracy: 0.6564 - val_loss: 0.6697 - val_accuracy: 0.5469\n",
      "Epoch 4463/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6037 - accuracy: 0.6583 - val_loss: 0.6430 - val_accuracy: 0.5890\n",
      "Epoch 4464/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6038 - accuracy: 0.6553 - val_loss: 0.6748 - val_accuracy: 0.5400\n",
      "Epoch 4465/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6042 - accuracy: 0.6571 - val_loss: 0.6384 - val_accuracy: 0.5934\n",
      "Epoch 4466/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6045 - accuracy: 0.6544 - val_loss: 0.6813 - val_accuracy: 0.5325\n",
      "Epoch 4467/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6052 - accuracy: 0.6561 - val_loss: 0.6330 - val_accuracy: 0.6021\n",
      "Epoch 4468/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6055 - accuracy: 0.6528 - val_loss: 0.6881 - val_accuracy: 0.5252\n",
      "Epoch 4469/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6541 - val_loss: 0.6316 - val_accuracy: 0.6056\n",
      "Epoch 4470/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6060 - accuracy: 0.6525 - val_loss: 0.6864 - val_accuracy: 0.5274\n",
      "Epoch 4471/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6061 - accuracy: 0.6542 - val_loss: 0.6345 - val_accuracy: 0.6001\n",
      "Epoch 4472/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6051 - accuracy: 0.6537 - val_loss: 0.6767 - val_accuracy: 0.5387\n",
      "Epoch 4473/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6046 - accuracy: 0.6569 - val_loss: 0.6425 - val_accuracy: 0.5881\n",
      "Epoch 4474/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6038 - accuracy: 0.6556 - val_loss: 0.6673 - val_accuracy: 0.5504\n",
      "Epoch 4475/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6033 - accuracy: 0.6587 - val_loss: 0.6502 - val_accuracy: 0.5778\n",
      "Epoch 4476/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6030 - accuracy: 0.6572 - val_loss: 0.6579 - val_accuracy: 0.5647\n",
      "Epoch 4477/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6029 - accuracy: 0.6583 - val_loss: 0.6575 - val_accuracy: 0.5634\n",
      "Epoch 4478/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6029 - accuracy: 0.6576 - val_loss: 0.6538 - val_accuracy: 0.5705\n",
      "Epoch 4479/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6029 - accuracy: 0.6578 - val_loss: 0.6608 - val_accuracy: 0.5579\n",
      "Epoch 4480/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6030 - accuracy: 0.6582 - val_loss: 0.6492 - val_accuracy: 0.5791\n",
      "Epoch 4481/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6031 - accuracy: 0.6573 - val_loss: 0.6685 - val_accuracy: 0.5495\n",
      "Epoch 4482/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6034 - accuracy: 0.6583 - val_loss: 0.6431 - val_accuracy: 0.5879\n",
      "Epoch 4483/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6037 - accuracy: 0.6556 - val_loss: 0.6751 - val_accuracy: 0.5402\n",
      "Epoch 4484/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6043 - accuracy: 0.6580 - val_loss: 0.6367 - val_accuracy: 0.5972\n",
      "Epoch 4485/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6048 - accuracy: 0.6544 - val_loss: 0.6868 - val_accuracy: 0.5280\n",
      "Epoch 4486/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6300 - val_accuracy: 0.6080\n",
      "Epoch 4487/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6063 - accuracy: 0.6524 - val_loss: 0.6919 - val_accuracy: 0.5206\n",
      "Epoch 4488/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6072 - accuracy: 0.6524 - val_loss: 0.6304 - val_accuracy: 0.6069\n",
      "Epoch 4489/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6060 - accuracy: 0.6536 - val_loss: 0.6843 - val_accuracy: 0.5290\n",
      "Epoch 4490/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6554 - val_loss: 0.6381 - val_accuracy: 0.5939\n",
      "Epoch 4491/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6045 - accuracy: 0.6543 - val_loss: 0.6726 - val_accuracy: 0.5446\n",
      "Epoch 4492/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6039 - accuracy: 0.6581 - val_loss: 0.6463 - val_accuracy: 0.5848\n",
      "Epoch 4493/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6569 - val_loss: 0.6615 - val_accuracy: 0.5581\n",
      "Epoch 4494/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6030 - accuracy: 0.6581 - val_loss: 0.6551 - val_accuracy: 0.5680\n",
      "Epoch 4495/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6029 - accuracy: 0.6576 - val_loss: 0.6563 - val_accuracy: 0.5694\n",
      "Epoch 4496/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6577 - val_loss: 0.6575 - val_accuracy: 0.5641\n",
      "Epoch 4497/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6029 - accuracy: 0.6578 - val_loss: 0.6526 - val_accuracy: 0.5733\n",
      "Epoch 4498/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6573 - val_loss: 0.6642 - val_accuracy: 0.5572\n",
      "Epoch 4499/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6030 - accuracy: 0.6587 - val_loss: 0.6481 - val_accuracy: 0.5804\n",
      "Epoch 4500/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6030 - accuracy: 0.6568 - val_loss: 0.6673 - val_accuracy: 0.5504\n",
      "Epoch 4501/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6585 - val_loss: 0.6432 - val_accuracy: 0.5871\n",
      "Epoch 4502/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6036 - accuracy: 0.6557 - val_loss: 0.6771 - val_accuracy: 0.5382\n",
      "Epoch 4503/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6043 - accuracy: 0.6572 - val_loss: 0.6361 - val_accuracy: 0.5983\n",
      "Epoch 4504/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6048 - accuracy: 0.6535 - val_loss: 0.6862 - val_accuracy: 0.5281\n",
      "Epoch 4505/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6059 - accuracy: 0.6544 - val_loss: 0.6299 - val_accuracy: 0.6087\n",
      "Epoch 4506/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6531 - val_loss: 0.6929 - val_accuracy: 0.5181\n",
      "Epoch 4507/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6073 - accuracy: 0.6528 - val_loss: 0.6301 - val_accuracy: 0.6085\n",
      "Epoch 4508/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6526 - val_loss: 0.6874 - val_accuracy: 0.5263\n",
      "Epoch 4509/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6061 - accuracy: 0.6543 - val_loss: 0.6363 - val_accuracy: 0.5983\n",
      "Epoch 4510/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6045 - accuracy: 0.6544 - val_loss: 0.6709 - val_accuracy: 0.5457\n",
      "Epoch 4511/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6576 - val_loss: 0.6488 - val_accuracy: 0.5826\n",
      "Epoch 4512/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6031 - accuracy: 0.6570 - val_loss: 0.6605 - val_accuracy: 0.5607\n",
      "Epoch 4513/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6031 - accuracy: 0.6580 - val_loss: 0.6583 - val_accuracy: 0.5630\n",
      "Epoch 4514/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6029 - accuracy: 0.6577 - val_loss: 0.6460 - val_accuracy: 0.5828\n",
      "Epoch 4515/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6033 - accuracy: 0.6559 - val_loss: 0.6755 - val_accuracy: 0.5417\n",
      "Epoch 4516/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6040 - accuracy: 0.6573 - val_loss: 0.6385 - val_accuracy: 0.5928\n",
      "Epoch 4517/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6043 - accuracy: 0.6545 - val_loss: 0.6799 - val_accuracy: 0.5329\n",
      "Epoch 4518/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6056 - accuracy: 0.6563 - val_loss: 0.6330 - val_accuracy: 0.6027\n",
      "Epoch 4519/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6052 - accuracy: 0.6534 - val_loss: 0.6870 - val_accuracy: 0.5281\n",
      "Epoch 4520/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6533 - val_loss: 0.6390 - val_accuracy: 0.5921\n",
      "Epoch 4521/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6043 - accuracy: 0.6548 - val_loss: 0.6685 - val_accuracy: 0.5475\n",
      "Epoch 4522/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6040 - accuracy: 0.6579 - val_loss: 0.6490 - val_accuracy: 0.5807\n",
      "Epoch 4523/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6584 - val_accuracy: 0.5639\n",
      "Epoch 4524/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6033 - accuracy: 0.6578 - val_loss: 0.6644 - val_accuracy: 0.5555\n",
      "Epoch 4525/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6582 - val_loss: 0.6417 - val_accuracy: 0.5904\n",
      "Epoch 4526/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6552 - val_loss: 0.6804 - val_accuracy: 0.5362\n",
      "Epoch 4527/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6051 - accuracy: 0.6549 - val_loss: 0.6337 - val_accuracy: 0.6018\n",
      "Epoch 4528/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6054 - accuracy: 0.6539 - val_loss: 0.6904 - val_accuracy: 0.5203\n",
      "Epoch 4529/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6078 - accuracy: 0.6528 - val_loss: 0.6297 - val_accuracy: 0.6109\n",
      "Epoch 4530/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6065 - accuracy: 0.6524 - val_loss: 0.6850 - val_accuracy: 0.5307\n",
      "Epoch 4531/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6066 - accuracy: 0.6536 - val_loss: 0.6466 - val_accuracy: 0.5837\n",
      "Epoch 4532/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6566 - val_loss: 0.6524 - val_accuracy: 0.5751\n",
      "Epoch 4533/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6041 - accuracy: 0.6558 - val_loss: 0.6750 - val_accuracy: 0.5406\n",
      "Epoch 4534/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6040 - accuracy: 0.6581 - val_loss: 0.6325 - val_accuracy: 0.6030\n",
      "Epoch 4535/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6080 - accuracy: 0.6524 - val_loss: 0.7077 - val_accuracy: 0.5004\n",
      "Epoch 4536/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6128 - accuracy: 0.6483 - val_loss: 0.6156 - val_accuracy: 0.6326\n",
      "Epoch 4537/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6479 - val_loss: 0.7065 - val_accuracy: 0.5066\n",
      "Epoch 4538/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6109 - accuracy: 0.6492 - val_loss: 0.6500 - val_accuracy: 0.5811\n",
      "Epoch 4539/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6545 - val_loss: 0.6473 - val_accuracy: 0.5817\n",
      "Epoch 4540/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6078 - accuracy: 0.6521 - val_loss: 0.6843 - val_accuracy: 0.5292\n",
      "Epoch 4541/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6528 - val_loss: 0.6301 - val_accuracy: 0.6080\n",
      "Epoch 4542/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6071 - accuracy: 0.6527 - val_loss: 0.6876 - val_accuracy: 0.5320\n",
      "Epoch 4543/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6107 - accuracy: 0.6510 - val_loss: 0.6682 - val_accuracy: 0.5491\n",
      "Epoch 4544/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6045 - accuracy: 0.6567 - val_loss: 0.6230 - val_accuracy: 0.6231\n",
      "Epoch 4545/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6117 - accuracy: 0.6498 - val_loss: 0.7243 - val_accuracy: 0.4830\n",
      "Epoch 4546/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6172 - accuracy: 0.6412 - val_loss: 0.6258 - val_accuracy: 0.6176\n",
      "Epoch 4547/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6149 - accuracy: 0.6463 - val_loss: 0.6800 - val_accuracy: 0.5311\n",
      "Epoch 4548/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6097 - accuracy: 0.6531 - val_loss: 0.6552 - val_accuracy: 0.5733\n",
      "Epoch 4549/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6127 - accuracy: 0.6476 - val_loss: 0.6530 - val_accuracy: 0.5749\n",
      "Epoch 4550/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6091 - accuracy: 0.6513 - val_loss: 0.6721 - val_accuracy: 0.5475\n",
      "Epoch 4551/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6548 - val_loss: 0.6494 - val_accuracy: 0.5762\n",
      "Epoch 4552/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6087 - accuracy: 0.6538 - val_loss: 0.6759 - val_accuracy: 0.5345\n",
      "Epoch 4553/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6072 - accuracy: 0.6535 - val_loss: 0.6346 - val_accuracy: 0.6056\n",
      "Epoch 4554/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6112 - accuracy: 0.6499 - val_loss: 0.6875 - val_accuracy: 0.5210\n",
      "Epoch 4555/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6085 - accuracy: 0.6514 - val_loss: 0.6479 - val_accuracy: 0.5789\n",
      "Epoch 4556/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6526 - val_loss: 0.6626 - val_accuracy: 0.5592\n",
      "Epoch 4557/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6078 - accuracy: 0.6547 - val_loss: 0.6624 - val_accuracy: 0.5667\n",
      "Epoch 4558/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6101 - accuracy: 0.6539 - val_loss: 0.6510 - val_accuracy: 0.5813\n",
      "Epoch 4559/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6071 - accuracy: 0.6540 - val_loss: 0.6775 - val_accuracy: 0.5406\n",
      "Epoch 4560/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6079 - accuracy: 0.6530 - val_loss: 0.6582 - val_accuracy: 0.5678\n",
      "Epoch 4561/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6060 - accuracy: 0.6537 - val_loss: 0.6525 - val_accuracy: 0.5771\n",
      "Epoch 4562/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6075 - accuracy: 0.6531 - val_loss: 0.6668 - val_accuracy: 0.5504\n",
      "Epoch 4563/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6429 - val_accuracy: 0.5882\n",
      "Epoch 4564/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6074 - accuracy: 0.6527 - val_loss: 0.6878 - val_accuracy: 0.5243\n",
      "Epoch 4565/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6071 - accuracy: 0.6528 - val_loss: 0.6360 - val_accuracy: 0.5986\n",
      "Epoch 4566/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6061 - accuracy: 0.6530 - val_loss: 0.6721 - val_accuracy: 0.5464\n",
      "Epoch 4567/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6045 - accuracy: 0.6566 - val_loss: 0.6560 - val_accuracy: 0.5700\n",
      "Epoch 4568/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6565 - val_loss: 0.6535 - val_accuracy: 0.5740\n",
      "Epoch 4569/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6038 - accuracy: 0.6578 - val_loss: 0.6645 - val_accuracy: 0.5559\n",
      "Epoch 4570/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6041 - accuracy: 0.6578 - val_loss: 0.6432 - val_accuracy: 0.5866\n",
      "Epoch 4571/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6047 - accuracy: 0.6545 - val_loss: 0.6735 - val_accuracy: 0.5431\n",
      "Epoch 4572/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6569 - val_loss: 0.6473 - val_accuracy: 0.5826\n",
      "Epoch 4573/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6040 - accuracy: 0.6569 - val_loss: 0.6683 - val_accuracy: 0.5506\n",
      "Epoch 4574/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6040 - accuracy: 0.6563 - val_loss: 0.6449 - val_accuracy: 0.5829\n",
      "Epoch 4575/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6036 - accuracy: 0.6563 - val_loss: 0.6668 - val_accuracy: 0.5524\n",
      "Epoch 4576/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6036 - accuracy: 0.6585 - val_loss: 0.6562 - val_accuracy: 0.5701\n",
      "Epoch 4577/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6031 - accuracy: 0.6581 - val_loss: 0.6542 - val_accuracy: 0.5720\n",
      "Epoch 4578/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6032 - accuracy: 0.6566 - val_loss: 0.6637 - val_accuracy: 0.5572\n",
      "Epoch 4579/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6576 - val_loss: 0.6494 - val_accuracy: 0.5804\n",
      "Epoch 4580/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6035 - accuracy: 0.6574 - val_loss: 0.6712 - val_accuracy: 0.5471\n",
      "Epoch 4581/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6036 - accuracy: 0.6576 - val_loss: 0.6426 - val_accuracy: 0.5871\n",
      "Epoch 4582/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6549 - val_loss: 0.6755 - val_accuracy: 0.5395\n",
      "Epoch 4583/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6580 - val_loss: 0.6418 - val_accuracy: 0.5912\n",
      "Epoch 4584/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6556 - val_loss: 0.6733 - val_accuracy: 0.5437\n",
      "Epoch 4585/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6569 - val_loss: 0.6441 - val_accuracy: 0.5862\n",
      "Epoch 4586/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6035 - accuracy: 0.6561 - val_loss: 0.6687 - val_accuracy: 0.5491\n",
      "Epoch 4587/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6032 - accuracy: 0.6589 - val_loss: 0.6521 - val_accuracy: 0.5754\n",
      "Epoch 4588/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6027 - accuracy: 0.6584 - val_loss: 0.6569 - val_accuracy: 0.5669\n",
      "Epoch 4589/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6572 - val_loss: 0.6592 - val_accuracy: 0.5667\n",
      "Epoch 4590/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6026 - accuracy: 0.6579 - val_loss: 0.6518 - val_accuracy: 0.5753\n",
      "Epoch 4591/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6583 - val_loss: 0.6659 - val_accuracy: 0.5513\n",
      "Epoch 4592/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6438 - val_accuracy: 0.5882\n",
      "Epoch 4593/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6563 - val_loss: 0.6731 - val_accuracy: 0.5427\n",
      "Epoch 4594/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6034 - accuracy: 0.6581 - val_loss: 0.6426 - val_accuracy: 0.5901\n",
      "Epoch 4595/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6036 - accuracy: 0.6566 - val_loss: 0.6735 - val_accuracy: 0.5422\n",
      "Epoch 4596/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6037 - accuracy: 0.6573 - val_loss: 0.6399 - val_accuracy: 0.5908\n",
      "Epoch 4597/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6034 - accuracy: 0.6557 - val_loss: 0.6722 - val_accuracy: 0.5460\n",
      "Epoch 4598/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6034 - accuracy: 0.6587 - val_loss: 0.6472 - val_accuracy: 0.5840\n",
      "Epoch 4599/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6574 - val_loss: 0.6631 - val_accuracy: 0.5568\n",
      "Epoch 4600/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6027 - accuracy: 0.6582 - val_loss: 0.6519 - val_accuracy: 0.5751\n",
      "Epoch 4601/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6023 - accuracy: 0.6582 - val_loss: 0.6586 - val_accuracy: 0.5683\n",
      "Epoch 4602/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6587 - val_accuracy: 0.5641\n",
      "Epoch 4603/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6024 - accuracy: 0.6578 - val_loss: 0.6518 - val_accuracy: 0.5765\n",
      "Epoch 4604/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6574 - val_loss: 0.6639 - val_accuracy: 0.5594\n",
      "Epoch 4605/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6025 - accuracy: 0.6584 - val_loss: 0.6482 - val_accuracy: 0.5820\n",
      "Epoch 4606/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6026 - accuracy: 0.6576 - val_loss: 0.6674 - val_accuracy: 0.5497\n",
      "Epoch 4607/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6583 - val_loss: 0.6448 - val_accuracy: 0.5864\n",
      "Epoch 4608/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6029 - accuracy: 0.6569 - val_loss: 0.6724 - val_accuracy: 0.5442\n",
      "Epoch 4609/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6032 - accuracy: 0.6588 - val_loss: 0.6418 - val_accuracy: 0.5904\n",
      "Epoch 4610/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6031 - accuracy: 0.6561 - val_loss: 0.6723 - val_accuracy: 0.5438\n",
      "Epoch 4611/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6582 - val_loss: 0.6425 - val_accuracy: 0.5915\n",
      "Epoch 4612/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6032 - accuracy: 0.6563 - val_loss: 0.6747 - val_accuracy: 0.5407\n",
      "Epoch 4613/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6581 - val_loss: 0.6402 - val_accuracy: 0.5928\n",
      "Epoch 4614/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6033 - accuracy: 0.6557 - val_loss: 0.6753 - val_accuracy: 0.5409\n",
      "Epoch 4615/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6586 - val_loss: 0.6396 - val_accuracy: 0.5935\n",
      "Epoch 4616/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6036 - accuracy: 0.6568 - val_loss: 0.6784 - val_accuracy: 0.5393\n",
      "Epoch 4617/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6577 - val_loss: 0.6379 - val_accuracy: 0.5943\n",
      "Epoch 4618/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6037 - accuracy: 0.6554 - val_loss: 0.6774 - val_accuracy: 0.5378\n",
      "Epoch 4619/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6038 - accuracy: 0.6579 - val_loss: 0.6387 - val_accuracy: 0.5948\n",
      "Epoch 4620/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6036 - accuracy: 0.6555 - val_loss: 0.6767 - val_accuracy: 0.5413\n",
      "Epoch 4621/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6037 - accuracy: 0.6573 - val_loss: 0.6406 - val_accuracy: 0.5930\n",
      "Epoch 4622/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6033 - accuracy: 0.6556 - val_loss: 0.6743 - val_accuracy: 0.5415\n",
      "Epoch 4623/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6033 - accuracy: 0.6589 - val_loss: 0.6414 - val_accuracy: 0.5917\n",
      "Epoch 4624/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6030 - accuracy: 0.6559 - val_loss: 0.6713 - val_accuracy: 0.5448\n",
      "Epoch 4625/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6030 - accuracy: 0.6584 - val_loss: 0.6441 - val_accuracy: 0.5895\n",
      "Epoch 4626/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6565 - val_loss: 0.6710 - val_accuracy: 0.5466\n",
      "Epoch 4627/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6028 - accuracy: 0.6596 - val_loss: 0.6437 - val_accuracy: 0.5890\n",
      "Epoch 4628/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6027 - accuracy: 0.6566 - val_loss: 0.6702 - val_accuracy: 0.5462\n",
      "Epoch 4629/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6028 - accuracy: 0.6590 - val_loss: 0.6438 - val_accuracy: 0.5895\n",
      "Epoch 4630/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6564 - val_loss: 0.6727 - val_accuracy: 0.5435\n",
      "Epoch 4631/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6030 - accuracy: 0.6588 - val_loss: 0.6413 - val_accuracy: 0.5924\n",
      "Epoch 4632/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6031 - accuracy: 0.6560 - val_loss: 0.6768 - val_accuracy: 0.5393\n",
      "Epoch 4633/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6035 - accuracy: 0.6585 - val_loss: 0.6371 - val_accuracy: 0.5961\n",
      "Epoch 4634/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6038 - accuracy: 0.6560 - val_loss: 0.6833 - val_accuracy: 0.5334\n",
      "Epoch 4635/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6046 - accuracy: 0.6569 - val_loss: 0.6329 - val_accuracy: 0.6041\n",
      "Epoch 4636/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6047 - accuracy: 0.6540 - val_loss: 0.6893 - val_accuracy: 0.5243\n",
      "Epoch 4637/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6550 - val_loss: 0.6302 - val_accuracy: 0.6094\n",
      "Epoch 4638/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6052 - accuracy: 0.6541 - val_loss: 0.6884 - val_accuracy: 0.5245\n",
      "Epoch 4639/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6055 - accuracy: 0.6555 - val_loss: 0.6355 - val_accuracy: 0.5992\n",
      "Epoch 4640/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6042 - accuracy: 0.6548 - val_loss: 0.6767 - val_accuracy: 0.5378\n",
      "Epoch 4641/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6036 - accuracy: 0.6586 - val_loss: 0.6423 - val_accuracy: 0.5904\n",
      "Epoch 4642/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6028 - accuracy: 0.6562 - val_loss: 0.6668 - val_accuracy: 0.5537\n",
      "Epoch 4643/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6519 - val_accuracy: 0.5765\n",
      "Epoch 4644/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6021 - accuracy: 0.6585 - val_loss: 0.6582 - val_accuracy: 0.5678\n",
      "Epoch 4645/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6020 - accuracy: 0.6591 - val_loss: 0.6570 - val_accuracy: 0.5672\n",
      "Epoch 4646/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6020 - accuracy: 0.6586 - val_loss: 0.6531 - val_accuracy: 0.5744\n",
      "Epoch 4647/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6587 - val_loss: 0.6640 - val_accuracy: 0.5566\n",
      "Epoch 4648/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6022 - accuracy: 0.6589 - val_loss: 0.6474 - val_accuracy: 0.5844\n",
      "Epoch 4649/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6023 - accuracy: 0.6578 - val_loss: 0.6691 - val_accuracy: 0.5488\n",
      "Epoch 4650/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6026 - accuracy: 0.6586 - val_loss: 0.6431 - val_accuracy: 0.5910\n",
      "Epoch 4651/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6028 - accuracy: 0.6563 - val_loss: 0.6760 - val_accuracy: 0.5391\n",
      "Epoch 4652/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6033 - accuracy: 0.6583 - val_loss: 0.6365 - val_accuracy: 0.5976\n",
      "Epoch 4653/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6038 - accuracy: 0.6553 - val_loss: 0.6859 - val_accuracy: 0.5296\n",
      "Epoch 4654/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6049 - accuracy: 0.6561 - val_loss: 0.6305 - val_accuracy: 0.6102\n",
      "Epoch 4655/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6053 - accuracy: 0.6544 - val_loss: 0.6939 - val_accuracy: 0.5157\n",
      "Epoch 4656/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6068 - accuracy: 0.6535 - val_loss: 0.6283 - val_accuracy: 0.6129\n",
      "Epoch 4657/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6058 - accuracy: 0.6537 - val_loss: 0.6904 - val_accuracy: 0.5234\n",
      "Epoch 4658/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6057 - accuracy: 0.6550 - val_loss: 0.6359 - val_accuracy: 0.5976\n",
      "Epoch 4659/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6039 - accuracy: 0.6550 - val_loss: 0.6719 - val_accuracy: 0.5427\n",
      "Epoch 4660/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6031 - accuracy: 0.6583 - val_loss: 0.6475 - val_accuracy: 0.5837\n",
      "Epoch 4661/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6022 - accuracy: 0.6579 - val_loss: 0.6608 - val_accuracy: 0.5617\n",
      "Epoch 4662/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6021 - accuracy: 0.6588 - val_loss: 0.6583 - val_accuracy: 0.5650\n",
      "Epoch 4663/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6019 - accuracy: 0.6587 - val_loss: 0.6481 - val_accuracy: 0.5837\n",
      "Epoch 4664/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6022 - accuracy: 0.6578 - val_loss: 0.6730 - val_accuracy: 0.5451\n",
      "Epoch 4665/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6028 - accuracy: 0.6583 - val_loss: 0.6393 - val_accuracy: 0.5924\n",
      "Epoch 4666/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6033 - accuracy: 0.6558 - val_loss: 0.6801 - val_accuracy: 0.5340\n",
      "Epoch 4667/15000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6045 - accuracy: 0.6574 - val_loss: 0.6319 - val_accuracy: 0.6076\n",
      "Epoch 4668/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6046 - accuracy: 0.6545 - val_loss: 0.6909 - val_accuracy: 0.5212\n",
      "Epoch 4669/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6056 - accuracy: 0.6549 - val_loss: 0.6346 - val_accuracy: 0.6014\n",
      "Epoch 4670/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6044 - accuracy: 0.6542 - val_loss: 0.6776 - val_accuracy: 0.5378\n",
      "Epoch 4671/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6576 - val_loss: 0.6393 - val_accuracy: 0.5961\n",
      "Epoch 4672/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6031 - accuracy: 0.6560 - val_loss: 0.6716 - val_accuracy: 0.5475\n",
      "Epoch 4673/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6031 - accuracy: 0.6577 - val_loss: 0.6520 - val_accuracy: 0.5769\n",
      "Epoch 4674/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6020 - accuracy: 0.6586 - val_loss: 0.6549 - val_accuracy: 0.5720\n",
      "Epoch 4675/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6023 - accuracy: 0.6584 - val_loss: 0.6627 - val_accuracy: 0.5586\n",
      "Epoch 4676/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6021 - accuracy: 0.6588 - val_loss: 0.6449 - val_accuracy: 0.5886\n",
      "Epoch 4677/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6030 - accuracy: 0.6567 - val_loss: 0.6815 - val_accuracy: 0.5327\n",
      "Epoch 4678/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6046 - accuracy: 0.6562 - val_loss: 0.6288 - val_accuracy: 0.6138\n",
      "Epoch 4679/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6056 - accuracy: 0.6539 - val_loss: 0.6968 - val_accuracy: 0.5185\n",
      "Epoch 4680/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6530 - val_loss: 0.6329 - val_accuracy: 0.6049\n",
      "Epoch 4681/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6529 - val_loss: 0.6794 - val_accuracy: 0.5400\n",
      "Epoch 4682/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6062 - accuracy: 0.6552 - val_loss: 0.6447 - val_accuracy: 0.5840\n",
      "Epoch 4683/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6042 - accuracy: 0.6551 - val_loss: 0.6570 - val_accuracy: 0.5689\n",
      "Epoch 4684/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6034 - accuracy: 0.6558 - val_loss: 0.6742 - val_accuracy: 0.5460\n",
      "Epoch 4685/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6563 - val_loss: 0.6371 - val_accuracy: 0.5999\n",
      "Epoch 4686/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6559 - val_loss: 0.6897 - val_accuracy: 0.5241\n",
      "Epoch 4687/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6541 - val_loss: 0.6270 - val_accuracy: 0.6158\n",
      "Epoch 4688/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6081 - accuracy: 0.6515 - val_loss: 0.7018 - val_accuracy: 0.5093\n",
      "Epoch 4689/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6093 - accuracy: 0.6492 - val_loss: 0.6299 - val_accuracy: 0.6089\n",
      "Epoch 4690/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6529 - val_loss: 0.6728 - val_accuracy: 0.5451\n",
      "Epoch 4691/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6060 - accuracy: 0.6526 - val_loss: 0.6673 - val_accuracy: 0.5517\n",
      "Epoch 4692/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6053 - accuracy: 0.6533 - val_loss: 0.6450 - val_accuracy: 0.5884\n",
      "Epoch 4693/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6051 - accuracy: 0.6565 - val_loss: 0.6800 - val_accuracy: 0.5340\n",
      "Epoch 4694/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6057 - accuracy: 0.6555 - val_loss: 0.6262 - val_accuracy: 0.6167\n",
      "Epoch 4695/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6062 - accuracy: 0.6525 - val_loss: 0.6892 - val_accuracy: 0.5237\n",
      "Epoch 4696/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6051 - accuracy: 0.6555 - val_loss: 0.6467 - val_accuracy: 0.5835\n",
      "Epoch 4697/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6047 - accuracy: 0.6556 - val_loss: 0.6641 - val_accuracy: 0.5546\n",
      "Epoch 4698/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6587 - val_loss: 0.6496 - val_accuracy: 0.5751\n",
      "Epoch 4699/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6029 - accuracy: 0.6567 - val_loss: 0.6511 - val_accuracy: 0.5754\n",
      "Epoch 4700/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6025 - accuracy: 0.6588 - val_loss: 0.6724 - val_accuracy: 0.5469\n",
      "Epoch 4701/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6031 - accuracy: 0.6576 - val_loss: 0.6391 - val_accuracy: 0.5954\n",
      "Epoch 4702/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6035 - accuracy: 0.6540 - val_loss: 0.6774 - val_accuracy: 0.5351\n",
      "Epoch 4703/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6571 - val_loss: 0.6387 - val_accuracy: 0.5955\n",
      "Epoch 4704/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6564 - val_loss: 0.6749 - val_accuracy: 0.5413\n",
      "Epoch 4705/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6038 - accuracy: 0.6567 - val_loss: 0.6431 - val_accuracy: 0.5888\n",
      "Epoch 4706/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6552 - val_loss: 0.6711 - val_accuracy: 0.5473\n",
      "Epoch 4707/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6590 - val_loss: 0.6492 - val_accuracy: 0.5813\n",
      "Epoch 4708/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6025 - accuracy: 0.6583 - val_loss: 0.6543 - val_accuracy: 0.5687\n",
      "Epoch 4709/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6023 - accuracy: 0.6573 - val_loss: 0.6618 - val_accuracy: 0.5616\n",
      "Epoch 4710/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6023 - accuracy: 0.6582 - val_loss: 0.6571 - val_accuracy: 0.5711\n",
      "Epoch 4711/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6023 - accuracy: 0.6590 - val_loss: 0.6613 - val_accuracy: 0.5596\n",
      "Epoch 4712/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6582 - val_loss: 0.6425 - val_accuracy: 0.5890\n",
      "Epoch 4713/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6561 - val_loss: 0.6750 - val_accuracy: 0.5451\n",
      "Epoch 4714/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6585 - val_loss: 0.6470 - val_accuracy: 0.5833\n",
      "Epoch 4715/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6029 - accuracy: 0.6568 - val_loss: 0.6682 - val_accuracy: 0.5512\n",
      "Epoch 4716/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6030 - accuracy: 0.6579 - val_loss: 0.6401 - val_accuracy: 0.5928\n",
      "Epoch 4717/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6029 - accuracy: 0.6554 - val_loss: 0.6766 - val_accuracy: 0.5422\n",
      "Epoch 4718/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6475 - val_accuracy: 0.5849\n",
      "Epoch 4719/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6027 - accuracy: 0.6570 - val_loss: 0.6663 - val_accuracy: 0.5537\n",
      "Epoch 4720/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6423 - val_accuracy: 0.5908\n",
      "Epoch 4721/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6025 - accuracy: 0.6568 - val_loss: 0.6727 - val_accuracy: 0.5482\n",
      "Epoch 4722/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6470 - val_accuracy: 0.5844\n",
      "Epoch 4723/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6025 - accuracy: 0.6566 - val_loss: 0.6691 - val_accuracy: 0.5501\n",
      "Epoch 4724/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6588 - val_loss: 0.6429 - val_accuracy: 0.5897\n",
      "Epoch 4725/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6025 - accuracy: 0.6575 - val_loss: 0.6721 - val_accuracy: 0.5449\n",
      "Epoch 4726/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6026 - accuracy: 0.6586 - val_loss: 0.6423 - val_accuracy: 0.5932\n",
      "Epoch 4727/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6027 - accuracy: 0.6559 - val_loss: 0.6763 - val_accuracy: 0.5398\n",
      "Epoch 4728/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6392 - val_accuracy: 0.5948\n",
      "Epoch 4729/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6030 - accuracy: 0.6564 - val_loss: 0.6786 - val_accuracy: 0.5369\n",
      "Epoch 4730/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6036 - accuracy: 0.6578 - val_loss: 0.6343 - val_accuracy: 0.6008\n",
      "Epoch 4731/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6038 - accuracy: 0.6554 - val_loss: 0.6879 - val_accuracy: 0.5270\n",
      "Epoch 4732/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6045 - accuracy: 0.6569 - val_loss: 0.6339 - val_accuracy: 0.6027\n",
      "Epoch 4733/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6043 - accuracy: 0.6548 - val_loss: 0.6841 - val_accuracy: 0.5294\n",
      "Epoch 4734/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6049 - accuracy: 0.6566 - val_loss: 0.6326 - val_accuracy: 0.6050\n",
      "Epoch 4735/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6549 - val_loss: 0.6807 - val_accuracy: 0.5378\n",
      "Epoch 4736/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6036 - accuracy: 0.6576 - val_loss: 0.6445 - val_accuracy: 0.5882\n",
      "Epoch 4737/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6023 - accuracy: 0.6573 - val_loss: 0.6640 - val_accuracy: 0.5583\n",
      "Epoch 4738/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6021 - accuracy: 0.6588 - val_loss: 0.6522 - val_accuracy: 0.5789\n",
      "Epoch 4739/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6015 - accuracy: 0.6593 - val_loss: 0.6552 - val_accuracy: 0.5723\n",
      "Epoch 4740/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6019 - accuracy: 0.6588 - val_loss: 0.6664 - val_accuracy: 0.5508\n",
      "Epoch 4741/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6020 - accuracy: 0.6592 - val_loss: 0.6403 - val_accuracy: 0.5917\n",
      "Epoch 4742/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6027 - accuracy: 0.6567 - val_loss: 0.6818 - val_accuracy: 0.5343\n",
      "Epoch 4743/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6564 - val_loss: 0.6333 - val_accuracy: 0.6021\n",
      "Epoch 4744/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6044 - accuracy: 0.6549 - val_loss: 0.6906 - val_accuracy: 0.5192\n",
      "Epoch 4745/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6064 - accuracy: 0.6547 - val_loss: 0.6280 - val_accuracy: 0.6155\n",
      "Epoch 4746/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6057 - accuracy: 0.6538 - val_loss: 0.6883 - val_accuracy: 0.5269\n",
      "Epoch 4747/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6054 - accuracy: 0.6553 - val_loss: 0.6439 - val_accuracy: 0.5893\n",
      "Epoch 4748/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6030 - accuracy: 0.6568 - val_loss: 0.6607 - val_accuracy: 0.5638\n",
      "Epoch 4749/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6578 - val_loss: 0.6599 - val_accuracy: 0.5678\n",
      "Epoch 4750/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6441 - val_accuracy: 0.5866\n",
      "Epoch 4751/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6037 - accuracy: 0.6564 - val_loss: 0.6879 - val_accuracy: 0.5259\n",
      "Epoch 4752/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6047 - accuracy: 0.6559 - val_loss: 0.6236 - val_accuracy: 0.6239\n",
      "Epoch 4753/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6073 - accuracy: 0.6523 - val_loss: 0.7070 - val_accuracy: 0.5042\n",
      "Epoch 4754/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6094 - accuracy: 0.6509 - val_loss: 0.6313 - val_accuracy: 0.6074\n",
      "Epoch 4755/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6069 - accuracy: 0.6521 - val_loss: 0.6745 - val_accuracy: 0.5460\n",
      "Epoch 4756/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6046 - accuracy: 0.6574 - val_loss: 0.6490 - val_accuracy: 0.5809\n",
      "Epoch 4757/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6035 - accuracy: 0.6573 - val_loss: 0.6492 - val_accuracy: 0.5789\n",
      "Epoch 4758/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6031 - accuracy: 0.6557 - val_loss: 0.6827 - val_accuracy: 0.5362\n",
      "Epoch 4759/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6040 - accuracy: 0.6562 - val_loss: 0.6358 - val_accuracy: 0.6008\n",
      "Epoch 4760/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6046 - accuracy: 0.6565 - val_loss: 0.6818 - val_accuracy: 0.5294\n",
      "Epoch 4761/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6050 - accuracy: 0.6553 - val_loss: 0.6324 - val_accuracy: 0.6071\n",
      "Epoch 4762/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6539 - val_loss: 0.6816 - val_accuracy: 0.5336\n",
      "Epoch 4763/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6577 - val_loss: 0.6443 - val_accuracy: 0.5855\n",
      "Epoch 4764/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6570 - val_loss: 0.6630 - val_accuracy: 0.5577\n",
      "Epoch 4765/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6568 - val_loss: 0.6569 - val_accuracy: 0.5672\n",
      "Epoch 4766/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6016 - accuracy: 0.6589 - val_loss: 0.6471 - val_accuracy: 0.5831\n",
      "Epoch 4767/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6028 - accuracy: 0.6587 - val_loss: 0.6771 - val_accuracy: 0.5367\n",
      "Epoch 4768/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6034 - accuracy: 0.6571 - val_loss: 0.6324 - val_accuracy: 0.6060\n",
      "Epoch 4769/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6049 - accuracy: 0.6533 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 4770/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6064 - accuracy: 0.6540 - val_loss: 0.6310 - val_accuracy: 0.6107\n",
      "Epoch 4771/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6056 - accuracy: 0.6555 - val_loss: 0.6830 - val_accuracy: 0.5314\n",
      "Epoch 4772/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6064 - accuracy: 0.6530 - val_loss: 0.6516 - val_accuracy: 0.5780\n",
      "Epoch 4773/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6045 - accuracy: 0.6536 - val_loss: 0.6557 - val_accuracy: 0.5720\n",
      "Epoch 4774/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6042 - accuracy: 0.6580 - val_loss: 0.6737 - val_accuracy: 0.5435\n",
      "Epoch 4775/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6039 - accuracy: 0.6581 - val_loss: 0.6265 - val_accuracy: 0.6153\n",
      "Epoch 4776/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6063 - accuracy: 0.6531 - val_loss: 0.6961 - val_accuracy: 0.5130\n",
      "Epoch 4777/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6062 - accuracy: 0.6542 - val_loss: 0.6377 - val_accuracy: 0.6025\n",
      "Epoch 4778/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6821 - val_accuracy: 0.5320\n",
      "Epoch 4779/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6043 - accuracy: 0.6567 - val_loss: 0.6345 - val_accuracy: 0.5990\n",
      "Epoch 4780/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6045 - accuracy: 0.6532 - val_loss: 0.6654 - val_accuracy: 0.5583\n",
      "Epoch 4781/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6586 - val_loss: 0.6613 - val_accuracy: 0.5645\n",
      "Epoch 4782/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6579 - val_loss: 0.6506 - val_accuracy: 0.5784\n",
      "Epoch 4783/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6023 - accuracy: 0.6561 - val_loss: 0.6667 - val_accuracy: 0.5506\n",
      "Epoch 4784/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6025 - accuracy: 0.6577 - val_loss: 0.6407 - val_accuracy: 0.5946\n",
      "Epoch 4785/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6033 - accuracy: 0.6573 - val_loss: 0.6801 - val_accuracy: 0.5358\n",
      "Epoch 4786/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6035 - accuracy: 0.6570 - val_loss: 0.6348 - val_accuracy: 0.6028\n",
      "Epoch 4787/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6046 - accuracy: 0.6534 - val_loss: 0.6819 - val_accuracy: 0.5314\n",
      "Epoch 4788/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6579 - val_loss: 0.6377 - val_accuracy: 0.6008\n",
      "Epoch 4789/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6040 - accuracy: 0.6569 - val_loss: 0.6735 - val_accuracy: 0.5460\n",
      "Epoch 4790/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6575 - val_loss: 0.6478 - val_accuracy: 0.5813\n",
      "Epoch 4791/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6030 - accuracy: 0.6553 - val_loss: 0.6663 - val_accuracy: 0.5590\n",
      "Epoch 4792/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6024 - accuracy: 0.6588 - val_loss: 0.6539 - val_accuracy: 0.5738\n",
      "Epoch 4793/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6019 - accuracy: 0.6591 - val_loss: 0.6464 - val_accuracy: 0.5820\n",
      "Epoch 4794/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6558 - val_loss: 0.6714 - val_accuracy: 0.5490\n",
      "Epoch 4795/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6021 - accuracy: 0.6585 - val_loss: 0.6467 - val_accuracy: 0.5820\n",
      "Epoch 4796/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6032 - accuracy: 0.6568 - val_loss: 0.6758 - val_accuracy: 0.5396\n",
      "Epoch 4797/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6031 - accuracy: 0.6568 - val_loss: 0.6323 - val_accuracy: 0.6063\n",
      "Epoch 4798/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6543 - val_loss: 0.6819 - val_accuracy: 0.5322\n",
      "Epoch 4799/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6036 - accuracy: 0.6580 - val_loss: 0.6438 - val_accuracy: 0.5893\n",
      "Epoch 4800/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6568 - val_loss: 0.6695 - val_accuracy: 0.5499\n",
      "Epoch 4801/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6026 - accuracy: 0.6571 - val_loss: 0.6471 - val_accuracy: 0.5820\n",
      "Epoch 4802/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6019 - accuracy: 0.6564 - val_loss: 0.6575 - val_accuracy: 0.5709\n",
      "Epoch 4803/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6590 - val_loss: 0.6671 - val_accuracy: 0.5537\n",
      "Epoch 4804/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6016 - accuracy: 0.6594 - val_loss: 0.6405 - val_accuracy: 0.5930\n",
      "Epoch 4805/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6031 - accuracy: 0.6551 - val_loss: 0.6815 - val_accuracy: 0.5309\n",
      "Epoch 4806/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6037 - accuracy: 0.6578 - val_loss: 0.6306 - val_accuracy: 0.6081\n",
      "Epoch 4807/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6551 - val_loss: 0.6944 - val_accuracy: 0.5221\n",
      "Epoch 4808/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6534 - val_loss: 0.6376 - val_accuracy: 0.6003\n",
      "Epoch 4809/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6058 - accuracy: 0.6523 - val_loss: 0.6740 - val_accuracy: 0.5471\n",
      "Epoch 4810/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6041 - accuracy: 0.6561 - val_loss: 0.6503 - val_accuracy: 0.5795\n",
      "Epoch 4811/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6033 - accuracy: 0.6584 - val_loss: 0.6487 - val_accuracy: 0.5798\n",
      "Epoch 4812/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6041 - accuracy: 0.6537 - val_loss: 0.6743 - val_accuracy: 0.5422\n",
      "Epoch 4813/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6031 - accuracy: 0.6573 - val_loss: 0.6447 - val_accuracy: 0.5884\n",
      "Epoch 4814/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6561 - val_loss: 0.6819 - val_accuracy: 0.5307\n",
      "Epoch 4815/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6570 - val_loss: 0.6287 - val_accuracy: 0.6134\n",
      "Epoch 4816/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6057 - accuracy: 0.6533 - val_loss: 0.6829 - val_accuracy: 0.5323\n",
      "Epoch 4817/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6040 - accuracy: 0.6580 - val_loss: 0.6421 - val_accuracy: 0.5950\n",
      "Epoch 4818/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6049 - accuracy: 0.6555 - val_loss: 0.6745 - val_accuracy: 0.5459\n",
      "Epoch 4819/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6574 - val_loss: 0.6477 - val_accuracy: 0.5789\n",
      "Epoch 4820/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6027 - accuracy: 0.6549 - val_loss: 0.6516 - val_accuracy: 0.5778\n",
      "Epoch 4821/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6023 - accuracy: 0.6595 - val_loss: 0.6714 - val_accuracy: 0.5519\n",
      "Epoch 4822/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6023 - accuracy: 0.6585 - val_loss: 0.6395 - val_accuracy: 0.5954\n",
      "Epoch 4823/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6041 - accuracy: 0.6542 - val_loss: 0.6854 - val_accuracy: 0.5281\n",
      "Epoch 4824/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6047 - accuracy: 0.6562 - val_loss: 0.6252 - val_accuracy: 0.6173\n",
      "Epoch 4825/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6535 - val_loss: 0.6988 - val_accuracy: 0.5144\n",
      "Epoch 4826/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6070 - accuracy: 0.6542 - val_loss: 0.6382 - val_accuracy: 0.5996\n",
      "Epoch 4827/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6057 - accuracy: 0.6535 - val_loss: 0.6692 - val_accuracy: 0.5539\n",
      "Epoch 4828/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6033 - accuracy: 0.6576 - val_loss: 0.6518 - val_accuracy: 0.5760\n",
      "Epoch 4829/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6036 - accuracy: 0.6579 - val_loss: 0.6481 - val_accuracy: 0.5796\n",
      "Epoch 4830/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6558 - val_loss: 0.6716 - val_accuracy: 0.5469\n",
      "Epoch 4831/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6027 - accuracy: 0.6568 - val_loss: 0.6513 - val_accuracy: 0.5786\n",
      "Epoch 4832/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6028 - accuracy: 0.6574 - val_loss: 0.6631 - val_accuracy: 0.5596\n",
      "Epoch 4833/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6018 - accuracy: 0.6592 - val_loss: 0.6467 - val_accuracy: 0.5795\n",
      "Epoch 4834/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6028 - accuracy: 0.6552 - val_loss: 0.6607 - val_accuracy: 0.5616\n",
      "Epoch 4835/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6011 - accuracy: 0.6593 - val_loss: 0.6552 - val_accuracy: 0.5725\n",
      "Epoch 4836/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6023 - accuracy: 0.6581 - val_loss: 0.6650 - val_accuracy: 0.5554\n",
      "Epoch 4837/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6011 - accuracy: 0.6591 - val_loss: 0.6471 - val_accuracy: 0.5839\n",
      "Epoch 4838/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6021 - accuracy: 0.6560 - val_loss: 0.6623 - val_accuracy: 0.5628\n",
      "Epoch 4839/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6015 - accuracy: 0.6598 - val_loss: 0.6494 - val_accuracy: 0.5820\n",
      "Epoch 4840/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6018 - accuracy: 0.6579 - val_loss: 0.6675 - val_accuracy: 0.5546\n",
      "Epoch 4841/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6017 - accuracy: 0.6583 - val_loss: 0.6500 - val_accuracy: 0.5811\n",
      "Epoch 4842/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6013 - accuracy: 0.6579 - val_loss: 0.6579 - val_accuracy: 0.5674\n",
      "Epoch 4843/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6016 - accuracy: 0.6589 - val_loss: 0.6581 - val_accuracy: 0.5707\n",
      "Epoch 4844/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6009 - accuracy: 0.6597 - val_loss: 0.6525 - val_accuracy: 0.5767\n",
      "Epoch 4845/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6016 - accuracy: 0.6574 - val_loss: 0.6670 - val_accuracy: 0.5522\n",
      "Epoch 4846/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6014 - accuracy: 0.6592 - val_loss: 0.6392 - val_accuracy: 0.5961\n",
      "Epoch 4847/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6026 - accuracy: 0.6570 - val_loss: 0.6833 - val_accuracy: 0.5334\n",
      "Epoch 4848/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6570 - val_loss: 0.6337 - val_accuracy: 0.6067\n",
      "Epoch 4849/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6043 - accuracy: 0.6545 - val_loss: 0.6883 - val_accuracy: 0.5228\n",
      "Epoch 4850/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6055 - accuracy: 0.6558 - val_loss: 0.6307 - val_accuracy: 0.6052\n",
      "Epoch 4851/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6046 - accuracy: 0.6550 - val_loss: 0.6798 - val_accuracy: 0.5382\n",
      "Epoch 4852/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6043 - accuracy: 0.6555 - val_loss: 0.6518 - val_accuracy: 0.5787\n",
      "Epoch 4853/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6023 - accuracy: 0.6566 - val_loss: 0.6563 - val_accuracy: 0.5714\n",
      "Epoch 4854/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6571 - val_loss: 0.6672 - val_accuracy: 0.5554\n",
      "Epoch 4855/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6586 - val_loss: 0.6334 - val_accuracy: 0.6036\n",
      "Epoch 4856/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6044 - accuracy: 0.6544 - val_loss: 0.6928 - val_accuracy: 0.5188\n",
      "Epoch 4857/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6052 - accuracy: 0.6549 - val_loss: 0.6288 - val_accuracy: 0.6140\n",
      "Epoch 4858/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6534 - val_loss: 0.6925 - val_accuracy: 0.5216\n",
      "Epoch 4859/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6053 - accuracy: 0.6551 - val_loss: 0.6364 - val_accuracy: 0.6014\n",
      "Epoch 4860/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6037 - accuracy: 0.6546 - val_loss: 0.6648 - val_accuracy: 0.5586\n",
      "Epoch 4861/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6021 - accuracy: 0.6593 - val_loss: 0.6565 - val_accuracy: 0.5718\n",
      "Epoch 4862/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6017 - accuracy: 0.6595 - val_loss: 0.6447 - val_accuracy: 0.5851\n",
      "Epoch 4863/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6022 - accuracy: 0.6558 - val_loss: 0.6806 - val_accuracy: 0.5367\n",
      "Epoch 4864/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6029 - accuracy: 0.6577 - val_loss: 0.6331 - val_accuracy: 0.6045\n",
      "Epoch 4865/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6565 - val_loss: 0.6892 - val_accuracy: 0.5219\n",
      "Epoch 4866/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6048 - accuracy: 0.6557 - val_loss: 0.6299 - val_accuracy: 0.6118\n",
      "Epoch 4867/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6548 - val_loss: 0.6799 - val_accuracy: 0.5360\n",
      "Epoch 4868/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6031 - accuracy: 0.6583 - val_loss: 0.6434 - val_accuracy: 0.5910\n",
      "Epoch 4869/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6021 - accuracy: 0.6590 - val_loss: 0.6609 - val_accuracy: 0.5597\n",
      "Epoch 4870/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6015 - accuracy: 0.6583 - val_loss: 0.6613 - val_accuracy: 0.5623\n",
      "Epoch 4871/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6011 - accuracy: 0.6590 - val_loss: 0.6448 - val_accuracy: 0.5871\n",
      "Epoch 4872/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6022 - accuracy: 0.6589 - val_loss: 0.6773 - val_accuracy: 0.5367\n",
      "Epoch 4873/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6304 - val_accuracy: 0.6103\n",
      "Epoch 4874/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6041 - accuracy: 0.6545 - val_loss: 0.6923 - val_accuracy: 0.5195\n",
      "Epoch 4875/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6051 - accuracy: 0.6550 - val_loss: 0.6313 - val_accuracy: 0.6081\n",
      "Epoch 4876/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6047 - accuracy: 0.6556 - val_loss: 0.6828 - val_accuracy: 0.5325\n",
      "Epoch 4877/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6561 - val_loss: 0.6424 - val_accuracy: 0.5875\n",
      "Epoch 4878/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6022 - accuracy: 0.6559 - val_loss: 0.6576 - val_accuracy: 0.5689\n",
      "Epoch 4879/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6016 - accuracy: 0.6591 - val_loss: 0.6696 - val_accuracy: 0.5543\n",
      "Epoch 4880/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6015 - accuracy: 0.6597 - val_loss: 0.6338 - val_accuracy: 0.6043\n",
      "Epoch 4881/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6541 - val_loss: 0.6934 - val_accuracy: 0.5170\n",
      "Epoch 4882/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6546 - val_loss: 0.6249 - val_accuracy: 0.6197\n",
      "Epoch 4883/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6063 - accuracy: 0.6538 - val_loss: 0.6965 - val_accuracy: 0.5163\n",
      "Epoch 4884/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6063 - accuracy: 0.6544 - val_loss: 0.6367 - val_accuracy: 0.5996\n",
      "Epoch 4885/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6040 - accuracy: 0.6547 - val_loss: 0.6635 - val_accuracy: 0.5614\n",
      "Epoch 4886/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6019 - accuracy: 0.6594 - val_loss: 0.6623 - val_accuracy: 0.5619\n",
      "Epoch 4887/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6018 - accuracy: 0.6601 - val_loss: 0.6370 - val_accuracy: 0.5999\n",
      "Epoch 4888/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6031 - accuracy: 0.6558 - val_loss: 0.6879 - val_accuracy: 0.5247\n",
      "Epoch 4889/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6559 - val_loss: 0.6331 - val_accuracy: 0.6032\n",
      "Epoch 4890/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6043 - accuracy: 0.6559 - val_loss: 0.6812 - val_accuracy: 0.5316\n",
      "Epoch 4891/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6031 - accuracy: 0.6579 - val_loss: 0.6390 - val_accuracy: 0.5952\n",
      "Epoch 4892/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6554 - val_loss: 0.6605 - val_accuracy: 0.5658\n",
      "Epoch 4893/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6008 - accuracy: 0.6595 - val_loss: 0.6618 - val_accuracy: 0.5650\n",
      "Epoch 4894/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6010 - accuracy: 0.6597 - val_loss: 0.6483 - val_accuracy: 0.5844\n",
      "Epoch 4895/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6012 - accuracy: 0.6587 - val_loss: 0.6719 - val_accuracy: 0.5422\n",
      "Epoch 4896/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6590 - val_loss: 0.6335 - val_accuracy: 0.6016\n",
      "Epoch 4897/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6026 - accuracy: 0.6557 - val_loss: 0.6831 - val_accuracy: 0.5331\n",
      "Epoch 4898/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6031 - accuracy: 0.6575 - val_loss: 0.6393 - val_accuracy: 0.5943\n",
      "Epoch 4899/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6562 - val_loss: 0.6713 - val_accuracy: 0.5482\n",
      "Epoch 4900/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6020 - accuracy: 0.6588 - val_loss: 0.6435 - val_accuracy: 0.5902\n",
      "Epoch 4901/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6013 - accuracy: 0.6586 - val_loss: 0.6632 - val_accuracy: 0.5605\n",
      "Epoch 4902/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6010 - accuracy: 0.6590 - val_loss: 0.6591 - val_accuracy: 0.5661\n",
      "Epoch 4903/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6007 - accuracy: 0.6593 - val_loss: 0.6473 - val_accuracy: 0.5839\n",
      "Epoch 4904/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6010 - accuracy: 0.6583 - val_loss: 0.6692 - val_accuracy: 0.5501\n",
      "Epoch 4905/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6013 - accuracy: 0.6596 - val_loss: 0.6410 - val_accuracy: 0.5930\n",
      "Epoch 4906/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6019 - accuracy: 0.6578 - val_loss: 0.6782 - val_accuracy: 0.5384\n",
      "Epoch 4907/15000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6029 - accuracy: 0.6573 - val_loss: 0.6342 - val_accuracy: 0.6028\n",
      "Epoch 4908/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6031 - accuracy: 0.6559 - val_loss: 0.6818 - val_accuracy: 0.5343\n",
      "Epoch 4909/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6414 - val_accuracy: 0.5926\n",
      "Epoch 4910/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6018 - accuracy: 0.6568 - val_loss: 0.6631 - val_accuracy: 0.5632\n",
      "Epoch 4911/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6016 - accuracy: 0.6591 - val_loss: 0.6551 - val_accuracy: 0.5756\n",
      "Epoch 4912/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6009 - accuracy: 0.6592 - val_loss: 0.6537 - val_accuracy: 0.5773\n",
      "Epoch 4913/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6015 - accuracy: 0.6586 - val_loss: 0.6690 - val_accuracy: 0.5519\n",
      "Epoch 4914/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6015 - accuracy: 0.6588 - val_loss: 0.6326 - val_accuracy: 0.6067\n",
      "Epoch 4915/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6030 - accuracy: 0.6550 - val_loss: 0.6903 - val_accuracy: 0.5258\n",
      "Epoch 4916/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6040 - accuracy: 0.6562 - val_loss: 0.6345 - val_accuracy: 0.6036\n",
      "Epoch 4917/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6047 - accuracy: 0.6547 - val_loss: 0.6842 - val_accuracy: 0.5285\n",
      "Epoch 4918/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6054 - accuracy: 0.6565 - val_loss: 0.6313 - val_accuracy: 0.6078\n",
      "Epoch 4919/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6042 - accuracy: 0.6540 - val_loss: 0.6739 - val_accuracy: 0.5488\n",
      "Epoch 4920/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6614 - val_accuracy: 0.5665\n",
      "Epoch 4921/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6014 - accuracy: 0.6591 - val_loss: 0.6453 - val_accuracy: 0.5846\n",
      "Epoch 4922/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6022 - accuracy: 0.6564 - val_loss: 0.6690 - val_accuracy: 0.5522\n",
      "Epoch 4923/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6025 - accuracy: 0.6585 - val_loss: 0.6381 - val_accuracy: 0.5954\n",
      "Epoch 4924/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6034 - accuracy: 0.6565 - val_loss: 0.6870 - val_accuracy: 0.5276\n",
      "Epoch 4925/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6038 - accuracy: 0.6572 - val_loss: 0.6315 - val_accuracy: 0.6109\n",
      "Epoch 4926/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6044 - accuracy: 0.6538 - val_loss: 0.6847 - val_accuracy: 0.5292\n",
      "Epoch 4927/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6579 - val_loss: 0.6394 - val_accuracy: 0.5994\n",
      "Epoch 4928/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6029 - accuracy: 0.6573 - val_loss: 0.6655 - val_accuracy: 0.5546\n",
      "Epoch 4929/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6022 - accuracy: 0.6576 - val_loss: 0.6499 - val_accuracy: 0.5795\n",
      "Epoch 4930/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6017 - accuracy: 0.6571 - val_loss: 0.6615 - val_accuracy: 0.5672\n",
      "Epoch 4931/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6012 - accuracy: 0.6595 - val_loss: 0.6632 - val_accuracy: 0.5608\n",
      "Epoch 4932/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6009 - accuracy: 0.6590 - val_loss: 0.6378 - val_accuracy: 0.5972\n",
      "Epoch 4933/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6020 - accuracy: 0.6556 - val_loss: 0.6775 - val_accuracy: 0.5413\n",
      "Epoch 4934/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6020 - accuracy: 0.6584 - val_loss: 0.6397 - val_accuracy: 0.5974\n",
      "Epoch 4935/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6036 - accuracy: 0.6568 - val_loss: 0.6863 - val_accuracy: 0.5278\n",
      "Epoch 4936/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6043 - accuracy: 0.6561 - val_loss: 0.6252 - val_accuracy: 0.6197\n",
      "Epoch 4937/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6045 - accuracy: 0.6547 - val_loss: 0.6867 - val_accuracy: 0.5290\n",
      "Epoch 4938/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6034 - accuracy: 0.6576 - val_loss: 0.6475 - val_accuracy: 0.5849\n",
      "Epoch 4939/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6021 - accuracy: 0.6580 - val_loss: 0.6562 - val_accuracy: 0.5709\n",
      "Epoch 4940/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6015 - accuracy: 0.6579 - val_loss: 0.6573 - val_accuracy: 0.5694\n",
      "Epoch 4941/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6011 - accuracy: 0.6590 - val_loss: 0.6469 - val_accuracy: 0.5881\n",
      "Epoch 4942/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6023 - accuracy: 0.6584 - val_loss: 0.6850 - val_accuracy: 0.5287\n",
      "Epoch 4943/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6032 - accuracy: 0.6579 - val_loss: 0.6228 - val_accuracy: 0.6253\n",
      "Epoch 4944/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6543 - val_loss: 0.7018 - val_accuracy: 0.5102\n",
      "Epoch 4945/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6068 - accuracy: 0.6537 - val_loss: 0.6315 - val_accuracy: 0.6076\n",
      "Epoch 4946/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6053 - accuracy: 0.6546 - val_loss: 0.6772 - val_accuracy: 0.5427\n",
      "Epoch 4947/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6042 - accuracy: 0.6570 - val_loss: 0.6452 - val_accuracy: 0.5897\n",
      "Epoch 4948/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6028 - accuracy: 0.6553 - val_loss: 0.6570 - val_accuracy: 0.5701\n",
      "Epoch 4949/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6014 - accuracy: 0.6601 - val_loss: 0.6760 - val_accuracy: 0.5426\n",
      "Epoch 4950/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6027 - accuracy: 0.6584 - val_loss: 0.6284 - val_accuracy: 0.6138\n",
      "Epoch 4951/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6037 - accuracy: 0.6556 - val_loss: 0.6879 - val_accuracy: 0.5263\n",
      "Epoch 4952/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6045 - accuracy: 0.6563 - val_loss: 0.6377 - val_accuracy: 0.5986\n",
      "Epoch 4953/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6041 - accuracy: 0.6559 - val_loss: 0.6798 - val_accuracy: 0.5353\n",
      "Epoch 4954/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6026 - accuracy: 0.6581 - val_loss: 0.6357 - val_accuracy: 0.6014\n",
      "Epoch 4955/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6020 - accuracy: 0.6563 - val_loss: 0.6630 - val_accuracy: 0.5621\n",
      "Epoch 4956/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6003 - accuracy: 0.6603 - val_loss: 0.6647 - val_accuracy: 0.5583\n",
      "Epoch 4957/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6009 - accuracy: 0.6599 - val_loss: 0.6464 - val_accuracy: 0.5857\n",
      "Epoch 4958/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6006 - accuracy: 0.6587 - val_loss: 0.6669 - val_accuracy: 0.5566\n",
      "Epoch 4959/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6014 - accuracy: 0.6588 - val_loss: 0.6393 - val_accuracy: 0.5928\n",
      "Epoch 4960/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6014 - accuracy: 0.6576 - val_loss: 0.6770 - val_accuracy: 0.5438\n",
      "Epoch 4961/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6016 - accuracy: 0.6589 - val_loss: 0.6433 - val_accuracy: 0.5904\n",
      "Epoch 4962/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6014 - accuracy: 0.6574 - val_loss: 0.6695 - val_accuracy: 0.5510\n",
      "Epoch 4963/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6011 - accuracy: 0.6598 - val_loss: 0.6419 - val_accuracy: 0.5910\n",
      "Epoch 4964/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6011 - accuracy: 0.6586 - val_loss: 0.6678 - val_accuracy: 0.5535\n",
      "Epoch 4965/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6006 - accuracy: 0.6594 - val_loss: 0.6491 - val_accuracy: 0.5842\n",
      "Epoch 4966/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6007 - accuracy: 0.6582 - val_loss: 0.6626 - val_accuracy: 0.5643\n",
      "Epoch 4967/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6002 - accuracy: 0.6604 - val_loss: 0.6500 - val_accuracy: 0.5817\n",
      "Epoch 4968/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6003 - accuracy: 0.6594 - val_loss: 0.6575 - val_accuracy: 0.5700\n",
      "Epoch 4969/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6001 - accuracy: 0.6598 - val_loss: 0.6556 - val_accuracy: 0.5751\n",
      "Epoch 4970/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6002 - accuracy: 0.6596 - val_loss: 0.6593 - val_accuracy: 0.5692\n",
      "Epoch 4971/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6545 - val_accuracy: 0.5764\n",
      "Epoch 4972/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6001 - accuracy: 0.6599 - val_loss: 0.6540 - val_accuracy: 0.5760\n",
      "Epoch 4973/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6577 - val_accuracy: 0.5725\n",
      "Epoch 4974/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6546 - val_accuracy: 0.5769\n",
      "Epoch 4975/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6593 - val_accuracy: 0.5685\n",
      "Epoch 4976/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5999 - accuracy: 0.6595 - val_loss: 0.6506 - val_accuracy: 0.5806\n",
      "Epoch 4977/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6599 - val_loss: 0.6623 - val_accuracy: 0.5628\n",
      "Epoch 4978/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6598 - val_loss: 0.6491 - val_accuracy: 0.5829\n",
      "Epoch 4979/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6002 - accuracy: 0.6589 - val_loss: 0.6670 - val_accuracy: 0.5561\n",
      "Epoch 4980/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6003 - accuracy: 0.6604 - val_loss: 0.6435 - val_accuracy: 0.5895\n",
      "Epoch 4981/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6006 - accuracy: 0.6585 - val_loss: 0.6742 - val_accuracy: 0.5455\n",
      "Epoch 4982/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6011 - accuracy: 0.6595 - val_loss: 0.6357 - val_accuracy: 0.6010\n",
      "Epoch 4983/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6018 - accuracy: 0.6570 - val_loss: 0.6851 - val_accuracy: 0.5305\n",
      "Epoch 4984/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6027 - accuracy: 0.6584 - val_loss: 0.6298 - val_accuracy: 0.6120\n",
      "Epoch 4985/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6030 - accuracy: 0.6558 - val_loss: 0.6907 - val_accuracy: 0.5247\n",
      "Epoch 4986/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6042 - accuracy: 0.6568 - val_loss: 0.6295 - val_accuracy: 0.6127\n",
      "Epoch 4987/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6032 - accuracy: 0.6551 - val_loss: 0.6868 - val_accuracy: 0.5287\n",
      "Epoch 4988/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6029 - accuracy: 0.6583 - val_loss: 0.6367 - val_accuracy: 0.5988\n",
      "Epoch 4989/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6015 - accuracy: 0.6569 - val_loss: 0.6689 - val_accuracy: 0.5530\n",
      "Epoch 4990/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6007 - accuracy: 0.6600 - val_loss: 0.6479 - val_accuracy: 0.5857\n",
      "Epoch 4991/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6594 - val_loss: 0.6602 - val_accuracy: 0.5676\n",
      "Epoch 4992/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6575 - val_accuracy: 0.5723\n",
      "Epoch 4993/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6477 - val_accuracy: 0.5840\n",
      "Epoch 4994/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5999 - accuracy: 0.6588 - val_loss: 0.6684 - val_accuracy: 0.5528\n",
      "Epoch 4995/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6003 - accuracy: 0.6599 - val_loss: 0.6414 - val_accuracy: 0.5924\n",
      "Epoch 4996/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6008 - accuracy: 0.6575 - val_loss: 0.6783 - val_accuracy: 0.5387\n",
      "Epoch 4997/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6018 - accuracy: 0.6589 - val_loss: 0.6317 - val_accuracy: 0.6061\n",
      "Epoch 4998/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6023 - accuracy: 0.6569 - val_loss: 0.6884 - val_accuracy: 0.5265\n",
      "Epoch 4999/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6033 - accuracy: 0.6579 - val_loss: 0.6311 - val_accuracy: 0.6080\n",
      "Epoch 5000/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6027 - accuracy: 0.6563 - val_loss: 0.6831 - val_accuracy: 0.5320\n",
      "Epoch 5001/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6028 - accuracy: 0.6581 - val_loss: 0.6355 - val_accuracy: 0.5992\n",
      "Epoch 5002/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6015 - accuracy: 0.6570 - val_loss: 0.6745 - val_accuracy: 0.5451\n",
      "Epoch 5003/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6010 - accuracy: 0.6599 - val_loss: 0.6441 - val_accuracy: 0.5881\n",
      "Epoch 5004/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6002 - accuracy: 0.6587 - val_loss: 0.6626 - val_accuracy: 0.5632\n",
      "Epoch 5005/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6000 - accuracy: 0.6601 - val_loss: 0.6512 - val_accuracy: 0.5813\n",
      "Epoch 5006/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6601 - val_accuracy: 0.5663\n",
      "Epoch 5007/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5997 - accuracy: 0.6604 - val_loss: 0.6514 - val_accuracy: 0.5802\n",
      "Epoch 5008/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5997 - accuracy: 0.6598 - val_loss: 0.6577 - val_accuracy: 0.5729\n",
      "Epoch 5009/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5996 - accuracy: 0.6603 - val_loss: 0.6556 - val_accuracy: 0.5740\n",
      "Epoch 5010/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5996 - accuracy: 0.6599 - val_loss: 0.6575 - val_accuracy: 0.5731\n",
      "Epoch 5011/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5996 - accuracy: 0.6604 - val_loss: 0.6531 - val_accuracy: 0.5787\n",
      "Epoch 5012/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5996 - accuracy: 0.6596 - val_loss: 0.6598 - val_accuracy: 0.5701\n",
      "Epoch 5013/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5996 - accuracy: 0.6602 - val_loss: 0.6521 - val_accuracy: 0.5780\n",
      "Epoch 5014/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5996 - accuracy: 0.6598 - val_loss: 0.6604 - val_accuracy: 0.5689\n",
      "Epoch 5015/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5997 - accuracy: 0.6601 - val_loss: 0.6482 - val_accuracy: 0.5851\n",
      "Epoch 5016/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5998 - accuracy: 0.6594 - val_loss: 0.6695 - val_accuracy: 0.5530\n",
      "Epoch 5017/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6001 - accuracy: 0.6604 - val_loss: 0.6399 - val_accuracy: 0.5946\n",
      "Epoch 5018/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6007 - accuracy: 0.6576 - val_loss: 0.6820 - val_accuracy: 0.5354\n",
      "Epoch 5019/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6020 - accuracy: 0.6581 - val_loss: 0.6282 - val_accuracy: 0.6155\n",
      "Epoch 5020/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6034 - accuracy: 0.6556 - val_loss: 0.7023 - val_accuracy: 0.5132\n",
      "Epoch 5021/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6068 - accuracy: 0.6539 - val_loss: 0.6198 - val_accuracy: 0.6293\n",
      "Epoch 5022/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6535 - val_loss: 0.7023 - val_accuracy: 0.5132\n",
      "Epoch 5023/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6063 - accuracy: 0.6551 - val_loss: 0.6336 - val_accuracy: 0.6038\n",
      "Epoch 5024/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6565 - val_loss: 0.6659 - val_accuracy: 0.5605\n",
      "Epoch 5025/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6007 - accuracy: 0.6603 - val_loss: 0.6556 - val_accuracy: 0.5736\n",
      "Epoch 5026/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5997 - accuracy: 0.6605 - val_loss: 0.6453 - val_accuracy: 0.5866\n",
      "Epoch 5027/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6008 - accuracy: 0.6578 - val_loss: 0.6842 - val_accuracy: 0.5296\n",
      "Epoch 5028/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6028 - accuracy: 0.6577 - val_loss: 0.6206 - val_accuracy: 0.6295\n",
      "Epoch 5029/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6055 - accuracy: 0.6545 - val_loss: 0.7128 - val_accuracy: 0.5009\n",
      "Epoch 5030/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6095 - accuracy: 0.6515 - val_loss: 0.6277 - val_accuracy: 0.6140\n",
      "Epoch 5031/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6526 - val_loss: 0.6733 - val_accuracy: 0.5486\n",
      "Epoch 5032/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6034 - accuracy: 0.6573 - val_loss: 0.6533 - val_accuracy: 0.5769\n",
      "Epoch 5033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6020 - accuracy: 0.6587 - val_loss: 0.6428 - val_accuracy: 0.5901\n",
      "Epoch 5034/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6025 - accuracy: 0.6567 - val_loss: 0.6902 - val_accuracy: 0.5263\n",
      "Epoch 5035/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6575 - val_loss: 0.6269 - val_accuracy: 0.6189\n",
      "Epoch 5036/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6046 - accuracy: 0.6559 - val_loss: 0.6904 - val_accuracy: 0.5227\n",
      "Epoch 5037/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6044 - accuracy: 0.6563 - val_loss: 0.6333 - val_accuracy: 0.6039\n",
      "Epoch 5038/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6031 - accuracy: 0.6552 - val_loss: 0.6723 - val_accuracy: 0.5471\n",
      "Epoch 5039/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6011 - accuracy: 0.6600 - val_loss: 0.6452 - val_accuracy: 0.5860\n",
      "Epoch 5040/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6007 - accuracy: 0.6586 - val_loss: 0.6607 - val_accuracy: 0.5639\n",
      "Epoch 5041/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6002 - accuracy: 0.6589 - val_loss: 0.6597 - val_accuracy: 0.5659\n",
      "Epoch 5042/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5999 - accuracy: 0.6590 - val_loss: 0.6442 - val_accuracy: 0.5890\n",
      "Epoch 5043/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6007 - accuracy: 0.6590 - val_loss: 0.6712 - val_accuracy: 0.5473\n",
      "Epoch 5044/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6007 - accuracy: 0.6594 - val_loss: 0.6372 - val_accuracy: 0.6001\n",
      "Epoch 5045/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6021 - accuracy: 0.6557 - val_loss: 0.6834 - val_accuracy: 0.5311\n",
      "Epoch 5046/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6578 - val_loss: 0.6284 - val_accuracy: 0.6160\n",
      "Epoch 5047/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6036 - accuracy: 0.6566 - val_loss: 0.6935 - val_accuracy: 0.5265\n",
      "Epoch 5048/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6048 - accuracy: 0.6559 - val_loss: 0.6392 - val_accuracy: 0.6001\n",
      "Epoch 5049/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6027 - accuracy: 0.6558 - val_loss: 0.6651 - val_accuracy: 0.5597\n",
      "Epoch 5050/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6582 - val_loss: 0.6577 - val_accuracy: 0.5696\n",
      "Epoch 5051/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6010 - accuracy: 0.6593 - val_loss: 0.6370 - val_accuracy: 0.6001\n",
      "Epoch 5052/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6030 - accuracy: 0.6559 - val_loss: 0.6961 - val_accuracy: 0.5170\n",
      "Epoch 5053/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6042 - accuracy: 0.6566 - val_loss: 0.6267 - val_accuracy: 0.6187\n",
      "Epoch 5054/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6065 - accuracy: 0.6535 - val_loss: 0.7007 - val_accuracy: 0.5144\n",
      "Epoch 5055/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6069 - accuracy: 0.6547 - val_loss: 0.6284 - val_accuracy: 0.6125\n",
      "Epoch 5056/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6048 - accuracy: 0.6532 - val_loss: 0.6691 - val_accuracy: 0.5541\n",
      "Epoch 5057/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6018 - accuracy: 0.6591 - val_loss: 0.6612 - val_accuracy: 0.5663\n",
      "Epoch 5058/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6011 - accuracy: 0.6595 - val_loss: 0.6411 - val_accuracy: 0.5959\n",
      "Epoch 5059/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6028 - accuracy: 0.6550 - val_loss: 0.6879 - val_accuracy: 0.5272\n",
      "Epoch 5060/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6565 - val_loss: 0.6257 - val_accuracy: 0.6156\n",
      "Epoch 5061/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6053 - accuracy: 0.6547 - val_loss: 0.6967 - val_accuracy: 0.5183\n",
      "Epoch 5062/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6052 - accuracy: 0.6552 - val_loss: 0.6350 - val_accuracy: 0.6050\n",
      "Epoch 5063/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6037 - accuracy: 0.6543 - val_loss: 0.6660 - val_accuracy: 0.5574\n",
      "Epoch 5064/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6009 - accuracy: 0.6594 - val_loss: 0.6553 - val_accuracy: 0.5740\n",
      "Epoch 5065/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6010 - accuracy: 0.6593 - val_loss: 0.6448 - val_accuracy: 0.5881\n",
      "Epoch 5066/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6013 - accuracy: 0.6574 - val_loss: 0.6780 - val_accuracy: 0.5411\n",
      "Epoch 5067/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6018 - accuracy: 0.6583 - val_loss: 0.6376 - val_accuracy: 0.5994\n",
      "Epoch 5068/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6023 - accuracy: 0.6570 - val_loss: 0.6771 - val_accuracy: 0.5415\n",
      "Epoch 5069/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6015 - accuracy: 0.6591 - val_loss: 0.6382 - val_accuracy: 0.5974\n",
      "Epoch 5070/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6010 - accuracy: 0.6568 - val_loss: 0.6630 - val_accuracy: 0.5647\n",
      "Epoch 5071/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6000 - accuracy: 0.6601 - val_loss: 0.6565 - val_accuracy: 0.5723\n",
      "Epoch 5072/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6001 - accuracy: 0.6594 - val_loss: 0.6542 - val_accuracy: 0.5767\n",
      "Epoch 5073/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5997 - accuracy: 0.6600 - val_loss: 0.6611 - val_accuracy: 0.5619\n",
      "Epoch 5074/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6000 - accuracy: 0.6592 - val_loss: 0.6402 - val_accuracy: 0.5944\n",
      "Epoch 5075/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6004 - accuracy: 0.6581 - val_loss: 0.6756 - val_accuracy: 0.5440\n",
      "Epoch 5076/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6007 - accuracy: 0.6592 - val_loss: 0.6433 - val_accuracy: 0.5908\n",
      "Epoch 5077/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6010 - accuracy: 0.6579 - val_loss: 0.6729 - val_accuracy: 0.5469\n",
      "Epoch 5078/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6012 - accuracy: 0.6589 - val_loss: 0.6349 - val_accuracy: 0.6030\n",
      "Epoch 5079/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6011 - accuracy: 0.6566 - val_loss: 0.6766 - val_accuracy: 0.5455\n",
      "Epoch 5080/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6013 - accuracy: 0.6586 - val_loss: 0.6465 - val_accuracy: 0.5870\n",
      "Epoch 5081/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6004 - accuracy: 0.6585 - val_loss: 0.6605 - val_accuracy: 0.5703\n",
      "Epoch 5082/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6001 - accuracy: 0.6598 - val_loss: 0.6529 - val_accuracy: 0.5780\n",
      "Epoch 5083/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5997 - accuracy: 0.6595 - val_loss: 0.6525 - val_accuracy: 0.5789\n",
      "Epoch 5084/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6003 - accuracy: 0.6591 - val_loss: 0.6698 - val_accuracy: 0.5522\n",
      "Epoch 5085/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6004 - accuracy: 0.6594 - val_loss: 0.6371 - val_accuracy: 0.6018\n",
      "Epoch 5086/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6014 - accuracy: 0.6572 - val_loss: 0.6824 - val_accuracy: 0.5347\n",
      "Epoch 5087/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6021 - accuracy: 0.6579 - val_loss: 0.6331 - val_accuracy: 0.6056\n",
      "Epoch 5088/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6559 - val_loss: 0.6799 - val_accuracy: 0.5402\n",
      "Epoch 5089/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6028 - accuracy: 0.6579 - val_loss: 0.6389 - val_accuracy: 0.5986\n",
      "Epoch 5090/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6021 - accuracy: 0.6567 - val_loss: 0.6729 - val_accuracy: 0.5515\n",
      "Epoch 5091/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6009 - accuracy: 0.6600 - val_loss: 0.6494 - val_accuracy: 0.5833\n",
      "Epoch 5092/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6002 - accuracy: 0.6591 - val_loss: 0.6523 - val_accuracy: 0.5769\n",
      "Epoch 5093/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6007 - accuracy: 0.6587 - val_loss: 0.6652 - val_accuracy: 0.5621\n",
      "Epoch 5094/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6003 - accuracy: 0.6600 - val_loss: 0.6438 - val_accuracy: 0.5886\n",
      "Epoch 5095/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6018 - accuracy: 0.6578 - val_loss: 0.6826 - val_accuracy: 0.5340\n",
      "Epoch 5096/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6025 - accuracy: 0.6580 - val_loss: 0.6232 - val_accuracy: 0.6239\n",
      "Epoch 5097/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6046 - accuracy: 0.6547 - val_loss: 0.7038 - val_accuracy: 0.5142\n",
      "Epoch 5098/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6061 - accuracy: 0.6549 - val_loss: 0.6354 - val_accuracy: 0.6056\n",
      "Epoch 5099/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6046 - accuracy: 0.6551 - val_loss: 0.6721 - val_accuracy: 0.5522\n",
      "Epoch 5100/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6030 - accuracy: 0.6583 - val_loss: 0.6459 - val_accuracy: 0.5868\n",
      "Epoch 5101/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6032 - accuracy: 0.6548 - val_loss: 0.6543 - val_accuracy: 0.5749\n",
      "Epoch 5102/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6000 - accuracy: 0.6592 - val_loss: 0.6693 - val_accuracy: 0.5592\n",
      "Epoch 5103/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6026 - accuracy: 0.6574 - val_loss: 0.6594 - val_accuracy: 0.5678\n",
      "Epoch 5104/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6012 - accuracy: 0.6587 - val_loss: 0.6403 - val_accuracy: 0.5924\n",
      "Epoch 5105/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6030 - accuracy: 0.6551 - val_loss: 0.6783 - val_accuracy: 0.5407\n",
      "Epoch 5106/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6022 - accuracy: 0.6578 - val_loss: 0.6359 - val_accuracy: 0.6052\n",
      "Epoch 5107/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6077 - accuracy: 0.6535 - val_loss: 0.7087 - val_accuracy: 0.5031\n",
      "Epoch 5108/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6503 - val_loss: 0.6234 - val_accuracy: 0.6279\n",
      "Epoch 5109/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6169 - accuracy: 0.6430 - val_loss: 0.7001 - val_accuracy: 0.5227\n",
      "Epoch 5110/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6101 - accuracy: 0.6520 - val_loss: 0.6458 - val_accuracy: 0.5890\n",
      "Epoch 5111/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6111 - accuracy: 0.6496 - val_loss: 0.6752 - val_accuracy: 0.5457\n",
      "Epoch 5112/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6018 - accuracy: 0.6596 - val_loss: 0.6428 - val_accuracy: 0.5943\n",
      "Epoch 5113/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6055 - accuracy: 0.6555 - val_loss: 0.6672 - val_accuracy: 0.5594\n",
      "Epoch 5114/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6553 - val_loss: 0.6468 - val_accuracy: 0.5831\n",
      "Epoch 5115/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6046 - accuracy: 0.6530 - val_loss: 0.6666 - val_accuracy: 0.5533\n",
      "Epoch 5116/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6015 - accuracy: 0.6590 - val_loss: 0.6485 - val_accuracy: 0.5835\n",
      "Epoch 5117/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6041 - accuracy: 0.6560 - val_loss: 0.6734 - val_accuracy: 0.5462\n",
      "Epoch 5118/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6025 - accuracy: 0.6575 - val_loss: 0.6406 - val_accuracy: 0.5970\n",
      "Epoch 5119/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6024 - accuracy: 0.6555 - val_loss: 0.6737 - val_accuracy: 0.5501\n",
      "Epoch 5120/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6504 - val_accuracy: 0.5769\n",
      "Epoch 5121/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6022 - accuracy: 0.6586 - val_loss: 0.6461 - val_accuracy: 0.5881\n",
      "Epoch 5122/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6007 - accuracy: 0.6570 - val_loss: 0.6598 - val_accuracy: 0.5652\n",
      "Epoch 5123/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6012 - accuracy: 0.6569 - val_loss: 0.6571 - val_accuracy: 0.5734\n",
      "Epoch 5124/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6008 - accuracy: 0.6589 - val_loss: 0.6625 - val_accuracy: 0.5628\n",
      "Epoch 5125/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6005 - accuracy: 0.6591 - val_loss: 0.6463 - val_accuracy: 0.5853\n",
      "Epoch 5126/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6006 - accuracy: 0.6581 - val_loss: 0.6626 - val_accuracy: 0.5634\n",
      "Epoch 5127/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6003 - accuracy: 0.6586 - val_loss: 0.6512 - val_accuracy: 0.5800\n",
      "Epoch 5128/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6000 - accuracy: 0.6593 - val_loss: 0.6615 - val_accuracy: 0.5656\n",
      "Epoch 5129/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6001 - accuracy: 0.6608 - val_loss: 0.6528 - val_accuracy: 0.5796\n",
      "Epoch 5130/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5998 - accuracy: 0.6583 - val_loss: 0.6566 - val_accuracy: 0.5753\n",
      "Epoch 5131/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5995 - accuracy: 0.6597 - val_loss: 0.6585 - val_accuracy: 0.5712\n",
      "Epoch 5132/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6490 - val_accuracy: 0.5839\n",
      "Epoch 5133/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5994 - accuracy: 0.6589 - val_loss: 0.6623 - val_accuracy: 0.5639\n",
      "Epoch 5134/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5998 - accuracy: 0.6590 - val_loss: 0.6518 - val_accuracy: 0.5804\n",
      "Epoch 5135/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5994 - accuracy: 0.6596 - val_loss: 0.6624 - val_accuracy: 0.5669\n",
      "Epoch 5136/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5995 - accuracy: 0.6606 - val_loss: 0.6473 - val_accuracy: 0.5860\n",
      "Epoch 5137/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5994 - accuracy: 0.6595 - val_loss: 0.6635 - val_accuracy: 0.5649\n",
      "Epoch 5138/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5994 - accuracy: 0.6592 - val_loss: 0.6505 - val_accuracy: 0.5833\n",
      "Epoch 5139/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5993 - accuracy: 0.6597 - val_loss: 0.6637 - val_accuracy: 0.5627\n",
      "Epoch 5140/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5994 - accuracy: 0.6606 - val_loss: 0.6480 - val_accuracy: 0.5879\n",
      "Epoch 5141/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5993 - accuracy: 0.6588 - val_loss: 0.6654 - val_accuracy: 0.5594\n",
      "Epoch 5142/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5993 - accuracy: 0.6591 - val_loss: 0.6469 - val_accuracy: 0.5871\n",
      "Epoch 5143/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5992 - accuracy: 0.6597 - val_loss: 0.6649 - val_accuracy: 0.5608\n",
      "Epoch 5144/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5994 - accuracy: 0.6602 - val_loss: 0.6441 - val_accuracy: 0.5923\n",
      "Epoch 5145/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5996 - accuracy: 0.6585 - val_loss: 0.6738 - val_accuracy: 0.5477\n",
      "Epoch 5146/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5999 - accuracy: 0.6601 - val_loss: 0.6385 - val_accuracy: 0.5988\n",
      "Epoch 5147/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6002 - accuracy: 0.6584 - val_loss: 0.6782 - val_accuracy: 0.5427\n",
      "Epoch 5148/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6009 - accuracy: 0.6591 - val_loss: 0.6341 - val_accuracy: 0.6071\n",
      "Epoch 5149/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6009 - accuracy: 0.6575 - val_loss: 0.6829 - val_accuracy: 0.5365\n",
      "Epoch 5150/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6012 - accuracy: 0.6599 - val_loss: 0.6348 - val_accuracy: 0.6058\n",
      "Epoch 5151/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6008 - accuracy: 0.6568 - val_loss: 0.6780 - val_accuracy: 0.5427\n",
      "Epoch 5152/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6007 - accuracy: 0.6589 - val_loss: 0.6381 - val_accuracy: 0.5990\n",
      "Epoch 5153/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6000 - accuracy: 0.6582 - val_loss: 0.6713 - val_accuracy: 0.5512\n",
      "Epoch 5154/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5996 - accuracy: 0.6610 - val_loss: 0.6449 - val_accuracy: 0.5906\n",
      "Epoch 5155/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5992 - accuracy: 0.6593 - val_loss: 0.6654 - val_accuracy: 0.5592\n",
      "Epoch 5156/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5991 - accuracy: 0.6601 - val_loss: 0.6482 - val_accuracy: 0.5844\n",
      "Epoch 5157/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5989 - accuracy: 0.6596 - val_loss: 0.6624 - val_accuracy: 0.5665\n",
      "Epoch 5158/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5989 - accuracy: 0.6610 - val_loss: 0.6475 - val_accuracy: 0.5866\n",
      "Epoch 5159/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5989 - accuracy: 0.6599 - val_loss: 0.6636 - val_accuracy: 0.5625\n",
      "Epoch 5160/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5989 - accuracy: 0.6605 - val_loss: 0.6479 - val_accuracy: 0.5859\n",
      "Epoch 5161/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5990 - accuracy: 0.6600 - val_loss: 0.6669 - val_accuracy: 0.5559\n",
      "Epoch 5162/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5991 - accuracy: 0.6603 - val_loss: 0.6408 - val_accuracy: 0.5961\n",
      "Epoch 5163/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5995 - accuracy: 0.6584 - val_loss: 0.6757 - val_accuracy: 0.5455\n",
      "Epoch 5164/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6000 - accuracy: 0.6595 - val_loss: 0.6362 - val_accuracy: 0.6036\n",
      "Epoch 5165/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6005 - accuracy: 0.6583 - val_loss: 0.6837 - val_accuracy: 0.5347\n",
      "Epoch 5166/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6015 - accuracy: 0.6583 - val_loss: 0.6292 - val_accuracy: 0.6142\n",
      "Epoch 5167/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6019 - accuracy: 0.6570 - val_loss: 0.6913 - val_accuracy: 0.5243\n",
      "Epoch 5168/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6031 - accuracy: 0.6584 - val_loss: 0.6279 - val_accuracy: 0.6162\n",
      "Epoch 5169/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6023 - accuracy: 0.6567 - val_loss: 0.6869 - val_accuracy: 0.5303\n",
      "Epoch 5170/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6022 - accuracy: 0.6587 - val_loss: 0.6345 - val_accuracy: 0.6061\n",
      "Epoch 5171/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6006 - accuracy: 0.6580 - val_loss: 0.6739 - val_accuracy: 0.5462\n",
      "Epoch 5172/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5999 - accuracy: 0.6608 - val_loss: 0.6440 - val_accuracy: 0.5915\n",
      "Epoch 5173/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5991 - accuracy: 0.6595 - val_loss: 0.6625 - val_accuracy: 0.5652\n",
      "Epoch 5174/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5988 - accuracy: 0.6601 - val_loss: 0.6522 - val_accuracy: 0.5806\n",
      "Epoch 5175/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5985 - accuracy: 0.6604 - val_loss: 0.6563 - val_accuracy: 0.5760\n",
      "Epoch 5176/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5986 - accuracy: 0.6610 - val_loss: 0.6563 - val_accuracy: 0.5736\n",
      "Epoch 5177/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5985 - accuracy: 0.6603 - val_loss: 0.6514 - val_accuracy: 0.5817\n",
      "Epoch 5178/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5985 - accuracy: 0.6605 - val_loss: 0.6629 - val_accuracy: 0.5656\n",
      "Epoch 5179/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5987 - accuracy: 0.6608 - val_loss: 0.6455 - val_accuracy: 0.5904\n",
      "Epoch 5180/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5989 - accuracy: 0.6592 - val_loss: 0.6712 - val_accuracy: 0.5521\n",
      "Epoch 5181/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5995 - accuracy: 0.6600 - val_loss: 0.6368 - val_accuracy: 0.6028\n",
      "Epoch 5182/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6002 - accuracy: 0.6579 - val_loss: 0.6853 - val_accuracy: 0.5327\n",
      "Epoch 5183/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6016 - accuracy: 0.6585 - val_loss: 0.6263 - val_accuracy: 0.6191\n",
      "Epoch 5184/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6026 - accuracy: 0.6563 - val_loss: 0.7003 - val_accuracy: 0.5166\n",
      "Epoch 5185/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6050 - accuracy: 0.6566 - val_loss: 0.6242 - val_accuracy: 0.6217\n",
      "Epoch 5186/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6035 - accuracy: 0.6553 - val_loss: 0.6908 - val_accuracy: 0.5259\n",
      "Epoch 5187/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6030 - accuracy: 0.6583 - val_loss: 0.6336 - val_accuracy: 0.6067\n",
      "Epoch 5188/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6005 - accuracy: 0.6578 - val_loss: 0.6690 - val_accuracy: 0.5559\n",
      "Epoch 5189/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5991 - accuracy: 0.6604 - val_loss: 0.6534 - val_accuracy: 0.5796\n",
      "Epoch 5190/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5985 - accuracy: 0.6609 - val_loss: 0.6497 - val_accuracy: 0.5844\n",
      "Epoch 5191/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5985 - accuracy: 0.6602 - val_loss: 0.6686 - val_accuracy: 0.5554\n",
      "Epoch 5192/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5992 - accuracy: 0.6606 - val_loss: 0.6354 - val_accuracy: 0.6056\n",
      "Epoch 5193/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6004 - accuracy: 0.6575 - val_loss: 0.6895 - val_accuracy: 0.5245\n",
      "Epoch 5194/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6026 - accuracy: 0.6578 - val_loss: 0.6238 - val_accuracy: 0.6228\n",
      "Epoch 5195/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6035 - accuracy: 0.6559 - val_loss: 0.7020 - val_accuracy: 0.5144\n",
      "Epoch 5196/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6056 - accuracy: 0.6557 - val_loss: 0.6267 - val_accuracy: 0.6167\n",
      "Epoch 5197/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6026 - accuracy: 0.6565 - val_loss: 0.6774 - val_accuracy: 0.5433\n",
      "Epoch 5198/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6006 - accuracy: 0.6602 - val_loss: 0.6485 - val_accuracy: 0.5831\n",
      "Epoch 5199/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5988 - accuracy: 0.6600 - val_loss: 0.6502 - val_accuracy: 0.5807\n",
      "Epoch 5200/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5986 - accuracy: 0.6601 - val_loss: 0.6719 - val_accuracy: 0.5479\n",
      "Epoch 5201/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5996 - accuracy: 0.6602 - val_loss: 0.6298 - val_accuracy: 0.6138\n",
      "Epoch 5202/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6014 - accuracy: 0.6587 - val_loss: 0.6973 - val_accuracy: 0.5181\n",
      "Epoch 5203/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6560 - val_loss: 0.6231 - val_accuracy: 0.6222\n",
      "Epoch 5204/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6043 - accuracy: 0.6543 - val_loss: 0.6948 - val_accuracy: 0.5201\n",
      "Epoch 5205/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6042 - accuracy: 0.6567 - val_loss: 0.6323 - val_accuracy: 0.6122\n",
      "Epoch 5206/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6011 - accuracy: 0.6591 - val_loss: 0.6651 - val_accuracy: 0.5594\n",
      "Epoch 5207/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5994 - accuracy: 0.6591 - val_loss: 0.6604 - val_accuracy: 0.5689\n",
      "Epoch 5208/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5988 - accuracy: 0.6599 - val_loss: 0.6400 - val_accuracy: 0.5965\n",
      "Epoch 5209/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6001 - accuracy: 0.6592 - val_loss: 0.6851 - val_accuracy: 0.5322\n",
      "Epoch 5210/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6021 - accuracy: 0.6580 - val_loss: 0.6231 - val_accuracy: 0.6224\n",
      "Epoch 5211/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6040 - accuracy: 0.6554 - val_loss: 0.7029 - val_accuracy: 0.5086\n",
      "Epoch 5212/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6058 - accuracy: 0.6543 - val_loss: 0.6272 - val_accuracy: 0.6180\n",
      "Epoch 5213/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6035 - accuracy: 0.6561 - val_loss: 0.6798 - val_accuracy: 0.5395\n",
      "Epoch 5214/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6021 - accuracy: 0.6580 - val_loss: 0.6468 - val_accuracy: 0.5864\n",
      "Epoch 5215/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5998 - accuracy: 0.6578 - val_loss: 0.6495 - val_accuracy: 0.5818\n",
      "Epoch 5216/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6790 - val_accuracy: 0.5389\n",
      "Epoch 5217/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6009 - accuracy: 0.6594 - val_loss: 0.6265 - val_accuracy: 0.6176\n",
      "Epoch 5218/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6550 - val_loss: 0.6965 - val_accuracy: 0.5163\n",
      "Epoch 5219/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6567 - val_loss: 0.6257 - val_accuracy: 0.6198\n",
      "Epoch 5220/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6557 - val_loss: 0.6866 - val_accuracy: 0.5364\n",
      "Epoch 5221/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6029 - accuracy: 0.6570 - val_loss: 0.6440 - val_accuracy: 0.5928\n",
      "Epoch 5222/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6010 - accuracy: 0.6575 - val_loss: 0.6567 - val_accuracy: 0.5756\n",
      "Epoch 5223/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5997 - accuracy: 0.6605 - val_loss: 0.6676 - val_accuracy: 0.5559\n",
      "Epoch 5224/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6001 - accuracy: 0.6609 - val_loss: 0.6279 - val_accuracy: 0.6122\n",
      "Epoch 5225/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6021 - accuracy: 0.6565 - val_loss: 0.6952 - val_accuracy: 0.5188\n",
      "Epoch 5226/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6578 - val_loss: 0.6353 - val_accuracy: 0.6045\n",
      "Epoch 5227/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6029 - accuracy: 0.6562 - val_loss: 0.6768 - val_accuracy: 0.5406\n",
      "Epoch 5228/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6008 - accuracy: 0.6600 - val_loss: 0.6388 - val_accuracy: 0.5979\n",
      "Epoch 5229/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5999 - accuracy: 0.6583 - val_loss: 0.6571 - val_accuracy: 0.5734\n",
      "Epoch 5230/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5986 - accuracy: 0.6612 - val_loss: 0.6682 - val_accuracy: 0.5583\n",
      "Epoch 5231/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5992 - accuracy: 0.6619 - val_loss: 0.6416 - val_accuracy: 0.5977\n",
      "Epoch 5232/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5996 - accuracy: 0.6584 - val_loss: 0.6729 - val_accuracy: 0.5455\n",
      "Epoch 5233/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6003 - accuracy: 0.6599 - val_loss: 0.6347 - val_accuracy: 0.6030\n",
      "Epoch 5234/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6008 - accuracy: 0.6567 - val_loss: 0.6810 - val_accuracy: 0.5398\n",
      "Epoch 5235/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6009 - accuracy: 0.6583 - val_loss: 0.6392 - val_accuracy: 0.6012\n",
      "Epoch 5236/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6007 - accuracy: 0.6588 - val_loss: 0.6706 - val_accuracy: 0.5533\n",
      "Epoch 5237/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5997 - accuracy: 0.6617 - val_loss: 0.6449 - val_accuracy: 0.5915\n",
      "Epoch 5238/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5995 - accuracy: 0.6595 - val_loss: 0.6601 - val_accuracy: 0.5685\n",
      "Epoch 5239/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5990 - accuracy: 0.6591 - val_loss: 0.6562 - val_accuracy: 0.5720\n",
      "Epoch 5240/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5990 - accuracy: 0.6600 - val_loss: 0.6555 - val_accuracy: 0.5756\n",
      "Epoch 5241/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5989 - accuracy: 0.6606 - val_loss: 0.6599 - val_accuracy: 0.5665\n",
      "Epoch 5242/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5988 - accuracy: 0.6600 - val_loss: 0.6430 - val_accuracy: 0.5957\n",
      "Epoch 5243/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5991 - accuracy: 0.6587 - val_loss: 0.6704 - val_accuracy: 0.5541\n",
      "Epoch 5244/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5992 - accuracy: 0.6611 - val_loss: 0.6473 - val_accuracy: 0.5864\n",
      "Epoch 5245/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5993 - accuracy: 0.6587 - val_loss: 0.6685 - val_accuracy: 0.5570\n",
      "Epoch 5246/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5994 - accuracy: 0.6599 - val_loss: 0.6379 - val_accuracy: 0.6005\n",
      "Epoch 5247/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5994 - accuracy: 0.6594 - val_loss: 0.6702 - val_accuracy: 0.5559\n",
      "Epoch 5248/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5990 - accuracy: 0.6617 - val_loss: 0.6510 - val_accuracy: 0.5815\n",
      "Epoch 5249/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5989 - accuracy: 0.6601 - val_loss: 0.6617 - val_accuracy: 0.5667\n",
      "Epoch 5250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5986 - accuracy: 0.6595 - val_loss: 0.6462 - val_accuracy: 0.5884\n",
      "Epoch 5251/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5985 - accuracy: 0.6598 - val_loss: 0.6633 - val_accuracy: 0.5654\n",
      "Epoch 5252/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5984 - accuracy: 0.6617 - val_loss: 0.6521 - val_accuracy: 0.5787\n",
      "Epoch 5253/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5984 - accuracy: 0.6607 - val_loss: 0.6595 - val_accuracy: 0.5711\n",
      "Epoch 5254/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5983 - accuracy: 0.6603 - val_loss: 0.6499 - val_accuracy: 0.5853\n",
      "Epoch 5255/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5983 - accuracy: 0.6606 - val_loss: 0.6630 - val_accuracy: 0.5658\n",
      "Epoch 5256/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5983 - accuracy: 0.6620 - val_loss: 0.6483 - val_accuracy: 0.5862\n",
      "Epoch 5257/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5983 - accuracy: 0.6603 - val_loss: 0.6639 - val_accuracy: 0.5649\n",
      "Epoch 5258/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5983 - accuracy: 0.6614 - val_loss: 0.6469 - val_accuracy: 0.5888\n",
      "Epoch 5259/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5985 - accuracy: 0.6597 - val_loss: 0.6687 - val_accuracy: 0.5559\n",
      "Epoch 5260/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5987 - accuracy: 0.6615 - val_loss: 0.6390 - val_accuracy: 0.6012\n",
      "Epoch 5261/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5991 - accuracy: 0.6591 - val_loss: 0.6798 - val_accuracy: 0.5415\n",
      "Epoch 5262/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5998 - accuracy: 0.6602 - val_loss: 0.6347 - val_accuracy: 0.6065\n",
      "Epoch 5263/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6002 - accuracy: 0.6584 - val_loss: 0.6837 - val_accuracy: 0.5345\n",
      "Epoch 5264/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6015 - accuracy: 0.6588 - val_loss: 0.6283 - val_accuracy: 0.6167\n",
      "Epoch 5265/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6011 - accuracy: 0.6575 - val_loss: 0.6895 - val_accuracy: 0.5285\n",
      "Epoch 5266/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6014 - accuracy: 0.6596 - val_loss: 0.6358 - val_accuracy: 0.6056\n",
      "Epoch 5267/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6003 - accuracy: 0.6579 - val_loss: 0.6738 - val_accuracy: 0.5495\n",
      "Epoch 5268/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5999 - accuracy: 0.6597 - val_loss: 0.6401 - val_accuracy: 0.5959\n",
      "Epoch 5269/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5988 - accuracy: 0.6600 - val_loss: 0.6678 - val_accuracy: 0.5581\n",
      "Epoch 5270/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5985 - accuracy: 0.6614 - val_loss: 0.6515 - val_accuracy: 0.5815\n",
      "Epoch 5271/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5981 - accuracy: 0.6608 - val_loss: 0.6529 - val_accuracy: 0.5804\n",
      "Epoch 5272/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5980 - accuracy: 0.6603 - val_loss: 0.6611 - val_accuracy: 0.5685\n",
      "Epoch 5273/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5981 - accuracy: 0.6609 - val_loss: 0.6485 - val_accuracy: 0.5873\n",
      "Epoch 5274/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5981 - accuracy: 0.6597 - val_loss: 0.6660 - val_accuracy: 0.5597\n",
      "Epoch 5275/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5986 - accuracy: 0.6613 - val_loss: 0.6408 - val_accuracy: 0.5974\n",
      "Epoch 5276/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5988 - accuracy: 0.6595 - val_loss: 0.6772 - val_accuracy: 0.5446\n",
      "Epoch 5277/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5996 - accuracy: 0.6606 - val_loss: 0.6333 - val_accuracy: 0.6078\n",
      "Epoch 5278/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6586 - val_loss: 0.6854 - val_accuracy: 0.5336\n",
      "Epoch 5279/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6011 - accuracy: 0.6588 - val_loss: 0.6327 - val_accuracy: 0.6113\n",
      "Epoch 5280/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6011 - accuracy: 0.6582 - val_loss: 0.6867 - val_accuracy: 0.5312\n",
      "Epoch 5281/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6017 - accuracy: 0.6589 - val_loss: 0.6280 - val_accuracy: 0.6164\n",
      "Epoch 5282/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6010 - accuracy: 0.6578 - val_loss: 0.6851 - val_accuracy: 0.5362\n",
      "Epoch 5283/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6009 - accuracy: 0.6595 - val_loss: 0.6411 - val_accuracy: 0.5988\n",
      "Epoch 5284/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5995 - accuracy: 0.6587 - val_loss: 0.6671 - val_accuracy: 0.5590\n",
      "Epoch 5285/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5990 - accuracy: 0.6619 - val_loss: 0.6457 - val_accuracy: 0.5902\n",
      "Epoch 5286/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5982 - accuracy: 0.6603 - val_loss: 0.6585 - val_accuracy: 0.5698\n",
      "Epoch 5287/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5985 - accuracy: 0.6596 - val_loss: 0.6614 - val_accuracy: 0.5676\n",
      "Epoch 5288/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5983 - accuracy: 0.6619 - val_loss: 0.6439 - val_accuracy: 0.5930\n",
      "Epoch 5289/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5987 - accuracy: 0.6595 - val_loss: 0.6757 - val_accuracy: 0.5464\n",
      "Epoch 5290/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5999 - accuracy: 0.6598 - val_loss: 0.6323 - val_accuracy: 0.6103\n",
      "Epoch 5291/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6003 - accuracy: 0.6585 - val_loss: 0.6883 - val_accuracy: 0.5285\n",
      "Epoch 5292/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6025 - accuracy: 0.6584 - val_loss: 0.6300 - val_accuracy: 0.6156\n",
      "Epoch 5293/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6017 - accuracy: 0.6577 - val_loss: 0.6870 - val_accuracy: 0.5362\n",
      "Epoch 5294/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6020 - accuracy: 0.6584 - val_loss: 0.6410 - val_accuracy: 0.5977\n",
      "Epoch 5295/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5992 - accuracy: 0.6595 - val_loss: 0.6586 - val_accuracy: 0.5733\n",
      "Epoch 5296/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5997 - accuracy: 0.6596 - val_loss: 0.6624 - val_accuracy: 0.5672\n",
      "Epoch 5297/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5985 - accuracy: 0.6617 - val_loss: 0.6387 - val_accuracy: 0.6021\n",
      "Epoch 5298/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6017 - accuracy: 0.6575 - val_loss: 0.6964 - val_accuracy: 0.5208\n",
      "Epoch 5299/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6049 - accuracy: 0.6569 - val_loss: 0.6121 - val_accuracy: 0.6425\n",
      "Epoch 5300/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6501 - val_loss: 0.7262 - val_accuracy: 0.4995\n",
      "Epoch 5301/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6123 - accuracy: 0.6494 - val_loss: 0.6497 - val_accuracy: 0.5901\n",
      "Epoch 5302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6098 - accuracy: 0.6493 - val_loss: 0.6570 - val_accuracy: 0.5756\n",
      "Epoch 5303/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6037 - accuracy: 0.6560 - val_loss: 0.6628 - val_accuracy: 0.5703\n",
      "Epoch 5304/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6112 - accuracy: 0.6514 - val_loss: 0.6577 - val_accuracy: 0.5744\n",
      "Epoch 5305/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6042 - accuracy: 0.6558 - val_loss: 0.6413 - val_accuracy: 0.5932\n",
      "Epoch 5306/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6063 - accuracy: 0.6519 - val_loss: 0.7092 - val_accuracy: 0.5110\n",
      "Epoch 5307/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6090 - accuracy: 0.6528 - val_loss: 0.6369 - val_accuracy: 0.6050\n",
      "Epoch 5308/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6035 - accuracy: 0.6553 - val_loss: 0.6620 - val_accuracy: 0.5659\n",
      "Epoch 5309/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6027 - accuracy: 0.6557 - val_loss: 0.6569 - val_accuracy: 0.5703\n",
      "Epoch 5310/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6013 - accuracy: 0.6565 - val_loss: 0.6401 - val_accuracy: 0.6014\n",
      "Epoch 5311/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6037 - accuracy: 0.6555 - val_loss: 0.6933 - val_accuracy: 0.5206\n",
      "Epoch 5312/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6562 - val_loss: 0.6255 - val_accuracy: 0.6224\n",
      "Epoch 5313/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6041 - accuracy: 0.6564 - val_loss: 0.6810 - val_accuracy: 0.5373\n",
      "Epoch 5314/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6020 - accuracy: 0.6576 - val_loss: 0.6523 - val_accuracy: 0.5784\n",
      "Epoch 5315/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6002 - accuracy: 0.6591 - val_loss: 0.6407 - val_accuracy: 0.5930\n",
      "Epoch 5316/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6002 - accuracy: 0.6590 - val_loss: 0.6758 - val_accuracy: 0.5479\n",
      "Epoch 5317/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6019 - accuracy: 0.6572 - val_loss: 0.6358 - val_accuracy: 0.6047\n",
      "Epoch 5318/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6014 - accuracy: 0.6570 - val_loss: 0.6807 - val_accuracy: 0.5378\n",
      "Epoch 5319/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6018 - accuracy: 0.6596 - val_loss: 0.6392 - val_accuracy: 0.5992\n",
      "Epoch 5320/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5997 - accuracy: 0.6595 - val_loss: 0.6604 - val_accuracy: 0.5674\n",
      "Epoch 5321/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5991 - accuracy: 0.6602 - val_loss: 0.6567 - val_accuracy: 0.5716\n",
      "Epoch 5322/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5986 - accuracy: 0.6602 - val_loss: 0.6521 - val_accuracy: 0.5791\n",
      "Epoch 5323/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5990 - accuracy: 0.6597 - val_loss: 0.6612 - val_accuracy: 0.5630\n",
      "Epoch 5324/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5990 - accuracy: 0.6611 - val_loss: 0.6403 - val_accuracy: 0.5957\n",
      "Epoch 5325/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5992 - accuracy: 0.6592 - val_loss: 0.6742 - val_accuracy: 0.5497\n",
      "Epoch 5326/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5996 - accuracy: 0.6598 - val_loss: 0.6437 - val_accuracy: 0.5935\n",
      "Epoch 5327/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5988 - accuracy: 0.6589 - val_loss: 0.6634 - val_accuracy: 0.5617\n",
      "Epoch 5328/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.5989 - accuracy: 0.6599 - val_loss: 0.6462 - val_accuracy: 0.5877\n",
      "Epoch 5329/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5984 - accuracy: 0.6596 - val_loss: 0.6645 - val_accuracy: 0.5641\n",
      "Epoch 5330/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5986 - accuracy: 0.6612 - val_loss: 0.6563 - val_accuracy: 0.5754\n",
      "Epoch 5331/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5980 - accuracy: 0.6613 - val_loss: 0.6465 - val_accuracy: 0.5881\n",
      "Epoch 5332/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5982 - accuracy: 0.6599 - val_loss: 0.6666 - val_accuracy: 0.5588\n",
      "Epoch 5333/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5983 - accuracy: 0.6612 - val_loss: 0.6439 - val_accuracy: 0.5954\n",
      "Epoch 5334/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5991 - accuracy: 0.6581 - val_loss: 0.6783 - val_accuracy: 0.5459\n",
      "Epoch 5335/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6001 - accuracy: 0.6602 - val_loss: 0.6310 - val_accuracy: 0.6125\n",
      "Epoch 5336/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6006 - accuracy: 0.6577 - val_loss: 0.6893 - val_accuracy: 0.5305\n",
      "Epoch 5337/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6016 - accuracy: 0.6594 - val_loss: 0.6338 - val_accuracy: 0.6054\n",
      "Epoch 5338/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6001 - accuracy: 0.6596 - val_loss: 0.6755 - val_accuracy: 0.5488\n",
      "Epoch 5339/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6006 - accuracy: 0.6586 - val_loss: 0.6414 - val_accuracy: 0.5955\n",
      "Epoch 5340/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5991 - accuracy: 0.6594 - val_loss: 0.6708 - val_accuracy: 0.5541\n",
      "Epoch 5341/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5992 - accuracy: 0.6614 - val_loss: 0.6541 - val_accuracy: 0.5784\n",
      "Epoch 5342/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5976 - accuracy: 0.6605 - val_loss: 0.6419 - val_accuracy: 0.5939\n",
      "Epoch 5343/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5987 - accuracy: 0.6599 - val_loss: 0.6758 - val_accuracy: 0.5480\n",
      "Epoch 5344/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5988 - accuracy: 0.6611 - val_loss: 0.6373 - val_accuracy: 0.6038\n",
      "Epoch 5345/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6015 - accuracy: 0.6570 - val_loss: 0.6956 - val_accuracy: 0.5225\n",
      "Epoch 5346/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6563 - val_loss: 0.6166 - val_accuracy: 0.6335\n",
      "Epoch 5347/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6052 - accuracy: 0.6547 - val_loss: 0.6995 - val_accuracy: 0.5206\n",
      "Epoch 5348/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6036 - accuracy: 0.6577 - val_loss: 0.6485 - val_accuracy: 0.5888\n",
      "Epoch 5349/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6013 - accuracy: 0.6589 - val_loss: 0.6513 - val_accuracy: 0.5829\n",
      "Epoch 5350/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6016 - accuracy: 0.6572 - val_loss: 0.6665 - val_accuracy: 0.5610\n",
      "Epoch 5351/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6034 - accuracy: 0.6569 - val_loss: 0.6377 - val_accuracy: 0.6021\n",
      "Epoch 5352/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6006 - accuracy: 0.6579 - val_loss: 0.6894 - val_accuracy: 0.5311\n",
      "Epoch 5353/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6040 - accuracy: 0.6580 - val_loss: 0.6460 - val_accuracy: 0.5897\n",
      "Epoch 5354/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5986 - accuracy: 0.6598 - val_loss: 0.6437 - val_accuracy: 0.5910\n",
      "Epoch 5355/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6007 - accuracy: 0.6584 - val_loss: 0.6831 - val_accuracy: 0.5353\n",
      "Epoch 5356/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6009 - accuracy: 0.6603 - val_loss: 0.6260 - val_accuracy: 0.6209\n",
      "Epoch 5357/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6524 - val_loss: 0.7180 - val_accuracy: 0.5004\n",
      "Epoch 5358/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6121 - accuracy: 0.6492 - val_loss: 0.6203 - val_accuracy: 0.6282\n",
      "Epoch 5359/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6499 - val_loss: 0.6681 - val_accuracy: 0.5594\n",
      "Epoch 5360/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5992 - accuracy: 0.6606 - val_loss: 0.6768 - val_accuracy: 0.5504\n",
      "Epoch 5361/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6044 - accuracy: 0.6584 - val_loss: 0.6416 - val_accuracy: 0.5959\n",
      "Epoch 5362/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5996 - accuracy: 0.6603 - val_loss: 0.6599 - val_accuracy: 0.5714\n",
      "Epoch 5363/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6584 - val_loss: 0.6544 - val_accuracy: 0.5776\n",
      "Epoch 5364/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5988 - accuracy: 0.6602 - val_loss: 0.6527 - val_accuracy: 0.5818\n",
      "Epoch 5365/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6023 - accuracy: 0.6581 - val_loss: 0.6795 - val_accuracy: 0.5395\n",
      "Epoch 5366/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6011 - accuracy: 0.6593 - val_loss: 0.6222 - val_accuracy: 0.6211\n",
      "Epoch 5367/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6052 - accuracy: 0.6546 - val_loss: 0.7026 - val_accuracy: 0.5142\n",
      "Epoch 5368/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6045 - accuracy: 0.6568 - val_loss: 0.6401 - val_accuracy: 0.6050\n",
      "Epoch 5369/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6066 - accuracy: 0.6552 - val_loss: 0.6763 - val_accuracy: 0.5512\n",
      "Epoch 5370/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6035 - accuracy: 0.6575 - val_loss: 0.6376 - val_accuracy: 0.6036\n",
      "Epoch 5371/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6070 - accuracy: 0.6518 - val_loss: 0.6716 - val_accuracy: 0.5544\n",
      "Epoch 5372/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6020 - accuracy: 0.6577 - val_loss: 0.6540 - val_accuracy: 0.5817\n",
      "Epoch 5373/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6567 - val_loss: 0.6761 - val_accuracy: 0.5488\n",
      "Epoch 5374/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6007 - accuracy: 0.6597 - val_loss: 0.6368 - val_accuracy: 0.6016\n",
      "Epoch 5375/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6025 - accuracy: 0.6577 - val_loss: 0.6728 - val_accuracy: 0.5497\n",
      "Epoch 5376/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6027 - accuracy: 0.6560 - val_loss: 0.6379 - val_accuracy: 0.6001\n",
      "Epoch 5377/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6002 - accuracy: 0.6572 - val_loss: 0.6698 - val_accuracy: 0.5557\n",
      "Epoch 5378/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6004 - accuracy: 0.6606 - val_loss: 0.6566 - val_accuracy: 0.5778\n",
      "Epoch 5379/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6000 - accuracy: 0.6591 - val_loss: 0.6459 - val_accuracy: 0.5891\n",
      "Epoch 5380/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5996 - accuracy: 0.6585 - val_loss: 0.6678 - val_accuracy: 0.5601\n",
      "Epoch 5381/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5992 - accuracy: 0.6612 - val_loss: 0.6475 - val_accuracy: 0.5886\n",
      "Epoch 5382/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6009 - accuracy: 0.6588 - val_loss: 0.6725 - val_accuracy: 0.5510\n",
      "Epoch 5383/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5998 - accuracy: 0.6597 - val_loss: 0.6332 - val_accuracy: 0.6098\n",
      "Epoch 5384/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6021 - accuracy: 0.6557 - val_loss: 0.6855 - val_accuracy: 0.5325\n",
      "Epoch 5385/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6020 - accuracy: 0.6581 - val_loss: 0.6346 - val_accuracy: 0.6047\n",
      "Epoch 5386/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6010 - accuracy: 0.6594 - val_loss: 0.6754 - val_accuracy: 0.5501\n",
      "Epoch 5387/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6002 - accuracy: 0.6592 - val_loss: 0.6473 - val_accuracy: 0.5891\n",
      "Epoch 5388/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5990 - accuracy: 0.6593 - val_loss: 0.6517 - val_accuracy: 0.5828\n",
      "Epoch 5389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5978 - accuracy: 0.6608 - val_loss: 0.6677 - val_accuracy: 0.5590\n",
      "Epoch 5390/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5992 - accuracy: 0.6596 - val_loss: 0.6400 - val_accuracy: 0.6012\n",
      "Epoch 5391/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5992 - accuracy: 0.6586 - val_loss: 0.6758 - val_accuracy: 0.5488\n",
      "Epoch 5392/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5996 - accuracy: 0.6599 - val_loss: 0.6388 - val_accuracy: 0.6021\n",
      "Epoch 5393/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5998 - accuracy: 0.6597 - val_loss: 0.6726 - val_accuracy: 0.5532\n",
      "Epoch 5394/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5989 - accuracy: 0.6607 - val_loss: 0.6412 - val_accuracy: 0.5965\n",
      "Epoch 5395/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5986 - accuracy: 0.6603 - val_loss: 0.6651 - val_accuracy: 0.5639\n",
      "Epoch 5396/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5982 - accuracy: 0.6612 - val_loss: 0.6542 - val_accuracy: 0.5789\n",
      "Epoch 5397/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5976 - accuracy: 0.6616 - val_loss: 0.6520 - val_accuracy: 0.5826\n",
      "Epoch 5398/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5977 - accuracy: 0.6605 - val_loss: 0.6623 - val_accuracy: 0.5649\n",
      "Epoch 5399/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5979 - accuracy: 0.6614 - val_loss: 0.6424 - val_accuracy: 0.5939\n",
      "Epoch 5400/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5981 - accuracy: 0.6600 - val_loss: 0.6705 - val_accuracy: 0.5546\n",
      "Epoch 5401/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5982 - accuracy: 0.6616 - val_loss: 0.6452 - val_accuracy: 0.5941\n",
      "Epoch 5402/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5983 - accuracy: 0.6589 - val_loss: 0.6693 - val_accuracy: 0.5574\n",
      "Epoch 5403/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5981 - accuracy: 0.6613 - val_loss: 0.6410 - val_accuracy: 0.5968\n",
      "Epoch 5404/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5981 - accuracy: 0.6608 - val_loss: 0.6662 - val_accuracy: 0.5625\n",
      "Epoch 5405/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5980 - accuracy: 0.6607 - val_loss: 0.6476 - val_accuracy: 0.5866\n",
      "Epoch 5406/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5976 - accuracy: 0.6613 - val_loss: 0.6625 - val_accuracy: 0.5680\n",
      "Epoch 5407/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5976 - accuracy: 0.6622 - val_loss: 0.6528 - val_accuracy: 0.5811\n",
      "Epoch 5408/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5972 - accuracy: 0.6608 - val_loss: 0.6533 - val_accuracy: 0.5820\n",
      "Epoch 5409/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5974 - accuracy: 0.6610 - val_loss: 0.6620 - val_accuracy: 0.5672\n",
      "Epoch 5410/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5974 - accuracy: 0.6620 - val_loss: 0.6446 - val_accuracy: 0.5917\n",
      "Epoch 5411/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5977 - accuracy: 0.6599 - val_loss: 0.6715 - val_accuracy: 0.5552\n",
      "Epoch 5412/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5981 - accuracy: 0.6609 - val_loss: 0.6396 - val_accuracy: 0.5992\n",
      "Epoch 5413/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5984 - accuracy: 0.6592 - val_loss: 0.6769 - val_accuracy: 0.5460\n",
      "Epoch 5414/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5991 - accuracy: 0.6617 - val_loss: 0.6333 - val_accuracy: 0.6083\n",
      "Epoch 5415/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5992 - accuracy: 0.6596 - val_loss: 0.6810 - val_accuracy: 0.5400\n",
      "Epoch 5416/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5996 - accuracy: 0.6603 - val_loss: 0.6370 - val_accuracy: 0.6032\n",
      "Epoch 5417/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5987 - accuracy: 0.6591 - val_loss: 0.6734 - val_accuracy: 0.5521\n",
      "Epoch 5418/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5987 - accuracy: 0.6610 - val_loss: 0.6413 - val_accuracy: 0.5961\n",
      "Epoch 5419/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5979 - accuracy: 0.6602 - val_loss: 0.6672 - val_accuracy: 0.5610\n",
      "Epoch 5420/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5979 - accuracy: 0.6616 - val_loss: 0.6499 - val_accuracy: 0.5857\n",
      "Epoch 5421/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5971 - accuracy: 0.6602 - val_loss: 0.6558 - val_accuracy: 0.5764\n",
      "Epoch 5422/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5974 - accuracy: 0.6605 - val_loss: 0.6567 - val_accuracy: 0.5749\n",
      "Epoch 5423/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5970 - accuracy: 0.6616 - val_loss: 0.6519 - val_accuracy: 0.5828\n",
      "Epoch 5424/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5975 - accuracy: 0.6609 - val_loss: 0.6647 - val_accuracy: 0.5621\n",
      "Epoch 5425/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5975 - accuracy: 0.6626 - val_loss: 0.6388 - val_accuracy: 0.5992\n",
      "Epoch 5426/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5981 - accuracy: 0.6606 - val_loss: 0.6776 - val_accuracy: 0.5455\n",
      "Epoch 5427/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5988 - accuracy: 0.6608 - val_loss: 0.6363 - val_accuracy: 0.6032\n",
      "Epoch 5428/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5995 - accuracy: 0.6588 - val_loss: 0.6865 - val_accuracy: 0.5334\n",
      "Epoch 5429/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6010 - accuracy: 0.6597 - val_loss: 0.6261 - val_accuracy: 0.6209\n",
      "Epoch 5430/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6008 - accuracy: 0.6578 - val_loss: 0.6899 - val_accuracy: 0.5312\n",
      "Epoch 5431/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6013 - accuracy: 0.6600 - val_loss: 0.6366 - val_accuracy: 0.6030\n",
      "Epoch 5432/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5991 - accuracy: 0.6589 - val_loss: 0.6702 - val_accuracy: 0.5572\n",
      "Epoch 5433/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5993 - accuracy: 0.6608 - val_loss: 0.6430 - val_accuracy: 0.5928\n",
      "Epoch 5434/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5981 - accuracy: 0.6595 - val_loss: 0.6618 - val_accuracy: 0.5676\n",
      "Epoch 5435/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5981 - accuracy: 0.6621 - val_loss: 0.6612 - val_accuracy: 0.5685\n",
      "Epoch 5436/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5970 - accuracy: 0.6628 - val_loss: 0.6395 - val_accuracy: 0.5990\n",
      "Epoch 5437/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5985 - accuracy: 0.6592 - val_loss: 0.6799 - val_accuracy: 0.5400\n",
      "Epoch 5438/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5992 - accuracy: 0.6609 - val_loss: 0.6304 - val_accuracy: 0.6147\n",
      "Epoch 5439/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6019 - accuracy: 0.6575 - val_loss: 0.7039 - val_accuracy: 0.5135\n",
      "Epoch 5440/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6564 - val_loss: 0.6163 - val_accuracy: 0.6366\n",
      "Epoch 5441/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6538 - val_loss: 0.6977 - val_accuracy: 0.5232\n",
      "Epoch 5442/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6029 - accuracy: 0.6582 - val_loss: 0.6476 - val_accuracy: 0.5910\n",
      "Epoch 5443/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6001 - accuracy: 0.6605 - val_loss: 0.6493 - val_accuracy: 0.5835\n",
      "Epoch 5444/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5998 - accuracy: 0.6588 - val_loss: 0.6717 - val_accuracy: 0.5539\n",
      "Epoch 5445/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6018 - accuracy: 0.6594 - val_loss: 0.6301 - val_accuracy: 0.6136\n",
      "Epoch 5446/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6013 - accuracy: 0.6577 - val_loss: 0.7011 - val_accuracy: 0.5223\n",
      "Epoch 5447/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6048 - accuracy: 0.6568 - val_loss: 0.6341 - val_accuracy: 0.6065\n",
      "Epoch 5448/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5998 - accuracy: 0.6589 - val_loss: 0.6648 - val_accuracy: 0.5663\n",
      "Epoch 5449/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5999 - accuracy: 0.6598 - val_loss: 0.6557 - val_accuracy: 0.5745\n",
      "Epoch 5450/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5980 - accuracy: 0.6611 - val_loss: 0.6408 - val_accuracy: 0.6001\n",
      "Epoch 5451/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6006 - accuracy: 0.6577 - val_loss: 0.6945 - val_accuracy: 0.5212\n",
      "Epoch 5452/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6587 - val_loss: 0.6191 - val_accuracy: 0.6354\n",
      "Epoch 5453/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6049 - accuracy: 0.6552 - val_loss: 0.7070 - val_accuracy: 0.5115\n",
      "Epoch 5454/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6052 - accuracy: 0.6558 - val_loss: 0.6367 - val_accuracy: 0.6072\n",
      "Epoch 5455/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6017 - accuracy: 0.6572 - val_loss: 0.6592 - val_accuracy: 0.5725\n",
      "Epoch 5456/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5995 - accuracy: 0.6598 - val_loss: 0.6636 - val_accuracy: 0.5658\n",
      "Epoch 5457/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6000 - accuracy: 0.6611 - val_loss: 0.6345 - val_accuracy: 0.6065\n",
      "Epoch 5458/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6000 - accuracy: 0.6580 - val_loss: 0.6960 - val_accuracy: 0.5250\n",
      "Epoch 5459/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6035 - accuracy: 0.6579 - val_loss: 0.6367 - val_accuracy: 0.6023\n",
      "Epoch 5460/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5988 - accuracy: 0.6597 - val_loss: 0.6569 - val_accuracy: 0.5747\n",
      "Epoch 5461/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5986 - accuracy: 0.6597 - val_loss: 0.6606 - val_accuracy: 0.5658\n",
      "Epoch 5462/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5980 - accuracy: 0.6607 - val_loss: 0.6395 - val_accuracy: 0.6019\n",
      "Epoch 5463/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5999 - accuracy: 0.6578 - val_loss: 0.6911 - val_accuracy: 0.5267\n",
      "Epoch 5464/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6016 - accuracy: 0.6588 - val_loss: 0.6221 - val_accuracy: 0.6290\n",
      "Epoch 5465/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6566 - val_loss: 0.6984 - val_accuracy: 0.5217\n",
      "Epoch 5466/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6578 - val_loss: 0.6349 - val_accuracy: 0.6058\n",
      "Epoch 5467/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6004 - accuracy: 0.6582 - val_loss: 0.6624 - val_accuracy: 0.5669\n",
      "Epoch 5468/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5984 - accuracy: 0.6615 - val_loss: 0.6583 - val_accuracy: 0.5734\n",
      "Epoch 5469/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5982 - accuracy: 0.6604 - val_loss: 0.6414 - val_accuracy: 0.5965\n",
      "Epoch 5470/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5985 - accuracy: 0.6601 - val_loss: 0.6866 - val_accuracy: 0.5312\n",
      "Epoch 5471/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6006 - accuracy: 0.6598 - val_loss: 0.6249 - val_accuracy: 0.6228\n",
      "Epoch 5472/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6010 - accuracy: 0.6581 - val_loss: 0.6897 - val_accuracy: 0.5300\n",
      "Epoch 5473/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6016 - accuracy: 0.6592 - val_loss: 0.6343 - val_accuracy: 0.6072\n",
      "Epoch 5474/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5994 - accuracy: 0.6588 - val_loss: 0.6692 - val_accuracy: 0.5572\n",
      "Epoch 5475/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5980 - accuracy: 0.6616 - val_loss: 0.6544 - val_accuracy: 0.5789\n",
      "Epoch 5476/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5969 - accuracy: 0.6620 - val_loss: 0.6420 - val_accuracy: 0.5965\n",
      "Epoch 5477/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5980 - accuracy: 0.6603 - val_loss: 0.6799 - val_accuracy: 0.5426\n",
      "Epoch 5478/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5991 - accuracy: 0.6613 - val_loss: 0.6307 - val_accuracy: 0.6131\n",
      "Epoch 5479/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6002 - accuracy: 0.6588 - val_loss: 0.6881 - val_accuracy: 0.5320\n",
      "Epoch 5480/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6011 - accuracy: 0.6598 - val_loss: 0.6306 - val_accuracy: 0.6142\n",
      "Epoch 5481/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6575 - val_loss: 0.6739 - val_accuracy: 0.5510\n",
      "Epoch 5482/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5985 - accuracy: 0.6618 - val_loss: 0.6513 - val_accuracy: 0.5857\n",
      "Epoch 5483/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5972 - accuracy: 0.6618 - val_loss: 0.6489 - val_accuracy: 0.5851\n",
      "Epoch 5484/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5977 - accuracy: 0.6599 - val_loss: 0.6682 - val_accuracy: 0.5599\n",
      "Epoch 5485/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5977 - accuracy: 0.6613 - val_loss: 0.6362 - val_accuracy: 0.6023\n",
      "Epoch 5486/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5992 - accuracy: 0.6591 - val_loss: 0.6849 - val_accuracy: 0.5364\n",
      "Epoch 5487/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6004 - accuracy: 0.6593 - val_loss: 0.6290 - val_accuracy: 0.6160\n",
      "Epoch 5488/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6006 - accuracy: 0.6577 - val_loss: 0.6806 - val_accuracy: 0.5426\n",
      "Epoch 5489/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5991 - accuracy: 0.6615 - val_loss: 0.6437 - val_accuracy: 0.5943\n",
      "Epoch 5490/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5981 - accuracy: 0.6611 - val_loss: 0.6611 - val_accuracy: 0.5694\n",
      "Epoch 5491/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5980 - accuracy: 0.6601 - val_loss: 0.6543 - val_accuracy: 0.5773\n",
      "Epoch 5492/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5972 - accuracy: 0.6609 - val_loss: 0.6513 - val_accuracy: 0.5807\n",
      "Epoch 5493/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5978 - accuracy: 0.6618 - val_loss: 0.6677 - val_accuracy: 0.5607\n",
      "Epoch 5494/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5975 - accuracy: 0.6620 - val_loss: 0.6350 - val_accuracy: 0.6087\n",
      "Epoch 5495/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5990 - accuracy: 0.6588 - val_loss: 0.6831 - val_accuracy: 0.5367\n",
      "Epoch 5496/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5992 - accuracy: 0.6616 - val_loss: 0.6356 - val_accuracy: 0.6072\n",
      "Epoch 5497/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5999 - accuracy: 0.6585 - val_loss: 0.6832 - val_accuracy: 0.5409\n",
      "Epoch 5498/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6005 - accuracy: 0.6595 - val_loss: 0.6311 - val_accuracy: 0.6116\n",
      "Epoch 5499/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5995 - accuracy: 0.6584 - val_loss: 0.6742 - val_accuracy: 0.5502\n",
      "Epoch 5500/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5987 - accuracy: 0.6617 - val_loss: 0.6528 - val_accuracy: 0.5826\n",
      "Epoch 5501/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5972 - accuracy: 0.6616 - val_loss: 0.6478 - val_accuracy: 0.5886\n",
      "Epoch 5502/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5981 - accuracy: 0.6595 - val_loss: 0.6676 - val_accuracy: 0.5619\n",
      "Epoch 5503/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5975 - accuracy: 0.6617 - val_loss: 0.6386 - val_accuracy: 0.6028\n",
      "Epoch 5504/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5998 - accuracy: 0.6596 - val_loss: 0.6903 - val_accuracy: 0.5298\n",
      "Epoch 5505/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6013 - accuracy: 0.6587 - val_loss: 0.6229 - val_accuracy: 0.6248\n",
      "Epoch 5506/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6560 - val_loss: 0.6934 - val_accuracy: 0.5245\n",
      "Epoch 5507/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6019 - accuracy: 0.6592 - val_loss: 0.6383 - val_accuracy: 0.6018\n",
      "Epoch 5508/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6004 - accuracy: 0.6581 - val_loss: 0.6670 - val_accuracy: 0.5656\n",
      "Epoch 5509/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6001 - accuracy: 0.6584 - val_loss: 0.6536 - val_accuracy: 0.5824\n",
      "Epoch 5510/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5985 - accuracy: 0.6594 - val_loss: 0.6492 - val_accuracy: 0.5839\n",
      "Epoch 5511/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5997 - accuracy: 0.6604 - val_loss: 0.6795 - val_accuracy: 0.5429\n",
      "Epoch 5512/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5994 - accuracy: 0.6607 - val_loss: 0.6218 - val_accuracy: 0.6259\n",
      "Epoch 5513/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6027 - accuracy: 0.6564 - val_loss: 0.6998 - val_accuracy: 0.5197\n",
      "Epoch 5514/15000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jgalvan/Desktop/Xylella fastidiosa detection/Coding/Main_file/Xylella_detection.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m n_training_examples \u001b[39m=\u001b[39m X_train_balanced\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Fit data to model    \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m history \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mfit(X_train_balanced, Y_train_balanced, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m                          validation_data \u001b[39m=\u001b[39;49m (X_val, Y_val), \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                          batch_size \u001b[39m=\u001b[39;49m n_training_examples, epochs \u001b[39m=\u001b[39;49m num_epochs, verbose\u001b[39m=\u001b[39;49mverbosity)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Generate generalization metrics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m scores \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mevaluate(X_val, Y_val, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation model evaluation\n",
    "ground_acc = 0\n",
    "\n",
    "fold_no = 1\n",
    "for train, validate in kfold.split(X_train, Y_train):\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    classifier = model()\n",
    "    \n",
    "    # Oversample the training set\n",
    "    X_train_balanced, Y_train_balanced = adasyn.fit_resample(X_train[train], Y_train[train])\n",
    "    X_val, Y_val = X_train[validate], Y_train[validate]\n",
    "    n_training_examples = X_train_balanced.shape[0]\n",
    "\n",
    "    \n",
    "    # Fit data to model    \n",
    "    history = classifier.fit(X_train_balanced, Y_train_balanced, \n",
    "                             validation_data = (X_val, Y_val), \n",
    "                             batch_size = n_training_examples, epochs = num_epochs, verbose=verbosity)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = classifier.evaluate(X_val, Y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {classifier.metrics_names[0]} of {scores[0]}; {classifier.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    if scores[1]>ground_acc:\n",
    "        ground_acc = scores[1]\n",
    "        classifier.save('ann_classifier_best_new.h5')\n",
    "        #file_management.save_lzma(train, 'train_set.lzma', '')\n",
    "        file_management.save_lzma(validate, 'validate_set.lzma', '')\n",
    "        train_set = train\n",
    "        validate_set = validate\n",
    "        \n",
    "        train_acc2 = history.history['accuracy']\n",
    "        val_acc2 = history.history['val_accuracy']\n",
    "        train_loss2 = history.history['loss']\n",
    "        val_loss2 = history.history['val_loss']\n",
    "            \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b76b91d1",
   "metadata": {},
   "source": [
    "Average scores for all folds: (only indices, 15000 epochs)\n",
    "> Accuracy: 77.90514145578656 (+- 1.4814076341552638)\n",
    "> Loss: 0.7443450008119855 (+- 0.1207884071335813)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f9e4f65",
   "metadata": {},
   "source": [
    "Average scores for all folds: (only bands, 15000 epochs)\n",
    "> Accuracy: 76.207948582513 (+- 2.8430736484859094)\n",
    "> Loss: 0.6742679306438991 (+- 0.09772139789920833)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6db9f4eb",
   "metadata": {},
   "source": [
    "Average scores for all folds (5000 epochs):\n",
    "> Accuracy: 59.658717257635935 (+- 1.2219046765570636)\n",
    "> Loss: 0.6586811542510986 (+- 0.00763990732993515)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "994b512d",
   "metadata": {},
   "source": [
    "# Average scores for all folds:\n",
    "> Accuracy: 55.4264451776232 (+- 1.6458214760896448)\n",
    "> Loss: 0.6831462894167218 (+- 0.006606582555030469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e37c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:39:31.751589Z",
     "start_time": "2022-08-11T21:39:29.925756Z"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DRAW THE LEARNING CURVES FOR THE BEST K-FOLD\n",
    "# =============================================================================\n",
    "#classifier = model()\n",
    "# history = classifier.fit(X[train_set], Y[train_set], validation_data = (X[test_set], Y[test_set]), batch_size = number_examples, epochs = num_epochs, verbose=verbosity)\n",
    "# train_acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# train_loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "epochs = np.arange(1, num_epochs+1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1\n",
    "                               \n",
    "                               ,2, figsize=(7.5, 5), sharex=True)\n",
    "#Draw accuracy curve\n",
    "ax1.plot(epochs, train_acc2, 'r-', label='Training set')\n",
    "ax1.plot(epochs, val_acc2, 'b-', label='Cross-validation set')\n",
    "ax1.axhline(1- sum(Y_train[validate_set])/len(Y_train[validate_set]), label='Negatives ratio', color='k')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_xlabel('Epochs', fontsize=12)\n",
    "ax1.legend(loc='best', fontsize=12)\n",
    "#Draw cost curve\n",
    "ax2.plot(epochs, train_loss2, 'r-', label='Training set')\n",
    "ax2.plot(epochs, val_loss2, 'b-', label='Cross-validation set')\n",
    "ax2.set_xlabel('Epochs', fontsize=12)\n",
    "ax2.set_ylabel('Loss', fontsize=12)\n",
    "ax2.legend(loc='best', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'ann_learning_curves3.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b76f826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:40:11.708785Z",
     "start_time": "2022-08-11T22:40:11.181341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 2ms/step\n",
      "[[1081  324]\n",
      " [ 174  311]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFUSSION MATRIX FOR THE BEST CLASSIFIER OVER VALIDATION SET\n",
    "# =============================================================================\n",
    "# Load the best classifier\n",
    "best_model_path = 'Classification figures/num_epochs_25000_oversampling_True_dropout_True '\n",
    "best_model = keras.models.load_model(os.path.join(best_model_path, 'ann_classifier_best_new.h5'))\n",
    "\n",
    "#train_set = file_management.load_lzma('train_set.lzma')\n",
    "validate_set = file_management.load_lzma(os.path.join(best_model_path,'validate_set.lzma'))\n",
    "# We evaluate the best classifier on its fold\n",
    "y_pred = best_model.predict(X_train[validate_set])\n",
    "\n",
    "Y_pred = np.round(y_pred)\n",
    "cm=confusion_matrix(Y_train[validate_set],Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e66d55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:40:13.538022Z",
     "start_time": "2022-08-11T22:40:13.507560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.65%\n",
      "Recall: 64.12%\n",
      "Precision: 48.98%\n",
      "F1-score: 55.54%\n",
      "Proportion of positives: 25.66%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OBTAIN ACCURACY, RECALL, PRECISION, F1SCORE FOR BEST MODEL\n",
    "# =============================================================================\n",
    "# Evalute its accuracy over the last kfold\n",
    "accuracy = accuracy_score(Y_train[validate_set], Y_pred)\n",
    "recall = recall_score(Y_train[validate_set], Y_pred)\n",
    "precision = precision_score(Y_train[validate_set], Y_pred)\n",
    "f1score = f1_score(Y_train[validate_set], Y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))\n",
    "print(\"Proportion of positives: %.2f%%\" %(100*sum(Y_train[validate_set]/len(Y_train[validate_set]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "805756e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ROC and AUC\n",
    "# =============================================================================\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_train[validate_set], y_pred)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='ANN 1-1 (AUC = {:.2f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate (specificity)', fontsize=16)\n",
    "plt.ylabel('True positive rate (sensitivity)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'roc_curve_validation_ANN11.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1e256",
   "metadata": {},
   "source": [
    "## Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83685325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "[[416 117]\n",
      " [ 62 101]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFUSSION MATRIX FOR THE BEST CLASSIFIER OVER TEST SET\n",
    "# =============================================================================\n",
    "# Load the best classifier\n",
    "#best_model = keras.models.load_model('ann_classifier_best_new.h5')\n",
    "\n",
    "X_test = file_management.load_lzma('X_test.lzma')\n",
    "Y_test = file_management.load_lzma('Y_test.lzma')\n",
    "\n",
    "# We evaluate the best classifier on its fold\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "Y_test_pred = np.round(y_test_pred)\n",
    "cm=confusion_matrix(Y_test,Y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f38e363",
   "metadata": {},
   "source": [
    "[[390 143]\n",
    " [ 86  77]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "baa7fd43",
   "metadata": {},
   "source": [
    "[[330 203]\n",
    " [ 58 105]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ae3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.28%\n",
      "Recall: 61.96%\n",
      "Precision: 46.33%\n",
      "F1-score: 53.02%\n",
      "Proportion of positives: 23.42%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OBTAIN ACCURACY, RECALL, PRECISION, F1SCORE FOR BEST MODEL\n",
    "# =============================================================================\n",
    "# Evalute its metrics\n",
    "accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "recall = recall_score(Y_test, Y_test_pred)\n",
    "precision = precision_score(Y_test, Y_test_pred)\n",
    "f1score = f1_score(Y_test, Y_test_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))\n",
    "print(\"Proportion of positives: %.2f%%\" %(100*sum(Y_test)/len(Y_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1fe8975",
   "metadata": {},
   "source": [
    "Accuracy: 67.10%\n",
    "Recall: 47.24%\n",
    "Precision: 35.00%\n",
    "F1-score: 40.21%\n",
    "Proportion of positives: 23.42%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67dd2a40",
   "metadata": {},
   "source": [
    "Accuracy: 62.50%\n",
    "Recall: 64.42%\n",
    "Precision: 34.09%\n",
    "F1-score: 44.59%\n",
    "Proportion of positives: 23.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b70e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:02.150675Z",
     "start_time": "2022-08-11T22:41:01.613756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ROC and AUC\n",
    "# =============================================================================\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_test, y_test_pred)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='ANN 1-1 (AUC = {:.2f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate (specificity)', fontsize=16)\n",
    "plt.ylabel('True positive rate (sensitivity)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'roc_curve_test_ANN11.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4eb6883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:21.452836Z",
     "start_time": "2022-08-11T22:41:13.109341Z"
    }
   },
   "source": [
    "X_test = reducer.transform(X[test_set])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31ff2829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:21.695540Z",
     "start_time": "2022-08-11T22:41:21.456059Z"
    }
   },
   "source": [
    "chart(X_test, Y[test_set])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1ec5a33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:21.928113Z",
     "start_time": "2022-08-11T22:41:21.698784Z"
    }
   },
   "source": [
    "chart(X_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327243b",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f34294b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T16:29:59.252Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# SVM\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf', gamma=0.0193, C = 100)\n",
    "svclassifier.fit(X[train_set], Y[train_set])\n",
    "\n",
    "y_pred = np.round(svclassifier.predict(X[test_set]))\n",
    "\n",
    "print(confusion_matrix(Y[test_set],y_pred))\n",
    "#### OJO CON COMO DEFINE LA MATRIZ DE CONFUSION PYTHON ####\n",
    "accuracy = accuracy_score(Y[test_set], y_pred)\n",
    "recall = recall_score(Y[test_set], y_pred)\n",
    "precision = precision_score(Y[test_set], y_pred)\n",
    "f1score = f1_score(Y[test_set], y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1d8684d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T16:29:59.551Z"
    }
   },
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 7\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=0) #fix the divition\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "ground_acc = 0\n",
    "\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    svclassifier = SVC(kernel='rbf', gamma=0.0193, C=100, probability=True)\n",
    "    svclassifier.fit(X[train], Y[train])\n",
    "    y_pred = svclassifier.predict_proba(X[test])[:,1]\n",
    "    #y_pred = svclassifier.predict(X[test])\n",
    "    # Generate generalization metrics\n",
    "    acc = accuracy_score(Y[test], np.round(y_pred))\n",
    "    print(f'Score for fold {fold_no}: Accuracy of {acc}')\n",
    "    acc_per_fold.append(acc)\n",
    "    loss_per_fold.append(log_loss(Y[test], y_pred))\n",
    "    if acc>ground_acc:\n",
    "        ground_acc = acc\n",
    "        test_set2 = test\n",
    "        y_pred2 = y_pred\n",
    "        \n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "128904f7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T16:29:59.865Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# ROC and AUC\n",
    "# =============================================================================\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y[test_set2], y_pred2)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='SVM (AUC = {:.2f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate (specificity)', fontsize=16)\n",
    "plt.ylabel('True positive rate (sensitivity)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'roc_curve_SVM.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeffe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xylella_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
